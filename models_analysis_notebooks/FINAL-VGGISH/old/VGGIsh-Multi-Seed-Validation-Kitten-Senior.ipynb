{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17da2043-9a5b-40fe-b3cb-f755b9a98deb",
   "metadata": {},
   "source": [
    "# VGGIsh Multi Seed Validation\n",
    "#### 5 Random (but reproducible) seeds are selected for 5 different runs of train/test\n",
    "#### Models have been optimised and verified on validation sets thoroughly, running a final train/test evaluation here\n",
    "#### The setup:\n",
    "\n",
    "- 4 fold StratifiedGroupKFold for stratification and ensuring each cat_id group only appears in one set at a time\n",
    "- Final scores averaged over the 4 folds\n",
    "- For each seed run we will explore the cat_id predictions through majority voting\n",
    "- For each run we will explore the potential impact of gender\n",
    "\n",
    "The dataset is highly unbalanced, resources for an unbiased estimate have been implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ac1e09ae-387c-4347-b6f5-8d09dd1bf3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam, Adamax, SGD, RMSprop, AdamW\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from focal_loss import SparseCategoricalFocalLoss\n",
    "import shap\n",
    "from keras.regularizers import l1, l2, L1L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d005cfd2-3eda-44c4-bbb5-af343e979bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seeds: [7270  860 5390 5191 5734]\n"
     ]
    }
   ],
   "source": [
    "# Set an initial seed for reproducibility\n",
    "np.random.seed(42)  \n",
    "\n",
    "# Generate a list of 5 random seeds\n",
    "random_seeds = np.random.randint(0, 10000, size=5)\n",
    "print(\"Random Seeds:\", random_seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae122a-9f9c-47a3-8835-2d46d2f8e2f9",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d5097e68-5153-440c-9294-dfa9e6061652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_initial_group_split(groups_train, groups_test):\n",
    "    \"\"\"\n",
    "    Check if any group is present in both the train and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - groups_train: Array of group identifiers for the train set\n",
    "    - groups_test: Array of group identifiers for the test set\n",
    "\n",
    "    Returns:\n",
    "    - Prints out any groups found in both sets and the count of such groups\n",
    "    \"\"\"\n",
    "    train_groups = set(groups_train)\n",
    "    test_groups = set(groups_test)\n",
    "    common_groups = train_groups.intersection(test_groups)\n",
    "\n",
    "    if common_groups:\n",
    "        print(f\"Warning: Found {len(common_groups)} common groups in both train/validation and test sets: {common_groups}\")\n",
    "    else:\n",
    "        print(\"No common groups found between train and test sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "88dfe2de-bb1e-4d49-9260-e056c39627bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform the swaps based on cat_id, ensuring swaps within the same age_group\n",
    "def swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids):\n",
    "    for cat_id in specific_cat_ids:\n",
    "        # Check if the specific cat_id is not in the training set\n",
    "        if cat_id not in dataframe.iloc[train_val_idx]['cat_id'].values:\n",
    "            # Get the age_group of this cat_id\n",
    "            age_group = dataframe[dataframe['cat_id'] == cat_id]['age_group'].iloc[0]\n",
    "                \n",
    "            # Find a different cat_id within the same age_group in the train set that is not in the test set\n",
    "            other_cat_ids_in_age_group = dataframe[(dataframe['age_group'] == age_group) & \n",
    "                                                   (dataframe['cat_id'] != cat_id) &\n",
    "                                                   (~dataframe['cat_id'].isin(dataframe.iloc[test_idx]['cat_id']))]['cat_id'].unique()\n",
    "            \n",
    "            # Choose one other cat_id for swapping\n",
    "            if len(other_cat_ids_in_age_group) > 0:\n",
    "                other_cat_id = np.random.choice(other_cat_ids_in_age_group)\n",
    "\n",
    "                # Find all instances of the other_cat_id in the train set\n",
    "                other_cat_id_train_val_indices = train_val_idx[dataframe.iloc[train_val_idx]['cat_id'] == other_cat_id]\n",
    "                \n",
    "                # Find all instances of the specific cat_id in the test set\n",
    "                cat_id_test_indices = test_idx[dataframe.iloc[test_idx]['cat_id'] == cat_id]\n",
    "                \n",
    "                # Swap the indices\n",
    "                train_val_idx = np.setdiff1d(train_val_idx, other_cat_id_train_val_indices, assume_unique=True)\n",
    "                test_idx = np.setdiff1d(test_idx, cat_id_test_indices, assume_unique=True)\n",
    "\n",
    "                train_val_idx = np.concatenate((train_val_idx, cat_id_test_indices))\n",
    "                test_idx = np.concatenate((test_idx, other_cat_id_train_val_indices))\n",
    "            else:\n",
    "                print(f\"No alternative cat_id found in the same age_group as {cat_id} for swapping.\")\n",
    "                \n",
    "    return train_val_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2e6c2d87-cfab-493e-bca8-b3b8976a2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify differences in groups\n",
    "def find_group_differences(original, new):\n",
    "    # Convert numpy arrays to sets for easy difference computation\n",
    "    original_set = set(original)\n",
    "    new_set = set(new)\n",
    "    # Find differences\n",
    "    moved_to_new = new_set - original_set\n",
    "    moved_to_original = original_set - new_set\n",
    "    return moved_to_new, moved_to_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6164b1c3-75dd-4549-aafd-cb6106297941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom logger function for local logs & stored in a .txt\n",
    "def logger(message, file=None):\n",
    "    print(message)\n",
    "    if file is not None:\n",
    "        with open(file, \"a\") as log_file:\n",
    "            log_file.write(message + \"\\n\")\n",
    "\n",
    "log_file_path = \"multi-seed-val-D13.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "899fb535-0e25-4c7b-b6a5-13231e26c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\", palette=\"deep\")\n",
    "\n",
    "# Define a custom color palette\n",
    "colors = [\"#6aabd1\", \"#b6e2d3\", \"#dac292\"] \n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "\n",
    "# Function to create bar plots with enhanced style\n",
    "def styled_barplot(data, x, y, title, xlabel, ylabel):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    bar_plot = sns.barplot(x=x, y=y, data=data, errorbar=None, width=0.5)  \n",
    "    plt.title(title, fontsize=16, fontweight='bold', color=\"#333333\")\n",
    "    plt.xlabel(xlabel, fontsize=14, fontweight='bold', color=\"#333333\")\n",
    "    plt.ylabel(ylabel, fontsize=14, fontweight='bold', color=\"#333333\")\n",
    "    plt.xticks(fontsize=12, color=\"#333333\")\n",
    "    plt.yticks(fontsize=12, color=\"#333333\")\n",
    "    plt.ylim(0, 100) \n",
    "\n",
    "    # Adding value labels on top of each bar\n",
    "    for p in bar_plot.patches:\n",
    "        height = p.get_height()\n",
    "        # Annotate the height value on the bar\n",
    "        bar_plot.annotate(f'{height:.1f}', \n",
    "                          (p.get_x() + p.get_width() / 2., height), \n",
    "                          ha='center', va='center', \n",
    "                          xytext=(0, -10), \n",
    "                          textcoords='offset points', fontsize=12, color=\"#333333\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936a24a-13bd-4bc3-be13-0b210a09b5da",
   "metadata": {},
   "source": [
    "# RANDOM SEED 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70136a37-0507-4c2e-8307-c2dd905432e8",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "14bb802b-f4bd-4464-a5fd-1977438428b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senior    178\n",
      "kitten    171\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(int(random_seeds[0])) \n",
    "np.random.seed(int(random_seeds[0]))\n",
    "tf.random.set_seed(int(random_seeds[0]))\n",
    "\n",
    "# Load datasets\n",
    "dataframe = pd.read_csv('/Users/astrid/PycharmProjects/audioset-thesis-work/audioset/vggish/embeddings/8april_looped_embeddings.csv')\n",
    "\n",
    "dataframe.drop('mean_freq', axis=1, inplace=True)\n",
    "\n",
    "def assign_age_group(age, age_groups):\n",
    "    for group_name, age_range in age_groups.items():\n",
    "        if age_range[0] <= age < age_range[1]:\n",
    "            return group_name\n",
    "    return 'Unknown'  # For any age that doesn't fit the defined groups\n",
    "\n",
    "# Define age groups\n",
    "age_groups = {\n",
    "    'kitten': (0, 0.5),\n",
    "    'adult': (0.5, 12),\n",
    "    'senior': (12, 20)\n",
    "}\n",
    "\n",
    "# Create a new column for the age group\n",
    "dataframe['age_group'] = dataframe['target'].apply(assign_age_group, age_groups=age_groups)\n",
    "\n",
    "# Drop Adult\n",
    "dataframe.drop(dataframe[dataframe['age_group'] == 'adult'].index, inplace=True)\n",
    "\n",
    "print(dataframe['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6ce97c28-4210-4150-a60b-acdbf0e7716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = dataframe.iloc[:, :-4].values  # all columns except the last four\n",
    "\n",
    "# Encode the 'age_group' column as integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y = label_encoder.fit_transform(dataframe['age_group'].values)\n",
    "\n",
    "# Use the encoded labels for splitting and one-hot encoding\n",
    "y = encoded_y  \n",
    "\n",
    "# Convert 'cat_id' column to numpy array to be used as groups array for GroupKFold\n",
    "groups = dataframe['cat_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c26f17c3-4d21-4537-a090-9ca00f2be51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f91a9c3-3474-4e83-8a5b-c5eb4a9a9223",
   "metadata": {},
   "source": [
    "## Run Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f4605c0b-f99d-48c3-8c2a-d87dd22c8946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_fold 1\n",
      "Train Set Group Distribution:\n",
      "047A    28\n",
      "057A    27\n",
      "055A    20\n",
      "097A    16\n",
      "059A    14\n",
      "111A    13\n",
      "116A    12\n",
      "051A    12\n",
      "040A    10\n",
      "014B    10\n",
      "045A     9\n",
      "094A     8\n",
      "117A     7\n",
      "050A     7\n",
      "109A     6\n",
      "108A     6\n",
      "044A     5\n",
      "104A     4\n",
      "058A     3\n",
      "056A     3\n",
      "054A     2\n",
      "093A     2\n",
      "011A     2\n",
      "061A     2\n",
      "043A     1\n",
      "049A     1\n",
      "041A     1\n",
      "048A     1\n",
      "115A     1\n",
      "110A     1\n",
      "090A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "046A    63\n",
      "106A    14\n",
      "042A    14\n",
      "016A    10\n",
      "051B     9\n",
      "113A     3\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    147\n",
      "F     64\n",
      "M     25\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    77\n",
      "M    33\n",
      "F     3\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 014B, 111A, 040A, 047A, 109A, 050A, 043...\n",
      "senior    [093A, 097A, 057A, 104A, 055A, 059A, 116A, 054...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten                [046A, 042A]\n",
      "senior    [106A, 113A, 051B, 016A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 14, 'senior': 18}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 2, 'senior': 4}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '014B' '024A' '040A' '041A' '043A' '044A' '045A' '047A' '048A'\n",
      " '049A' '050A' '051A' '054A' '055A' '056A' '057A' '058A' '059A' '061A'\n",
      " '090A' '093A' '094A' '097A' '104A' '108A' '109A' '110A' '111A' '115A'\n",
      " '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['016A' '042A' '046A' '051B' '106A' '113A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "senior    142\n",
      "kitten     94\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "kitten    77\n",
      "senior    36\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "senior    142\n",
      "kitten     94\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "kitten    77\n",
      "senior    36\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({1: 142, 0: 94})\n",
      "Epoch 1/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.7668 - accuracy: 0.5678\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3885 - accuracy: 0.8178\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.2534 - accuracy: 0.8729\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.1714 - accuracy: 0.9153\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.1117 - accuracy: 0.9068\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.0718 - accuracy: 0.9322\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.0017 - accuracy: 0.9280\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.0273 - accuracy: 0.9110\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.9436 - accuracy: 0.9449\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.9194 - accuracy: 0.9449\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.8952 - accuracy: 0.9449\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.8589 - accuracy: 0.9619\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.8587 - accuracy: 0.9449\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.8059 - accuracy: 0.9576\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.7853 - accuracy: 0.9619\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.7725 - accuracy: 0.9619\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.7413 - accuracy: 0.9661\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.7109 - accuracy: 0.9831\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.7112 - accuracy: 0.9703\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.7118 - accuracy: 0.9576\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.6730 - accuracy: 0.9831\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.6611 - accuracy: 0.9703\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.6621 - accuracy: 0.9619\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.6199 - accuracy: 0.9788\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.6020 - accuracy: 0.9915\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.6168 - accuracy: 0.9703\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.6015 - accuracy: 0.9703\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.6003 - accuracy: 0.9703\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.5571 - accuracy: 0.9831\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.5702 - accuracy: 0.9746\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.5757 - accuracy: 0.9576\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.5216 - accuracy: 0.9831\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.5394 - accuracy: 0.9746\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.5128 - accuracy: 0.9831\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.5445 - accuracy: 0.9576\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4748 - accuracy: 0.9915\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4829 - accuracy: 0.9746\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.4671 - accuracy: 0.9873\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4621 - accuracy: 0.9915\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.4433 - accuracy: 0.9915\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.4305 - accuracy: 0.9915\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.4454 - accuracy: 0.9703\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.4350 - accuracy: 0.9788\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4428 - accuracy: 0.9661\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4145 - accuracy: 0.9831\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4663 - accuracy: 0.9661\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3839 - accuracy: 1.0000\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3940 - accuracy: 0.9788\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3792 - accuracy: 0.9958\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3940 - accuracy: 0.9703\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3602 - accuracy: 0.9831\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3517 - accuracy: 0.9958\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3468 - accuracy: 0.9873\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.3348 - accuracy: 0.9958\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.3363 - accuracy: 0.9873\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.3247 - accuracy: 1.0000\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3433 - accuracy: 0.9831\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3129 - accuracy: 0.9958\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3232 - accuracy: 0.9873\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3127 - accuracy: 0.9873\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2993 - accuracy: 0.9958\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3027 - accuracy: 0.9915\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2934 - accuracy: 0.9915\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.2930 - accuracy: 0.9873\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2731 - accuracy: 0.9958\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2739 - accuracy: 0.9915\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2571 - accuracy: 1.0000\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2642 - accuracy: 0.9873\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2584 - accuracy: 0.9958\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2435 - accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2429 - accuracy: 0.9958\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2508 - accuracy: 0.9873\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2345 - accuracy: 0.9958\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2459 - accuracy: 0.9873\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2476 - accuracy: 0.9915\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2159 - accuracy: 1.0000\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2231 - accuracy: 0.9958\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2059 - accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2070 - accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2043 - accuracy: 1.0000\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1905 - accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1957 - accuracy: 0.9915\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2056 - accuracy: 0.9831\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.2045 - accuracy: 0.9831\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1799 - accuracy: 0.9958\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1992 - accuracy: 0.9831\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1820 - accuracy: 0.9915\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1645 - accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1835 - accuracy: 0.9958\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1594 - accuracy: 0.9958\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1590 - accuracy: 0.9958\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1595 - accuracy: 0.9958\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1534 - accuracy: 0.9958\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1438 - accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1582 - accuracy: 0.9958\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1304 - accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1661 - accuracy: 0.9873\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1340 - accuracy: 0.9915\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1245 - accuracy: 0.9915\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1412 - accuracy: 0.9915\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1643 - accuracy: 0.9788\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1120 - accuracy: 0.9958\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1218 - accuracy: 0.9873\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1148 - accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1037 - accuracy: 0.9958\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1130 - accuracy: 0.9915\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1026 - accuracy: 0.9958\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0974 - accuracy: 0.9958\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.0911 - accuracy: 0.9958\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0849 - accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0885 - accuracy: 0.9958\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0755 - accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1088 - accuracy: 0.9788\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0800 - accuracy: 0.9958\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0650 - accuracy: 0.9958\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0685 - accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0545 - accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0676 - accuracy: 0.9915\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0659 - accuracy: 0.9915\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0615 - accuracy: 0.9958\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0581 - accuracy: 0.9873\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0526 - accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0597 - accuracy: 0.9915\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0569 - accuracy: 0.9915\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0332 - accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0394 - accuracy: 0.9958\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0502 - accuracy: 0.9831\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0390 - accuracy: 0.9873\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0449 - accuracy: 0.9873\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0250 - accuracy: 0.9958\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0153 - accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0134 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0162 - accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0151 - accuracy: 0.9958\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0161 - accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0087 - accuracy: 0.9958\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9952 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.0015 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9963 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9924 - accuracy: 0.9958\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9896 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0070 - accuracy: 0.9915\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9950 - accuracy: 0.9958\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9844 - accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9838 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9776 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9755 - accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9671 - accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9673 - accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9645 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9616 - accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9634 - accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9604 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9477 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9596 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9530 - accuracy: 0.9958\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9487 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9425 - accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9491 - accuracy: 0.9915\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9593 - accuracy: 0.9873\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9417 - accuracy: 0.9958\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9481 - accuracy: 0.9958\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9382 - accuracy: 0.9915\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9483 - accuracy: 0.9915\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9307 - accuracy: 0.9958\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9233 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9172 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9253 - accuracy: 0.9915\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9185 - accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9150 - accuracy: 0.9958\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9151 - accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9065 - accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9252 - accuracy: 0.9873\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9052 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9153 - accuracy: 0.9958\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8932 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9113 - accuracy: 0.9958\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8944 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8923 - accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8968 - accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8961 - accuracy: 0.9958\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8846 - accuracy: 0.9958\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9295 - accuracy: 0.9788\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8805 - accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8839 - accuracy: 0.9958\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8804 - accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8919 - accuracy: 0.9915\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8720 - accuracy: 0.9958\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8645 - accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8790 - accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8703 - accuracy: 0.9958\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8645 - accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8751 - accuracy: 0.9915\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8595 - accuracy: 0.9958\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8614 - accuracy: 0.9958\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8584 - accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8515 - accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8550 - accuracy: 0.9958\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8464 - accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8446 - accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8448 - accuracy: 0.9958\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8571 - accuracy: 0.9873\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8417 - accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8440 - accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8404 - accuracy: 0.9958\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8445 - accuracy: 0.9958\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8301 - accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8689 - accuracy: 0.9831\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8249 - accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8472 - accuracy: 0.9873\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8337 - accuracy: 0.9958\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8221 - accuracy: 0.9958\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8282 - accuracy: 0.9958\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8227 - accuracy: 0.9958\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8184 - accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8239 - accuracy: 0.9958\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8176 - accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8193 - accuracy: 0.9915\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8181 - accuracy: 0.9958\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8034 - accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8149 - accuracy: 0.9873\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8008 - accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7971 - accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8048 - accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7983 - accuracy: 0.9958\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7962 - accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8203 - accuracy: 0.9831\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8052 - accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7879 - accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7976 - accuracy: 0.9873\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7947 - accuracy: 0.9958\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7852 - accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7820 - accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7865 - accuracy: 0.9958\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7893 - accuracy: 0.9958\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7784 - accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7771 - accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7729 - accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7724 - accuracy: 0.9958\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7685 - accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7759 - accuracy: 0.9915\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7625 - accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7622 - accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7593 - accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7662 - accuracy: 0.9958\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7551 - accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7569 - accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7542 - accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7678 - accuracy: 0.9958\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7531 - accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7505 - accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7553 - accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7442 - accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7415 - accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7427 - accuracy: 0.9958\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7424 - accuracy: 0.9958\n",
      "Epoch 257/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7401 - accuracy: 0.9958\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7499 - accuracy: 0.9915\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7432 - accuracy: 0.9958\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7338 - accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7495 - accuracy: 0.9915\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.9958\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7473 - accuracy: 0.9915\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.9958\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7300 - accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.9958\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7332 - accuracy: 0.9958\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7337 - accuracy: 0.9915\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.9958\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7221 - accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.9958\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7220 - accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7064 - accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7045 - accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7034 - accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.9958\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.9958\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6992 - accuracy: 0.9958\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.9958\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.9958\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 1.0000\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9475 - accuracy: 0.8761\n",
      "4/4 [==============================] - 0s 878us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 1.00 (6/6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before appending - Cat IDs: 0, Predictions: 0, Actuals: 0, Gender: 0\n",
      "After appending - Cat IDs: 113, Predictions: 113, Actuals: 113, Gender: 113\n",
      "Final Test Results - Loss: 0.9475265741348267, Accuracy: 0.8761062026023865, Precision: 0.854639844256976, Recall: 0.8943001443001443, F1 Score: 0.8660230352303524\n",
      "Confusion Matrix:\n",
      " [[65 12]\n",
      " [ 2 34]]\n",
      "outer_fold 2\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "055A    20\n",
      "106A    14\n",
      "042A    14\n",
      "116A    12\n",
      "016A    10\n",
      "040A    10\n",
      "051B     9\n",
      "045A     9\n",
      "050A     7\n",
      "117A     7\n",
      "108A     6\n",
      "044A     5\n",
      "058A     3\n",
      "056A     3\n",
      "113A     3\n",
      "093A     2\n",
      "061A     2\n",
      "011A     2\n",
      "090A     1\n",
      "110A     1\n",
      "115A     1\n",
      "043A     1\n",
      "048A     1\n",
      "041A     1\n",
      "049A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "047A    28\n",
      "057A    27\n",
      "097A    16\n",
      "059A    14\n",
      "111A    13\n",
      "051A    12\n",
      "014B    10\n",
      "094A     8\n",
      "109A     6\n",
      "104A     4\n",
      "054A     2\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    122\n",
      "F     51\n",
      "M     36\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    102\n",
      "M     22\n",
      "F     16\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 040A, 046A, 042A, 050A, 043A, 049A, 041...\n",
      "senior    [093A, 106A, 055A, 113A, 116A, 051B, 117A, 056...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten                      [014B, 111A, 047A, 109A]\n",
      "senior    [097A, 057A, 104A, 059A, 054A, 051A, 094A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 12, 'senior': 15}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 4, 'senior': 7}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '016A' '024A' '040A' '041A' '042A' '043A' '044A' '045A' '046A'\n",
      " '048A' '049A' '050A' '051B' '055A' '056A' '058A' '061A' '090A' '093A'\n",
      " '106A' '108A' '110A' '113A' '115A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['014B' '047A' '051A' '054A' '057A' '059A' '094A' '097A' '104A' '109A'\n",
      " '111A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "kitten    114\n",
      "senior     95\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "senior    83\n",
      "kitten    57\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "kitten    114\n",
      "senior     95\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "senior    83\n",
      "kitten    57\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 114, 1: 95})\n",
      "Epoch 1/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8257 - accuracy: 0.6124\n",
      "Epoch 2/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4131 - accuracy: 0.7751\n",
      "Epoch 3/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3287 - accuracy: 0.8182\n",
      "Epoch 4/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2380 - accuracy: 0.8660\n",
      "Epoch 5/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1631 - accuracy: 0.8612\n",
      "Epoch 6/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1452 - accuracy: 0.8852\n",
      "Epoch 7/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0516 - accuracy: 0.9139\n",
      "Epoch 8/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0970 - accuracy: 0.8900\n",
      "Epoch 9/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0106 - accuracy: 0.9091\n",
      "Epoch 10/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9603 - accuracy: 0.9139\n",
      "Epoch 11/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9179 - accuracy: 0.9426\n",
      "Epoch 12/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8832 - accuracy: 0.9330\n",
      "Epoch 13/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8518 - accuracy: 0.9378\n",
      "Epoch 14/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.8411 - accuracy: 0.9474\n",
      "Epoch 15/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7963 - accuracy: 0.9474\n",
      "Epoch 16/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7766 - accuracy: 0.9569\n",
      "Epoch 17/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7418 - accuracy: 0.9569\n",
      "Epoch 18/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7473 - accuracy: 0.9617\n",
      "Epoch 19/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6984 - accuracy: 0.9713\n",
      "Epoch 20/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6731 - accuracy: 0.9713\n",
      "Epoch 21/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6732 - accuracy: 0.9617\n",
      "Epoch 22/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6440 - accuracy: 0.9665\n",
      "Epoch 23/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6567 - accuracy: 0.9426\n",
      "Epoch 24/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6053 - accuracy: 0.9713\n",
      "Epoch 25/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6135 - accuracy: 0.9569\n",
      "Epoch 26/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5722 - accuracy: 0.9713\n",
      "Epoch 27/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5538 - accuracy: 0.9856\n",
      "Epoch 28/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5744 - accuracy: 0.9569\n",
      "Epoch 29/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5302 - accuracy: 0.9761\n",
      "Epoch 30/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5372 - accuracy: 0.9665\n",
      "Epoch 31/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5422 - accuracy: 0.9569\n",
      "Epoch 32/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5103 - accuracy: 0.9761\n",
      "Epoch 33/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4884 - accuracy: 0.9761\n",
      "Epoch 34/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4779 - accuracy: 0.9665\n",
      "Epoch 35/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4781 - accuracy: 0.9809\n",
      "Epoch 36/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4641 - accuracy: 0.9856\n",
      "Epoch 37/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4451 - accuracy: 0.9856\n",
      "Epoch 38/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4368 - accuracy: 0.9856\n",
      "Epoch 39/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4240 - accuracy: 0.9856\n",
      "Epoch 40/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4080 - accuracy: 0.9952\n",
      "Epoch 41/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4050 - accuracy: 0.9904\n",
      "Epoch 42/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3900 - accuracy: 0.9904\n",
      "Epoch 43/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3802 - accuracy: 0.9856\n",
      "Epoch 44/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3803 - accuracy: 0.9904\n",
      "Epoch 45/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3802 - accuracy: 0.9856\n",
      "Epoch 46/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3723 - accuracy: 0.9904\n",
      "Epoch 47/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3505 - accuracy: 1.0000\n",
      "Epoch 48/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3368 - accuracy: 0.9952\n",
      "Epoch 49/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3364 - accuracy: 1.0000\n",
      "Epoch 50/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3193 - accuracy: 1.0000\n",
      "Epoch 51/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3351 - accuracy: 0.9809\n",
      "Epoch 52/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3229 - accuracy: 0.9904\n",
      "Epoch 53/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3053 - accuracy: 0.9952\n",
      "Epoch 54/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3052 - accuracy: 0.9952\n",
      "Epoch 55/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3158 - accuracy: 0.9809\n",
      "Epoch 56/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2990 - accuracy: 0.9952\n",
      "Epoch 57/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2903 - accuracy: 0.9856\n",
      "Epoch 58/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2792 - accuracy: 1.0000\n",
      "Epoch 59/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2757 - accuracy: 0.9952\n",
      "Epoch 60/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2821 - accuracy: 0.9904\n",
      "Epoch 61/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2733 - accuracy: 0.9856\n",
      "Epoch 62/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2500 - accuracy: 0.9952\n",
      "Epoch 63/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2545 - accuracy: 0.9904\n",
      "Epoch 64/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2466 - accuracy: 0.9856\n",
      "Epoch 65/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2426 - accuracy: 1.0000\n",
      "Epoch 66/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2324 - accuracy: 0.9952\n",
      "Epoch 67/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2203 - accuracy: 1.0000\n",
      "Epoch 68/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2196 - accuracy: 0.9952\n",
      "Epoch 69/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2157 - accuracy: 0.9952\n",
      "Epoch 70/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2165 - accuracy: 0.9952\n",
      "Epoch 71/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2136 - accuracy: 0.9952\n",
      "Epoch 72/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2076 - accuracy: 0.9952\n",
      "Epoch 73/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2203 - accuracy: 0.9809\n",
      "Epoch 74/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2202 - accuracy: 0.9856\n",
      "Epoch 75/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1962 - accuracy: 0.9904\n",
      "Epoch 76/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1873 - accuracy: 0.9952\n",
      "Epoch 77/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1993 - accuracy: 0.9904\n",
      "Epoch 78/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1844 - accuracy: 0.9952\n",
      "Epoch 79/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1752 - accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1772 - accuracy: 0.9904\n",
      "Epoch 81/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1693 - accuracy: 0.9904\n",
      "Epoch 82/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1582 - accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1551 - accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1611 - accuracy: 0.9904\n",
      "Epoch 85/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1500 - accuracy: 0.9952\n",
      "Epoch 86/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1550 - accuracy: 0.9952\n",
      "Epoch 87/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1339 - accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1373 - accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1492 - accuracy: 0.9904\n",
      "Epoch 90/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1280 - accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1243 - accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1181 - accuracy: 0.9952\n",
      "Epoch 93/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1479 - accuracy: 0.9856\n",
      "Epoch 94/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1214 - accuracy: 0.9904\n",
      "Epoch 95/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1139 - accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1126 - accuracy: 0.9952\n",
      "Epoch 97/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1000 - accuracy: 1.0000\n",
      "Epoch 98/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1212 - accuracy: 0.9761\n",
      "Epoch 99/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1144 - accuracy: 0.9856\n",
      "Epoch 100/300\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.0898 - accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0845 - accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0854 - accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0775 - accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0781 - accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0729 - accuracy: 0.9952\n",
      "Epoch 106/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0669 - accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0715 - accuracy: 0.9904\n",
      "Epoch 108/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0618 - accuracy: 0.9952\n",
      "Epoch 109/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0581 - accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0667 - accuracy: 0.9952\n",
      "Epoch 111/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0610 - accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0456 - accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0781 - accuracy: 0.9904\n",
      "Epoch 114/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0424 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0465 - accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0460 - accuracy: 0.9952\n",
      "Epoch 117/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0450 - accuracy: 0.9904\n",
      "Epoch 118/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0307 - accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0450 - accuracy: 0.9952\n",
      "Epoch 120/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0334 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0217 - accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0284 - accuracy: 0.9904\n",
      "Epoch 123/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0182 - accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0136 - accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0128 - accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0116 - accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9986 - accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0004 - accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0105 - accuracy: 0.9952\n",
      "Epoch 130/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0001 - accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9947 - accuracy: 0.9952\n",
      "Epoch 132/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9967 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0126 - accuracy: 0.9952\n",
      "Epoch 134/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9842 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9973 - accuracy: 0.9904\n",
      "Epoch 136/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9794 - accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9802 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9806 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9824 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9689 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9776 - accuracy: 0.9952\n",
      "Epoch 142/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9687 - accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9620 - accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9835 - accuracy: 0.9904\n",
      "Epoch 145/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9580 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9705 - accuracy: 0.9952\n",
      "Epoch 147/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9757 - accuracy: 0.9904\n",
      "Epoch 148/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9677 - accuracy: 0.9904\n",
      "Epoch 149/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9543 - accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9586 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9457 - accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9482 - accuracy: 0.9952\n",
      "Epoch 153/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9359 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9396 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9376 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9335 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9350 - accuracy: 0.9952\n",
      "Epoch 158/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9358 - accuracy: 0.9952\n",
      "Epoch 159/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9379 - accuracy: 0.9904\n",
      "Epoch 160/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9354 - accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9355 - accuracy: 0.9952\n",
      "Epoch 162/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9256 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9231 - accuracy: 0.9952\n",
      "Epoch 164/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9215 - accuracy: 0.9952\n",
      "Epoch 165/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9268 - accuracy: 0.9904\n",
      "Epoch 166/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9131 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9124 - accuracy: 0.9952\n",
      "Epoch 168/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9123 - accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9160 - accuracy: 0.9952\n",
      "Epoch 170/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9067 - accuracy: 0.9952\n",
      "Epoch 171/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9044 - accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9024 - accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9046 - accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8921 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8979 - accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8985 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9023 - accuracy: 0.9952\n",
      "Epoch 178/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8946 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8833 - accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8813 - accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9027 - accuracy: 0.9904\n",
      "Epoch 182/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8942 - accuracy: 0.9952\n",
      "Epoch 183/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8757 - accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8775 - accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8721 - accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8701 - accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8781 - accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8666 - accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8814 - accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8632 - accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8594 - accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8637 - accuracy: 0.9952\n",
      "Epoch 193/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8660 - accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8539 - accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8552 - accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8461 - accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8508 - accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8453 - accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8437 - accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8442 - accuracy: 0.9952\n",
      "Epoch 201/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8386 - accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8415 - accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8380 - accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8331 - accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8332 - accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8273 - accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8266 - accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8284 - accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8242 - accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8238 - accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8212 - accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8147 - accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8234 - accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8114 - accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8236 - accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8112 - accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8139 - accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8052 - accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8062 - accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7985 - accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8003 - accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7937 - accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7921 - accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7918 - accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7932 - accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7870 - accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7884 - accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7825 - accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7814 - accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7784 - accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7817 - accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7744 - accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7741 - accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7733 - accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7728 - accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7677 - accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7640 - accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7614 - accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7626 - accuracy: 1.0000\n",
      "Epoch 240/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7609 - accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7631 - accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7564 - accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7528 - accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7541 - accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7476 - accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7588 - accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7508 - accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7413 - accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7440 - accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7399 - accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7351 - accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7511 - accuracy: 0.9856\n",
      "Epoch 255/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7352 - accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7356 - accuracy: 0.9952\n",
      "Epoch 257/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7337 - accuracy: 0.9952\n",
      "Epoch 258/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.9952\n",
      "Epoch 259/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7208 - accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.9952\n",
      "Epoch 265/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7075 - accuracy: 0.9952\n",
      "Epoch 269/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.9952\n",
      "Epoch 270/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.9952\n",
      "Epoch 271/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7071 - accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7045 - accuracy: 0.9952\n",
      "Epoch 275/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6784 - accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6752 - accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.9952\n",
      "Epoch 296/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 1.0000\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7452 - accuracy: 0.9643\n",
      "5/5 [==============================] - 0s 848us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 1.00 (11/11)\n",
      "Before appending - Cat IDs: 113, Predictions: 113, Actuals: 113, Gender: 113\n",
      "After appending - Cat IDs: 253, Predictions: 253, Actuals: 253, Gender: 253\n",
      "Final Test Results - Loss: 0.7451801300048828, Accuracy: 0.9642857313156128, Precision: 0.9596774193548387, Recall: 0.9698795180722892, F1 Score: 0.9634636463280963\n",
      "Confusion Matrix:\n",
      " [[57  0]\n",
      " [ 5 78]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outer_fold 3\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "057A    27\n",
      "055A    20\n",
      "097A    16\n",
      "059A    14\n",
      "106A    14\n",
      "042A    14\n",
      "111A    13\n",
      "116A    12\n",
      "051A    12\n",
      "016A    10\n",
      "014B    10\n",
      "040A    10\n",
      "051B     9\n",
      "094A     8\n",
      "117A     7\n",
      "109A     6\n",
      "104A     4\n",
      "113A     3\n",
      "056A     3\n",
      "054A     2\n",
      "093A     2\n",
      "049A     1\n",
      "048A     1\n",
      "090A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "045A    9\n",
      "050A    7\n",
      "108A    6\n",
      "044A    5\n",
      "058A    3\n",
      "011A    2\n",
      "061A    2\n",
      "043A    1\n",
      "041A    1\n",
      "115A    1\n",
      "110A    1\n",
      "024A    1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    196\n",
      "F     59\n",
      "M     55\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    28\n",
      "F     8\n",
      "M     3\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [014B, 111A, 040A, 046A, 047A, 042A, 109A, 049...\n",
      "senior    [093A, 097A, 057A, 106A, 104A, 055A, 059A, 113...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten    [044A, 050A, 043A, 041A, 045A, 115A, 110A]\n",
      "senior                [058A, 108A, 011A, 061A, 024A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 9, 'senior': 17}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 7, 'senior': 5}\n",
      "Unique Training/Validation Group IDs:\n",
      "['014B' '016A' '040A' '042A' '046A' '047A' '048A' '049A' '051A' '051B'\n",
      " '054A' '055A' '056A' '057A' '059A' '090A' '093A' '094A' '097A' '104A'\n",
      " '106A' '109A' '111A' '113A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['011A' '024A' '041A' '043A' '044A' '045A' '050A' '058A' '061A' '108A'\n",
      " '110A' '115A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "senior    164\n",
      "kitten    146\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "kitten    25\n",
      "senior    14\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "senior    164\n",
      "kitten    146\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "kitten    25\n",
      "senior    14\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({1: 164, 0: 146})\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5471 - accuracy: 0.7548\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2105 - accuracy: 0.9097\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.1216 - accuracy: 0.9290\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.0586 - accuracy: 0.9355\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.0252 - accuracy: 0.9226\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.9325 - accuracy: 0.9742\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.9058 - accuracy: 0.9484\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8559 - accuracy: 0.9581\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8498 - accuracy: 0.9613\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7856 - accuracy: 0.9742\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7575 - accuracy: 0.9645\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7375 - accuracy: 0.9742\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7238 - accuracy: 0.9645\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6517 - accuracy: 0.9806\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6346 - accuracy: 0.9871\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6346 - accuracy: 0.9839\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5872 - accuracy: 0.9871\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5926 - accuracy: 0.9839\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5701 - accuracy: 0.9742\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5509 - accuracy: 0.9677\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5208 - accuracy: 0.9871\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5121 - accuracy: 0.9774\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4792 - accuracy: 0.9903\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4650 - accuracy: 0.9935\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4455 - accuracy: 0.9935\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4383 - accuracy: 0.9806\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4336 - accuracy: 0.9742\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4073 - accuracy: 0.9935\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4099 - accuracy: 0.9839\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3916 - accuracy: 0.9806\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3856 - accuracy: 0.9806\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3854 - accuracy: 0.9806\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3604 - accuracy: 0.9839\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3439 - accuracy: 0.9935\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3449 - accuracy: 0.9839\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3312 - accuracy: 0.9839\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3045 - accuracy: 0.9903\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3054 - accuracy: 0.9871\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2955 - accuracy: 0.9935\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2873 - accuracy: 0.9903\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2794 - accuracy: 0.9903\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2583 - accuracy: 1.0000\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2765 - accuracy: 0.9806\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2555 - accuracy: 0.9935\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2466 - accuracy: 0.9903\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2397 - accuracy: 0.9903\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2338 - accuracy: 0.9871\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2399 - accuracy: 0.9839\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2129 - accuracy: 0.9903\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2070 - accuracy: 0.9903\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2074 - accuracy: 0.9903\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1940 - accuracy: 0.9903\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1792 - accuracy: 0.9903\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1696 - accuracy: 0.9968\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1659 - accuracy: 0.9935\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1487 - accuracy: 0.9968\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1551 - accuracy: 0.9968\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1573 - accuracy: 0.9871\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1511 - accuracy: 0.9903\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1374 - accuracy: 0.9935\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1144 - accuracy: 1.0000\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1239 - accuracy: 0.9968\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1218 - accuracy: 0.9935\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1035 - accuracy: 0.9968\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1067 - accuracy: 0.9935\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0993 - accuracy: 0.9903\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0974 - accuracy: 0.9935\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0778 - accuracy: 1.0000\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0686 - accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0666 - accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0659 - accuracy: 1.0000\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0600 - accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0625 - accuracy: 0.9903\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0505 - accuracy: 0.9968\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0558 - accuracy: 0.9903\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0460 - accuracy: 0.9935\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0322 - accuracy: 0.9968\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0274 - accuracy: 0.9935\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0374 - accuracy: 0.9903\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0159 - accuracy: 0.9968\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0113 - accuracy: 0.9968\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0058 - accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0138 - accuracy: 0.9871\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0115 - accuracy: 0.9871\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9948 - accuracy: 0.9968\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9855 - accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9818 - accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9837 - accuracy: 0.9968\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9845 - accuracy: 0.9903\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9708 - accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9632 - accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9731 - accuracy: 0.9935\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9637 - accuracy: 0.9935\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9478 - accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9527 - accuracy: 0.9968\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9397 - accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9461 - accuracy: 0.9968\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9409 - accuracy: 0.9968\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9326 - accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9312 - accuracy: 0.9968\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9289 - accuracy: 0.9935\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9183 - accuracy: 0.9968\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9156 - accuracy: 0.9968\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9131 - accuracy: 0.9968\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9045 - accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9081 - accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9023 - accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8908 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8977 - accuracy: 0.9935\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8854 - accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8809 - accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8786 - accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8837 - accuracy: 0.9968\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8656 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8655 - accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8623 - accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8591 - accuracy: 0.9968\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8576 - accuracy: 0.9968\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8506 - accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8391 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8500 - accuracy: 0.9968\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8490 - accuracy: 0.9968\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8400 - accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8396 - accuracy: 0.9968\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8286 - accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8244 - accuracy: 0.9968\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8278 - accuracy: 0.9968\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8179 - accuracy: 0.9968\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8167 - accuracy: 0.9968\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8100 - accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8157 - accuracy: 0.9903\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8019 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8042 - accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7959 - accuracy: 0.9968\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8006 - accuracy: 0.9968\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8013 - accuracy: 0.9935\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7859 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7851 - accuracy: 0.9968\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7867 - accuracy: 0.9968\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7769 - accuracy: 0.9968\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7804 - accuracy: 0.9935\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7835 - accuracy: 0.9968\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7734 - accuracy: 0.9968\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7813 - accuracy: 0.9968\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7877 - accuracy: 0.9839\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7670 - accuracy: 0.9935\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7571 - accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7608 - accuracy: 0.9935\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7557 - accuracy: 0.9968\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7472 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7558 - accuracy: 0.9935\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7596 - accuracy: 0.9903\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7385 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7356 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7347 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7346 - accuracy: 0.9935\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7331 - accuracy: 0.9968\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7213 - accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7388 - accuracy: 0.9839\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.9903\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.9968\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.9968\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7060 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.9968\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7048 - accuracy: 0.9968\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.9968\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.9935\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.9935\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.9935\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6737 - accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.9968\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6606 - accuracy: 0.9968\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.9968\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.9935\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6298 - accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - 0s 992us/step - loss: 0.6230 - accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6174 - accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6158 - accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6123 - accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6122 - accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6076 - accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6046 - accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6077 - accuracy: 0.9968\n",
      "Epoch 211/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6055 - accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6033 - accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6017 - accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5945 - accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6020 - accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5935 - accuracy: 0.9968\n",
      "Epoch 217/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5924 - accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5878 - accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5857 - accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5872 - accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5854 - accuracy: 0.9968\n",
      "Epoch 222/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5839 - accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5782 - accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.9968\n",
      "Epoch 226/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5703 - accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5626 - accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.9968\n",
      "Epoch 234/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5561 - accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5587 - accuracy: 0.9968\n",
      "Epoch 236/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5504 - accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.9968\n",
      "Epoch 239/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5504 - accuracy: 0.9968\n",
      "Epoch 240/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5440 - accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5424 - accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5416 - accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.9968\n",
      "Epoch 246/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.9968\n",
      "Epoch 248/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5365 - accuracy: 0.9968\n",
      "Epoch 249/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5414 - accuracy: 0.9935\n",
      "Epoch 250/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5307 - accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5378 - accuracy: 0.9935\n",
      "Epoch 252/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5319 - accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5265 - accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.9935\n",
      "Epoch 255/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5181 - accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5385 - accuracy: 0.9935\n",
      "Epoch 258/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5308 - accuracy: 0.9935\n",
      "Epoch 259/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.9935\n",
      "Epoch 260/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5131 - accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.9968\n",
      "Epoch 265/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.9968\n",
      "Epoch 266/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.9968\n",
      "Epoch 277/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.9968\n",
      "Epoch 283/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1349 - accuracy: 0.7692\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.75 (9/12)\n",
      "Before appending - Cat IDs: 253, Predictions: 253, Actuals: 253, Gender: 253\n",
      "After appending - Cat IDs: 292, Predictions: 292, Actuals: 292, Gender: 292\n",
      "Final Test Results - Loss: 1.134868860244751, Accuracy: 0.7692307829856873, Precision: 0.7722222222222223, Recall: 0.71, F1 Score: 0.7225296442687748\n",
      "Confusion Matrix:\n",
      " [[23  2]\n",
      " [ 7  7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_fold 4\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "057A    27\n",
      "097A    16\n",
      "042A    14\n",
      "106A    14\n",
      "059A    14\n",
      "111A    13\n",
      "051A    12\n",
      "016A    10\n",
      "014B    10\n",
      "051B     9\n",
      "045A     9\n",
      "094A     8\n",
      "050A     7\n",
      "108A     6\n",
      "109A     6\n",
      "044A     5\n",
      "104A     4\n",
      "058A     3\n",
      "113A     3\n",
      "061A     2\n",
      "011A     2\n",
      "054A     2\n",
      "041A     1\n",
      "043A     1\n",
      "115A     1\n",
      "110A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "055A    20\n",
      "116A    12\n",
      "040A    10\n",
      "117A     7\n",
      "056A     3\n",
      "093A     2\n",
      "049A     1\n",
      "048A     1\n",
      "090A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    207\n",
      "M     58\n",
      "F     27\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "F    40\n",
      "X    17\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 014B, 111A, 046A, 047A, 042A, 109A, 050...\n",
      "senior    [097A, 057A, 106A, 104A, 059A, 113A, 051B, 054...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten                      [040A, 049A, 048A]\n",
      "senior    [093A, 055A, 116A, 117A, 056A, 090A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 13, 'senior': 16}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 3, 'senior': 6}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '014B' '016A' '024A' '041A' '042A' '043A' '044A' '045A' '046A'\n",
      " '047A' '050A' '051A' '051B' '054A' '057A' '058A' '059A' '061A' '094A'\n",
      " '097A' '104A' '106A' '108A' '109A' '110A' '111A' '113A' '115A']\n",
      "Unique Test Group IDs:\n",
      "['040A' '048A' '049A' '055A' '056A' '090A' '093A' '116A' '117A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "kitten    159\n",
      "senior    133\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "senior    45\n",
      "kitten    12\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "kitten    159\n",
      "senior    133\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "senior    45\n",
      "kitten    12\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 159, 1: 133})\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5332 - accuracy: 0.7500\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2704 - accuracy: 0.8767\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2195 - accuracy: 0.9007\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.1279 - accuracy: 0.9315\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.0746 - accuracy: 0.9281\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.0424 - accuracy: 0.9212\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.0137 - accuracy: 0.9247\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.9644 - accuracy: 0.9452\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.9047 - accuracy: 0.9486\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8630 - accuracy: 0.9658\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8604 - accuracy: 0.9486\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8531 - accuracy: 0.9418\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8222 - accuracy: 0.9418\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8068 - accuracy: 0.9658\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7594 - accuracy: 0.9692\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7622 - accuracy: 0.9623\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7485 - accuracy: 0.9692\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7301 - accuracy: 0.9726\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7037 - accuracy: 0.9692\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6824 - accuracy: 0.9726\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6777 - accuracy: 0.9658\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6739 - accuracy: 0.9589\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6576 - accuracy: 0.9658\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6482 - accuracy: 0.9760\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6302 - accuracy: 0.9795\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6079 - accuracy: 0.9863\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6214 - accuracy: 0.9760\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6133 - accuracy: 0.9692\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5814 - accuracy: 0.9863\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5480 - accuracy: 0.9897\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5565 - accuracy: 0.9829\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5532 - accuracy: 0.9760\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5351 - accuracy: 0.9829\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5648 - accuracy: 0.9623\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5193 - accuracy: 0.9897\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5327 - accuracy: 0.9692\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5040 - accuracy: 0.9932\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5275 - accuracy: 0.9623\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5223 - accuracy: 0.9692\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5008 - accuracy: 0.9795\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4720 - accuracy: 0.9897\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4902 - accuracy: 0.9692\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.5014 - accuracy: 0.9760\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4609 - accuracy: 0.9760\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4526 - accuracy: 0.9829\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4461 - accuracy: 0.9863\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4385 - accuracy: 0.9897\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4436 - accuracy: 0.9829\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4278 - accuracy: 0.9932\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4325 - accuracy: 0.9795\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4424 - accuracy: 0.9795\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4236 - accuracy: 0.9795\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.4266 - accuracy: 0.9795\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4094 - accuracy: 0.9897\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.4023 - accuracy: 0.9897\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3868 - accuracy: 0.9897\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3735 - accuracy: 0.9897\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3825 - accuracy: 0.9795\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3721 - accuracy: 0.9829\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3729 - accuracy: 0.9932\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3741 - accuracy: 0.9897\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3566 - accuracy: 0.9966\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3726 - accuracy: 0.9829\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3524 - accuracy: 0.9863\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3716 - accuracy: 0.9760\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3604 - accuracy: 0.9795\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3375 - accuracy: 0.9932\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3319 - accuracy: 0.9932\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3345 - accuracy: 0.9897\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3338 - accuracy: 0.9863\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3362 - accuracy: 0.9795\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3090 - accuracy: 0.9966\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3152 - accuracy: 0.9863\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3067 - accuracy: 0.9966\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3037 - accuracy: 0.9932\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2914 - accuracy: 0.9897\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3133 - accuracy: 0.9795\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2935 - accuracy: 0.9897\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3128 - accuracy: 0.9863\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.3129 - accuracy: 0.9760\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2821 - accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2779 - accuracy: 0.9897\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2691 - accuracy: 0.9932\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2704 - accuracy: 0.9897\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2709 - accuracy: 0.9897\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2601 - accuracy: 0.9863\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2620 - accuracy: 0.9932\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2608 - accuracy: 0.9897\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2573 - accuracy: 0.9897\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2427 - accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2498 - accuracy: 0.9932\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2481 - accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2430 - accuracy: 0.9932\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2427 - accuracy: 0.9932\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2263 - accuracy: 0.9932\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2265 - accuracy: 0.9932\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2273 - accuracy: 0.9932\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2368 - accuracy: 0.9863\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2283 - accuracy: 0.9863\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2235 - accuracy: 0.9897\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2281 - accuracy: 0.9863\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2007 - accuracy: 0.9966\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2352 - accuracy: 0.9795\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2221 - accuracy: 0.9897\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2034 - accuracy: 0.9932\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2301 - accuracy: 0.9795\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2058 - accuracy: 0.9863\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1884 - accuracy: 0.9932\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2083 - accuracy: 0.9760\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1848 - accuracy: 0.9966\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1981 - accuracy: 0.9863\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1801 - accuracy: 0.9966\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1814 - accuracy: 0.9932\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1682 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1717 - accuracy: 0.9966\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1768 - accuracy: 0.9966\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.2035 - accuracy: 0.9795\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1636 - accuracy: 0.9932\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1746 - accuracy: 0.9863\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1610 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1594 - accuracy: 0.9966\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1629 - accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1688 - accuracy: 0.9897\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1458 - accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1527 - accuracy: 0.9966\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1675 - accuracy: 0.9795\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1379 - accuracy: 0.9966\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1396 - accuracy: 0.9966\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1422 - accuracy: 0.9932\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1599 - accuracy: 0.9897\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1481 - accuracy: 0.9897\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1233 - accuracy: 0.9966\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1321 - accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1430 - accuracy: 0.9795\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1289 - accuracy: 0.9932\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1651 - accuracy: 0.9795\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1122 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1194 - accuracy: 0.9966\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1092 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1166 - accuracy: 0.9897\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1164 - accuracy: 0.9932\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1142 - accuracy: 0.9966\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1140 - accuracy: 0.9966\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1077 - accuracy: 0.9897\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0949 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0966 - accuracy: 0.9932\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1045 - accuracy: 0.9897\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0938 - accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1024 - accuracy: 0.9932\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1120 - accuracy: 0.9897\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1048 - accuracy: 0.9863\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0885 - accuracy: 0.9966\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0822 - accuracy: 0.9966\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1002 - accuracy: 0.9897\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1094 - accuracy: 0.9863\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0783 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0843 - accuracy: 0.9932\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0939 - accuracy: 0.9829\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0845 - accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0674 - accuracy: 0.9966\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0784 - accuracy: 0.9897\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0659 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0619 - accuracy: 0.9966\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0823 - accuracy: 0.9863\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0574 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0897 - accuracy: 0.9795\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0916 - accuracy: 0.9795\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0991 - accuracy: 0.9829\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0882 - accuracy: 0.9829\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0595 - accuracy: 0.9966\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0585 - accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0647 - accuracy: 0.9932\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0513 - accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0625 - accuracy: 0.9932\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0659 - accuracy: 0.9897\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 0s 999us/step - loss: 1.0621 - accuracy: 0.9795\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0645 - accuracy: 0.9829\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0474 - accuracy: 0.9897\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0433 - accuracy: 0.9966\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0463 - accuracy: 0.9932\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0452 - accuracy: 0.9897\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0372 - accuracy: 0.9966\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0328 - accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0359 - accuracy: 0.9966\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0491 - accuracy: 0.9932\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0286 - accuracy: 0.9966\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0361 - accuracy: 0.9932\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0274 - accuracy: 0.9966\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0182 - accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0354 - accuracy: 0.9932\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0334 - accuracy: 0.9932\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0329 - accuracy: 0.9897\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0198 - accuracy: 0.9932\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0261 - accuracy: 0.9932\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0122 - accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0287 - accuracy: 0.9863\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0115 - accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0028 - accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0038 - accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0228 - accuracy: 0.9829\n",
      "Epoch 201/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0232 - accuracy: 0.9897\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0045 - accuracy: 0.9966\n",
      "Epoch 203/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0256 - accuracy: 0.9863\n",
      "Epoch 204/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0134 - accuracy: 0.9932\n",
      "Epoch 205/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0070 - accuracy: 0.9966\n",
      "Epoch 206/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9938 - accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0059 - accuracy: 0.9932\n",
      "Epoch 208/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0138 - accuracy: 0.9897\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - 0s 972us/step - loss: 0.9961 - accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0276 - accuracy: 0.9863\n",
      "Epoch 211/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9913 - accuracy: 0.9966\n",
      "Epoch 212/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0151 - accuracy: 0.9863\n",
      "Epoch 213/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0084 - accuracy: 0.9897\n",
      "Epoch 214/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9923 - accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9938 - accuracy: 0.9932\n",
      "Epoch 216/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9891 - accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0254 - accuracy: 0.9829\n",
      "Epoch 218/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9962 - accuracy: 0.9932\n",
      "Epoch 219/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0065 - accuracy: 0.9897\n",
      "Epoch 220/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9924 - accuracy: 0.9932\n",
      "Epoch 221/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9907 - accuracy: 0.9966\n",
      "Epoch 222/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9917 - accuracy: 0.9966\n",
      "Epoch 223/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9873 - accuracy: 0.9966\n",
      "Epoch 224/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9850 - accuracy: 0.9932\n",
      "Epoch 225/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9969 - accuracy: 0.9897\n",
      "Epoch 226/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9873 - accuracy: 0.9966\n",
      "Epoch 227/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9816 - accuracy: 0.9966\n",
      "Epoch 228/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9774 - accuracy: 0.9966\n",
      "Epoch 229/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9720 - accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9767 - accuracy: 0.9966\n",
      "Epoch 231/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9723 - accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9709 - accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9716 - accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9654 - accuracy: 0.9966\n",
      "Epoch 235/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9759 - accuracy: 0.9932\n",
      "Epoch 236/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9564 - accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9707 - accuracy: 0.9932\n",
      "Epoch 238/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9682 - accuracy: 0.9966\n",
      "Epoch 239/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9682 - accuracy: 0.9932\n",
      "Epoch 240/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9745 - accuracy: 0.9932\n",
      "Epoch 241/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9625 - accuracy: 0.9966\n",
      "Epoch 242/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9920 - accuracy: 0.9829\n",
      "Epoch 243/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9539 - accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9820 - accuracy: 0.9932\n",
      "Epoch 245/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9709 - accuracy: 0.9897\n",
      "Epoch 246/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9592 - accuracy: 0.9966\n",
      "Epoch 247/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9528 - accuracy: 0.9966\n",
      "Epoch 248/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9610 - accuracy: 0.9932\n",
      "Epoch 249/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9605 - accuracy: 0.9897\n",
      "Epoch 250/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9751 - accuracy: 0.9863\n",
      "Epoch 251/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9466 - accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9477 - accuracy: 0.9966\n",
      "Epoch 253/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9533 - accuracy: 0.9966\n",
      "Epoch 254/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9446 - accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9520 - accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9471 - accuracy: 0.9932\n",
      "Epoch 257/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9377 - accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.9382 - accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9479 - accuracy: 0.9932\n",
      "Epoch 260/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9516 - accuracy: 0.9897\n",
      "Epoch 261/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9349 - accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9507 - accuracy: 0.9863\n",
      "Epoch 263/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9396 - accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9630 - accuracy: 0.9863\n",
      "Epoch 265/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9343 - accuracy: 0.9966\n",
      "Epoch 266/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9370 - accuracy: 0.9966\n",
      "Epoch 267/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9428 - accuracy: 0.9932\n",
      "Epoch 268/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9471 - accuracy: 0.9932\n",
      "Epoch 269/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9410 - accuracy: 0.9932\n",
      "Epoch 270/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9373 - accuracy: 0.9966\n",
      "Epoch 271/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9396 - accuracy: 0.9932\n",
      "Epoch 272/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9517 - accuracy: 0.9932\n",
      "Epoch 273/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9193 - accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9236 - accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9301 - accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9263 - accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9217 - accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9179 - accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9204 - accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9138 - accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9232 - accuracy: 0.9966\n",
      "Epoch 282/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9154 - accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9126 - accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9330 - accuracy: 0.9897\n",
      "Epoch 285/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9161 - accuracy: 0.9932\n",
      "Epoch 286/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9200 - accuracy: 0.9932\n",
      "Epoch 287/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9169 - accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9198 - accuracy: 0.9966\n",
      "Epoch 289/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9072 - accuracy: 0.9966\n",
      "Epoch 290/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9097 - accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9177 - accuracy: 0.9932\n",
      "Epoch 292/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9126 - accuracy: 0.9932\n",
      "Epoch 293/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9271 - accuracy: 0.9932\n",
      "Epoch 294/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9033 - accuracy: 0.9966\n",
      "Epoch 295/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9039 - accuracy: 0.9966\n",
      "Epoch 296/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9012 - accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9039 - accuracy: 0.9966\n",
      "Epoch 298/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8980 - accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8945 - accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8911 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9317 - accuracy: 0.9825\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.89 (8/9)\n",
      "Before appending - Cat IDs: 292, Predictions: 292, Actuals: 292, Gender: 292\n",
      "After appending - Cat IDs: 349, Predictions: 349, Actuals: 349, Gender: 349\n",
      "Final Test Results - Loss: 0.931678831577301, Accuracy: 0.9824561476707458, Precision: 0.9615384615384616, Recall: 0.9888888888888889, F1 Score: 0.9743820224719102\n",
      "Confusion Matrix:\n",
      " [[12  0]\n",
      " [ 1 44]]\n",
      "\n",
      "Final Average F1-Score across all UNSEEN TEST sets: 0.8815995870747835\n",
      "\n",
      "Final Average Loss across all UNSEEN TEST sets: 0.9398135989904404\n",
      "\n",
      "Final Average Accuracy across all UNSEEN TEST sets: 0.8980197161436081\n",
      "\n",
      "Final Average Precision across all UNSEEN TEST sets: 0.8870194868431247\n",
      "\n",
      "Final Average Recall across all UNSEEN TEST sets: 0.8907671378153306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "all_cat_ids = []\n",
    "all_predicted_age_groups = []\n",
    "all_actual_age_groups = []\n",
    "all_gender = []\n",
    "\n",
    "# Define the StratifiedGroupKFold splitter for 4 fold CV with random shuffling\n",
    "outer_cv = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=int(random_seeds[0]))\n",
    "\n",
    "# unseen test set metrics\n",
    "unseen_losses, unseen_accuracies, unseen_precisions, unseen_recalls, unseen_f1 = [], [], [], [], []\n",
    "\n",
    "outer_fold = 0\n",
    "\n",
    "# Use the splitter to generate indices for training and testing sets\n",
    "# Note: GroupShuffleSplit.split returns indices, so we use it to index the arrays\n",
    "for train_val_idx, test_idx in outer_cv.split(X, y, groups):\n",
    "    outer_fold += 1\n",
    "    logger(f\"outer_fold {outer_fold}\", file=log_file_path)\n",
    "\n",
    "    # Convert indices back to DataFrame for easy manipulation\n",
    "    df_train_val = dataframe.iloc[train_val_idx]\n",
    "    df_test = dataframe.iloc[test_idx]\n",
    "\n",
    "    ##############################\n",
    "    # ASSESSING SPLITS BY CAT_ID #\n",
    "    ##############################\n",
    "    \n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test['cat_id'].value_counts()  \n",
    "    \n",
    "    # Log or print the distribution\n",
    "    logger(f\"Train Set Group Distribution:\\n{training_validation_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Group Distribution:\\n{testing_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test['gender'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Training Set Gender Distribution BEFORE SWAP:\\n{training_gender_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Gender Distribution BEFORE SWAP:\\n{testing_gender_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Group by 'age_group' and then list unique 'cat_id' within each age group\n",
    "    unique_cat_ids_per_age_group_train_val = df_train_val.groupby('age_group')['cat_id'].unique()\n",
    "    unique_cat_ids_per_age_group_test = df_test.groupby('age_group')['cat_id'].unique()\n",
    "    \n",
    "    # Log results\n",
    "    logger(f\"Unique Cat IDs per Age Group in Training/Validation Set:\\n{unique_cat_ids_per_age_group_train_val}\", file=log_file_path)\n",
    "    logger(f\"Unique Cat IDs per Age Group in Testing Set:\\n{unique_cat_ids_per_age_group_test}\", file=log_file_path)\n",
    "\n",
    "    # Calculate the count of unique identifiers per age group for training and testing set\n",
    "    counts_train_val = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_train_val.items()}\n",
    "    counts_test = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_test.items()}\n",
    "\n",
    "    # Log the counts of unique identifiers per age group\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Training/Validation Set:\\n{counts_train_val}\", file=log_file_path)\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Testing Set:\\n{counts_test}\", file=log_file_path)\n",
    "\n",
    "    #######################################################\n",
    "    # CONTINUE WITH ENSURING VALID AND APPROPRIATE SPLITS #\n",
    "    #######################################################\n",
    "    \n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    groups_train_val, groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # logging identifier splits \n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "\n",
    "    # # check group splits\n",
    "    # check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # # Specify the cat_ids that must be in the training/validation set\n",
    "    # specific_cat_ids = ['000A', '046A']\n",
    "    \n",
    "    # # Perform the swapping operation\n",
    "    # train_val_idx, test_idx = swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids)\n",
    "    \n",
    "    # # Re-assign the sets based on the updated indices\n",
    "    # X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    # y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    # new_groups_train_val, new_groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # # Find differences for training and test sets\n",
    "    # moved_to_train_val, removed_from_train_val = find_group_differences(groups_train_val, new_groups_train_val)\n",
    "    # moved_to_test, removed_from_test = find_group_differences(groups_test, new_groups_test)\n",
    "    \n",
    "    # # Display the results\n",
    "    # logger(f\"Moved to Training/Validation Set:\\n{moved_to_train_val}\", file=log_file_path)\n",
    "    # logger(f\"Removed from Training/Validation Set:\\n{removed_from_train_val}\", file=log_file_path)\n",
    "    # logger(f\"Moved to Test Set:\\n{moved_to_test}\", file=log_file_path)\n",
    "    # logger(f\"Removed from Test Set\\n{removed_from_test}\", file=log_file_path)\n",
    "\n",
    "    # # Update X_train_val, X_test, y_train_val, y_test, groups_train_val, groups_test based on updated indices\n",
    "    # X_train_val = X[train_val_idx]\n",
    "    # y_train_val = y[train_val_idx]\n",
    "    # groups_train_val = groups[train_val_idx]\n",
    "    \n",
    "    # X_test = X[test_idx]\n",
    "    # y_test = y[test_idx]\n",
    "    # groups_test = groups[test_idx]\n",
    "\n",
    "    # # logging identifier splits again after potential swaps\n",
    "    # unique_train_val_groups = np.unique(groups_train_val)\n",
    "    # unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    # logger(f\"AFTER SWAP - Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    # logger(f\"AFTER SWAP - Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "    \n",
    "    # # Verify the lengths are consistent\n",
    "    # logger(f\"Length of X_train_val:\\n{len(X_train_val)}\", file=log_file_path)\n",
    "    # logger(f\"Length of y_train_val:\\n{len(y_train_val)}\", file=log_file_path)\n",
    "    # logger(f\"Length of groups_train_val:\\n{len(groups_train_val)}\", file=log_file_path)\n",
    "\n",
    "    # # Check group splits once more\n",
    "    # check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Convert the modified indices back to a DataFrame representing the updated df_train_val\n",
    "    df_train_val_updated = dataframe.iloc[train_val_idx].copy()\n",
    "    df_test_updated = dataframe.iloc[test_idx].copy()\n",
    "\n",
    "    ############################\n",
    "    # LOGGING AGE GROUP SPLITS #\n",
    "    ############################\n",
    "\n",
    "    # Get the distribution of age groups of age groups before the update\n",
    "    training_validation_age_group_distribution = df_train_val['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test['age_group'].value_counts()\n",
    "    \n",
    "    # Logthe distribution\n",
    "    logger(f\"Train Age Group Distribution BEFORE SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution BEFORE SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Get the distribution of age groups after the update\n",
    "    training_validation_age_group_distribution = df_train_val_updated['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test_updated['age_group'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Train Age Group Distribution AFTER SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution AFTER SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "    \n",
    "    ########################################################\n",
    "    # TRACKING FINAL CAT_IDs & GENDER AFTER REDISTRIBUTION #\n",
    "    ########################################################\n",
    "\n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val_updated['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test_updated['cat_id'].value_counts()  \n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val_updated['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test_updated['gender'].value_counts()\n",
    "    \n",
    "    logger(f\"\\n Starting training on unseen test set\\n\", file=log_file_path)\n",
    "\n",
    "    ###################\n",
    "    # PREPARING MODEL #\n",
    "    ###################\n",
    "\n",
    "    # Calculate the distribution of age groups in y_train_val\n",
    "    age_group_distribution = Counter(y_train_val)\n",
    "    print(\"Age group distribution:\", age_group_distribution)\n",
    "\n",
    "    # EarlyStopping callback: monitor 'loss' instead of 'val_loss' for the test set\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='loss',  \n",
    "        min_delta=0.001, \n",
    "        patience=30,  \n",
    "        verbose=1,  \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "\n",
    "    # One final shuffle to ensure randomness\n",
    "    outer_shuffle_idx = np.random.permutation(len(X_train_val))\n",
    "    X_train_val = X_train_val[outer_shuffle_idx]\n",
    "    y_train_val = y_train_val[outer_shuffle_idx]\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler_full = StandardScaler().fit(X_train_val)\n",
    "    X_train_full_scaled = scaler_full.transform(X_train_val)\n",
    "    X_test_scaled = scaler_full.transform(X_test)\n",
    "    \n",
    "    # Encode the labels\n",
    "    y_train_full_encoded = y_train_val.astype('float32')\n",
    "    y_test_encoded = y_test.astype('float32')\n",
    "\n",
    "    #######################\n",
    "    # BUILD & TRAIN MODEL #\n",
    "    #######################\n",
    "\n",
    "    # Define optimizers\n",
    "    optimizers = {\n",
    "        'Adamax': Adamax(learning_rate=0.00038188800331973483)\n",
    "    }\n",
    "    \n",
    "    # Full model definition with dynamic number of layers\n",
    "    model_full = Sequential()\n",
    "    model_full.add(Dense(480, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(X_train_full_scaled.shape[1],)))  # units and input shape from parameters\n",
    "    model_full.add(BatchNormalization())\n",
    "    model_full.add(Dropout(0.27188281261238406))\n",
    "    model_full.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = optimizers['Adamax']  # optimizer selection\n",
    "    \n",
    "    # Compile the model for binary classification\n",
    "    model_full.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model on the full training set\n",
    "    history_full = model_full.fit(X_train_full_scaled, y_train_full_encoded, epochs=300, batch_size=32,\n",
    "                                  verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on the held-out test set\n",
    "    test_loss, test_accuracy = model_full.evaluate(X_test_scaled, y_test_encoded)\n",
    "\n",
    "    # y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    # y_test_pred = np.argmax(y_test_pred_prob, axis=1)  \n",
    "    # y_test_true = np.argmax(y_test_encoded, axis=1)    \n",
    "\n",
    "    # Predict probabilities for the test set\n",
    "    y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    \n",
    "    # Convert probabilities to class labels (0 or 1) using a threshold of 0.5\n",
    "    y_test_pred = (y_test_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # y_test_encoded should be a 1D array of 0s and 1s if prepared as suggested for binary classification\n",
    "    y_test_true = y_test_encoded\n",
    "\n",
    "    ################################\n",
    "    # LOG MAJORITY VOTE PER CAT_ID #\n",
    "    ################################\n",
    "\n",
    "    # Convert numeric predictions back to age group labels\n",
    "    predicted_age_groups = y_test_pred\n",
    "    actual_labels = y_test_true\n",
    "    \n",
    "    # Map predictions and actual labels back to cat_ids\n",
    "    test_results = pd.DataFrame({\n",
    "        'cat_id': df_test_updated['cat_id'],\n",
    "        'predicted_age_group': predicted_age_groups,\n",
    "        'actual_age_group': actual_labels\n",
    "    })\n",
    "    \n",
    "    # Group by cat_id and aggregate predicted age groups\n",
    "    majority_votes = test_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "    actual_groups = test_results.groupby('cat_id')['actual_age_group'].first()\n",
    "    \n",
    "    # Calculate the accuracy of majority voting\n",
    "    correct_predictions = (majority_votes == actual_groups).sum()\n",
    "    total_cats = len(actual_groups)\n",
    "    majority_vote_accuracy = correct_predictions / total_cats\n",
    "    \n",
    "    # Log the accuracy of the majority voting\n",
    "    logger(f\"Majority Vote Accuracy for cat_id for this fold: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)\n",
    "\n",
    "    ####################################################\n",
    "    # COLLECT PREDICTIONS FOR GENDER & CAT_ID ANALYSIS #\n",
    "    ####################################################\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'Before appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Extend lists with current fold results\n",
    "    all_cat_ids.extend(df_test_updated['cat_id'].tolist())\n",
    "    all_predicted_age_groups.extend(predicted_age_groups)\n",
    "    all_actual_age_groups.extend(actual_labels)\n",
    "    all_gender.extend(df_test_updated['gender'].tolist())\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'After appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    test_precision = precision_score(y_test_true, y_test_pred, average='macro')  # Use 'macro' for imbalanced datasets\n",
    "    test_recall = recall_score(y_test_true, y_test_pred, average='macro')\n",
    "    test_f1 = f1_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "    # prepare averages of outer metrics\n",
    "    unseen_f1.append(test_f1)\n",
    "    unseen_losses.append(test_loss)\n",
    "    unseen_accuracies.append(test_accuracy)\n",
    "    unseen_precisions.append(test_precision)\n",
    "    unseen_recalls.append(test_recall)\n",
    "\n",
    "    # Print final test results\n",
    "    logger(f\"Final Test Results - Loss: {test_loss}, Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}\", file=log_file_path)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    logger(f\"Confusion Matrix:\\n {cm}\", file=log_file_path)\n",
    "\n",
    "# Calculate the overall average metrics\n",
    "unseen_set_avg_f1 = np.mean(unseen_f1)\n",
    "unseen_set_avg_loss = np.mean(unseen_losses)\n",
    "unseen_set_avg_acc = np.mean(unseen_accuracies)\n",
    "unseen_set_avg_precision = np.mean(unseen_precisions)\n",
    "unseen_set_avg_recall = np.mean(unseen_recalls)\n",
    "\n",
    "logger(f\"\\nFinal Average F1-Score across all UNSEEN TEST sets: {unseen_set_avg_f1}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Loss across all UNSEEN TEST sets: {unseen_set_avg_loss}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Accuracy across all UNSEEN TEST sets: {unseen_set_avg_acc}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Precision across all UNSEEN TEST sets: {unseen_set_avg_precision}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Recall across all UNSEEN TEST sets: {unseen_set_avg_recall}\\n\", file=log_file_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79e793-c694-4bc7-8cc6-05e124ddf71f",
   "metadata": {},
   "source": [
    "## Majority Voting on Total Entries per cat_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2c3c239d-6215-4589-a583-b37a18ca22cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking - Cat IDs: 349, Predictions: 349, Actuals: 349, Gender: 349\n"
     ]
    }
   ],
   "source": [
    "# Debugging print statements\n",
    "print(f'Checking - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "99978976-e4a9-4c04-a6b2-6b14a3111277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results df\n",
    "full_results = pd.DataFrame({\n",
    "    'cat_id': all_cat_ids,\n",
    "    'predicted_age_group': all_predicted_age_groups,\n",
    "    'actual_age_group': all_actual_age_groups,\n",
    "    'all_gender': all_gender\n",
    "})\n",
    "\n",
    "# create a correct majority prediction column\n",
    "full_results['correct'] = full_results['predicted_age_group'] == full_results['actual_age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "189b812b-d37f-462f-a99f-6de8e4a7899f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Majority Vote Accuracy for cat_id: 0.89 (34/38)\n"
     ]
    }
   ],
   "source": [
    "# Group by cat_id and aggregate predicted age groups\n",
    "majority_votes = full_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first()\n",
    "\n",
    "# Calculate the accuracy of majority voting\n",
    "correct_predictions = (majority_votes == actual_groups).sum()\n",
    "total_cats = len(actual_groups)\n",
    "majority_vote_accuracy = correct_predictions / total_cats\n",
    "\n",
    "logger(f\"Overall Majority Vote Accuracy for cat_id: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "907d957f-7340-4a76-b3fa-7cf166f43049",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Detailed df with predictions, actual labels, and comparison including majority vote\n",
    "detailed_results = full_results.groupby('cat_id').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Predictions': list(x['predicted_age_group']),\n",
    "        'Majority Vote': x['predicted_age_group'].mode()[0],\n",
    "        'Actual Age Group': x['actual_age_group'].iloc[0],\n",
    "        'Correct Majority Vote': x['predicted_age_group'].mode()[0] == x['actual_age_group'].iloc[0]\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Convert to DataFrame for better formatting and display\n",
    "detailed_results = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7016fa20-094f-409a-9a2f-b6d6793aed03",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Majority Vote</th>\n",
       "      <th>Actual Age Group</th>\n",
       "      <th>Correct Majority Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>011A</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>104A</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>014B</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>057A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>059A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>090A</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>094A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>097A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>106A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>054A</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>109A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>110A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>111A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>113A</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>115A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>116A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>055A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>056A</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>051B</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>051A</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>016A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>024A</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>040A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>041A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>042A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>043A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>044A</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>045A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>046A</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>047A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>048A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>049A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>050A</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>117A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>108A</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>093A</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>061A</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>058A</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat_id                                        Predictions  Majority Vote  Actual Age Group  Correct Majority Vote\n",
       "0    011A                                             [1, 1]              1               1.0                   True\n",
       "28   104A                                       [1, 1, 1, 1]              1               1.0                   True\n",
       "1    014B                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "20   057A  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, ...              1               1.0                   True\n",
       "22   059A         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "24   090A                                                [1]              1               1.0                   True\n",
       "26   094A                           [1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "27   097A   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "29   106A         [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]              1               1.0                   True\n",
       "17   054A                                             [1, 1]              1               1.0                   True\n",
       "31   109A                                 [0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "32   110A                                                [0]              0               0.0                   True\n",
       "33   111A            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "34   113A                                          [1, 1, 1]              1               1.0                   True\n",
       "35   115A                                                [0]              0               0.0                   True\n",
       "36   116A               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "18   055A  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              1               1.0                   True\n",
       "19   056A                                          [1, 1, 1]              1               1.0                   True\n",
       "16   051B                        [1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "15   051A               [1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "2    016A                     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "3    024A                                                [1]              1               1.0                   True\n",
       "4    040A                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "5    041A                                                [0]              0               0.0                   True\n",
       "6    042A         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "7    043A                                                [0]              0               0.0                   True\n",
       "8    044A                                    [0, 1, 0, 0, 0]              0               0.0                   True\n",
       "9    045A                        [0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "10   046A  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...              0               0.0                   True\n",
       "11   047A  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              0               0.0                   True\n",
       "12   048A                                                [0]              0               0.0                   True\n",
       "13   049A                                                [0]              0               0.0                   True\n",
       "14   050A                              [0, 1, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "37   117A                              [1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "30   108A                                 [0, 1, 1, 1, 0, 0]              0               1.0                  False\n",
       "25   093A                                             [0, 1]              0               1.0                  False\n",
       "23   061A                                             [0, 1]              0               1.0                  False\n",
       "21   058A                                          [0, 0, 0]              0               1.0                  False"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "sorted_detailed_results = detailed_results.sort_values(by='Correct Majority Vote', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "994531fd-e6fb-4491-9eab-86e41ac1ed3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Majority Votes per Class:\n",
      "actual_age_group\n",
      "0.0    16\n",
      "1.0    18\n",
      "Name: Majority_Correct, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create df for majority votes\n",
    "majority_df = majority_votes.reset_index()\n",
    "majority_df.columns = ['cat_id', 'Majority_Vote']\n",
    "\n",
    "# Get actual groups for each cat_id\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first().reset_index()\n",
    "\n",
    "# Merge majority votes with actual groups\n",
    "majority_with_actual = pd.merge(majority_df, actual_groups, on='cat_id')\n",
    "\n",
    "# Add a column to check if the majority vote was correct\n",
    "majority_with_actual['Majority_Correct'] = majority_with_actual['Majority_Vote'] == majority_with_actual['actual_age_group']\n",
    "\n",
    "# Count correct majority votes per class\n",
    "correct_majority_votes_per_class = majority_with_actual.groupby('actual_age_group')['Majority_Correct'].sum()\n",
    "\n",
    "print(\"Correct Majority Votes per Class:\")\n",
    "print(correct_majority_votes_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "229af3e2-6a64-4f3d-a594-e04108fce87f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics for Majority Votes:\n",
      "   actual_age_group  total_count  correct_count    accuracy\n",
      "0               0.0           16             16  100.000000\n",
      "1               1.0           22             18   81.818182\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = majority_with_actual.groupby('actual_age_group').agg(\n",
    "    total_count=('Majority_Correct', 'size'),  # Total number of cases per class\n",
    "    correct_count=('Majority_Correct', 'sum')  # Sum of correct predictions per class\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log detailed stats\n",
    "print(\"Detailed Class Statistics for Majority Votes:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3960450a-db52-4464-a965-00f1e600bda5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics for Majority Votes\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Accuracy of Majority Votes by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bbf768-64c2-48ec-80e3-3a961b0b12a6",
   "metadata": {},
   "source": [
    "## Detailed Class Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fe16003e-4015-4d28-ae37-ca0c94952758",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics:\n",
      "   actual_age_group  total_count  correct_count   accuracy\n",
      "0               0.0          171            157  91.812865\n",
      "1               1.0          178            163  91.573034\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = full_results.groupby('actual_age_group').agg(\n",
    "    total_count=('correct', 'size'),\n",
    "    correct_count=('correct', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log the detailed stats\n",
    "print(\"Detailed Class Statistics:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5b5b8766-b4bd-4dd2-92e2-6513741b03ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics (Overall)\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Overall Accuracy by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efa447-1e32-42df-8664-a3f1f0e0f812",
   "metadata": {},
   "source": [
    "## Gender Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5eecd6a6-4094-4747-8029-f795a87f8ff0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Gender:\n",
      "  all_gender  count  correct  accuracy\n",
      "0          F     67       61     91.04\n",
      "1          M     58       55     94.83\n",
      "2          X    224      204     91.07\n"
     ]
    }
   ],
   "source": [
    "# Group by gender and calculate the total count, correct predictions, and accuracy\n",
    "gender_stats = full_results.groupby('all_gender').agg(\n",
    "    count=('cat_id', 'size'),  # Total number of cases per gender\n",
    "    correct=('correct', 'sum')  # Sum of correct predictions per gender\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each gender\n",
    "gender_stats['accuracy'] = (gender_stats['correct'] / gender_stats['count'] * 100).round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy by Gender:\")\n",
    "print(gender_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "115592e9-47eb-42fe-8cb5-26beeb7328ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Accuracy by Gender\n",
    "styled_barplot(gender_stats, 'all_gender', 'accuracy', \n",
    "               'Accuracy by Gender', \n",
    "               'Gender', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae066af0-659b-43f0-924c-2c50be0e6c40",
   "metadata": {},
   "source": [
    "# RANDOM SEED 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be86ae6-0659-45b8-b237-6a9e2a7113f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "cc76296a-4029-447e-b12c-41520160251a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senior    178\n",
      "kitten    171\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(int(random_seeds[1])) \n",
    "np.random.seed(int(random_seeds[1]))\n",
    "tf.random.set_seed(int(random_seeds[1]))\n",
    "\n",
    "# Load datasets\n",
    "dataframe = pd.read_csv('/Users/astrid/PycharmProjects/audioset-thesis-work/audioset/vggish/embeddings/8april_looped_embeddings.csv')\n",
    "\n",
    "dataframe.drop('mean_freq', axis=1, inplace=True)\n",
    "\n",
    "def assign_age_group(age, age_groups):\n",
    "    for group_name, age_range in age_groups.items():\n",
    "        if age_range[0] <= age < age_range[1]:\n",
    "            return group_name\n",
    "    return 'Unknown'  # For any age that doesn't fit the defined groups\n",
    "\n",
    "# Define age groups\n",
    "age_groups = {\n",
    "    'kitten': (0, 0.5),\n",
    "    'adult': (0.5, 12),\n",
    "    'senior': (12, 20)\n",
    "}\n",
    "\n",
    "# Create a new column for the age group\n",
    "dataframe['age_group'] = dataframe['target'].apply(assign_age_group, age_groups=age_groups)\n",
    "\n",
    "# Drop Adult\n",
    "dataframe.drop(dataframe[dataframe['age_group'] == 'adult'].index, inplace=True)\n",
    "\n",
    "print(dataframe['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "093977a2-1813-4a02-9573-f757b3d2a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = dataframe.iloc[:, :-4].values  # all columns except the last four\n",
    "\n",
    "# Encode the 'age_group' column as integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y = label_encoder.fit_transform(dataframe['age_group'].values)\n",
    "\n",
    "# Use the encoded labels for splitting and one-hot encoding\n",
    "y = encoded_y  \n",
    "\n",
    "# Convert 'cat_id' column to numpy array to be used as groups array for GroupKFold\n",
    "groups = dataframe['cat_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0c89dbfa-4c9b-4e46-a0d9-f659db30532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a62fdf-86b5-45e7-9249-73a55985936a",
   "metadata": {},
   "source": [
    "## Run Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a421362c-0f20-4393-8279-0e70e8845972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_fold 1\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "057A    27\n",
      "097A    16\n",
      "106A    14\n",
      "042A    14\n",
      "059A    14\n",
      "111A    13\n",
      "116A    12\n",
      "014B    10\n",
      "040A    10\n",
      "016A    10\n",
      "045A     9\n",
      "051B     9\n",
      "094A     8\n",
      "050A     7\n",
      "117A     7\n",
      "109A     6\n",
      "108A     6\n",
      "104A     4\n",
      "056A     3\n",
      "058A     3\n",
      "113A     3\n",
      "054A     2\n",
      "061A     2\n",
      "049A     1\n",
      "041A     1\n",
      "048A     1\n",
      "115A     1\n",
      "110A     1\n",
      "090A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "055A    20\n",
      "051A    12\n",
      "044A     5\n",
      "093A     2\n",
      "011A     2\n",
      "043A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    216\n",
      "M     58\n",
      "F     33\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "F    34\n",
      "X     8\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [014B, 111A, 040A, 046A, 047A, 042A, 109A, 050...\n",
      "senior    [097A, 057A, 106A, 104A, 059A, 113A, 116A, 051...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten                [044A, 043A]\n",
      "senior    [093A, 055A, 051A, 011A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 14, 'senior': 18}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 2, 'senior': 4}\n",
      "Unique Training/Validation Group IDs:\n",
      "['014B' '016A' '024A' '040A' '041A' '042A' '045A' '046A' '047A' '048A'\n",
      " '049A' '050A' '051B' '054A' '056A' '057A' '058A' '059A' '061A' '090A'\n",
      " '094A' '097A' '104A' '106A' '108A' '109A' '110A' '111A' '113A' '115A'\n",
      " '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['011A' '043A' '044A' '051A' '055A' '093A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "kitten    165\n",
      "senior    142\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "senior    36\n",
      "kitten     6\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "kitten    165\n",
      "senior    142\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "senior    36\n",
      "kitten     6\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 165, 1: 142})\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8458 - accuracy: 0.5505\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.7850\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.8534\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3421 - accuracy: 0.8730\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2665 - accuracy: 0.9186\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.8990\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.9251\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.9446\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2104 - accuracy: 0.9381\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2152 - accuracy: 0.9349\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1707 - accuracy: 0.9446\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9544\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.9479\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1297 - accuracy: 0.9674\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1442 - accuracy: 0.9479\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9642\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9577\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9381\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9902\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9577\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9609\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9739\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9805\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9805\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9707\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9739\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9707\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0896 - accuracy: 0.9805\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9902\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9805\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9805\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9837\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9837\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9935\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9935\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9902\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9805\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9902\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.9870\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9837\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9707\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0690 - accuracy: 0.9739\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0529 - accuracy: 0.9902\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0619 - accuracy: 0.9837\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9967\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0610 - accuracy: 0.9837\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9805\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9935\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9772\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9902\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9967\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0667 - accuracy: 0.9837\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9870\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9837\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9902\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0531 - accuracy: 0.9902\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9707\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9935\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0454 - accuracy: 0.9967\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0588 - accuracy: 0.9902\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9870\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 0.9935\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9967\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9902\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 0.9902\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9902\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0482 - accuracy: 0.9902\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0333 - accuracy: 0.9967\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9902\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9967\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9870\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9902\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9837\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 0.9967\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9902\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 0.9902\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9967\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9967\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0335 - accuracy: 0.9902\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9902\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 0.9870\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.9967\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9967\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9967\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 977us/step - loss: 0.0237 - accuracy: 0.9967\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9935\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9935\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9935\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9967\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.9902\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9967\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0340 - accuracy: 0.9870\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 0.9967\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9967\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9967\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9935\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.9967\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9967\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9967\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9935\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9967\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9967\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.9967\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9967\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9967\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9967\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.9967\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9870\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9935\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9967\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 0.9967\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9967\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.9967\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.9967\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9967\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9902\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9967\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.9967\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9967\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.9967\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9967\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9935\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.9967\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 0.9967\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9967\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9967\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.9967\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.9967\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9967\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 0.9967\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9967\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 0s 961us/step - loss: 0.0093 - accuracy: 0.9967\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0122 - accuracy: 0.9935\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 0s 961us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9967\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 201/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 171.\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 201: early stopping\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1516 - accuracy: 0.9286\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.83 (5/6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before appending - Cat IDs: 0, Predictions: 0, Actuals: 0, Gender: 0\n",
      "After appending - Cat IDs: 42, Predictions: 42, Actuals: 42, Gender: 42\n",
      "Final Test Results - Loss: 0.1516280174255371, Accuracy: 0.9285714030265808, Precision: 0.8333333333333333, Recall: 0.9583333333333333, F1 Score: 0.8782608695652174\n",
      "Confusion Matrix:\n",
      " [[ 6  0]\n",
      " [ 3 33]]\n",
      "outer_fold 2\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "057A    27\n",
      "055A    20\n",
      "106A    14\n",
      "042A    14\n",
      "051A    12\n",
      "116A    12\n",
      "040A    10\n",
      "016A    10\n",
      "014B    10\n",
      "045A     9\n",
      "050A     7\n",
      "109A     6\n",
      "108A     6\n",
      "044A     5\n",
      "104A     4\n",
      "056A     3\n",
      "058A     3\n",
      "113A     3\n",
      "093A     2\n",
      "011A     2\n",
      "043A     1\n",
      "049A     1\n",
      "041A     1\n",
      "110A     1\n",
      "090A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "097A    16\n",
      "059A    14\n",
      "111A    13\n",
      "051B     9\n",
      "094A     8\n",
      "117A     7\n",
      "054A     2\n",
      "061A     2\n",
      "048A     1\n",
      "115A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    191\n",
      "F     60\n",
      "M     24\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "M    34\n",
      "X    33\n",
      "F     7\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 014B, 040A, 046A, 047A, 042A, 109A, 050...\n",
      "senior    [093A, 057A, 106A, 104A, 055A, 113A, 116A, 056...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten                                  [111A, 048A, 115A]\n",
      "senior    [097A, 059A, 051B, 054A, 117A, 094A, 061A, 024A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 13, 'senior': 14}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 3, 'senior': 8}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '014B' '016A' '040A' '041A' '042A' '043A' '044A' '045A' '046A'\n",
      " '047A' '049A' '050A' '051A' '055A' '056A' '057A' '058A' '090A' '093A'\n",
      " '104A' '106A' '108A' '109A' '110A' '113A' '116A']\n",
      "Unique Test Group IDs:\n",
      "['024A' '048A' '051B' '054A' '059A' '061A' '094A' '097A' '111A' '115A'\n",
      " '117A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "kitten    156\n",
      "senior    119\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "senior    59\n",
      "kitten    15\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "kitten    156\n",
      "senior    119\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "senior    59\n",
      "kitten    15\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 156, 1: 119})\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7927\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.8400\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2847 - accuracy: 0.8982\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2369 - accuracy: 0.9164\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.9200\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.9455\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.9418\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9564\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.9418\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9709\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9418\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9600\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9745\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1317 - accuracy: 0.9709\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9709\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.9745\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9818\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9709\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9782\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9673\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9927\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9636\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.9673\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9709\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9673\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9673\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0774 - accuracy: 0.9818\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9927\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0758 - accuracy: 0.9891\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.9855\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.9891\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.9891\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9891\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.9927\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9782\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0579 - accuracy: 0.9927\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9818\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9782\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0537 - accuracy: 0.9964\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 0.9818\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0539 - accuracy: 0.9927\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9927\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9855\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0443 - accuracy: 0.9964\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9964\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9891\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9964\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9818\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9818\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9964\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9818\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9964\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9927\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 0.9927\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9927\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0561 - accuracy: 0.9818\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9891\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9927\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9818\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0389 - accuracy: 0.9964\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9782\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9927\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9927\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 1.0000\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9927\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9964\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 0.9964\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9891\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9964\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9855\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9964\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0333 - accuracy: 0.9964\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9964\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9964\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0310 - accuracy: 0.9964\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 0.9855\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9927\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9964\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.9927\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9964\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9964\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9964\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9891\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9891\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9964\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9964\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0439 - accuracy: 0.9964\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9891\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9855\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9964\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9964\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9964\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9964\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9891\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 0.9964\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9964\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9964\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9964\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9964\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9964\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9964\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9927\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9927\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9927\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9891\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9927\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9891\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9964\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9964\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9891\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9927\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9964\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9927\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9964\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9964\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9964\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9927\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.9964\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.9964\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9964\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9927\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 0.9964\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9927\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 0.9964\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9891\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9964\n",
      "Epoch 161/300\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 131.\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 161: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0576 - accuracy: 0.9730\n",
      "3/3 [==============================] - 0s 935us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.91 (10/11)\n",
      "Before appending - Cat IDs: 42, Predictions: 42, Actuals: 42, Gender: 42\n",
      "After appending - Cat IDs: 116, Predictions: 116, Actuals: 116, Gender: 116\n",
      "Final Test Results - Loss: 0.05759727582335472, Accuracy: 0.9729729890823364, Precision: 0.9411764705882353, Recall: 0.9830508474576272, F1 Score: 0.9601293103448276\n",
      "Confusion Matrix:\n",
      " [[15  0]\n",
      " [ 2 57]]\n",
      "outer_fold 3\n",
      "Train Set Group Distribution:\n",
      "055A    20\n",
      "097A    16\n",
      "042A    14\n",
      "059A    14\n",
      "111A    13\n",
      "051A    12\n",
      "116A    12\n",
      "051B     9\n",
      "094A     8\n",
      "117A     7\n",
      "108A     6\n",
      "044A     5\n",
      "104A     4\n",
      "113A     3\n",
      "058A     3\n",
      "054A     2\n",
      "093A     2\n",
      "011A     2\n",
      "061A     2\n",
      "043A     1\n",
      "049A     1\n",
      "041A     1\n",
      "048A     1\n",
      "115A     1\n",
      "090A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "057A    27\n",
      "106A    14\n",
      "014B    10\n",
      "040A    10\n",
      "016A    10\n",
      "045A     9\n",
      "050A     7\n",
      "109A     6\n",
      "056A     3\n",
      "110A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "F    67\n",
      "X    60\n",
      "M    34\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    164\n",
      "M     24\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten     [044A, 111A, 042A, 043A, 049A, 041A, 048A, 115A]\n",
      "senior    [093A, 097A, 104A, 055A, 059A, 113A, 116A, 051...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten    [014B, 040A, 046A, 047A, 109A, 050A, 045A, 110A]\n",
      "senior                            [057A, 106A, 056A, 016A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 8, 'senior': 18}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 8, 'senior': 4}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '024A' '041A' '042A' '043A' '044A' '048A' '049A' '051A' '051B'\n",
      " '054A' '055A' '058A' '059A' '061A' '090A' '093A' '094A' '097A' '104A'\n",
      " '108A' '111A' '113A' '115A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['014B' '016A' '040A' '045A' '046A' '047A' '050A' '056A' '057A' '106A'\n",
      " '109A' '110A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "senior    124\n",
      "kitten     37\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "kitten    134\n",
      "senior     54\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "senior    124\n",
      "kitten     37\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "kitten    134\n",
      "senior     54\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({1: 124, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.9146 - accuracy: 0.6025\n",
      "Epoch 2/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7516\n",
      "Epoch 3/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7764\n",
      "Epoch 4/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7764\n",
      "Epoch 5/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.7826\n",
      "Epoch 6/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3745 - accuracy: 0.8385\n",
      "Epoch 7/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8571\n",
      "Epoch 8/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8571\n",
      "Epoch 9/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8261\n",
      "Epoch 10/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3599 - accuracy: 0.8447\n",
      "Epoch 11/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.8882\n",
      "Epoch 12/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2683 - accuracy: 0.9193\n",
      "Epoch 13/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2671 - accuracy: 0.9130\n",
      "Epoch 14/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2688 - accuracy: 0.8944\n",
      "Epoch 15/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9255\n",
      "Epoch 16/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.9068\n",
      "Epoch 17/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.9068\n",
      "Epoch 18/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2698 - accuracy: 0.8882\n",
      "Epoch 19/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2309 - accuracy: 0.9317\n",
      "Epoch 20/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9130\n",
      "Epoch 21/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.9379\n",
      "Epoch 22/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.9379\n",
      "Epoch 23/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2152 - accuracy: 0.9317\n",
      "Epoch 24/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9068\n",
      "Epoch 25/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.9503\n",
      "Epoch 26/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 0.9255\n",
      "Epoch 27/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1796 - accuracy: 0.9565\n",
      "Epoch 28/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9565\n",
      "Epoch 29/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.9379\n",
      "Epoch 30/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.9441\n",
      "Epoch 31/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1741 - accuracy: 0.9627\n",
      "Epoch 32/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9565\n",
      "Epoch 33/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.9317\n",
      "Epoch 34/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9689\n",
      "Epoch 35/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9689\n",
      "Epoch 36/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9565\n",
      "Epoch 37/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9627\n",
      "Epoch 38/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.9255\n",
      "Epoch 39/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9565\n",
      "Epoch 40/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 0.9565\n",
      "Epoch 41/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9814\n",
      "Epoch 42/300\n",
      "6/6 [==============================] - 0s 998us/step - loss: 0.1799 - accuracy: 0.9317\n",
      "Epoch 43/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.9441\n",
      "Epoch 44/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9814\n",
      "Epoch 45/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9379\n",
      "Epoch 46/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9689\n",
      "Epoch 47/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9752\n",
      "Epoch 48/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9503\n",
      "Epoch 49/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9565\n",
      "Epoch 50/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9876\n",
      "Epoch 51/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0982 - accuracy: 0.9814\n",
      "Epoch 52/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.9689\n",
      "Epoch 53/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.9814\n",
      "Epoch 54/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9689\n",
      "Epoch 55/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.9752\n",
      "Epoch 56/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 1.0000\n",
      "Epoch 57/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9752\n",
      "Epoch 58/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0820 - accuracy: 1.0000\n",
      "Epoch 59/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1121 - accuracy: 0.9689\n",
      "Epoch 60/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9689\n",
      "Epoch 61/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9876\n",
      "Epoch 62/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9814\n",
      "Epoch 63/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0973 - accuracy: 0.9814\n",
      "Epoch 64/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9876\n",
      "Epoch 65/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9814\n",
      "Epoch 66/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1009 - accuracy: 0.9689\n",
      "Epoch 67/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9752\n",
      "Epoch 68/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9814\n",
      "Epoch 69/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0705 - accuracy: 0.9876\n",
      "Epoch 70/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9814\n",
      "Epoch 71/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9938\n",
      "Epoch 72/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9938\n",
      "Epoch 73/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9876\n",
      "Epoch 74/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0689 - accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9876\n",
      "Epoch 76/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9876\n",
      "Epoch 77/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.9876\n",
      "Epoch 78/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0789 - accuracy: 0.9814\n",
      "Epoch 79/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9876\n",
      "Epoch 80/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9752\n",
      "Epoch 81/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0825 - accuracy: 0.9752\n",
      "Epoch 82/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0617 - accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9938\n",
      "Epoch 84/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0777 - accuracy: 0.9876\n",
      "Epoch 85/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9503\n",
      "Epoch 86/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0719 - accuracy: 0.9876\n",
      "Epoch 87/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.9689\n",
      "Epoch 88/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0663 - accuracy: 0.9938\n",
      "Epoch 89/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.9627\n",
      "Epoch 90/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9876\n",
      "Epoch 91/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0663 - accuracy: 0.9938\n",
      "Epoch 92/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9627\n",
      "Epoch 94/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.9876\n",
      "Epoch 95/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9876\n",
      "Epoch 96/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9814\n",
      "Epoch 97/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9814\n",
      "Epoch 98/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0862 - accuracy: 0.9876\n",
      "Epoch 99/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0590 - accuracy: 0.9938\n",
      "Epoch 100/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9876\n",
      "Epoch 104/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9938\n",
      "Epoch 105/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9876\n",
      "Epoch 106/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9876\n",
      "Epoch 107/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9814\n",
      "Epoch 108/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0476 - accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0559 - accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1015 - accuracy: 0.9627\n",
      "Epoch 113/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9938\n",
      "Epoch 114/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0596 - accuracy: 0.9938\n",
      "Epoch 115/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.9441\n",
      "Epoch 118/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9938\n",
      "Epoch 119/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0409 - accuracy: 0.9938\n",
      "Epoch 121/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9938\n",
      "Epoch 123/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9814\n",
      "Epoch 124/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9938\n",
      "Epoch 125/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9876\n",
      "Epoch 126/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0644 - accuracy: 0.9876\n",
      "Epoch 127/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9814\n",
      "Epoch 129/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0619 - accuracy: 0.9876\n",
      "Epoch 130/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0599 - accuracy: 0.9876\n",
      "Epoch 131/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0409 - accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9938\n",
      "Epoch 134/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9938\n",
      "Epoch 135/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9938\n",
      "Epoch 138/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9938\n",
      "Epoch 140/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9876\n",
      "Epoch 141/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9938\n",
      "Epoch 144/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.9565\n",
      "Epoch 145/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9938\n",
      "Epoch 147/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9938\n",
      "Epoch 150/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9938\n",
      "Epoch 151/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9876\n",
      "Epoch 152/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9938\n",
      "Epoch 158/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0579 - accuracy: 0.9876\n",
      "Epoch 160/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0443 - accuracy: 0.9876\n",
      "Epoch 161/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9938\n",
      "Epoch 163/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 0.9938\n",
      "Epoch 164/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9938\n",
      "Epoch 165/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 0.9938\n",
      "Epoch 167/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9938\n",
      "Epoch 168/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9938\n",
      "Epoch 173/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9876\n",
      "Epoch 175/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9938\n",
      "Epoch 182/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9876\n",
      "Epoch 183/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9938\n",
      "Epoch 184/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9938\n",
      "Epoch 185/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9876\n",
      "Epoch 188/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 0.9938\n",
      "Epoch 192/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9938\n",
      "Epoch 195/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9876\n",
      "Epoch 196/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9938\n",
      "Epoch 200/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.9938\n",
      "Epoch 202/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9938\n",
      "Epoch 205/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9876\n",
      "Epoch 207/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9938\n",
      "Epoch 210/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9938\n",
      "Epoch 213/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9938\n",
      "Epoch 216/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9938\n",
      "Epoch 219/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9938\n",
      "Epoch 220/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9938\n",
      "Epoch 224/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9938\n",
      "Epoch 225/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9938\n",
      "Epoch 227/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9627\n",
      "Epoch 229/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9938\n",
      "Epoch 231/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9938\n",
      "Epoch 233/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9938\n",
      "Epoch 234/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9938\n",
      "Epoch 237/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9876\n",
      "Epoch 240/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9938\n",
      "Epoch 241/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9938\n",
      "Epoch 243/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0339 - accuracy: 0.9938\n",
      "Epoch 247/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9938\n",
      "Epoch 248/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9938\n",
      "Epoch 249/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9938\n",
      "Epoch 259/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9938\n",
      "Epoch 260/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9814\n",
      "Epoch 261/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9938\n",
      "Epoch 267/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9938\n",
      "Epoch 282/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "6/6 [==============================] - 0s 987us/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9689\n",
      "Epoch 291/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9938\n",
      "Epoch 293/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9938\n",
      "Epoch 296/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9938\n",
      "Epoch 297/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9938\n",
      "Epoch 298/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9938\n",
      "6/6 [==============================] - 0s 810us/step - loss: 0.4486 - accuracy: 0.7819\n",
      "6/6 [==============================] - 0s 725us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 1.00 (12/12)\n",
      "Before appending - Cat IDs: 116, Predictions: 116, Actuals: 116, Gender: 116\n",
      "After appending - Cat IDs: 304, Predictions: 304, Actuals: 304, Gender: 304\n",
      "Final Test Results - Loss: 0.44861701130867004, Accuracy: 0.7819148898124695, Precision: 0.7490855457227139, Recall: 0.7917357656163626, F1 Score: 0.7580893199008254\n",
      "Confusion Matrix:\n",
      " [[103  31]\n",
      " [ 10  44]]\n",
      "outer_fold 4\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "057A    27\n",
      "055A    20\n",
      "097A    16\n",
      "059A    14\n",
      "106A    14\n",
      "111A    13\n",
      "051A    12\n",
      "014B    10\n",
      "016A    10\n",
      "040A    10\n",
      "045A     9\n",
      "051B     9\n",
      "094A     8\n",
      "117A     7\n",
      "050A     7\n",
      "109A     6\n",
      "044A     5\n",
      "056A     3\n",
      "011A     2\n",
      "061A     2\n",
      "054A     2\n",
      "093A     2\n",
      "048A     1\n",
      "043A     1\n",
      "115A     1\n",
      "110A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Group Distribution:\n",
      "042A    14\n",
      "116A    12\n",
      "108A     6\n",
      "104A     4\n",
      "113A     3\n",
      "058A     3\n",
      "049A     1\n",
      "041A     1\n",
      "090A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    205\n",
      "M     58\n",
      "F     41\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "F    26\n",
      "X    19\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 014B, 111A, 040A, 046A, 047A, 109A, 050...\n",
      "senior    [093A, 097A, 057A, 106A, 055A, 059A, 051B, 054...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten                      [042A, 049A, 041A]\n",
      "senior    [104A, 113A, 116A, 058A, 108A, 090A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 13, 'senior': 16}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 3, 'senior': 6}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '014B' '016A' '024A' '040A' '043A' '044A' '045A' '046A' '047A'\n",
      " '048A' '050A' '051A' '051B' '054A' '055A' '056A' '057A' '059A' '061A'\n",
      " '093A' '094A' '097A' '106A' '109A' '110A' '111A' '115A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['041A' '042A' '049A' '058A' '090A' '104A' '108A' '113A' '116A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "kitten    155\n",
      "senior    149\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "senior    29\n",
      "kitten    16\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "kitten    155\n",
      "senior    149\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "senior    29\n",
      "kitten    16\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 155, 1: 149})\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.7401\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2820 - accuracy: 0.9145\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2531 - accuracy: 0.9079\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.9441\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9342\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9474\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.9178\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9408\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9572\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9474\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.9572\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9474\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9638\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9474\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.9770\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9704\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9803\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0976 - accuracy: 0.9704\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9704\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9671\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9737\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9868\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9803\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9803\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0776 - accuracy: 0.9770\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.9803\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9868\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9770\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 1.0000\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0597 - accuracy: 0.9934\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9803\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0593 - accuracy: 0.9901\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9836\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0540 - accuracy: 0.9868\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9934\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9901\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9638\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9967\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.9803\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0599 - accuracy: 0.9836\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9737\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9901\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0400 - accuracy: 1.0000\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9901\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9770\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9901\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9737\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0352 - accuracy: 0.9934\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 0.9967\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.9836\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0454 - accuracy: 0.9901\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9803\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 1.0000\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0471 - accuracy: 0.9868\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9934\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9901\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9737\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 970us/step - loss: 0.0311 - accuracy: 0.9967\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9868\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9901\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9934\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9836\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9836\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9868\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9934\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9967\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0358 - accuracy: 0.9934\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0335 - accuracy: 0.9934\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9967\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9934\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9836\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9934\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9868\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9934\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9967\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9868\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9967\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9868\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.9934\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9934\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9967\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9967\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9967\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9967\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.9967\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 0.9901\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9934\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9934\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9967\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9967\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9934\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9967\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9868\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9967\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9934\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0357 - accuracy: 0.9836\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9967\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9934\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9868\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9967\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9901\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9967\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9934\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9967\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9967\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 0.9967\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9934\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9934\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.9967\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9967\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 0.9868\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9967\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 0.9967\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 0.9967\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 998us/step - loss: 0.0137 - accuracy: 0.9967\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0310 - accuracy: 0.9934\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9901\n",
      "Epoch 150/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 120.\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 150: early stopping\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8444\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.56 (5/9)\n",
      "Before appending - Cat IDs: 304, Predictions: 304, Actuals: 304, Gender: 304\n",
      "After appending - Cat IDs: 349, Predictions: 349, Actuals: 349, Gender: 349\n",
      "Final Test Results - Loss: 0.32947880029678345, Accuracy: 0.8444444537162781, Precision: 0.8299595141700404, Recall: 0.8512931034482758, F1 Score: 0.8363636363636363\n",
      "Confusion Matrix:\n",
      " [[14  2]\n",
      " [ 5 24]]\n",
      "\n",
      "Final Average F1-Score across all UNSEEN TEST sets: 0.8582107840436267\n",
      "\n",
      "Final Average Loss across all UNSEEN TEST sets: 0.24683027621358633\n",
      "\n",
      "Final Average Accuracy across all UNSEEN TEST sets: 0.8819759339094162\n",
      "\n",
      "Final Average Precision across all UNSEEN TEST sets: 0.8383887159535808\n",
      "\n",
      "Final Average Recall across all UNSEEN TEST sets: 0.8961032624638997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "all_cat_ids = []\n",
    "all_predicted_age_groups = []\n",
    "all_actual_age_groups = []\n",
    "all_gender = []\n",
    "\n",
    "# Define the StratifiedGroupKFold splitter for 4 fold CV with random shuffling\n",
    "outer_cv = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=int(random_seeds[1]))\n",
    "\n",
    "# unseen test set metrics\n",
    "unseen_losses, unseen_accuracies, unseen_precisions, unseen_recalls, unseen_f1 = [], [], [], [], []\n",
    "\n",
    "outer_fold = 0\n",
    "\n",
    "# Use the splitter to generate indices for training and testing sets\n",
    "# Note: GroupShuffleSplit.split returns indices, so we use it to index the arrays\n",
    "for train_val_idx, test_idx in outer_cv.split(X, y, groups):\n",
    "    outer_fold += 1\n",
    "    logger(f\"outer_fold {outer_fold}\", file=log_file_path)\n",
    "\n",
    "    # Convert indices back to DataFrame for easy manipulation\n",
    "    df_train_val = dataframe.iloc[train_val_idx]\n",
    "    df_test = dataframe.iloc[test_idx]\n",
    "\n",
    "    ##############################\n",
    "    # ASSESSING SPLITS BY CAT_ID #\n",
    "    ##############################\n",
    "    \n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test['cat_id'].value_counts()  \n",
    "    \n",
    "    # Log or print the distribution\n",
    "    logger(f\"Train Set Group Distribution:\\n{training_validation_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Group Distribution:\\n{testing_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test['gender'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Training Set Gender Distribution BEFORE SWAP:\\n{training_gender_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Gender Distribution BEFORE SWAP:\\n{testing_gender_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Group by 'age_group' and then list unique 'cat_id' within each age group\n",
    "    unique_cat_ids_per_age_group_train_val = df_train_val.groupby('age_group')['cat_id'].unique()\n",
    "    unique_cat_ids_per_age_group_test = df_test.groupby('age_group')['cat_id'].unique()\n",
    "    \n",
    "    # Log results\n",
    "    logger(f\"Unique Cat IDs per Age Group in Training/Validation Set:\\n{unique_cat_ids_per_age_group_train_val}\", file=log_file_path)\n",
    "    logger(f\"Unique Cat IDs per Age Group in Testing Set:\\n{unique_cat_ids_per_age_group_test}\", file=log_file_path)\n",
    "\n",
    "    # Calculate the count of unique identifiers per age group for training and testing set\n",
    "    counts_train_val = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_train_val.items()}\n",
    "    counts_test = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_test.items()}\n",
    "\n",
    "    # Log the counts of unique identifiers per age group\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Training/Validation Set:\\n{counts_train_val}\", file=log_file_path)\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Testing Set:\\n{counts_test}\", file=log_file_path)\n",
    "\n",
    "    #######################################################\n",
    "    # CONTINUE WITH ENSURING VALID AND APPROPRIATE SPLITS #\n",
    "    #######################################################\n",
    "    \n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    groups_train_val, groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # logging identifier splits \n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "\n",
    "    # # check group splits\n",
    "    # check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # # Specify the cat_ids that must be in the training/validation set\n",
    "    # specific_cat_ids = ['000A', '046A']\n",
    "    \n",
    "    # # Perform the swapping operation\n",
    "    # train_val_idx, test_idx = swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids)\n",
    "    \n",
    "    # # Re-assign the sets based on the updated indices\n",
    "    # X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    # y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    # new_groups_train_val, new_groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # # Find differences for training and test sets\n",
    "    # moved_to_train_val, removed_from_train_val = find_group_differences(groups_train_val, new_groups_train_val)\n",
    "    # moved_to_test, removed_from_test = find_group_differences(groups_test, new_groups_test)\n",
    "    \n",
    "    # # Display the results\n",
    "    # logger(f\"Moved to Training/Validation Set:\\n{moved_to_train_val}\", file=log_file_path)\n",
    "    # logger(f\"Removed from Training/Validation Set:\\n{removed_from_train_val}\", file=log_file_path)\n",
    "    # logger(f\"Moved to Test Set:\\n{moved_to_test}\", file=log_file_path)\n",
    "    # logger(f\"Removed from Test Set\\n{removed_from_test}\", file=log_file_path)\n",
    "\n",
    "    # # Update X_train_val, X_test, y_train_val, y_test, groups_train_val, groups_test based on updated indices\n",
    "    # X_train_val = X[train_val_idx]\n",
    "    # y_train_val = y[train_val_idx]\n",
    "    # groups_train_val = groups[train_val_idx]\n",
    "    \n",
    "    # X_test = X[test_idx]\n",
    "    # y_test = y[test_idx]\n",
    "    # groups_test = groups[test_idx]\n",
    "\n",
    "    # # logging identifier splits again after potential swaps\n",
    "    # unique_train_val_groups = np.unique(groups_train_val)\n",
    "    # unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    # logger(f\"AFTER SWAP - Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    # logger(f\"AFTER SWAP - Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "    \n",
    "    # # Verify the lengths are consistent\n",
    "    # logger(f\"Length of X_train_val:\\n{len(X_train_val)}\", file=log_file_path)\n",
    "    # logger(f\"Length of y_train_val:\\n{len(y_train_val)}\", file=log_file_path)\n",
    "    # logger(f\"Length of groups_train_val:\\n{len(groups_train_val)}\", file=log_file_path)\n",
    "\n",
    "    # # Check group splits once more\n",
    "    # check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Convert the modified indices back to a DataFrame representing the updated df_train_val\n",
    "    df_train_val_updated = dataframe.iloc[train_val_idx].copy()\n",
    "    df_test_updated = dataframe.iloc[test_idx].copy()\n",
    "\n",
    "    ############################\n",
    "    # LOGGING AGE GROUP SPLITS #\n",
    "    ############################\n",
    "\n",
    "    # Get the distribution of age groups of age groups before the update\n",
    "    training_validation_age_group_distribution = df_train_val['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test['age_group'].value_counts()\n",
    "    \n",
    "    # Logthe distribution\n",
    "    logger(f\"Train Age Group Distribution BEFORE SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution BEFORE SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Get the distribution of age groups after the update\n",
    "    training_validation_age_group_distribution = df_train_val_updated['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test_updated['age_group'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Train Age Group Distribution AFTER SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution AFTER SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "    \n",
    "    ########################################################\n",
    "    # TRACKING FINAL CAT_IDs & GENDER AFTER REDISTRIBUTION #\n",
    "    ########################################################\n",
    "\n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val_updated['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test_updated['cat_id'].value_counts()  \n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val_updated['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test_updated['gender'].value_counts()\n",
    "    \n",
    "    logger(f\"\\n Starting training on unseen test set\\n\", file=log_file_path)\n",
    "\n",
    "    ###################\n",
    "    # PREPARING MODEL #\n",
    "    ###################\n",
    "\n",
    "    # Calculate the distribution of age groups in y_train_val\n",
    "    age_group_distribution = Counter(y_train_val)\n",
    "    print(\"Age group distribution:\", age_group_distribution)\n",
    "\n",
    "    # EarlyStopping callback: monitor 'loss' instead of 'val_loss' for the test set\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='loss',  \n",
    "        min_delta=0.001, \n",
    "        patience=30,  \n",
    "        verbose=1,  \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "\n",
    "    # One final shuffle to ensure randomness\n",
    "    outer_shuffle_idx = np.random.permutation(len(X_train_val))\n",
    "    X_train_val = X_train_val[outer_shuffle_idx]\n",
    "    y_train_val = y_train_val[outer_shuffle_idx]\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler_full = StandardScaler().fit(X_train_val)\n",
    "    X_train_full_scaled = scaler_full.transform(X_train_val)\n",
    "    X_test_scaled = scaler_full.transform(X_test)\n",
    "    \n",
    "    # Encode the labels\n",
    "    y_train_full_encoded = y_train_val.astype('float32')\n",
    "    y_test_encoded = y_test.astype('float32')\n",
    "\n",
    "    #######################\n",
    "    # BUILD & TRAIN MODEL #\n",
    "    #######################\n",
    "\n",
    "    # Define optimizers\n",
    "    optimizers = {\n",
    "        'Adamax': Adamax(learning_rate=0.00038188800331973483)\n",
    "    }\n",
    "    \n",
    "    # Full model definition with dynamic number of layers\n",
    "    model_full = Sequential()\n",
    "    model_full.add(Dense(480, activation='relu', input_shape=(X_train_full_scaled.shape[1],)))  # units and input shape from parameters\n",
    "    model_full.add(BatchNormalization())\n",
    "    model_full.add(Dropout(0.27188281261238406))\n",
    "    model_full.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = optimizers['Adamax']  # optimizer selection\n",
    "    \n",
    "    # Compile the model for binary classification\n",
    "    model_full.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model on the full training set\n",
    "    history_full = model_full.fit(X_train_full_scaled, y_train_full_encoded, epochs=300, batch_size=32,\n",
    "                                  verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on the held-out test set\n",
    "    test_loss, test_accuracy = model_full.evaluate(X_test_scaled, y_test_encoded)\n",
    "\n",
    "    # y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    # y_test_pred = np.argmax(y_test_pred_prob, axis=1)  \n",
    "    # y_test_true = np.argmax(y_test_encoded, axis=1)    \n",
    "\n",
    "    # Predict probabilities for the test set\n",
    "    y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    \n",
    "    # Convert probabilities to class labels (0 or 1) using a threshold of 0.5\n",
    "    y_test_pred = (y_test_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # y_test_encoded should be a 1D array of 0s and 1s if prepared as suggested for binary classification\n",
    "    y_test_true = y_test_encoded\n",
    "\n",
    "    ################################\n",
    "    # LOG MAJORITY VOTE PER CAT_ID #\n",
    "    ################################\n",
    "\n",
    "    # Convert numeric predictions back to age group labels\n",
    "    predicted_age_groups = y_test_pred\n",
    "    actual_labels = y_test_true\n",
    "    \n",
    "    # Map predictions and actual labels back to cat_ids\n",
    "    test_results = pd.DataFrame({\n",
    "        'cat_id': df_test_updated['cat_id'],\n",
    "        'predicted_age_group': predicted_age_groups,\n",
    "        'actual_age_group': actual_labels\n",
    "    })\n",
    "    \n",
    "    # Group by cat_id and aggregate predicted age groups\n",
    "    majority_votes = test_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "    actual_groups = test_results.groupby('cat_id')['actual_age_group'].first()\n",
    "    \n",
    "    # Calculate the accuracy of majority voting\n",
    "    correct_predictions = (majority_votes == actual_groups).sum()\n",
    "    total_cats = len(actual_groups)\n",
    "    majority_vote_accuracy = correct_predictions / total_cats\n",
    "    \n",
    "    # Log the accuracy of the majority voting\n",
    "    logger(f\"Majority Vote Accuracy for cat_id for this fold: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)\n",
    "\n",
    "    ####################################################\n",
    "    # COLLECT PREDICTIONS FOR GENDER & CAT_ID ANALYSIS #\n",
    "    ####################################################\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'Before appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Extend lists with current fold results\n",
    "    all_cat_ids.extend(df_test_updated['cat_id'].tolist())\n",
    "    all_predicted_age_groups.extend(predicted_age_groups)\n",
    "    all_actual_age_groups.extend(actual_labels)\n",
    "    all_gender.extend(df_test_updated['gender'].tolist())\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'After appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    test_precision = precision_score(y_test_true, y_test_pred, average='macro')  # Use 'macro' for imbalanced datasets\n",
    "    test_recall = recall_score(y_test_true, y_test_pred, average='macro')\n",
    "    test_f1 = f1_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "    # prepare averages of outer metrics\n",
    "    unseen_f1.append(test_f1)\n",
    "    unseen_losses.append(test_loss)\n",
    "    unseen_accuracies.append(test_accuracy)\n",
    "    unseen_precisions.append(test_precision)\n",
    "    unseen_recalls.append(test_recall)\n",
    "\n",
    "    # Print final test results\n",
    "    logger(f\"Final Test Results - Loss: {test_loss}, Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}\", file=log_file_path)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    logger(f\"Confusion Matrix:\\n {cm}\", file=log_file_path)\n",
    "\n",
    "# Calculate the overall average metrics\n",
    "unseen_set_avg_f1 = np.mean(unseen_f1)\n",
    "unseen_set_avg_loss = np.mean(unseen_losses)\n",
    "unseen_set_avg_acc = np.mean(unseen_accuracies)\n",
    "unseen_set_avg_precision = np.mean(unseen_precisions)\n",
    "unseen_set_avg_recall = np.mean(unseen_recalls)\n",
    "\n",
    "logger(f\"\\nFinal Average F1-Score across all UNSEEN TEST sets: {unseen_set_avg_f1}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Loss across all UNSEEN TEST sets: {unseen_set_avg_loss}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Accuracy across all UNSEEN TEST sets: {unseen_set_avg_acc}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Precision across all UNSEEN TEST sets: {unseen_set_avg_precision}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Recall across all UNSEEN TEST sets: {unseen_set_avg_recall}\\n\", file=log_file_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2845ad-17c1-494a-8bd0-971aefca9f01",
   "metadata": {},
   "source": [
    "## Majority Voting on Total Entries per cat_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3910db95-6772-4098-bef1-fb5857901e5c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking - Cat IDs: 349, Predictions: 349, Actuals: 349, Gender: 349\n"
     ]
    }
   ],
   "source": [
    "# Debugging print statements\n",
    "print(f'Checking - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d543c7c2-c11b-4511-ba5a-c52969a61a62",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create results df\n",
    "full_results = pd.DataFrame({\n",
    "    'cat_id': all_cat_ids,\n",
    "    'predicted_age_group': all_predicted_age_groups,\n",
    "    'actual_age_group': all_actual_age_groups,\n",
    "    'all_gender': all_gender\n",
    "})\n",
    "\n",
    "# create a correct majority prediction column\n",
    "full_results['correct'] = full_results['predicted_age_group'] == full_results['actual_age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6b6f2173-89a8-40ba-afa6-410005c2dcb1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Majority Vote Accuracy for cat_id: 0.84 (32/38)\n"
     ]
    }
   ],
   "source": [
    "# Group by cat_id and aggregate predicted age groups\n",
    "majority_votes = full_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first()\n",
    "\n",
    "# Calculate the accuracy of majority voting\n",
    "correct_predictions = (majority_votes == actual_groups).sum()\n",
    "total_cats = len(actual_groups)\n",
    "majority_vote_accuracy = correct_predictions / total_cats\n",
    "\n",
    "logger(f\"Overall Majority Vote Accuracy for cat_id: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "aa8d9ba5-9d96-4aee-b3e2-ba87553d1899",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Detailed df with predictions, actual labels, and comparison including majority vote\n",
    "detailed_results = full_results.groupby('cat_id').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Predictions': list(x['predicted_age_group']),\n",
    "        'Majority Vote': x['predicted_age_group'].mode()[0],\n",
    "        'Actual Age Group': x['actual_age_group'].iloc[0],\n",
    "        'Correct Majority Vote': x['predicted_age_group'].mode()[0] == x['actual_age_group'].iloc[0]\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Convert to DataFrame for better formatting and display\n",
    "detailed_results = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0b4ff1f7-d22d-4409-98d4-49e9a82bcb58",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Majority Vote</th>\n",
       "      <th>Actual Age Group</th>\n",
       "      <th>Correct Majority Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>011A</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>104A</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>014B</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>057A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>059A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>090A</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>094A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>097A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>106A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>054A</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>109A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>110A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>111A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>113A</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>115A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>116A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>055A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>056A</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>051B</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>046A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>016A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>024A</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>040A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>042A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>043A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>044A</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>051A</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>045A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>047A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>048A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>050A</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>117A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>093A</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>108A</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>061A</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>041A</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>049A</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>058A</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat_id                                        Predictions  Majority Vote  Actual Age Group  Correct Majority Vote\n",
       "0    011A                                             [1, 1]              1               1.0                   True\n",
       "28   104A                                       [1, 1, 1, 1]              1               1.0                   True\n",
       "1    014B                     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]              0               0.0                   True\n",
       "20   057A  [1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, ...              1               1.0                   True\n",
       "22   059A         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "24   090A                                                [1]              1               1.0                   True\n",
       "26   094A                           [1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "27   097A   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]              1               1.0                   True\n",
       "29   106A         [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]              1               1.0                   True\n",
       "17   054A                                             [1, 1]              1               1.0                   True\n",
       "31   109A                                 [0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "32   110A                                                [0]              0               0.0                   True\n",
       "33   111A            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "34   113A                                          [1, 1, 1]              1               1.0                   True\n",
       "35   115A                                                [0]              0               0.0                   True\n",
       "36   116A               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "18   055A  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              1               1.0                   True\n",
       "19   056A                                          [1, 1, 1]              1               1.0                   True\n",
       "16   051B                        [1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "10   046A  [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...              0               0.0                   True\n",
       "2    016A                     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "3    024A                                                [1]              1               1.0                   True\n",
       "4    040A                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "6    042A         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "7    043A                                                [0]              0               0.0                   True\n",
       "8    044A                                    [0, 0, 0, 0, 0]              0               0.0                   True\n",
       "15   051A               [1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "9    045A                        [0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "11   047A  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...              0               0.0                   True\n",
       "12   048A                                                [0]              0               0.0                   True\n",
       "14   050A                              [0, 1, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "37   117A                              [1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "25   093A                                             [0, 1]              0               1.0                  False\n",
       "30   108A                                 [0, 1, 1, 1, 0, 0]              0               1.0                  False\n",
       "23   061A                                             [0, 1]              0               1.0                  False\n",
       "5    041A                                                [1]              1               0.0                  False\n",
       "13   049A                                                [1]              1               0.0                  False\n",
       "21   058A                                          [1, 0, 0]              0               1.0                  False"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "sorted_detailed_results = detailed_results.sort_values(by='Correct Majority Vote', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5ec47984-bc63-4f3f-a7a4-d3979dbd4c52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Majority Votes per Class:\n",
      "actual_age_group\n",
      "0.0    14\n",
      "1.0    18\n",
      "Name: Majority_Correct, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create df for majority votes\n",
    "majority_df = majority_votes.reset_index()\n",
    "majority_df.columns = ['cat_id', 'Majority_Vote']\n",
    "\n",
    "# Get actual groups for each cat_id\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first().reset_index()\n",
    "\n",
    "# Merge majority votes with actual groups\n",
    "majority_with_actual = pd.merge(majority_df, actual_groups, on='cat_id')\n",
    "\n",
    "# Add a column to check if the majority vote was correct\n",
    "majority_with_actual['Majority_Correct'] = majority_with_actual['Majority_Vote'] == majority_with_actual['actual_age_group']\n",
    "\n",
    "# Count correct majority votes per class\n",
    "correct_majority_votes_per_class = majority_with_actual.groupby('actual_age_group')['Majority_Correct'].sum()\n",
    "\n",
    "print(\"Correct Majority Votes per Class:\")\n",
    "print(correct_majority_votes_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "952d49d2-180d-4f36-85b0-6e2b96610559",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics for Majority Votes:\n",
      "   actual_age_group  total_count  correct_count   accuracy\n",
      "0               0.0           16             14  87.500000\n",
      "1               1.0           22             18  81.818182\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = majority_with_actual.groupby('actual_age_group').agg(\n",
    "    total_count=('Majority_Correct', 'size'),  # Total number of cases per class\n",
    "    correct_count=('Majority_Correct', 'sum')  # Sum of correct predictions per class\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log detailed stats\n",
    "print(\"Detailed Class Statistics for Majority Votes:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6a94de06-f9df-49f6-99e7-abc9024f3dc0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics for Majority Votes\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Accuracy of Majority Votes by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885dd133-e156-4b01-8e84-4d94546e0eca",
   "metadata": {},
   "source": [
    "## Detailed Class Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "dd0127df-e0fb-4862-9ac4-2113bd346e78",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics:\n",
      "   actual_age_group  total_count  correct_count   accuracy\n",
      "0               0.0          171            138  80.701754\n",
      "1               1.0          178            158  88.764045\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = full_results.groupby('actual_age_group').agg(\n",
    "    total_count=('correct', 'size'),\n",
    "    correct_count=('correct', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log the detailed stats\n",
    "print(\"Detailed Class Statistics:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4a0df220-5e5c-4c46-8474-ac4ecf291071",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics (Overall)\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Overall Accuracy by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a7528-860f-45b0-8c00-d0ddf10a0d8f",
   "metadata": {},
   "source": [
    "## Gender Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2924eee7-fd8b-4cee-9e43-bb0352e4c43b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Gender:\n",
      "  all_gender  count  correct  accuracy\n",
      "0          F     67       62     92.54\n",
      "1          M     58       55     94.83\n",
      "2          X    224      179     79.91\n"
     ]
    }
   ],
   "source": [
    "# Group by gender and calculate the total count, correct predictions, and accuracy\n",
    "gender_stats = full_results.groupby('all_gender').agg(\n",
    "    count=('cat_id', 'size'),  # Total number of cases per gender\n",
    "    correct=('correct', 'sum')  # Sum of correct predictions per gender\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each gender\n",
    "gender_stats['accuracy'] = (gender_stats['correct'] / gender_stats['count'] * 100).round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy by Gender:\")\n",
    "print(gender_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b7b2139e-f100-44e6-aff4-807f96753499",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Accuracy by Gender\n",
    "styled_barplot(gender_stats, 'all_gender', 'accuracy', \n",
    "               'Accuracy by Gender', \n",
    "               'Gender', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df58f49-cac6-40b1-8422-e3d95576c453",
   "metadata": {},
   "source": [
    "# RANDOM SEED 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "bf9d1b64-575e-47ca-bf37-e8916438d506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senior    178\n",
      "kitten    171\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(int(random_seeds[2]))\n",
    "np.random.seed(int(random_seeds[2]))\n",
    "tf.random.set_seed(int(random_seeds[2]))\n",
    "\n",
    "# Load datasets\n",
    "dataframe = pd.read_csv('/Users/astrid/PycharmProjects/audioset-thesis-work/audioset/vggish/embeddings/8april_looped_embeddings.csv')\n",
    "\n",
    "dataframe.drop('mean_freq', axis=1, inplace=True)\n",
    "\n",
    "def assign_age_group(age, age_groups):\n",
    "    for group_name, age_range in age_groups.items():\n",
    "        if age_range[0] <= age < age_range[1]:\n",
    "            return group_name\n",
    "    return 'Unknown'  # For any age that doesn't fit the defined groups\n",
    "\n",
    "# Define age groups\n",
    "age_groups = {\n",
    "    'kitten': (0, 0.5),\n",
    "    'adult': (0.5, 12),\n",
    "    'senior': (12, 20)\n",
    "}\n",
    "\n",
    "# Create a new column for the age group\n",
    "dataframe['age_group'] = dataframe['target'].apply(assign_age_group, age_groups=age_groups)\n",
    "\n",
    "# Drop Adult\n",
    "dataframe.drop(dataframe[dataframe['age_group'] == 'adult'].index, inplace=True)\n",
    "\n",
    "print(dataframe['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "91d5db1d-6c9f-4047-97b9-5a0eef4fbaaa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = dataframe.iloc[:, :-4].values  # all columns except the last four\n",
    "\n",
    "# Encode the 'age_group' column as integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y = label_encoder.fit_transform(dataframe['age_group'].values)\n",
    "\n",
    "# Use the encoded labels for splitting and one-hot encoding\n",
    "y = encoded_y  \n",
    "\n",
    "# Convert 'cat_id' column to numpy array to be used as groups array for GroupKFold\n",
    "groups = dataframe['cat_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e435598c-cabc-4129-8504-68aac9cc06bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e29b526-5098-4ce6-bc77-a93d1e6e1397",
   "metadata": {},
   "source": [
    "## Run Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "79a922e6-198c-4c43-a6f2-90dc580ae875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_fold 1\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "055A    20\n",
      "097A    16\n",
      "106A    14\n",
      "042A    14\n",
      "059A    14\n",
      "111A    13\n",
      "051A    12\n",
      "116A    12\n",
      "016A    10\n",
      "040A    10\n",
      "051B     9\n",
      "045A     9\n",
      "094A     8\n",
      "050A     7\n",
      "109A     6\n",
      "108A     6\n",
      "044A     5\n",
      "104A     4\n",
      "056A     3\n",
      "058A     3\n",
      "113A     3\n",
      "011A     2\n",
      "054A     2\n",
      "093A     2\n",
      "041A     1\n",
      "049A     1\n",
      "043A     1\n",
      "048A     1\n",
      "115A     1\n",
      "090A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "057A    27\n",
      "014B    10\n",
      "117A     7\n",
      "061A     2\n",
      "110A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    186\n",
      "F     60\n",
      "M     55\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    38\n",
      "F     7\n",
      "M     3\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 111A, 040A, 046A, 047A, 042A, 109A, 050...\n",
      "senior    [093A, 097A, 106A, 104A, 055A, 059A, 113A, 116...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten                [014B, 110A]\n",
      "senior    [057A, 117A, 061A, 024A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 14, 'senior': 18}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 2, 'senior': 4}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '016A' '040A' '041A' '042A' '043A' '044A' '045A' '046A' '047A'\n",
      " '048A' '049A' '050A' '051A' '051B' '054A' '055A' '056A' '058A' '059A'\n",
      " '090A' '093A' '094A' '097A' '104A' '106A' '108A' '109A' '111A' '113A'\n",
      " '115A' '116A']\n",
      "Unique Test Group IDs:\n",
      "['014B' '024A' '057A' '061A' '110A' '117A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "kitten    160\n",
      "senior    141\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "senior    37\n",
      "kitten    11\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "kitten    160\n",
      "senior    141\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "senior    37\n",
      "kitten    11\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 160, 1: 141})\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.6213\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.8239\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8571\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2918 - accuracy: 0.8904\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9336\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.9169\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.9236\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.9369\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.9336\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9601\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9435\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9635\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9635\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9734\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9701\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9701\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9801\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9668\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9734\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9767\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0774 - accuracy: 0.9867\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9834\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9834\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0826 - accuracy: 0.9867\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9701\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9834\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.9801\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0815 - accuracy: 0.9767\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0793 - accuracy: 0.9834\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9734\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0866 - accuracy: 0.9834\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9900\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9867\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9867\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9967\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9967\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0571 - accuracy: 0.9867\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9867\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9900\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9900\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0620 - accuracy: 0.9867\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0531 - accuracy: 0.9867\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9967\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9900\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0489 - accuracy: 0.9867\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9967\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 0.9900\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9900\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9967\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9900\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 1.0000\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9934\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 1.0000\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 0.9967\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0538 - accuracy: 0.9867\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9934\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9867\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0400 - accuracy: 0.9900\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9934\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9900\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9934\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9967\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0579 - accuracy: 0.9900\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9867\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9834\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0489 - accuracy: 0.9900\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9900\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 1.0000\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.9934\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9900\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9967\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9967\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9934\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9967\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9967\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9967\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9967\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9934\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9967\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9934\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9934\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9967\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9934\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9934\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9967\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9967\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9967\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9967\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.9967\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9967\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 967us/step - loss: 0.0388 - accuracy: 0.9900\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 0.9967\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9967\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9900\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9834\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9900\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9900\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9934\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0200 - accuracy: 0.9967\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9967\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 0.9967\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9934\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9934\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9967\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.9967\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9967\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 0.9967\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9934\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 117.\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 147: early stopping\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8542\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.83 (5/6)\n",
      "Before appending - Cat IDs: 0, Predictions: 0, Actuals: 0, Gender: 0\n",
      "After appending - Cat IDs: 48, Predictions: 48, Actuals: 48, Gender: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Results - Loss: 0.3068283498287201, Accuracy: 0.8541666865348816, Precision: 0.7920168067226891, Recall: 0.8415233415233416, F1 Score: 0.8107042253521127\n",
      "Confusion Matrix:\n",
      " [[ 9  2]\n",
      " [ 5 32]]\n",
      "outer_fold 2\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "057A    27\n",
      "097A    16\n",
      "106A    14\n",
      "042A    14\n",
      "111A    13\n",
      "116A    12\n",
      "014B    10\n",
      "016A    10\n",
      "051B     9\n",
      "045A     9\n",
      "117A     7\n",
      "108A     6\n",
      "109A     6\n",
      "044A     5\n",
      "056A     3\n",
      "058A     3\n",
      "113A     3\n",
      "054A     2\n",
      "093A     2\n",
      "061A     2\n",
      "049A     1\n",
      "048A     1\n",
      "115A     1\n",
      "110A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "055A    20\n",
      "059A    14\n",
      "051A    12\n",
      "040A    10\n",
      "094A     8\n",
      "050A     7\n",
      "104A     4\n",
      "011A     2\n",
      "043A     1\n",
      "041A     1\n",
      "090A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    205\n",
      "M     36\n",
      "F     28\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "F    39\n",
      "M    22\n",
      "X    19\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 014B, 111A, 046A, 047A, 042A, 109A, 049...\n",
      "senior    [093A, 097A, 057A, 106A, 113A, 116A, 051B, 054...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten                      [040A, 050A, 043A, 041A]\n",
      "senior    [104A, 055A, 059A, 051A, 094A, 011A, 090A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 12, 'senior': 15}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 4, 'senior': 7}\n",
      "Unique Training/Validation Group IDs:\n",
      "['014B' '016A' '024A' '042A' '044A' '045A' '046A' '047A' '048A' '049A'\n",
      " '051B' '054A' '056A' '057A' '058A' '061A' '093A' '097A' '106A' '108A'\n",
      " '109A' '110A' '111A' '113A' '115A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['011A' '040A' '041A' '043A' '050A' '051A' '055A' '059A' '090A' '094A'\n",
      " '104A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "kitten    152\n",
      "senior    117\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "senior    61\n",
      "kitten    19\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "kitten    152\n",
      "senior    117\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "senior    61\n",
      "kitten    19\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 152, 1: 117})\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.6431\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7993\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.8327\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3155 - accuracy: 0.8625\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2611 - accuracy: 0.9182\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.9294\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.9033\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.9331\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.9554\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.9331\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1546 - accuracy: 0.9628\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9405\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9703\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.9703\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9703\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9665\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.9703\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9814\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.9740\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9703\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9851\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0915 - accuracy: 0.9814\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9777\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1027 - accuracy: 0.9703\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1037 - accuracy: 0.9703\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9517\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9851\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.9777\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0797 - accuracy: 0.9926\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0820 - accuracy: 0.9926\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.9814\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0876 - accuracy: 0.9777\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9926\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0681 - accuracy: 0.9888\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9888\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.9851\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 982us/step - loss: 0.0833 - accuracy: 0.9740\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9888\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0682 - accuracy: 0.9888\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0975 - accuracy: 0.9703\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9703\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 1.0000\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.0643 - accuracy: 0.9851\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9851\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0800 - accuracy: 0.9777\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9888\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 961us/step - loss: 0.0591 - accuracy: 0.9926\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9926\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 1.0000\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 984us/step - loss: 0.0650 - accuracy: 0.9926\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0422 - accuracy: 0.9963\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9740\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 0.9926\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9851\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 1.0000\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0681 - accuracy: 0.9814\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9926\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0528 - accuracy: 0.9963\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9888\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0670 - accuracy: 0.9888\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 0.9814\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9963\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 1.0000\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9926\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 0.9926\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0596 - accuracy: 0.9814\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9926\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0443 - accuracy: 0.9963\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9888\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9963\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9963\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0422 - accuracy: 0.9963\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9888\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9963\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9888\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9703\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9851\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9926\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9963\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9963\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9926\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9926\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9963\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0460 - accuracy: 0.9888\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0335 - accuracy: 0.9888\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9926\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 0.9963\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 0.0300 - accuracy: 0.9963\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9963\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 978us/step - loss: 0.0297 - accuracy: 0.9963\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9963\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9963\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9963\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9926\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9888\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9963\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9963\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9777\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9926\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9963\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9963\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9926\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9963\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9963\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9963\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9963\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9963\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9963\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9963\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9926\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9926\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.9963\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9963\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.9963\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9963\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9888\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9963\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9963\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9926\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9963\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0281 - accuracy: 0.9888\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.9851\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9926\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.9963\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9963\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 0.9963\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9963\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9963\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9963\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0200 - accuracy: 0.9963\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0310 - accuracy: 0.9926\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9851\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9963\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 956us/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.9926\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9963\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.9963\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 0.9963\n",
      "Epoch 182/300\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 152.\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 182: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9500\n",
      "3/3 [==============================] - 0s 916us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 1.00 (11/11)\n",
      "Before appending - Cat IDs: 48, Predictions: 48, Actuals: 48, Gender: 48\n",
      "After appending - Cat IDs: 128, Predictions: 128, Actuals: 128, Gender: 128\n",
      "Final Test Results - Loss: 0.0845973938703537, Accuracy: 0.949999988079071, Precision: 0.9200968523002422, Recall: 0.9490940465918896, F1 Score: 0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[18  1]\n",
      " [ 3 58]]\n",
      "outer_fold 3\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "057A    27\n",
      "055A    20\n",
      "097A    16\n",
      "042A    14\n",
      "059A    14\n",
      "051A    12\n",
      "014B    10\n",
      "040A    10\n",
      "045A     9\n",
      "094A     8\n",
      "050A     7\n",
      "117A     7\n",
      "108A     6\n",
      "104A     4\n",
      "056A     3\n",
      "011A     2\n",
      "061A     2\n",
      "041A     1\n",
      "043A     1\n",
      "048A     1\n",
      "115A     1\n",
      "110A     1\n",
      "090A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "106A    14\n",
      "111A    13\n",
      "116A    12\n",
      "016A    10\n",
      "051B     9\n",
      "109A     6\n",
      "044A     5\n",
      "113A     3\n",
      "058A     3\n",
      "093A     2\n",
      "054A     2\n",
      "049A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    192\n",
      "F     52\n",
      "M     25\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "M    33\n",
      "X    32\n",
      "F    15\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [014B, 040A, 046A, 047A, 042A, 050A, 043A, 041...\n",
      "senior    [097A, 057A, 104A, 055A, 059A, 117A, 056A, 051...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten                            [044A, 111A, 109A, 049A]\n",
      "senior    [093A, 106A, 113A, 116A, 051B, 054A, 058A, 016A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 12, 'senior': 14}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 4, 'senior': 8}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '014B' '024A' '040A' '041A' '042A' '043A' '045A' '046A' '047A'\n",
      " '048A' '050A' '051A' '055A' '056A' '057A' '059A' '061A' '090A' '094A'\n",
      " '097A' '104A' '108A' '110A' '115A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['016A' '044A' '049A' '051B' '054A' '058A' '093A' '106A' '109A' '111A'\n",
      " '113A' '116A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "kitten    146\n",
      "senior    123\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "senior    55\n",
      "kitten    25\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "kitten    146\n",
      "senior    123\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "senior    55\n",
      "kitten    25\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 146, 1: 123})\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6771 - accuracy: 0.6283\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8625\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2761 - accuracy: 0.9108\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.9108\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.9294\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.9442\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1423 - accuracy: 0.9740\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9442\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9703\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1322 - accuracy: 0.9628\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9777\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9442\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9740\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9591\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9814\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1027 - accuracy: 0.9814\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9703\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9665\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9888\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0878 - accuracy: 0.9851\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9777\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9888\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.9851\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1038 - accuracy: 0.9777\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9591\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9740\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0880 - accuracy: 0.9814\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9926\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9740\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.9851\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9814\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0782 - accuracy: 0.9851\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0681 - accuracy: 0.9888\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0589 - accuracy: 0.9888\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9851\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9888\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.9888\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.9851\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0534 - accuracy: 0.9888\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9851\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9963\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9814\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9888\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 1.0000\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9963\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0453 - accuracy: 0.9926\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9963\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0557 - accuracy: 0.9851\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9926\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 0.9926\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9963\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9851\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9777\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0685 - accuracy: 0.9740\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 1.0000\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9851\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 1.0000\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9926\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9963\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9963\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9888\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0551 - accuracy: 0.9851\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9963\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9740\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9926\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9926\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9963\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9963\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9926\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9963\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9926\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9926\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0474 - accuracy: 0.9926\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9926\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9963\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0513 - accuracy: 0.9851\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.9888\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0311 - accuracy: 0.9926\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 0.9926\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9888\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9926\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9926\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9963\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9926\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.9888\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9963\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9963\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9963\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.9963\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 0.9963\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9926\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9963\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9963\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9963\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9963\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9963\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0281 - accuracy: 0.9926\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9963\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 0.9963\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9926\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9926\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9851\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9926\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.9963\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 0.9851\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.9963\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 0.9963\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 0.9963\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0371 - accuracy: 0.9888\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9963\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9963\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9926\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 0.9926\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9888\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.9963\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9926\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9888\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0341 - accuracy: 0.9926\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9926\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0318 - accuracy: 0.9963\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9963\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 0.9963\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 0.9963\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9963\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9963\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.9963\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.9888\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0477 - accuracy: 0.9814\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9851\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9926\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 192.\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9963\n",
      "Epoch 222: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3140 - accuracy: 0.8625\n",
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy for cat_id for this fold: 0.83 (10/12)\n",
      "Before appending - Cat IDs: 128, Predictions: 128, Actuals: 128, Gender: 128\n",
      "After appending - Cat IDs: 208, Predictions: 208, Actuals: 208, Gender: 208\n",
      "Final Test Results - Loss: 0.3139762878417969, Accuracy: 0.862500011920929, Precision: 0.8472222222222222, Recall: 0.9, F1 Score: 0.8542805100182149\n",
      "Confusion Matrix:\n",
      " [[25  0]\n",
      " [11 44]]\n",
      "outer_fold 4\n",
      "Train Set Group Distribution:\n",
      "057A    27\n",
      "055A    20\n",
      "106A    14\n",
      "059A    14\n",
      "111A    13\n",
      "051A    12\n",
      "116A    12\n",
      "016A    10\n",
      "040A    10\n",
      "014B    10\n",
      "051B     9\n",
      "094A     8\n",
      "117A     7\n",
      "050A     7\n",
      "109A     6\n",
      "044A     5\n",
      "104A     4\n",
      "058A     3\n",
      "113A     3\n",
      "061A     2\n",
      "011A     2\n",
      "054A     2\n",
      "093A     2\n",
      "049A     1\n",
      "041A     1\n",
      "043A     1\n",
      "110A     1\n",
      "090A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "097A    16\n",
      "042A    14\n",
      "045A     9\n",
      "108A     6\n",
      "056A     3\n",
      "048A     1\n",
      "115A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    89\n",
      "F    61\n",
      "M    58\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    135\n",
      "F      6\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 014B, 111A, 040A, 109A, 050A, 043A, 049...\n",
      "senior    [093A, 057A, 106A, 104A, 055A, 059A, 113A, 116...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten    [046A, 047A, 042A, 045A, 048A, 115A]\n",
      "senior                      [097A, 056A, 108A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 10, 'senior': 19}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 6, 'senior': 3}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '014B' '016A' '024A' '040A' '041A' '043A' '044A' '049A' '050A'\n",
      " '051A' '051B' '054A' '055A' '057A' '058A' '059A' '061A' '090A' '093A'\n",
      " '094A' '104A' '106A' '109A' '110A' '111A' '113A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['042A' '045A' '046A' '047A' '048A' '056A' '097A' '108A' '115A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "senior    153\n",
      "kitten     55\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "kitten    116\n",
      "senior     25\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "senior    153\n",
      "kitten     55\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "kitten    116\n",
      "senior     25\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({1: 153, 0: 55})\n",
      "Epoch 1/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7769 - accuracy: 0.5385\n",
      "Epoch 2/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.7356\n",
      "Epoch 3/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.8269\n",
      "Epoch 4/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8750\n",
      "Epoch 5/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8894\n",
      "Epoch 6/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8990\n",
      "Epoch 7/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2924 - accuracy: 0.8894\n",
      "Epoch 8/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2647 - accuracy: 0.9279\n",
      "Epoch 9/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2339 - accuracy: 0.9183\n",
      "Epoch 10/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.9087\n",
      "Epoch 11/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.9327\n",
      "Epoch 12/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2110 - accuracy: 0.9375\n",
      "Epoch 13/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2080 - accuracy: 0.9423\n",
      "Epoch 14/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.9567\n",
      "Epoch 15/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9423\n",
      "Epoch 16/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.9471\n",
      "Epoch 17/300\n",
      "7/7 [==============================] - 0s 963us/step - loss: 0.1889 - accuracy: 0.9567\n",
      "Epoch 18/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.9615\n",
      "Epoch 19/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9615\n",
      "Epoch 20/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9567\n",
      "Epoch 21/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9567\n",
      "Epoch 22/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9712\n",
      "Epoch 23/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9808\n",
      "Epoch 24/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9663\n",
      "Epoch 25/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.9663\n",
      "Epoch 26/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9663\n",
      "Epoch 27/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9615\n",
      "Epoch 28/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9760\n",
      "Epoch 29/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9760\n",
      "Epoch 30/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9663\n",
      "Epoch 31/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9615\n",
      "Epoch 32/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9856\n",
      "Epoch 33/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1017 - accuracy: 0.9760\n",
      "Epoch 34/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9663\n",
      "Epoch 35/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0878 - accuracy: 0.9904\n",
      "Epoch 36/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9856\n",
      "Epoch 37/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9856\n",
      "Epoch 38/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.9808\n",
      "Epoch 39/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9808\n",
      "Epoch 40/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0774 - accuracy: 0.9808\n",
      "Epoch 41/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9856\n",
      "Epoch 42/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.9856\n",
      "Epoch 43/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9856\n",
      "Epoch 44/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.9760\n",
      "Epoch 45/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9808\n",
      "Epoch 46/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9952\n",
      "Epoch 47/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9904\n",
      "Epoch 48/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.9904\n",
      "Epoch 49/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9952\n",
      "Epoch 50/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 1.0000\n",
      "Epoch 51/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9904\n",
      "Epoch 52/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0527 - accuracy: 1.0000\n",
      "Epoch 53/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0753 - accuracy: 0.9760\n",
      "Epoch 54/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9952\n",
      "Epoch 55/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0645 - accuracy: 0.9856\n",
      "Epoch 56/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9808\n",
      "Epoch 57/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0551 - accuracy: 0.9952\n",
      "Epoch 58/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9856\n",
      "Epoch 59/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9904\n",
      "Epoch 60/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9856\n",
      "Epoch 61/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.9952\n",
      "Epoch 62/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9856\n",
      "Epoch 63/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9952\n",
      "Epoch 64/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 1.0000\n",
      "Epoch 65/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9952\n",
      "Epoch 66/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9904\n",
      "Epoch 67/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9904\n",
      "Epoch 68/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9952\n",
      "Epoch 69/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0731 - accuracy: 0.9856\n",
      "Epoch 71/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9952\n",
      "Epoch 72/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 0.9952\n",
      "Epoch 74/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9952\n",
      "Epoch 76/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 1.0000\n",
      "Epoch 77/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0539 - accuracy: 0.9904\n",
      "Epoch 79/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0333 - accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9952\n",
      "Epoch 81/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9760\n",
      "Epoch 82/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9952\n",
      "Epoch 83/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9952\n",
      "Epoch 84/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9952\n",
      "Epoch 85/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "7/7 [==============================] - 0s 999us/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9952\n",
      "Epoch 88/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 0.9952\n",
      "Epoch 92/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0389 - accuracy: 0.9952\n",
      "Epoch 93/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0333 - accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 0.9904\n",
      "Epoch 96/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 0.9952\n",
      "Epoch 97/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9952\n",
      "Epoch 98/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0548 - accuracy: 0.9904\n",
      "Epoch 99/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0462 - accuracy: 0.9952\n",
      "Epoch 100/300\n",
      "7/7 [==============================] - 0s 974us/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0443 - accuracy: 0.9904\n",
      "Epoch 102/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9952\n",
      "Epoch 104/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9952\n",
      "Epoch 107/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9952\n",
      "Epoch 108/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9904\n",
      "Epoch 109/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9808\n",
      "Epoch 111/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0472 - accuracy: 0.9904\n",
      "Epoch 112/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 0.9856\n",
      "Epoch 113/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9952\n",
      "Epoch 114/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.0296 - accuracy: 0.9904\n",
      "Epoch 117/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9952\n",
      "Epoch 118/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 0.9904\n",
      "Epoch 119/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0352 - accuracy: 0.9952\n",
      "Epoch 122/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9904\n",
      "Epoch 123/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9904\n",
      "Epoch 126/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9952\n",
      "Epoch 129/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9952\n",
      "Epoch 131/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9952\n",
      "Epoch 134/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9952\n",
      "Epoch 135/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9808\n",
      "Epoch 136/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.9952\n",
      "Epoch 137/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9904\n",
      "Epoch 145/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9856\n",
      "Epoch 149/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9952\n",
      "Epoch 150/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9952\n",
      "Epoch 151/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9952\n",
      "Epoch 156/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9904\n",
      "Epoch 157/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 0.9952\n",
      "Epoch 160/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9952\n",
      "Epoch 162/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9856\n",
      "Epoch 169/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9904\n",
      "Epoch 170/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9952\n",
      "Epoch 171/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9904\n",
      "Epoch 172/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9952\n",
      "Epoch 174/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0358 - accuracy: 0.9904\n",
      "Epoch 177/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9952\n",
      "Epoch 180/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9952\n",
      "Epoch 181/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "7/7 [==============================] - 0s 986us/step - loss: 0.0181 - accuracy: 0.9952\n",
      "Epoch 185/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9952\n",
      "Epoch 190/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9904\n",
      "Epoch 201/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 0.9952\n",
      "Epoch 202/300\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.0175 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 172.\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9904\n",
      "Epoch 202: early stopping\n",
      "5/5 [==============================] - 0s 950us/step - loss: 1.4205 - accuracy: 0.3901\n",
      "5/5 [==============================] - 0s 740us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.67 (6/9)\n",
      "Before appending - Cat IDs: 208, Predictions: 208, Actuals: 208, Gender: 208\n",
      "After appending - Cat IDs: 349, Predictions: 349, Actuals: 349, Gender: 349\n",
      "Final Test Results - Loss: 1.4205093383789062, Accuracy: 0.39007091522216797, Precision: 0.5630952380952381, Recall: 0.5822413793103448, F1 Score: 0.386336032388664\n",
      "Confusion Matrix:\n",
      " [[33 83]\n",
      " [ 3 22]]\n",
      "\n",
      "Final Average F1-Score across all UNSEEN TEST sets: 0.7461635252730812\n",
      "\n",
      "Final Average Loss across all UNSEEN TEST sets: 0.5314778424799442\n",
      "\n",
      "Final Average Accuracy across all UNSEEN TEST sets: 0.7641844004392624\n",
      "\n",
      "Final Average Precision across all UNSEEN TEST sets: 0.7806077798350979\n",
      "\n",
      "Final Average Recall across all UNSEEN TEST sets: 0.818214691856394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "all_cat_ids = []\n",
    "all_predicted_age_groups = []\n",
    "all_actual_age_groups = []\n",
    "all_gender = []\n",
    "\n",
    "# Define the StratifiedGroupKFold splitter for 4 fold CV with random shuffling\n",
    "outer_cv = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=int(random_seeds[2]))\n",
    "\n",
    "# unseen test set metrics\n",
    "unseen_losses, unseen_accuracies, unseen_precisions, unseen_recalls, unseen_f1 = [], [], [], [], []\n",
    "\n",
    "outer_fold = 0\n",
    "\n",
    "# Use the splitter to generate indices for training and testing sets\n",
    "# Note: GroupShuffleSplit.split returns indices, so we use it to index the arrays\n",
    "for train_val_idx, test_idx in outer_cv.split(X, y, groups):\n",
    "    outer_fold += 1\n",
    "    logger(f\"outer_fold {outer_fold}\", file=log_file_path)\n",
    "\n",
    "    # Convert indices back to DataFrame for easy manipulation\n",
    "    df_train_val = dataframe.iloc[train_val_idx]\n",
    "    df_test = dataframe.iloc[test_idx]\n",
    "\n",
    "    ##############################\n",
    "    # ASSESSING SPLITS BY CAT_ID #\n",
    "    ##############################\n",
    "    \n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test['cat_id'].value_counts()  \n",
    "    \n",
    "    # Log or print the distribution\n",
    "    logger(f\"Train Set Group Distribution:\\n{training_validation_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Group Distribution:\\n{testing_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test['gender'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Training Set Gender Distribution BEFORE SWAP:\\n{training_gender_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Gender Distribution BEFORE SWAP:\\n{testing_gender_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Group by 'age_group' and then list unique 'cat_id' within each age group\n",
    "    unique_cat_ids_per_age_group_train_val = df_train_val.groupby('age_group')['cat_id'].unique()\n",
    "    unique_cat_ids_per_age_group_test = df_test.groupby('age_group')['cat_id'].unique()\n",
    "    \n",
    "    # Log results\n",
    "    logger(f\"Unique Cat IDs per Age Group in Training/Validation Set:\\n{unique_cat_ids_per_age_group_train_val}\", file=log_file_path)\n",
    "    logger(f\"Unique Cat IDs per Age Group in Testing Set:\\n{unique_cat_ids_per_age_group_test}\", file=log_file_path)\n",
    "\n",
    "    # Calculate the count of unique identifiers per age group for training and testing set\n",
    "    counts_train_val = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_train_val.items()}\n",
    "    counts_test = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_test.items()}\n",
    "\n",
    "    # Log the counts of unique identifiers per age group\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Training/Validation Set:\\n{counts_train_val}\", file=log_file_path)\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Testing Set:\\n{counts_test}\", file=log_file_path)\n",
    "\n",
    "    #######################################################\n",
    "    # CONTINUE WITH ENSURING VALID AND APPROPRIATE SPLITS #\n",
    "    #######################################################\n",
    "    \n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    groups_train_val, groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # logging identifier splits \n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "\n",
    "    # # check group splits\n",
    "    # check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # # Specify the cat_ids that must be in the training/validation set\n",
    "    # specific_cat_ids = ['000A', '046A']\n",
    "    \n",
    "    # # Perform the swapping operation\n",
    "    # train_val_idx, test_idx = swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids)\n",
    "    \n",
    "    # # Re-assign the sets based on the updated indices\n",
    "    # X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    # y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    # new_groups_train_val, new_groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # # Find differences for training and test sets\n",
    "    # moved_to_train_val, removed_from_train_val = find_group_differences(groups_train_val, new_groups_train_val)\n",
    "    # moved_to_test, removed_from_test = find_group_differences(groups_test, new_groups_test)\n",
    "    \n",
    "    # # Display the results\n",
    "    # logger(f\"Moved to Training/Validation Set:\\n{moved_to_train_val}\", file=log_file_path)\n",
    "    # logger(f\"Removed from Training/Validation Set:\\n{removed_from_train_val}\", file=log_file_path)\n",
    "    # logger(f\"Moved to Test Set:\\n{moved_to_test}\", file=log_file_path)\n",
    "    # logger(f\"Removed from Test Set\\n{removed_from_test}\", file=log_file_path)\n",
    "\n",
    "    # # Update X_train_val, X_test, y_train_val, y_test, groups_train_val, groups_test based on updated indices\n",
    "    # X_train_val = X[train_val_idx]\n",
    "    # y_train_val = y[train_val_idx]\n",
    "    # groups_train_val = groups[train_val_idx]\n",
    "    \n",
    "    # X_test = X[test_idx]\n",
    "    # y_test = y[test_idx]\n",
    "    # groups_test = groups[test_idx]\n",
    "\n",
    "    # # logging identifier splits again after potential swaps\n",
    "    # unique_train_val_groups = np.unique(groups_train_val)\n",
    "    # unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    # logger(f\"AFTER SWAP - Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    # logger(f\"AFTER SWAP - Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "    \n",
    "    # # Verify the lengths are consistent\n",
    "    # logger(f\"Length of X_train_val:\\n{len(X_train_val)}\", file=log_file_path)\n",
    "    # logger(f\"Length of y_train_val:\\n{len(y_train_val)}\", file=log_file_path)\n",
    "    # logger(f\"Length of groups_train_val:\\n{len(groups_train_val)}\", file=log_file_path)\n",
    "\n",
    "    # # Check group splits once more\n",
    "    # check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Convert the modified indices back to a DataFrame representing the updated df_train_val\n",
    "    df_train_val_updated = dataframe.iloc[train_val_idx].copy()\n",
    "    df_test_updated = dataframe.iloc[test_idx].copy()\n",
    "\n",
    "    ############################\n",
    "    # LOGGING AGE GROUP SPLITS #\n",
    "    ############################\n",
    "\n",
    "    # Get the distribution of age groups of age groups before the update\n",
    "    training_validation_age_group_distribution = df_train_val['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test['age_group'].value_counts()\n",
    "    \n",
    "    # Logthe distribution\n",
    "    logger(f\"Train Age Group Distribution BEFORE SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution BEFORE SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Get the distribution of age groups after the update\n",
    "    training_validation_age_group_distribution = df_train_val_updated['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test_updated['age_group'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Train Age Group Distribution AFTER SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution AFTER SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "    \n",
    "    ########################################################\n",
    "    # TRACKING FINAL CAT_IDs & GENDER AFTER REDISTRIBUTION #\n",
    "    ########################################################\n",
    "\n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val_updated['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test_updated['cat_id'].value_counts()  \n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val_updated['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test_updated['gender'].value_counts()\n",
    "    \n",
    "    logger(f\"\\n Starting training on unseen test set\\n\", file=log_file_path)\n",
    "\n",
    "    ###################\n",
    "    # PREPARING MODEL #\n",
    "    ###################\n",
    "\n",
    "    # Calculate the distribution of age groups in y_train_val\n",
    "    age_group_distribution = Counter(y_train_val)\n",
    "    print(\"Age group distribution:\", age_group_distribution)\n",
    "\n",
    "    # EarlyStopping callback: monitor 'loss' instead of 'val_loss' for the test set\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='loss',  \n",
    "        min_delta=0.001, \n",
    "        patience=30,  \n",
    "        verbose=1,  \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "\n",
    "    # One final shuffle to ensure randomness\n",
    "    outer_shuffle_idx = np.random.permutation(len(X_train_val))\n",
    "    X_train_val = X_train_val[outer_shuffle_idx]\n",
    "    y_train_val = y_train_val[outer_shuffle_idx]\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler_full = StandardScaler().fit(X_train_val)\n",
    "    X_train_full_scaled = scaler_full.transform(X_train_val)\n",
    "    X_test_scaled = scaler_full.transform(X_test)\n",
    "    \n",
    "    # Encode the labels\n",
    "    y_train_full_encoded = y_train_val.astype('float32')\n",
    "    y_test_encoded = y_test.astype('float32')\n",
    "\n",
    "    #######################\n",
    "    # BUILD & TRAIN MODEL #\n",
    "    #######################\n",
    "\n",
    "    # Define optimizers\n",
    "    optimizers = {\n",
    "        'Adamax': Adamax(learning_rate=0.00038188800331973483)\n",
    "    }\n",
    "    \n",
    "    # Full model definition with dynamic number of layers\n",
    "    model_full = Sequential()\n",
    "    model_full.add(Dense(480, activation='relu', input_shape=(X_train_full_scaled.shape[1],)))  # units and input shape from parameters\n",
    "    model_full.add(BatchNormalization())\n",
    "    model_full.add(Dropout(0.27188281261238406))\n",
    "    model_full.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = optimizers['Adamax']  # optimizer selection\n",
    "    \n",
    "    # Compile the model for binary classification\n",
    "    model_full.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model on the full training set\n",
    "    history_full = model_full.fit(X_train_full_scaled, y_train_full_encoded, epochs=300, batch_size=32,\n",
    "                                  verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on the held-out test set\n",
    "    test_loss, test_accuracy = model_full.evaluate(X_test_scaled, y_test_encoded)\n",
    "\n",
    "    # y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    # y_test_pred = np.argmax(y_test_pred_prob, axis=1)  \n",
    "    # y_test_true = np.argmax(y_test_encoded, axis=1)    \n",
    "\n",
    "    # Predict probabilities for the test set\n",
    "    y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    \n",
    "    # Convert probabilities to class labels (0 or 1) using a threshold of 0.5\n",
    "    y_test_pred = (y_test_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # y_test_encoded should be a 1D array of 0s and 1s if prepared as suggested for binary classification\n",
    "    y_test_true = y_test_encoded\n",
    "\n",
    "    ################################\n",
    "    # LOG MAJORITY VOTE PER CAT_ID #\n",
    "    ################################\n",
    "\n",
    "    # Convert numeric predictions back to age group labels\n",
    "    predicted_age_groups = y_test_pred\n",
    "    actual_labels = y_test_true\n",
    "    \n",
    "    # Map predictions and actual labels back to cat_ids\n",
    "    test_results = pd.DataFrame({\n",
    "        'cat_id': df_test_updated['cat_id'],\n",
    "        'predicted_age_group': predicted_age_groups,\n",
    "        'actual_age_group': actual_labels\n",
    "    })\n",
    "    \n",
    "    # Group by cat_id and aggregate predicted age groups\n",
    "    majority_votes = test_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "    actual_groups = test_results.groupby('cat_id')['actual_age_group'].first()\n",
    "    \n",
    "    # Calculate the accuracy of majority voting\n",
    "    correct_predictions = (majority_votes == actual_groups).sum()\n",
    "    total_cats = len(actual_groups)\n",
    "    majority_vote_accuracy = correct_predictions / total_cats\n",
    "    \n",
    "    # Log the accuracy of the majority voting\n",
    "    logger(f\"Majority Vote Accuracy for cat_id for this fold: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)\n",
    "\n",
    "    ####################################################\n",
    "    # COLLECT PREDICTIONS FOR GENDER & CAT_ID ANALYSIS #\n",
    "    ####################################################\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'Before appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Extend lists with current fold results\n",
    "    all_cat_ids.extend(df_test_updated['cat_id'].tolist())\n",
    "    all_predicted_age_groups.extend(predicted_age_groups)\n",
    "    all_actual_age_groups.extend(actual_labels)\n",
    "    all_gender.extend(df_test_updated['gender'].tolist())\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'After appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    test_precision = precision_score(y_test_true, y_test_pred, average='macro')  # Use 'macro' for imbalanced datasets\n",
    "    test_recall = recall_score(y_test_true, y_test_pred, average='macro')\n",
    "    test_f1 = f1_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "    # prepare averages of outer metrics\n",
    "    unseen_f1.append(test_f1)\n",
    "    unseen_losses.append(test_loss)\n",
    "    unseen_accuracies.append(test_accuracy)\n",
    "    unseen_precisions.append(test_precision)\n",
    "    unseen_recalls.append(test_recall)\n",
    "\n",
    "    # Print final test results\n",
    "    logger(f\"Final Test Results - Loss: {test_loss}, Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}\", file=log_file_path)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    logger(f\"Confusion Matrix:\\n {cm}\", file=log_file_path)\n",
    "\n",
    "# Calculate the overall average metrics\n",
    "unseen_set_avg_f1 = np.mean(unseen_f1)\n",
    "unseen_set_avg_loss = np.mean(unseen_losses)\n",
    "unseen_set_avg_acc = np.mean(unseen_accuracies)\n",
    "unseen_set_avg_precision = np.mean(unseen_precisions)\n",
    "unseen_set_avg_recall = np.mean(unseen_recalls)\n",
    "\n",
    "logger(f\"\\nFinal Average F1-Score across all UNSEEN TEST sets: {unseen_set_avg_f1}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Loss across all UNSEEN TEST sets: {unseen_set_avg_loss}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Accuracy across all UNSEEN TEST sets: {unseen_set_avg_acc}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Precision across all UNSEEN TEST sets: {unseen_set_avg_precision}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Recall across all UNSEEN TEST sets: {unseen_set_avg_recall}\\n\", file=log_file_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be692ae4-6d3f-4353-b5bf-554d20da4df3",
   "metadata": {},
   "source": [
    "## Majority Voting on Total Entries per cat_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8da9a092-ed2e-4397-a6c8-2c4888735265",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking - Cat IDs: 349, Predictions: 349, Actuals: 349, Gender: 349\n"
     ]
    }
   ],
   "source": [
    "# Debugging print statements\n",
    "print(f'Checking - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "51cf386a-c49e-4716-ba15-aa3b7930419a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create results df\n",
    "full_results = pd.DataFrame({\n",
    "    'cat_id': all_cat_ids,\n",
    "    'predicted_age_group': all_predicted_age_groups,\n",
    "    'actual_age_group': all_actual_age_groups,\n",
    "    'all_gender': all_gender\n",
    "})\n",
    "\n",
    "# create a correct majority prediction column\n",
    "full_results['correct'] = full_results['predicted_age_group'] == full_results['actual_age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a8d43ac5-d50e-430d-98a1-ff4f45006bae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Majority Vote Accuracy for cat_id: 0.84 (32/38)\n"
     ]
    }
   ],
   "source": [
    "# Group by cat_id and aggregate predicted age groups\n",
    "majority_votes = full_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first()\n",
    "\n",
    "# Calculate the accuracy of majority voting\n",
    "correct_predictions = (majority_votes == actual_groups).sum()\n",
    "total_cats = len(actual_groups)\n",
    "majority_vote_accuracy = correct_predictions / total_cats\n",
    "\n",
    "logger(f\"Overall Majority Vote Accuracy for cat_id: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ccc9acb7-bb1b-42a6-bb25-cdf5a3356315",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Detailed df with predictions, actual labels, and comparison including majority vote\n",
    "detailed_results = full_results.groupby('cat_id').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Predictions': list(x['predicted_age_group']),\n",
    "        'Majority Vote': x['predicted_age_group'].mode()[0],\n",
    "        'Actual Age Group': x['actual_age_group'].iloc[0],\n",
    "        'Correct Majority Vote': x['predicted_age_group'].mode()[0] == x['actual_age_group'].iloc[0]\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Convert to DataFrame for better formatting and display\n",
    "detailed_results = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "95e69b27-cae1-4a3a-ba70-5244a11aadf1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Majority Vote</th>\n",
       "      <th>Actual Age Group</th>\n",
       "      <th>Correct Majority Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>011A</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>104A</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>057A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>058A</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>059A</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>090A</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>094A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>097A</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>108A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>055A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>109A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>110A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>111A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>113A</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>115A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>116A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>014B</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>056A</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>054A</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>051B</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>016A</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 0, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>024A</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>040A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>041A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>042A</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>043A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>044A</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>045A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>049A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>050A</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>051A</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>117A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>046A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>106A</td>\n",
       "      <td>[0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>047A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>093A</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>048A</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>061A</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat_id                                        Predictions  Majority Vote  Actual Age Group  Correct Majority Vote\n",
       "0    011A                                             [1, 1]              1               1.0                   True\n",
       "28   104A                                       [1, 1, 1, 1]              1               1.0                   True\n",
       "20   057A  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, ...              1               1.0                   True\n",
       "21   058A                                          [1, 1, 1]              1               1.0                   True\n",
       "22   059A         [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "24   090A                                                [1]              1               1.0                   True\n",
       "26   094A                           [1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "27   097A   [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]              1               1.0                   True\n",
       "30   108A                                 [1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "18   055A  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              1               1.0                   True\n",
       "31   109A                                 [0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "32   110A                                                [0]              0               0.0                   True\n",
       "33   111A            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "34   113A                                          [1, 1, 1]              1               1.0                   True\n",
       "35   115A                                                [0]              0               0.0                   True\n",
       "36   116A               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "1    014B                     [0, 0, 0, 1, 0, 0, 0, 0, 1, 0]              0               0.0                   True\n",
       "19   056A                                          [1, 1, 1]              1               1.0                   True\n",
       "17   054A                                             [1, 1]              1               1.0                   True\n",
       "16   051B                        [1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "2    016A                     [1, 0, 0, 1, 1, 1, 0, 1, 1, 1]              1               1.0                   True\n",
       "3    024A                                                [1]              1               1.0                   True\n",
       "4    040A                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "5    041A                                                [0]              0               0.0                   True\n",
       "6    042A         [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0]              0               0.0                   True\n",
       "7    043A                                                [0]              0               0.0                   True\n",
       "8    044A                                    [0, 0, 0, 0, 0]              0               0.0                   True\n",
       "9    045A                        [0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "13   049A                                                [0]              0               0.0                   True\n",
       "14   050A                              [0, 1, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "15   051A               [1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "37   117A                              [1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "10   046A  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, ...              1               0.0                  False\n",
       "29   106A         [0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]              0               1.0                  False\n",
       "11   047A  [1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...              1               0.0                  False\n",
       "25   093A                                             [0, 1]              0               1.0                  False\n",
       "12   048A                                                [1]              1               0.0                  False\n",
       "23   061A                                             [1, 0]              0               1.0                  False"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "sorted_detailed_results = detailed_results.sort_values(by='Correct Majority Vote', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d36b3c54-3377-4249-a774-6d31557e36da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Majority Votes per Class:\n",
      "actual_age_group\n",
      "0.0    13\n",
      "1.0    19\n",
      "Name: Majority_Correct, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create df for majority votes\n",
    "majority_df = majority_votes.reset_index()\n",
    "majority_df.columns = ['cat_id', 'Majority_Vote']\n",
    "\n",
    "# Get actual groups for each cat_id\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first().reset_index()\n",
    "\n",
    "# Merge majority votes with actual groups\n",
    "majority_with_actual = pd.merge(majority_df, actual_groups, on='cat_id')\n",
    "\n",
    "# Add a column to check if the majority vote was correct\n",
    "majority_with_actual['Majority_Correct'] = majority_with_actual['Majority_Vote'] == majority_with_actual['actual_age_group']\n",
    "\n",
    "# Count correct majority votes per class\n",
    "correct_majority_votes_per_class = majority_with_actual.groupby('actual_age_group')['Majority_Correct'].sum()\n",
    "\n",
    "print(\"Correct Majority Votes per Class:\")\n",
    "print(correct_majority_votes_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b36eb8a4-57f3-48c0-b92c-4a8e5a52c59e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics for Majority Votes:\n",
      "   actual_age_group  total_count  correct_count   accuracy\n",
      "0               0.0           16             13  81.250000\n",
      "1               1.0           22             19  86.363636\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = majority_with_actual.groupby('actual_age_group').agg(\n",
    "    total_count=('Majority_Correct', 'size'),  # Total number of cases per class\n",
    "    correct_count=('Majority_Correct', 'sum')  # Sum of correct predictions per class\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log detailed stats\n",
    "print(\"Detailed Class Statistics for Majority Votes:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1750e2da-df8c-4f00-b860-539dd822864f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics for Majority Votes\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Accuracy of Majority Votes by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6b34e-2368-4956-8241-8e6ab6e8cf81",
   "metadata": {},
   "source": [
    "## Detailed Class Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "fdefd9be-6e6d-4903-a0ec-7824da4313d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics:\n",
      "   actual_age_group  total_count  correct_count   accuracy\n",
      "0               0.0          171             85  49.707602\n",
      "1               1.0          178            156  87.640449\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = full_results.groupby('actual_age_group').agg(\n",
    "    total_count=('correct', 'size'),\n",
    "    correct_count=('correct', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log the detailed stats\n",
    "print(\"Detailed Class Statistics:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "57576e25-349c-46e0-b57b-8bf3cee3b5de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics (Overall)\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Overall Accuracy by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b69785-d4c1-49ab-ba75-4a733326cdc1",
   "metadata": {},
   "source": [
    "## Gender Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "15c5b6e5-d7b0-4089-ae78-3dafe1cead3e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Gender:\n",
      "  all_gender  count  correct  accuracy\n",
      "0          F     67       65     97.01\n",
      "1          M     58       46     79.31\n",
      "2          X    224      130     58.04\n"
     ]
    }
   ],
   "source": [
    "# Group by gender and calculate the total count, correct predictions, and accuracy\n",
    "gender_stats = full_results.groupby('all_gender').agg(\n",
    "    count=('cat_id', 'size'),  # Total number of cases per gender\n",
    "    correct=('correct', 'sum')  # Sum of correct predictions per gender\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each gender\n",
    "gender_stats['accuracy'] = (gender_stats['correct'] / gender_stats['count'] * 100).round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy by Gender:\")\n",
    "print(gender_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b6001f1b-3f01-42e9-8761-4253acbed5e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Gender:\n",
      "  all_gender  count  correct  accuracy\n",
      "0          F     67       65     97.01\n",
      "1          M     58       46     79.31\n",
      "2          X    224      130     58.04\n"
     ]
    }
   ],
   "source": [
    "# Group by gender and calculate the total count, correct predictions, and accuracy\n",
    "gender_stats = full_results.groupby('all_gender').agg(\n",
    "    count=('cat_id', 'size'),  # Total number of cases per gender\n",
    "    correct=('correct', 'sum')  # Sum of correct predictions per gender\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each gender\n",
    "gender_stats['accuracy'] = (gender_stats['correct'] / gender_stats['count'] * 100).round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy by Gender:\")\n",
    "print(gender_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71b5d44-f489-4de0-8785-4bfa52d09797",
   "metadata": {},
   "source": [
    "# RANDOM SEED 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c4439fc4-670c-4009-8ca9-23c419ee99ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senior    178\n",
      "kitten    171\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(int(random_seeds[3])) \n",
    "np.random.seed(int(random_seeds[3]))\n",
    "tf.random.set_seed(int(random_seeds[3]))\n",
    "\n",
    "# Load datasets\n",
    "dataframe = pd.read_csv('/Users/astrid/PycharmProjects/audioset-thesis-work/audioset/vggish/embeddings/8april_looped_embeddings.csv')\n",
    "\n",
    "dataframe.drop('mean_freq', axis=1, inplace=True)\n",
    "\n",
    "def assign_age_group(age, age_groups):\n",
    "    for group_name, age_range in age_groups.items():\n",
    "        if age_range[0] <= age < age_range[1]:\n",
    "            return group_name\n",
    "    return 'Unknown'  # For any age that doesn't fit the defined groups\n",
    "\n",
    "# Define age groups\n",
    "age_groups = {\n",
    "    'kitten': (0, 0.5),\n",
    "    'adult': (0.5, 12),\n",
    "    'senior': (12, 20)\n",
    "}\n",
    "\n",
    "# Create a new column for the age group\n",
    "dataframe['age_group'] = dataframe['target'].apply(assign_age_group, age_groups=age_groups)\n",
    "\n",
    "# Drop Adult\n",
    "dataframe.drop(dataframe[dataframe['age_group'] == 'adult'].index, inplace=True)\n",
    "\n",
    "print(dataframe['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5fe04e3d-fd90-43c1-97af-5eac75e35f85",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = dataframe.iloc[:, :-4].values  # all columns except the last four\n",
    "\n",
    "# Encode the 'age_group' column as integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y = label_encoder.fit_transform(dataframe['age_group'].values)\n",
    "\n",
    "# Use the encoded labels for splitting and one-hot encoding\n",
    "y = encoded_y  \n",
    "\n",
    "# Convert 'cat_id' column to numpy array to be used as groups array for GroupKFold\n",
    "groups = dataframe['cat_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "2ed5261d-2aeb-412e-a017-65b461a2cf5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f70aa6-1716-400a-be48-cccb3511542e",
   "metadata": {},
   "source": [
    "## Run Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fb9d0248-481e-4807-85dd-407fa88963f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_fold 1\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "057A    27\n",
      "055A    20\n",
      "097A    16\n",
      "106A    14\n",
      "042A    14\n",
      "059A    14\n",
      "111A    13\n",
      "051A    12\n",
      "116A    12\n",
      "051B     9\n",
      "045A     9\n",
      "094A     8\n",
      "117A     7\n",
      "050A     7\n",
      "109A     6\n",
      "108A     6\n",
      "044A     5\n",
      "104A     4\n",
      "056A     3\n",
      "113A     3\n",
      "011A     2\n",
      "061A     2\n",
      "054A     2\n",
      "093A     2\n",
      "041A     1\n",
      "048A     1\n",
      "043A     1\n",
      "115A     1\n",
      "090A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "014B    10\n",
      "040A    10\n",
      "016A    10\n",
      "058A     3\n",
      "049A     1\n",
      "110A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    199\n",
      "F     67\n",
      "M     48\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    25\n",
      "M    10\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 111A, 046A, 047A, 042A, 109A, 050A, 043...\n",
      "senior    [093A, 097A, 057A, 106A, 104A, 055A, 059A, 113...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten    [014B, 040A, 049A, 110A]\n",
      "senior                [058A, 016A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 12, 'senior': 20}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 4, 'senior': 2}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '024A' '041A' '042A' '043A' '044A' '045A' '046A' '047A' '048A'\n",
      " '050A' '051A' '051B' '054A' '055A' '056A' '057A' '059A' '061A' '090A'\n",
      " '093A' '094A' '097A' '104A' '106A' '108A' '109A' '111A' '113A' '115A'\n",
      " '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['014B' '016A' '040A' '049A' '058A' '110A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "senior    165\n",
      "kitten    149\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "kitten    22\n",
      "senior    13\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "senior    165\n",
      "kitten    149\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "kitten    22\n",
      "senior    13\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({1: 165, 0: 149})\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.6592\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4092 - accuracy: 0.8503\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.8535\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2649 - accuracy: 0.9172\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2034 - accuracy: 0.9268\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.9299\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.9459\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.9522\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9427\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 0.9713\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1611 - accuracy: 0.9554\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.9522\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9586\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9682\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9713\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1035 - accuracy: 0.9841\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9841\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9586\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.9873\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9873\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9873\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.9682\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0826 - accuracy: 0.9745\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9745\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0758 - accuracy: 0.9873\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9777\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9904\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9777\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9841\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9682\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9873\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 0.9873\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9809\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9841\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9841\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 0.9873\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9809\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9904\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9841\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0548 - accuracy: 0.9904\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 0.9873\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9777\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9936\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9936\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9809\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9936\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9841\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 0.9968\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9936\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9968\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9841\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9968\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9873\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9904\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9841\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9936\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 0.9904\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9873\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9968\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9873\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9968\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9904\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0616 - accuracy: 0.9777\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 0.9968\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 0.9809\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9968\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0318 - accuracy: 0.9968\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9968\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9968\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9936\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.9968\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9936\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0281 - accuracy: 0.9968\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9968\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9904\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 0.9904\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9936\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0485 - accuracy: 0.9904\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9968\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9904\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9936\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9841\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9936\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9936\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9968\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9936\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9968\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9936\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9936\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9968\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9936\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.9904\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 996us/step - loss: 0.0243 - accuracy: 0.9968\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9936\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0354 - accuracy: 0.9904\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9968\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9968\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9968\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 957us/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9936\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9936\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 958us/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 983us/step - loss: 0.0354 - accuracy: 0.9904\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 941us/step - loss: 0.0393 - accuracy: 0.9904\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9968\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 979us/step - loss: 0.0226 - accuracy: 0.9904\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.0200 - accuracy: 0.9968\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9968\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.9968\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9968\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9936\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0150 - accuracy: 0.9968\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 984us/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.9968\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9936\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 974us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9904\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9968\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 0.9968\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.9968\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9936\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 0s 926us/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9936\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 0s 991us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9968\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 0.9968\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 0.9968\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9873\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.9968\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9968\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 0.9968\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.9968\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 0.9968\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9968\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 186/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 156.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9904\n",
      "Epoch 186: early stopping\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2145 - accuracy: 0.9143\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 1.00 (6/6)\n",
      "Before appending - Cat IDs: 0, Predictions: 0, Actuals: 0, Gender: 0\n",
      "After appending - Cat IDs: 35, Predictions: 35, Actuals: 35, Gender: 35\n",
      "Final Test Results - Loss: 0.21449701488018036, Accuracy: 0.9142857193946838, Precision: 0.9148550724637681, Recall: 0.9003496503496504, F1 Score: 0.9066666666666665\n",
      "Confusion Matrix:\n",
      " [[21  1]\n",
      " [ 2 11]]\n",
      "outer_fold 2\n",
      "Train Set Group Distribution:\n",
      "057A    27\n",
      "097A    16\n",
      "106A    14\n",
      "042A    14\n",
      "059A    14\n",
      "116A    12\n",
      "051A    12\n",
      "014B    10\n",
      "040A    10\n",
      "016A    10\n",
      "045A     9\n",
      "108A     6\n",
      "109A     6\n",
      "104A     4\n",
      "058A     3\n",
      "056A     3\n",
      "113A     3\n",
      "093A     2\n",
      "054A     2\n",
      "011A     2\n",
      "061A     2\n",
      "043A     1\n",
      "049A     1\n",
      "041A     1\n",
      "048A     1\n",
      "115A     1\n",
      "110A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "055A    20\n",
      "111A    13\n",
      "051B     9\n",
      "094A     8\n",
      "117A     7\n",
      "050A     7\n",
      "044A     5\n",
      "090A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    108\n",
      "M     40\n",
      "F     39\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    116\n",
      "F     28\n",
      "M     18\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [014B, 040A, 042A, 109A, 043A, 049A, 041A, 045...\n",
      "senior    [093A, 097A, 057A, 106A, 104A, 059A, 113A, 116...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten          [044A, 111A, 046A, 047A, 050A]\n",
      "senior    [055A, 051B, 117A, 094A, 090A, 024A]\n",
      "Name: cat_id, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 11, 'senior': 16}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 5, 'senior': 6}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '014B' '016A' '040A' '041A' '042A' '043A' '045A' '048A' '049A'\n",
      " '051A' '054A' '056A' '057A' '058A' '059A' '061A' '093A' '097A' '104A'\n",
      " '106A' '108A' '109A' '110A' '113A' '115A' '116A']\n",
      "Unique Test Group IDs:\n",
      "['024A' '044A' '046A' '047A' '050A' '051B' '055A' '090A' '094A' '111A'\n",
      " '117A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "senior    132\n",
      "kitten     55\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "kitten    116\n",
      "senior     46\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "senior    132\n",
      "kitten     55\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "kitten    116\n",
      "senior     46\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({1: 132, 0: 55})\n",
      "Epoch 1/300\n",
      "6/6 [==============================] - 1s 17ms/step - loss: 0.6693 - accuracy: 0.6257\n",
      "Epoch 2/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.7861\n",
      "Epoch 3/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8235\n",
      "Epoch 4/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8289\n",
      "Epoch 5/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8930\n",
      "Epoch 6/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8930\n",
      "Epoch 7/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3093 - accuracy: 0.8984\n",
      "Epoch 8/300\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2554 - accuracy: 0.9198\n",
      "Epoch 9/300\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2464 - accuracy: 0.9305\n",
      "Epoch 10/300\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.2433 - accuracy: 0.9037\n",
      "Epoch 11/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2086 - accuracy: 0.9091\n",
      "Epoch 12/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9305\n",
      "Epoch 13/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1986 - accuracy: 0.9465\n",
      "Epoch 14/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.9412\n",
      "Epoch 15/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1969 - accuracy: 0.9412\n",
      "Epoch 16/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9305\n",
      "Epoch 17/300\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.2117 - accuracy: 0.9305\n",
      "Epoch 18/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9572\n",
      "Epoch 19/300\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1815 - accuracy: 0.9519\n",
      "Epoch 20/300\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1706 - accuracy: 0.9465\n",
      "Epoch 21/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1930 - accuracy: 0.9412\n",
      "Epoch 22/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9572\n",
      "Epoch 23/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1291 - accuracy: 0.9679\n",
      "Epoch 24/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1489 - accuracy: 0.9626\n",
      "Epoch 25/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9626\n",
      "Epoch 26/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1251 - accuracy: 0.9733\n",
      "Epoch 27/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9893\n",
      "Epoch 28/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1570 - accuracy: 0.9519\n",
      "Epoch 29/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9679\n",
      "Epoch 30/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9733\n",
      "Epoch 31/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9733\n",
      "Epoch 32/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9786\n",
      "Epoch 33/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.9679\n",
      "Epoch 34/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9679\n",
      "Epoch 35/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.9733\n",
      "Epoch 36/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9840\n",
      "Epoch 37/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0981 - accuracy: 0.9840\n",
      "Epoch 38/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9733\n",
      "Epoch 39/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9626\n",
      "Epoch 40/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.9893\n",
      "Epoch 41/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1139 - accuracy: 0.9840\n",
      "Epoch 42/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9893\n",
      "Epoch 43/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9786\n",
      "Epoch 44/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0975 - accuracy: 0.9733\n",
      "Epoch 45/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 1.0000\n",
      "Epoch 46/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.9786\n",
      "Epoch 47/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.9786\n",
      "Epoch 48/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9893\n",
      "Epoch 49/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9947\n",
      "Epoch 50/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9893\n",
      "Epoch 51/300\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.9947\n",
      "Epoch 52/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 1.0000\n",
      "Epoch 53/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9893\n",
      "Epoch 54/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9947\n",
      "Epoch 55/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9626\n",
      "Epoch 56/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9786\n",
      "Epoch 57/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9893\n",
      "Epoch 58/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9626\n",
      "Epoch 59/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9893\n",
      "Epoch 60/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 1.0000\n",
      "Epoch 61/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9786\n",
      "Epoch 62/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9893\n",
      "Epoch 63/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9893\n",
      "Epoch 64/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9893\n",
      "Epoch 65/300\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9893\n",
      "Epoch 66/300\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.9947\n",
      "Epoch 67/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0641 - accuracy: 0.9840\n",
      "Epoch 68/300\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9947\n",
      "Epoch 69/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0517 - accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0677 - accuracy: 0.9840\n",
      "Epoch 71/300\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0505 - accuracy: 0.9893\n",
      "Epoch 72/300\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0616 - accuracy: 0.9893\n",
      "Epoch 73/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9947\n",
      "Epoch 74/300\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9947\n",
      "Epoch 75/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9893\n",
      "Epoch 76/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0409 - accuracy: 0.9947\n",
      "Epoch 77/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 0.9947\n",
      "Epoch 78/300\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9947\n",
      "Epoch 79/300\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0488 - accuracy: 0.9947\n",
      "Epoch 80/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9947\n",
      "Epoch 81/300\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0395 - accuracy: 0.9947\n",
      "Epoch 82/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9840\n",
      "Epoch 83/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9893\n",
      "Epoch 84/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.9947\n",
      "Epoch 85/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9947\n",
      "Epoch 87/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9840\n",
      "Epoch 88/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9947\n",
      "Epoch 91/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9947\n",
      "Epoch 92/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9947\n",
      "Epoch 94/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9893\n",
      "Epoch 95/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9840\n",
      "Epoch 96/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9947\n",
      "Epoch 97/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9893\n",
      "Epoch 98/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9893\n",
      "Epoch 99/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0480 - accuracy: 0.9947\n",
      "Epoch 101/300\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0462 - accuracy: 0.9840\n",
      "Epoch 102/300\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0409 - accuracy: 0.9947\n",
      "Epoch 103/300\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0725 - accuracy: 0.9733\n",
      "Epoch 104/300\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9947\n",
      "Epoch 105/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9947\n",
      "Epoch 107/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9893\n",
      "Epoch 108/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9947\n",
      "Epoch 111/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9947\n",
      "Epoch 112/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9893\n",
      "Epoch 116/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9947\n",
      "Epoch 117/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9947\n",
      "Epoch 118/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 0.9947\n",
      "Epoch 122/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0335 - accuracy: 0.9947\n",
      "Epoch 126/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9947\n",
      "Epoch 128/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.9947\n",
      "Epoch 129/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9947\n",
      "Epoch 130/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9947\n",
      "Epoch 136/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9947\n",
      "Epoch 138/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0318 - accuracy: 0.9947\n",
      "Epoch 139/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9947\n",
      "Epoch 140/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9947\n",
      "Epoch 144/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9947\n",
      "Epoch 146/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9947\n",
      "Epoch 152/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9947\n",
      "Epoch 153/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9947\n",
      "Epoch 154/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.9893\n",
      "Epoch 155/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9947\n",
      "Epoch 161/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9947\n",
      "Epoch 162/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0354 - accuracy: 0.9893\n",
      "Epoch 166/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9947\n",
      "Epoch 168/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9893\n",
      "Epoch 169/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.0197 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 142.\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9947\n",
      "Epoch 172: early stopping\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7593\n",
      "6/6 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy for cat_id for this fold: 0.91 (10/11)\n",
      "Before appending - Cat IDs: 35, Predictions: 35, Actuals: 35, Gender: 35\n",
      "After appending - Cat IDs: 197, Predictions: 197, Actuals: 197, Gender: 197\n",
      "Final Test Results - Loss: 0.4762410819530487, Accuracy: 0.7592592835426331, Precision: 0.7705882352941176, Recall: 0.8318965517241379, F1 Score: 0.7501087687378871\n",
      "Confusion Matrix:\n",
      " [[77 39]\n",
      " [ 0 46]]\n",
      "outer_fold 3\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "055A    20\n",
      "042A    14\n",
      "111A    13\n",
      "051A    12\n",
      "016A    10\n",
      "040A    10\n",
      "014B    10\n",
      "051B     9\n",
      "094A     8\n",
      "050A     7\n",
      "117A     7\n",
      "108A     6\n",
      "109A     6\n",
      "044A     5\n",
      "058A     3\n",
      "054A     2\n",
      "093A     2\n",
      "061A     2\n",
      "049A     1\n",
      "041A     1\n",
      "115A     1\n",
      "110A     1\n",
      "090A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "057A    27\n",
      "097A    16\n",
      "106A    14\n",
      "059A    14\n",
      "116A    12\n",
      "045A     9\n",
      "104A     4\n",
      "113A     3\n",
      "056A     3\n",
      "011A     2\n",
      "043A     1\n",
      "048A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    167\n",
      "F     46\n",
      "M     30\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    57\n",
      "M    28\n",
      "F    21\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 014B, 111A, 040A, 046A, 047A, 042A, 109...\n",
      "senior    [093A, 055A, 051B, 054A, 117A, 051A, 058A, 016...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten                                   [043A, 045A, 048A]\n",
      "senior    [097A, 057A, 106A, 104A, 059A, 113A, 116A, 056...\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 13, 'senior': 13}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 3, 'senior': 9}\n",
      "Unique Training/Validation Group IDs:\n",
      "['014B' '016A' '024A' '040A' '041A' '042A' '044A' '046A' '047A' '049A'\n",
      " '050A' '051A' '051B' '054A' '055A' '058A' '061A' '090A' '093A' '094A'\n",
      " '108A' '109A' '110A' '111A' '115A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['011A' '043A' '045A' '048A' '056A' '057A' '059A' '097A' '104A' '106A'\n",
      " '113A' '116A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "kitten    160\n",
      "senior     83\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "senior    95\n",
      "kitten    11\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "kitten    160\n",
      "senior     83\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "senior    95\n",
      "kitten    11\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 160, 1: 83})\n",
      "Epoch 1/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6763 - accuracy: 0.6173\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4350 - accuracy: 0.7901\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8354\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.9177\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8724\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9424\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9383\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.9218\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9300\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9671\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1659 - accuracy: 0.9671\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.9588\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1584 - accuracy: 0.9588\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9383\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1377 - accuracy: 0.9671\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9712\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9671\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 0.9712\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.9835\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9918\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.9794\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9877\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1277 - accuracy: 0.9506\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.9753\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 0.9959\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9630\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0930 - accuracy: 0.9794\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9877\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0897 - accuracy: 0.9794\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9794\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0848 - accuracy: 0.9794\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.9877\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0690 - accuracy: 0.9877\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.9794\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9877\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0617 - accuracy: 0.9918\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0757 - accuracy: 0.9794\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9918\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9835\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0772 - accuracy: 0.9835\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9835\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0559 - accuracy: 0.9959\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9835\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9918\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9918\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9794\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 1.0000\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 1.0000\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9959\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9918\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 1.0000\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9959\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9877\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9959\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.9835\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9959\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 1.0000\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0619 - accuracy: 0.9877\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0477 - accuracy: 0.9918\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9959\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9959\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9794\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 0.9959\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9959\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0494 - accuracy: 0.9959\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9877\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9918\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9959\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 0.9959\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9918\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9959\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9959\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9959\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9959\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9959\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9959\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9959\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9959\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9959\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9877\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.9835\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0391 - accuracy: 0.9918\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0295 - accuracy: 0.9959\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0252 - accuracy: 0.9959\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.9959\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9877\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9877\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9959\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9959\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 0.9918\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.9959\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9918\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9918\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9959\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9918\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9959\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9959\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9918\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9959\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9959\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 0.9877\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9959\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9959\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9959\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9959\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.9918\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9959\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9959\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.9959\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.9918\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9918\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9918\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9959\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9959\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.9959\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9959\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9959\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9959\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0161 - accuracy: 0.9959\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9959\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9918\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9959\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9918\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9918\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 0.9959\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.9959\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 0.9959\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9918\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 184.\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 214: early stopping\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9717\n",
      "4/4 [==============================] - 0s 865us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 1.00 (12/12)\n",
      "Before appending - Cat IDs: 197, Predictions: 197, Actuals: 197, Gender: 197\n",
      "After appending - Cat IDs: 303, Predictions: 303, Actuals: 303, Gender: 303\n",
      "Final Test Results - Loss: 0.06767930835485458, Accuracy: 0.9716981053352356, Precision: 0.8928571428571428, Recall: 0.9842105263157894, F1 Score: 0.9319786096256685"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      " [[11  0]\n",
      " [ 3 92]]\n",
      "outer_fold 4\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "057A    27\n",
      "055A    20\n",
      "097A    16\n",
      "106A    14\n",
      "059A    14\n",
      "111A    13\n",
      "116A    12\n",
      "040A    10\n",
      "016A    10\n",
      "014B    10\n",
      "051B     9\n",
      "045A     9\n",
      "094A     8\n",
      "117A     7\n",
      "050A     7\n",
      "044A     5\n",
      "104A     4\n",
      "058A     3\n",
      "056A     3\n",
      "113A     3\n",
      "011A     2\n",
      "043A     1\n",
      "049A     1\n",
      "048A     1\n",
      "110A     1\n",
      "090A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "042A    14\n",
      "051A    12\n",
      "109A     6\n",
      "108A     6\n",
      "093A     2\n",
      "054A     2\n",
      "061A     2\n",
      "041A     1\n",
      "115A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    198\n",
      "M     56\n",
      "F     49\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    26\n",
      "F    18\n",
      "M     2\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 014B, 111A, 040A, 046A, 047A, 050A, 043...\n",
      "senior    [097A, 057A, 106A, 104A, 055A, 059A, 113A, 116...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten          [042A, 109A, 041A, 115A]\n",
      "senior    [093A, 054A, 051A, 108A, 061A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 12, 'senior': 17}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 4, 'senior': 5}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '014B' '016A' '024A' '040A' '043A' '044A' '045A' '046A' '047A'\n",
      " '048A' '049A' '050A' '051B' '055A' '056A' '057A' '058A' '059A' '090A'\n",
      " '094A' '097A' '104A' '106A' '110A' '111A' '113A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['041A' '042A' '051A' '054A' '061A' '093A' '108A' '109A' '115A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "senior    154\n",
      "kitten    149\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "senior    24\n",
      "kitten    22\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "senior    154\n",
      "kitten    149\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "senior    24\n",
      "kitten    22\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({1: 154, 0: 149})\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8119\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8779\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.8977\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.9241\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9439\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.9406\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1634 - accuracy: 0.9505\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9703\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9373\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.9340\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.9703\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1118 - accuracy: 0.9769\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9604\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0982 - accuracy: 0.9769\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9637\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9736\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9670\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9868\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9835\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0934 - accuracy: 0.9670\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9868\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9934\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0887 - accuracy: 0.9769\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0556 - accuracy: 0.9868\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0675 - accuracy: 0.9868\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9901\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.9835\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0628 - accuracy: 0.9901\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9703\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9934\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9934\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9835\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9802\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 1.0000\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 1.0000\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0422 - accuracy: 0.9934\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0551 - accuracy: 0.9901\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9802\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.9868\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9934\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9934\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9868\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9934\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9868\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 0.9967\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9835\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 0.9868\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9901\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9934\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9802\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9967\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9901\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.9934\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9901\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 0.9967\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9967\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 0.9868\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9802\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9934\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9901\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9934\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.9967\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.9967\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9934\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9868\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9967\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 0.9934\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9934\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 0.9934\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.9967\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9901\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9967\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.9901\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 0.9901\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9967\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9967\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9934\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9934\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9901\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9967\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9967\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9934\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9901\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9934\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9769\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.9967\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9901\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9934\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9934\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.9967\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0132 - accuracy: 0.9967\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.9934\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 0.9967\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9967\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0178 - accuracy: 0.9967\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0183 - accuracy: 0.9967\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0274 - accuracy: 0.9868\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9934\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9934\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9967\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9967\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9967\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 0.9934\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0124 - accuracy: 0.9967\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9901\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 0.9967\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.9967\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9967\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 0.9967\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9967\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9967\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9967\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9967\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9901\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9967\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 0.9901\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9967\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.9967\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 0.9967\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.9967\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 0.9967\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9967\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 191/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 161.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 191: early stopping\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9348\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.89 (8/9)\n",
      "Before appending - Cat IDs: 303, Predictions: 303, Actuals: 303, Gender: 303\n",
      "After appending - Cat IDs: 349, Predictions: 349, Actuals: 349, Gender: 349\n",
      "Final Test Results - Loss: 0.22218666970729828, Accuracy: 0.9347826242446899, Precision: 0.94, Recall: 0.9375, F1 Score: 0.9347517730496454\n",
      "Confusion Matrix:\n",
      " [[22  0]\n",
      " [ 3 21]]\n",
      "\n",
      "Final Average F1-Score across all UNSEEN TEST sets: 0.8808764545199669\n",
      "\n",
      "Final Average Loss across all UNSEEN TEST sets: 0.24515101872384548\n",
      "\n",
      "Final Average Accuracy across all UNSEEN TEST sets: 0.8950064331293106\n",
      "\n",
      "Final Average Precision across all UNSEEN TEST sets: 0.8795751126537571\n",
      "\n",
      "Final Average Recall across all UNSEEN TEST sets: 0.9134891820973945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "all_cat_ids = []\n",
    "all_predicted_age_groups = []\n",
    "all_actual_age_groups = []\n",
    "all_gender = []\n",
    "\n",
    "# Define the StratifiedGroupKFold splitter for 4 fold CV with random shuffling\n",
    "outer_cv = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=int(random_seeds[3]))\n",
    "\n",
    "# unseen test set metrics\n",
    "unseen_losses, unseen_accuracies, unseen_precisions, unseen_recalls, unseen_f1 = [], [], [], [], []\n",
    "\n",
    "outer_fold = 0\n",
    "\n",
    "# Use the splitter to generate indices for training and testing sets\n",
    "# Note: GroupShuffleSplit.split returns indices, so we use it to index the arrays\n",
    "for train_val_idx, test_idx in outer_cv.split(X, y, groups):\n",
    "    outer_fold += 1\n",
    "    logger(f\"outer_fold {outer_fold}\", file=log_file_path)\n",
    "\n",
    "    # Convert indices back to DataFrame for easy manipulation\n",
    "    df_train_val = dataframe.iloc[train_val_idx]\n",
    "    df_test = dataframe.iloc[test_idx]\n",
    "\n",
    "    ##############################\n",
    "    # ASSESSING SPLITS BY CAT_ID #\n",
    "    ##############################\n",
    "    \n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test['cat_id'].value_counts()  \n",
    "    \n",
    "    # Log or print the distribution\n",
    "    logger(f\"Train Set Group Distribution:\\n{training_validation_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Group Distribution:\\n{testing_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test['gender'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Training Set Gender Distribution BEFORE SWAP:\\n{training_gender_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Gender Distribution BEFORE SWAP:\\n{testing_gender_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Group by 'age_group' and then list unique 'cat_id' within each age group\n",
    "    unique_cat_ids_per_age_group_train_val = df_train_val.groupby('age_group')['cat_id'].unique()\n",
    "    unique_cat_ids_per_age_group_test = df_test.groupby('age_group')['cat_id'].unique()\n",
    "    \n",
    "    # Log results\n",
    "    logger(f\"Unique Cat IDs per Age Group in Training/Validation Set:\\n{unique_cat_ids_per_age_group_train_val}\", file=log_file_path)\n",
    "    logger(f\"Unique Cat IDs per Age Group in Testing Set:\\n{unique_cat_ids_per_age_group_test}\", file=log_file_path)\n",
    "\n",
    "    # Calculate the count of unique identifiers per age group for training and testing set\n",
    "    counts_train_val = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_train_val.items()}\n",
    "    counts_test = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_test.items()}\n",
    "\n",
    "    # Log the counts of unique identifiers per age group\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Training/Validation Set:\\n{counts_train_val}\", file=log_file_path)\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Testing Set:\\n{counts_test}\", file=log_file_path)\n",
    "\n",
    "    #######################################################\n",
    "    # CONTINUE WITH ENSURING VALID AND APPROPRIATE SPLITS #\n",
    "    #######################################################\n",
    "    \n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    groups_train_val, groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # logging identifier splits \n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "\n",
    "    # # check group splits\n",
    "    # check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # # Specify the cat_ids that must be in the training/validation set\n",
    "    # specific_cat_ids = ['000A', '046A']\n",
    "    \n",
    "    # # Perform the swapping operation\n",
    "    # train_val_idx, test_idx = swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids)\n",
    "    \n",
    "    # # Re-assign the sets based on the updated indices\n",
    "    # X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    # y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    # new_groups_train_val, new_groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # # Find differences for training and test sets\n",
    "    # moved_to_train_val, removed_from_train_val = find_group_differences(groups_train_val, new_groups_train_val)\n",
    "    # moved_to_test, removed_from_test = find_group_differences(groups_test, new_groups_test)\n",
    "    \n",
    "    # # Display the results\n",
    "    # logger(f\"Moved to Training/Validation Set:\\n{moved_to_train_val}\", file=log_file_path)\n",
    "    # logger(f\"Removed from Training/Validation Set:\\n{removed_from_train_val}\", file=log_file_path)\n",
    "    # logger(f\"Moved to Test Set:\\n{moved_to_test}\", file=log_file_path)\n",
    "    # logger(f\"Removed from Test Set\\n{removed_from_test}\", file=log_file_path)\n",
    "\n",
    "    # # Update X_train_val, X_test, y_train_val, y_test, groups_train_val, groups_test based on updated indices\n",
    "    # X_train_val = X[train_val_idx]\n",
    "    # y_train_val = y[train_val_idx]\n",
    "    # groups_train_val = groups[train_val_idx]\n",
    "    \n",
    "    # X_test = X[test_idx]\n",
    "    # y_test = y[test_idx]\n",
    "    # groups_test = groups[test_idx]\n",
    "\n",
    "    # # logging identifier splits again after potential swaps\n",
    "    # unique_train_val_groups = np.unique(groups_train_val)\n",
    "    # unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    # logger(f\"AFTER SWAP - Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    # logger(f\"AFTER SWAP - Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "    \n",
    "    # # Verify the lengths are consistent\n",
    "    # logger(f\"Length of X_train_val:\\n{len(X_train_val)}\", file=log_file_path)\n",
    "    # logger(f\"Length of y_train_val:\\n{len(y_train_val)}\", file=log_file_path)\n",
    "    # logger(f\"Length of groups_train_val:\\n{len(groups_train_val)}\", file=log_file_path)\n",
    "\n",
    "    # # Check group splits once more\n",
    "    # check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Convert the modified indices back to a DataFrame representing the updated df_train_val\n",
    "    df_train_val_updated = dataframe.iloc[train_val_idx].copy()\n",
    "    df_test_updated = dataframe.iloc[test_idx].copy()\n",
    "\n",
    "    ############################\n",
    "    # LOGGING AGE GROUP SPLITS #\n",
    "    ############################\n",
    "\n",
    "    # Get the distribution of age groups of age groups before the update\n",
    "    training_validation_age_group_distribution = df_train_val['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test['age_group'].value_counts()\n",
    "    \n",
    "    # Logthe distribution\n",
    "    logger(f\"Train Age Group Distribution BEFORE SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution BEFORE SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Get the distribution of age groups after the update\n",
    "    training_validation_age_group_distribution = df_train_val_updated['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test_updated['age_group'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Train Age Group Distribution AFTER SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution AFTER SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "    \n",
    "    ########################################################\n",
    "    # TRACKING FINAL CAT_IDs & GENDER AFTER REDISTRIBUTION #\n",
    "    ########################################################\n",
    "\n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val_updated['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test_updated['cat_id'].value_counts()  \n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val_updated['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test_updated['gender'].value_counts()\n",
    "    \n",
    "    logger(f\"\\n Starting training on unseen test set\\n\", file=log_file_path)\n",
    "\n",
    "    ###################\n",
    "    # PREPARING MODEL #\n",
    "    ###################\n",
    "\n",
    "    # Calculate the distribution of age groups in y_train_val\n",
    "    age_group_distribution = Counter(y_train_val)\n",
    "    print(\"Age group distribution:\", age_group_distribution)\n",
    "\n",
    "    # EarlyStopping callback: monitor 'loss' instead of 'val_loss' for the test set\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='loss',  \n",
    "        min_delta=0.001, \n",
    "        patience=30,  \n",
    "        verbose=1,  \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "\n",
    "    # One final shuffle to ensure randomness\n",
    "    outer_shuffle_idx = np.random.permutation(len(X_train_val))\n",
    "    X_train_val = X_train_val[outer_shuffle_idx]\n",
    "    y_train_val = y_train_val[outer_shuffle_idx]\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler_full = StandardScaler().fit(X_train_val)\n",
    "    X_train_full_scaled = scaler_full.transform(X_train_val)\n",
    "    X_test_scaled = scaler_full.transform(X_test)\n",
    "    \n",
    "    # Encode the labels\n",
    "    y_train_full_encoded = y_train_val.astype('float32')\n",
    "    y_test_encoded = y_test.astype('float32')\n",
    "\n",
    "    #######################\n",
    "    # BUILD & TRAIN MODEL #\n",
    "    #######################\n",
    "\n",
    "    # Define optimizers\n",
    "    optimizers = {\n",
    "        'Adamax': Adamax(learning_rate=0.00038188800331973483)\n",
    "    }\n",
    "    \n",
    "    # Full model definition with dynamic number of layers\n",
    "    model_full = Sequential()\n",
    "    model_full.add(Dense(480, activation='relu', input_shape=(X_train_full_scaled.shape[1],)))  # units and input shape from parameters\n",
    "    model_full.add(BatchNormalization())\n",
    "    model_full.add(Dropout(0.27188281261238406))\n",
    "    model_full.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = optimizers['Adamax']  # optimizer selection\n",
    "    \n",
    "    # Compile the model for binary classification\n",
    "    model_full.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model on the full training set\n",
    "    history_full = model_full.fit(X_train_full_scaled, y_train_full_encoded, epochs=300, batch_size=32,\n",
    "                                  verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on the held-out test set\n",
    "    test_loss, test_accuracy = model_full.evaluate(X_test_scaled, y_test_encoded)\n",
    "\n",
    "    # y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    # y_test_pred = np.argmax(y_test_pred_prob, axis=1)  \n",
    "    # y_test_true = np.argmax(y_test_encoded, axis=1)    \n",
    "\n",
    "    # Predict probabilities for the test set\n",
    "    y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    \n",
    "    # Convert probabilities to class labels (0 or 1) using a threshold of 0.5\n",
    "    y_test_pred = (y_test_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # y_test_encoded should be a 1D array of 0s and 1s if prepared as suggested for binary classification\n",
    "    y_test_true = y_test_encoded\n",
    "\n",
    "    ################################\n",
    "    # LOG MAJORITY VOTE PER CAT_ID #\n",
    "    ################################\n",
    "\n",
    "    # Convert numeric predictions back to age group labels\n",
    "    predicted_age_groups = y_test_pred\n",
    "    actual_labels = y_test_true\n",
    "    \n",
    "    # Map predictions and actual labels back to cat_ids\n",
    "    test_results = pd.DataFrame({\n",
    "        'cat_id': df_test_updated['cat_id'],\n",
    "        'predicted_age_group': predicted_age_groups,\n",
    "        'actual_age_group': actual_labels\n",
    "    })\n",
    "    \n",
    "    # Group by cat_id and aggregate predicted age groups\n",
    "    majority_votes = test_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "    actual_groups = test_results.groupby('cat_id')['actual_age_group'].first()\n",
    "    \n",
    "    # Calculate the accuracy of majority voting\n",
    "    correct_predictions = (majority_votes == actual_groups).sum()\n",
    "    total_cats = len(actual_groups)\n",
    "    majority_vote_accuracy = correct_predictions / total_cats\n",
    "    \n",
    "    # Log the accuracy of the majority voting\n",
    "    logger(f\"Majority Vote Accuracy for cat_id for this fold: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)\n",
    "\n",
    "    ####################################################\n",
    "    # COLLECT PREDICTIONS FOR GENDER & CAT_ID ANALYSIS #\n",
    "    ####################################################\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'Before appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Extend lists with current fold results\n",
    "    all_cat_ids.extend(df_test_updated['cat_id'].tolist())\n",
    "    all_predicted_age_groups.extend(predicted_age_groups)\n",
    "    all_actual_age_groups.extend(actual_labels)\n",
    "    all_gender.extend(df_test_updated['gender'].tolist())\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'After appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    test_precision = precision_score(y_test_true, y_test_pred, average='macro')  # Use 'macro' for imbalanced datasets\n",
    "    test_recall = recall_score(y_test_true, y_test_pred, average='macro')\n",
    "    test_f1 = f1_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "    # prepare averages of outer metrics\n",
    "    unseen_f1.append(test_f1)\n",
    "    unseen_losses.append(test_loss)\n",
    "    unseen_accuracies.append(test_accuracy)\n",
    "    unseen_precisions.append(test_precision)\n",
    "    unseen_recalls.append(test_recall)\n",
    "\n",
    "    # Print final test results\n",
    "    logger(f\"Final Test Results - Loss: {test_loss}, Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}\", file=log_file_path)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    logger(f\"Confusion Matrix:\\n {cm}\", file=log_file_path)\n",
    "\n",
    "# Calculate the overall average metrics\n",
    "unseen_set_avg_f1 = np.mean(unseen_f1)\n",
    "unseen_set_avg_loss = np.mean(unseen_losses)\n",
    "unseen_set_avg_acc = np.mean(unseen_accuracies)\n",
    "unseen_set_avg_precision = np.mean(unseen_precisions)\n",
    "unseen_set_avg_recall = np.mean(unseen_recalls)\n",
    "\n",
    "logger(f\"\\nFinal Average F1-Score across all UNSEEN TEST sets: {unseen_set_avg_f1}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Loss across all UNSEEN TEST sets: {unseen_set_avg_loss}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Accuracy across all UNSEEN TEST sets: {unseen_set_avg_acc}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Precision across all UNSEEN TEST sets: {unseen_set_avg_precision}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Recall across all UNSEEN TEST sets: {unseen_set_avg_recall}\\n\", file=log_file_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0522ad-89f9-479c-b073-c5e720fc6221",
   "metadata": {},
   "source": [
    "## Majority Voting on Total Entries per cat_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ecac477e-680c-4a82-abcb-2b3a2dbfbea4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking - Cat IDs: 349, Predictions: 349, Actuals: 349, Gender: 349\n"
     ]
    }
   ],
   "source": [
    "# Debugging print statements\n",
    "print(f'Checking - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ce33a298-d7a3-40ec-8f78-00c109118230",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create results df\n",
    "full_results = pd.DataFrame({\n",
    "    'cat_id': all_cat_ids,\n",
    "    'predicted_age_group': all_predicted_age_groups,\n",
    "    'actual_age_group': all_actual_age_groups,\n",
    "    'all_gender': all_gender\n",
    "})\n",
    "\n",
    "# create a correct majority prediction column\n",
    "full_results['correct'] = full_results['predicted_age_group'] == full_results['actual_age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "23d083a1-d61a-4fce-9b56-667a9930bfe0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Majority Vote Accuracy for cat_id: 0.95 (36/38)\n"
     ]
    }
   ],
   "source": [
    "# Group by cat_id and aggregate predicted age groups\n",
    "majority_votes = full_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first()\n",
    "\n",
    "# Calculate the accuracy of majority voting\n",
    "correct_predictions = (majority_votes == actual_groups).sum()\n",
    "total_cats = len(actual_groups)\n",
    "majority_vote_accuracy = correct_predictions / total_cats\n",
    "\n",
    "logger(f\"Overall Majority Vote Accuracy for cat_id: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "431e9ecf-be90-466a-a1b7-dd98f7fb2a9a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Detailed df with predictions, actual labels, and comparison including majority vote\n",
    "detailed_results = full_results.groupby('cat_id').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Predictions': list(x['predicted_age_group']),\n",
    "        'Majority Vote': x['predicted_age_group'].mode()[0],\n",
    "        'Actual Age Group': x['actual_age_group'].iloc[0],\n",
    "        'Correct Majority Vote': x['predicted_age_group'].mode()[0] == x['actual_age_group'].iloc[0]\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Convert to DataFrame for better formatting and display\n",
    "detailed_results = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "42e4a5c0-56dd-4771-820f-bcecaf391f0c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Majority Vote</th>\n",
       "      <th>Actual Age Group</th>\n",
       "      <th>Correct Majority Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>011A</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>014B</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>058A</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>059A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>061A</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>090A</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>094A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>097A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>104A</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>106A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>108A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>109A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>110A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>111A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>113A</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>115A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>116A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>057A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>056A</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>055A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>045A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>016A</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>024A</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>040A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>041A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>042A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>043A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>044A</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>117A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>054A</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>047A</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>048A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>049A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>050A</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>051A</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>051B</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>093A</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>046A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat_id                                        Predictions  Majority Vote  Actual Age Group  Correct Majority Vote\n",
       "0    011A                                             [1, 1]              1               1.0                   True\n",
       "1    014B                     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]              0               0.0                   True\n",
       "21   058A                                          [1, 1, 1]              1               1.0                   True\n",
       "22   059A         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "23   061A                                             [1, 1]              1               1.0                   True\n",
       "24   090A                                                [1]              1               1.0                   True\n",
       "26   094A                           [1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "27   097A   [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "28   104A                                       [1, 1, 1, 1]              1               1.0                   True\n",
       "29   106A         [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]              1               1.0                   True\n",
       "30   108A                                 [1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "31   109A                                 [0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "32   110A                                                [0]              0               0.0                   True\n",
       "33   111A            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "34   113A                                          [1, 1, 1]              1               1.0                   True\n",
       "35   115A                                                [0]              0               0.0                   True\n",
       "36   116A               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "20   057A  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              1               1.0                   True\n",
       "19   056A                                          [1, 1, 1]              1               1.0                   True\n",
       "18   055A  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              1               1.0                   True\n",
       "9    045A                        [0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "2    016A                     [1, 0, 0, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "3    024A                                                [1]              1               1.0                   True\n",
       "4    040A                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "5    041A                                                [0]              0               0.0                   True\n",
       "6    042A         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "7    043A                                                [0]              0               0.0                   True\n",
       "8    044A                                    [0, 0, 0, 0, 0]              0               0.0                   True\n",
       "37   117A                              [1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "17   054A                                             [1, 1]              1               1.0                   True\n",
       "11   047A  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...              0               0.0                   True\n",
       "12   048A                                                [0]              0               0.0                   True\n",
       "13   049A                                                [0]              0               0.0                   True\n",
       "14   050A                              [0, 1, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "15   051A               [1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "16   051B                        [1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "25   093A                                             [0, 1]              0               1.0                  False\n",
       "10   046A  [1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, ...              1               0.0                  False"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "sorted_detailed_results = detailed_results.sort_values(by='Correct Majority Vote', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "bc2e5ff6-b761-4b71-b7cd-9eb24aae0ebc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Majority Votes per Class:\n",
      "actual_age_group\n",
      "0.0    15\n",
      "1.0    21\n",
      "Name: Majority_Correct, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create df for majority votes\n",
    "majority_df = majority_votes.reset_index()\n",
    "majority_df.columns = ['cat_id', 'Majority_Vote']\n",
    "\n",
    "# Get actual groups for each cat_id\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first().reset_index()\n",
    "\n",
    "# Merge majority votes with actual groups\n",
    "majority_with_actual = pd.merge(majority_df, actual_groups, on='cat_id')\n",
    "\n",
    "# Add a column to check if the majority vote was correct\n",
    "majority_with_actual['Majority_Correct'] = majority_with_actual['Majority_Vote'] == majority_with_actual['actual_age_group']\n",
    "\n",
    "# Count correct majority votes per class\n",
    "correct_majority_votes_per_class = majority_with_actual.groupby('actual_age_group')['Majority_Correct'].sum()\n",
    "\n",
    "print(\"Correct Majority Votes per Class:\")\n",
    "print(correct_majority_votes_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ff925f9d-efd5-46a0-89a0-1fb3da66a46a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics for Majority Votes:\n",
      "   actual_age_group  total_count  correct_count   accuracy\n",
      "0               0.0           16             15  93.750000\n",
      "1               1.0           22             21  95.454545\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = majority_with_actual.groupby('actual_age_group').agg(\n",
    "    total_count=('Majority_Correct', 'size'),  # Total number of cases per class\n",
    "    correct_count=('Majority_Correct', 'sum')  # Sum of correct predictions per class\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log detailed stats\n",
    "print(\"Detailed Class Statistics for Majority Votes:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d8f08817-c78c-4654-b195-911f2a9ccb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics for Majority Votes\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Accuracy of Majority Votes by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea6f284-fe35-4071-8054-5e5a086b4ed9",
   "metadata": {},
   "source": [
    "## Detailed Class Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4394c6ec-6da8-42de-aaaa-bc1b17bbf74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics:\n",
      "   actual_age_group  total_count  correct_count   accuracy\n",
      "0               0.0          171            131  76.608187\n",
      "1               1.0          178            170  95.505618\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = full_results.groupby('actual_age_group').agg(\n",
    "    total_count=('correct', 'size'),\n",
    "    correct_count=('correct', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log the detailed stats\n",
    "print(\"Detailed Class Statistics:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8d541c77-590d-4b79-b526-85520ea5c4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics (Overall)\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Overall Accuracy by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c98d75-f483-4819-b292-975bd229cfd2",
   "metadata": {},
   "source": [
    "## Gender Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "c7325b11-ab06-45bd-8e77-d498737b7552",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Gender:\n",
      "  all_gender  count  correct  accuracy\n",
      "0          F     67       65     97.01\n",
      "1          M     58       54     93.10\n",
      "2          X    224      182     81.25\n"
     ]
    }
   ],
   "source": [
    "# Group by gender and calculate the total count, correct predictions, and accuracy\n",
    "gender_stats = full_results.groupby('all_gender').agg(\n",
    "    count=('cat_id', 'size'),  # Total number of cases per gender\n",
    "    correct=('correct', 'sum')  # Sum of correct predictions per gender\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each gender\n",
    "gender_stats['accuracy'] = (gender_stats['correct'] / gender_stats['count'] * 100).round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy by Gender:\")\n",
    "print(gender_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "777ae0eb-dab5-47c0-86a7-0d3c6b01b9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Accuracy by Gender\n",
    "styled_barplot(gender_stats, 'all_gender', 'accuracy', \n",
    "               'Accuracy by Gender', \n",
    "               'Gender', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40270db-853d-46a1-acb4-8dab8a4f9c81",
   "metadata": {},
   "source": [
    "# RANDOM SEED 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "588e6cfb-6ee5-4b51-a9ee-79dcbfbb208c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senior    178\n",
      "kitten    171\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(int(random_seeds[4]))\n",
    "np.random.seed(int(random_seeds[4]))\n",
    "tf.random.set_seed(int(random_seeds[4]))\n",
    "\n",
    "# Load datasets\n",
    "dataframe = pd.read_csv('/Users/astrid/PycharmProjects/audioset-thesis-work/audioset/vggish/embeddings/8april_looped_embeddings.csv')\n",
    "\n",
    "dataframe.drop('mean_freq', axis=1, inplace=True)\n",
    "\n",
    "def assign_age_group(age, age_groups):\n",
    "    for group_name, age_range in age_groups.items():\n",
    "        if age_range[0] <= age < age_range[1]:\n",
    "            return group_name\n",
    "    return 'Unknown'  # For any age that doesn't fit the defined groups\n",
    "\n",
    "# Define age groups\n",
    "age_groups = {\n",
    "    'kitten': (0, 0.5),\n",
    "    'adult': (0.5, 12),\n",
    "    'senior': (12, 20)\n",
    "}\n",
    "\n",
    "# Create a new column for the age group\n",
    "dataframe['age_group'] = dataframe['target'].apply(assign_age_group, age_groups=age_groups)\n",
    "\n",
    "# Drop Adult\n",
    "dataframe.drop(dataframe[dataframe['age_group'] == 'adult'].index, inplace=True)\n",
    "\n",
    "print(dataframe['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "432a9515-e7f1-482c-bdaf-73cb07a9132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = dataframe.iloc[:, :-4].values  # all columns except the last four\n",
    "\n",
    "# Encode the 'age_group' column as integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y = label_encoder.fit_transform(dataframe['age_group'].values)\n",
    "\n",
    "# Use the encoded labels for splitting and one-hot encoding\n",
    "y = encoded_y  \n",
    "\n",
    "# Convert 'cat_id' column to numpy array to be used as groups array for GroupKFold\n",
    "groups = dataframe['cat_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "8231e441-4472-4d9b-8ddf-dc285c07923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b9ed6b-6d2f-491e-95d8-73d33edeef6a",
   "metadata": {},
   "source": [
    "## Run Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "6cd63258-8a3b-4bc0-9ac6-ae8aa4b515b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_fold 1\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "057A    27\n",
      "055A    20\n",
      "097A    16\n",
      "106A    14\n",
      "042A    14\n",
      "059A    14\n",
      "111A    13\n",
      "051A    12\n",
      "016A    10\n",
      "040A    10\n",
      "014B    10\n",
      "045A     9\n",
      "094A     8\n",
      "117A     7\n",
      "050A     7\n",
      "109A     6\n",
      "044A     5\n",
      "104A     4\n",
      "056A     3\n",
      "054A     2\n",
      "093A     2\n",
      "011A     2\n",
      "061A     2\n",
      "043A     1\n",
      "041A     1\n",
      "048A     1\n",
      "115A     1\n",
      "110A     1\n",
      "090A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "116A    12\n",
      "051B     9\n",
      "108A     6\n",
      "113A     3\n",
      "058A     3\n",
      "049A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    220\n",
      "M     49\n",
      "F     46\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "F    21\n",
      "M     9\n",
      "X     4\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 014B, 111A, 040A, 046A, 047A, 042A, 109...\n",
      "senior    [093A, 097A, 057A, 106A, 104A, 055A, 059A, 054...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten                            [049A]\n",
      "senior    [113A, 116A, 051B, 058A, 108A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 15, 'senior': 17}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 1, 'senior': 5}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '014B' '016A' '024A' '040A' '041A' '042A' '043A' '044A' '045A'\n",
      " '046A' '047A' '048A' '050A' '051A' '054A' '055A' '056A' '057A' '059A'\n",
      " '061A' '090A' '093A' '094A' '097A' '104A' '106A' '109A' '110A' '111A'\n",
      " '115A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['049A' '051B' '058A' '108A' '113A' '116A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "kitten    170\n",
      "senior    145\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "senior    33\n",
      "kitten     1\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "kitten    170\n",
      "senior    145\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "senior    33\n",
      "kitten     1\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 170, 1: 145})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7746\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8730\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.8952\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9270\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9206\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1915 - accuracy: 0.9365\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1651 - accuracy: 0.9587\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1377 - accuracy: 0.9651\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9619\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9619\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9651\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9683\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 0.9683\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.9683\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9492\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9810\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9746\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9810\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9714\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9841\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.9714\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0811 - accuracy: 0.9810\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9810\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9873\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9841\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9937\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0782 - accuracy: 0.9841\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0751 - accuracy: 0.9905\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9810\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9810\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9810\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9810\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9905\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9937\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9873\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0597 - accuracy: 0.9778\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.9778\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9905\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9905\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9841\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9968\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9714\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9873\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9968\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9873\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9810\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9841\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 0.9937\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9841\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9905\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0489 - accuracy: 0.9905\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0388 - accuracy: 0.9968\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9937\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9810\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9937\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9937\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9841\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.9968\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9968\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9905\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9968\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0471 - accuracy: 0.9841\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9905\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 0.9937\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9937\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9968\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9841\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9873\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9968\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0389 - accuracy: 0.9905\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.9937\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9968\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9937\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 0.9905\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9937\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.9937\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9968\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9968\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.9937\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9968\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9968\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9968\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 0.9905\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9968\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 0.9968\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9841\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9968\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9905\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9905\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9905\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9905\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9968\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9968\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9968\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9968\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0364 - accuracy: 0.9905\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9937\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9968\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9968\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9937\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.9968\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9968\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9937\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9937\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9968\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9968\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9937\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9905\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9905\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 969us/step - loss: 0.0142 - accuracy: 0.9968\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9968\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.9937\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 0.9968\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 0.9968\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9968\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9968\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 0.9968\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.9968\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 0.9968\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 0.9968\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 0.9968\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 0s 968us/step - loss: 0.0212 - accuracy: 0.9968\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9968\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 0.9968\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 0.9968\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9968\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9937\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9968\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 197/300\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 167.\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.9968\n",
      "Epoch 197: early stopping\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8824\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy for cat_id for this fold: 0.83 (5/6)\n",
      "Before appending - Cat IDs: 0, Predictions: 0, Actuals: 0, Gender: 0\n",
      "After appending - Cat IDs: 34, Predictions: 34, Actuals: 34, Gender: 34\n",
      "Final Test Results - Loss: 0.3420588970184326, Accuracy: 0.8823529481887817, Precision: 0.6, Recall: 0.9393939393939394, F1 Score: 0.6344086021505376\n",
      "Confusion Matrix:\n",
      " [[ 1  0]\n",
      " [ 4 29]]\n",
      "outer_fold 2\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "047A    28\n",
      "055A    20\n",
      "097A    16\n",
      "106A    14\n",
      "042A    14\n",
      "059A    14\n",
      "111A    13\n",
      "116A    12\n",
      "040A    10\n",
      "045A     9\n",
      "051B     9\n",
      "109A     6\n",
      "108A     6\n",
      "044A     5\n",
      "104A     4\n",
      "113A     3\n",
      "056A     3\n",
      "058A     3\n",
      "054A     2\n",
      "093A     2\n",
      "011A     2\n",
      "043A     1\n",
      "049A     1\n",
      "041A     1\n",
      "048A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "057A    27\n",
      "051A    12\n",
      "014B    10\n",
      "016A    10\n",
      "094A     8\n",
      "117A     7\n",
      "050A     7\n",
      "061A     2\n",
      "115A     1\n",
      "110A     1\n",
      "090A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    178\n",
      "F     47\n",
      "M     38\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    46\n",
      "F    20\n",
      "M    20\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 111A, 040A, 046A, 047A, 042A, 109A, 043...\n",
      "senior    [093A, 097A, 106A, 104A, 055A, 059A, 113A, 116...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten                      [014B, 050A, 115A, 110A]\n",
      "senior    [057A, 117A, 051A, 016A, 094A, 061A, 090A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 12, 'senior': 15}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 4, 'senior': 7}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '024A' '040A' '041A' '042A' '043A' '044A' '045A' '046A' '047A'\n",
      " '048A' '049A' '051B' '054A' '055A' '056A' '058A' '059A' '093A' '097A'\n",
      " '104A' '106A' '108A' '109A' '111A' '113A' '116A']\n",
      "Unique Test Group IDs:\n",
      "['014B' '016A' '050A' '051A' '057A' '061A' '090A' '094A' '110A' '115A'\n",
      " '117A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "kitten    152\n",
      "senior    111\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "senior    67\n",
      "kitten    19\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "kitten    152\n",
      "senior    111\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "senior    67\n",
      "kitten    19\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 152, 1: 111})\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.6350\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3800 - accuracy: 0.8631\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3098 - accuracy: 0.8859\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.9202\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2807 - accuracy: 0.8973\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2414 - accuracy: 0.9240\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.9506\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9620\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9506\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.9392\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9734\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9734\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9582\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9696\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9620\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9810\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.9848\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9848\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9696\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9734\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9848\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.9810\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9772\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0977 - accuracy: 0.9658\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9772\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.9810\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0663 - accuracy: 0.9886\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9886\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9810\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9962\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9924\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9848\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 0.0760 - accuracy: 0.9696\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9924\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9810\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9886\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 0.9772\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9886\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0525 - accuracy: 0.9962\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0579 - accuracy: 0.9886\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9924\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9962\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9848\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0635 - accuracy: 0.9886\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9924\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0623 - accuracy: 0.9810\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 990us/step - loss: 0.0406 - accuracy: 0.9924\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 983us/step - loss: 0.0413 - accuracy: 0.9924\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9848\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 0.9962\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.9962\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9886\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9962\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 977us/step - loss: 0.0503 - accuracy: 0.9886\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0647 - accuracy: 0.9810\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0371 - accuracy: 0.9962\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.9962\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0519 - accuracy: 0.9848\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9962\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 1.0000\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9962\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0455 - accuracy: 0.9962\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 966us/step - loss: 0.0322 - accuracy: 0.9924\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9962\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 949us/step - loss: 0.0339 - accuracy: 0.9924\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0453 - accuracy: 0.9886\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9886\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0393 - accuracy: 0.9962\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9962\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0628 - accuracy: 0.9810\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0352 - accuracy: 0.9924\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0470 - accuracy: 0.9924\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9924\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9962\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9924\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 0.9962\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9962\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0290 - accuracy: 0.9962\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9962\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9962\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9962\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9962\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9962\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9962\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9924\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9886\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9962\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9924\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 0.9962\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 989us/step - loss: 0.0355 - accuracy: 0.9886\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9962\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 0.9924\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 978us/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9962\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9962\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 0.0241 - accuracy: 0.9924\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9962\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9962\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 981us/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9962\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 979us/step - loss: 0.0184 - accuracy: 0.9962\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 942us/step - loss: 0.0227 - accuracy: 0.9924\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 969us/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 928us/step - loss: 0.0162 - accuracy: 0.9962\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9924\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9962\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 983us/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.9962\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9962\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9962\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9886\n",
      "Epoch 150/300\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 120.\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9962\n",
      "Epoch 150: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2599 - accuracy: 0.8488\n",
      "3/3 [==============================] - 0s 882us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.91 (10/11)\n",
      "Before appending - Cat IDs: 34, Predictions: 34, Actuals: 34, Gender: 34\n",
      "After appending - Cat IDs: 120, Predictions: 120, Actuals: 120, Gender: 120\n",
      "Final Test Results - Loss: 0.25985291600227356, Accuracy: 0.8488371968269348, Precision: 0.7863300492610837, Recall: 0.8652788688138255, F1 Score: 0.8097021276595744\n",
      "Confusion Matrix:\n",
      " [[17  2]\n",
      " [11 56]]\n",
      "outer_fold 3\n",
      "Train Set Group Distribution:\n",
      "047A    28\n",
      "057A    27\n",
      "106A    14\n",
      "111A    13\n",
      "116A    12\n",
      "051A    12\n",
      "016A    10\n",
      "040A    10\n",
      "014B    10\n",
      "051B     9\n",
      "094A     8\n",
      "117A     7\n",
      "050A     7\n",
      "109A     6\n",
      "108A     6\n",
      "044A     5\n",
      "104A     4\n",
      "113A     3\n",
      "058A     3\n",
      "061A     2\n",
      "054A     2\n",
      "093A     2\n",
      "049A     1\n",
      "115A     1\n",
      "110A     1\n",
      "090A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "046A    63\n",
      "055A    20\n",
      "097A    16\n",
      "042A    14\n",
      "059A    14\n",
      "045A     9\n",
      "056A     3\n",
      "011A     2\n",
      "043A     1\n",
      "041A     1\n",
      "048A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    116\n",
      "F     45\n",
      "M     43\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    108\n",
      "F     22\n",
      "M     15\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [044A, 014B, 111A, 040A, 047A, 109A, 050A, 049...\n",
      "senior    [093A, 057A, 106A, 104A, 113A, 116A, 051B, 054...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten    [046A, 042A, 043A, 041A, 045A, 048A]\n",
      "senior    [097A, 055A, 059A, 056A, 011A, 024A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 10, 'senior': 16}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 6, 'senior': 6}\n",
      "Unique Training/Validation Group IDs:\n",
      "['014B' '016A' '040A' '044A' '047A' '049A' '050A' '051A' '051B' '054A'\n",
      " '057A' '058A' '061A' '090A' '093A' '094A' '104A' '106A' '108A' '109A'\n",
      " '110A' '111A' '113A' '115A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['011A' '024A' '041A' '042A' '043A' '045A' '046A' '048A' '055A' '056A'\n",
      " '059A' '097A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "senior    122\n",
      "kitten     82\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "kitten    89\n",
      "senior    56\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "senior    122\n",
      "kitten     82\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "kitten    89\n",
      "senior    56\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({1: 122, 0: 82})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.6422\n",
      "Epoch 2/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7745\n",
      "Epoch 3/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8431\n",
      "Epoch 4/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8676\n",
      "Epoch 5/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8627\n",
      "Epoch 6/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.8971\n",
      "Epoch 7/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9167\n",
      "Epoch 8/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2572 - accuracy: 0.9216\n",
      "Epoch 9/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9363\n",
      "Epoch 10/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.9314\n",
      "Epoch 11/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.9265\n",
      "Epoch 12/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.9657\n",
      "Epoch 13/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9363\n",
      "Epoch 14/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9363\n",
      "Epoch 15/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9559\n",
      "Epoch 16/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9706\n",
      "Epoch 17/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9657\n",
      "Epoch 18/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9755\n",
      "Epoch 19/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.9706\n",
      "Epoch 20/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9510\n",
      "Epoch 21/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.9706\n",
      "Epoch 22/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9755\n",
      "Epoch 23/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9755\n",
      "Epoch 24/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.9706\n",
      "Epoch 25/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9657\n",
      "Epoch 26/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9706\n",
      "Epoch 27/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9412\n",
      "Epoch 28/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9559\n",
      "Epoch 29/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9902\n",
      "Epoch 30/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0949 - accuracy: 0.9804\n",
      "Epoch 31/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.9853\n",
      "Epoch 32/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9853\n",
      "Epoch 33/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9902\n",
      "Epoch 34/300\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.9608\n",
      "Epoch 35/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9706\n",
      "Epoch 36/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9804\n",
      "Epoch 37/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9853\n",
      "Epoch 38/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9804\n",
      "Epoch 39/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0803 - accuracy: 0.9804\n",
      "Epoch 40/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9853\n",
      "Epoch 41/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 1.0000\n",
      "Epoch 42/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0825 - accuracy: 0.9853\n",
      "Epoch 43/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9804\n",
      "Epoch 44/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0551 - accuracy: 0.9951\n",
      "Epoch 45/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.9755\n",
      "Epoch 46/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9853\n",
      "Epoch 47/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9804\n",
      "Epoch 48/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9804\n",
      "Epoch 49/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9902\n",
      "Epoch 50/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9755\n",
      "Epoch 51/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 0.9804\n",
      "Epoch 52/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0552 - accuracy: 0.9902\n",
      "Epoch 53/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9902\n",
      "Epoch 54/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9804\n",
      "Epoch 55/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9853\n",
      "Epoch 56/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0534 - accuracy: 0.9951\n",
      "Epoch 57/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0839 - accuracy: 0.9755\n",
      "Epoch 58/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9804\n",
      "Epoch 59/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9804\n",
      "Epoch 60/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9902\n",
      "Epoch 61/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0670 - accuracy: 0.9755\n",
      "Epoch 62/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 0.9853\n",
      "Epoch 63/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9853\n",
      "Epoch 64/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9951\n",
      "Epoch 65/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0646 - accuracy: 0.9755\n",
      "Epoch 66/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0513 - accuracy: 0.9902\n",
      "Epoch 67/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0645 - accuracy: 0.9853\n",
      "Epoch 68/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9804\n",
      "Epoch 69/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9902\n",
      "Epoch 70/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9951\n",
      "Epoch 71/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9853\n",
      "Epoch 72/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.9853\n",
      "Epoch 73/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0485 - accuracy: 0.9951\n",
      "Epoch 74/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9706\n",
      "Epoch 75/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 0.9951\n",
      "Epoch 76/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.9951\n",
      "Epoch 77/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9853\n",
      "Epoch 78/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9902\n",
      "Epoch 79/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9902\n",
      "Epoch 80/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9804\n",
      "Epoch 81/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0610 - accuracy: 0.9853\n",
      "Epoch 82/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9902\n",
      "Epoch 83/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0455 - accuracy: 0.9853\n",
      "Epoch 84/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0528 - accuracy: 0.9804\n",
      "Epoch 85/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0549 - accuracy: 0.9853\n",
      "Epoch 86/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0383 - accuracy: 0.9902\n",
      "Epoch 88/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9853\n",
      "Epoch 90/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9902\n",
      "Epoch 91/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 0.9853\n",
      "Epoch 92/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0803 - accuracy: 0.9804\n",
      "Epoch 93/300\n",
      "7/7 [==============================] - 0s 937us/step - loss: 0.0417 - accuracy: 0.9951\n",
      "Epoch 94/300\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.0502 - accuracy: 0.9902\n",
      "Epoch 95/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9951\n",
      "Epoch 96/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9804\n",
      "Epoch 97/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9951\n",
      "Epoch 98/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9951\n",
      "Epoch 100/300\n",
      "7/7 [==============================] - 0s 996us/step - loss: 0.0352 - accuracy: 0.9951\n",
      "Epoch 101/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0471 - accuracy: 0.9853\n",
      "Epoch 102/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9853\n",
      "Epoch 103/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9951\n",
      "Epoch 104/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9902\n",
      "Epoch 105/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9853\n",
      "Epoch 106/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9951\n",
      "Epoch 107/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9853\n",
      "Epoch 108/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.9951\n",
      "Epoch 109/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9755\n",
      "Epoch 110/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9755\n",
      "Epoch 111/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9902\n",
      "Epoch 112/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0426 - accuracy: 0.9853\n",
      "Epoch 113/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9951\n",
      "Epoch 114/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9804\n",
      "Epoch 116/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9951\n",
      "Epoch 117/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9951\n",
      "Epoch 119/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9951\n",
      "Epoch 120/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9951\n",
      "Epoch 122/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9902\n",
      "Epoch 124/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9853\n",
      "Epoch 125/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9951\n",
      "Epoch 128/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9853\n",
      "Epoch 129/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0383 - accuracy: 0.9853\n",
      "Epoch 130/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9951\n",
      "Epoch 131/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9951\n",
      "Epoch 132/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9902\n",
      "Epoch 134/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0352 - accuracy: 0.9902\n",
      "Epoch 137/300\n",
      "7/7 [==============================] - 0s 996us/step - loss: 0.0454 - accuracy: 0.9804\n",
      "Epoch 138/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0357 - accuracy: 0.9951\n",
      "Epoch 139/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0348 - accuracy: 0.9951\n",
      "Epoch 141/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9951\n",
      "Epoch 142/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9853\n",
      "Epoch 143/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0789 - accuracy: 0.9608\n",
      "Epoch 144/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9951\n",
      "Epoch 145/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9853\n",
      "Epoch 148/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9902\n",
      "Epoch 149/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9951\n",
      "Epoch 151/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 0.9755\n",
      "Epoch 152/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9951\n",
      "Epoch 153/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 0.9951\n",
      "Epoch 156/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9951\n",
      "Epoch 159/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9951\n",
      "Epoch 160/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9902\n",
      "Epoch 161/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9951\n",
      "Epoch 165/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9951\n",
      "Epoch 166/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9902\n",
      "Epoch 167/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.9853\n",
      "Epoch 174/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.0194 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 146.\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 176: early stopping\n",
      "5/5 [==============================] - 0s 887us/step - loss: 0.4792 - accuracy: 0.7379\n",
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy for cat_id for this fold: 0.92 (11/12)\n",
      "Before appending - Cat IDs: 120, Predictions: 120, Actuals: 120, Gender: 120\n",
      "After appending - Cat IDs: 265, Predictions: 265, Actuals: 265, Gender: 265\n",
      "Final Test Results - Loss: 0.47924816608428955, Accuracy: 0.7379310131072998, Precision: 0.7818181818181817, Recall: 0.7798956661316212, F1 Score: 0.7379185692541856\n",
      "Confusion Matrix:\n",
      " [[53 36]\n",
      " [ 2 54]]\n",
      "outer_fold 4\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "057A    27\n",
      "055A    20\n",
      "097A    16\n",
      "042A    14\n",
      "059A    14\n",
      "116A    12\n",
      "051A    12\n",
      "014B    10\n",
      "016A    10\n",
      "051B     9\n",
      "045A     9\n",
      "094A     8\n",
      "117A     7\n",
      "050A     7\n",
      "108A     6\n",
      "056A     3\n",
      "058A     3\n",
      "113A     3\n",
      "061A     2\n",
      "011A     2\n",
      "090A     1\n",
      "110A     1\n",
      "115A     1\n",
      "043A     1\n",
      "048A     1\n",
      "041A     1\n",
      "049A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "047A    28\n",
      "106A    14\n",
      "111A    13\n",
      "040A    10\n",
      "109A     6\n",
      "044A     5\n",
      "104A     4\n",
      "093A     2\n",
      "054A     2\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    158\n",
      "F     63\n",
      "M     44\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    66\n",
      "M    14\n",
      "F     4\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "kitten    [014B, 046A, 042A, 050A, 043A, 049A, 041A, 045...\n",
      "senior    [097A, 057A, 055A, 059A, 113A, 116A, 051B, 117...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "kitten    [044A, 111A, 040A, 047A, 109A]\n",
      "senior          [093A, 106A, 104A, 054A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'kitten': 11, 'senior': 18}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'kitten': 5, 'senior': 4}\n",
      "Unique Training/Validation Group IDs:\n",
      "['011A' '014B' '016A' '024A' '041A' '042A' '043A' '045A' '046A' '048A'\n",
      " '049A' '050A' '051A' '051B' '055A' '056A' '057A' '058A' '059A' '061A'\n",
      " '090A' '094A' '097A' '108A' '110A' '113A' '115A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['040A' '044A' '047A' '054A' '093A' '104A' '106A' '109A' '111A']\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "senior    156\n",
      "kitten    109\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "kitten    62\n",
      "senior    22\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "senior    156\n",
      "kitten    109\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "kitten    62\n",
      "senior    22\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({1: 156, 0: 109})\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.6717\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8151\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3400 - accuracy: 0.8491\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2876 - accuracy: 0.9170\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2497 - accuracy: 0.9245\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2573 - accuracy: 0.9094\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.9434\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.9509\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1737 - accuracy: 0.9434\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1709 - accuracy: 0.9547\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1719 - accuracy: 0.9434\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9623\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9358\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 0.1564 - accuracy: 0.9623\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9585\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9547\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9774\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1362 - accuracy: 0.9774\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 973us/step - loss: 0.1353 - accuracy: 0.9585\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9509\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9509\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 988us/step - loss: 0.1045 - accuracy: 0.9736\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.9811\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9849\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.9736\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9660\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9811\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0843 - accuracy: 0.9811\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 924us/step - loss: 0.0860 - accuracy: 0.9774\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0885 - accuracy: 0.9774\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 993us/step - loss: 0.0986 - accuracy: 0.9736\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9849\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 978us/step - loss: 0.0784 - accuracy: 0.9887\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9962\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 992us/step - loss: 0.0633 - accuracy: 0.9962\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9887\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9698\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 0.9887\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 0.9736\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.9774\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0800 - accuracy: 0.9811\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0807 - accuracy: 0.9849\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9925\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9925\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.9925\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9925\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 951us/step - loss: 0.0513 - accuracy: 0.9962\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9925\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9849\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9887\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0589 - accuracy: 0.9849\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.9925\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9925\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 1.0000\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 937us/step - loss: 0.0544 - accuracy: 0.9849\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 1.0000\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9925\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 1.0000\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 0.9962\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 0.9962\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0579 - accuracy: 0.9849\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0416 - accuracy: 1.0000\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 0.9925\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0383 - accuracy: 0.9962\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9849\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9811\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.9962\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0549 - accuracy: 0.9887\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9925\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 0.9887\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9962\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0576 - accuracy: 0.9925\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9962\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 0.9962\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9811\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0409 - accuracy: 0.9962\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.9962\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9962\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9925\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9887\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9962\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0340 - accuracy: 0.9925\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0538 - accuracy: 0.9849\n",
      "Epoch 89/300\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 0.0425 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 59.\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 1.0000\n",
      "Epoch 89: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9167\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.89 (8/9)\n",
      "Before appending - Cat IDs: 265, Predictions: 265, Actuals: 265, Gender: 265\n",
      "After appending - Cat IDs: 349, Predictions: 349, Actuals: 349, Gender: 349\n",
      "Final Test Results - Loss: 0.16985930502414703, Accuracy: 0.9166666865348816, Precision: 0.9492753623188406, Recall: 0.8409090909090908, F1 Score: 0.878687848153497\n",
      "Confusion Matrix:\n",
      " [[62  0]\n",
      " [ 7 15]]\n",
      "\n",
      "Final Average F1-Score across all UNSEEN TEST sets: 0.7651792868044487\n",
      "\n",
      "Final Average Loss across all UNSEEN TEST sets: 0.3127548210322857\n",
      "\n",
      "Final Average Accuracy across all UNSEEN TEST sets: 0.8464469611644745\n",
      "\n",
      "Final Average Precision across all UNSEEN TEST sets: 0.7793558983495266\n",
      "\n",
      "Final Average Recall across all UNSEEN TEST sets: 0.8563693913121193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "all_cat_ids = []\n",
    "all_predicted_age_groups = []\n",
    "all_actual_age_groups = []\n",
    "all_gender = []\n",
    "\n",
    "# Define the StratifiedGroupKFold splitter for 4 fold CV with random shuffling\n",
    "outer_cv = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=int(random_seeds[4]))\n",
    "\n",
    "# unseen test set metrics\n",
    "unseen_losses, unseen_accuracies, unseen_precisions, unseen_recalls, unseen_f1 = [], [], [], [], []\n",
    "\n",
    "outer_fold = 0\n",
    "\n",
    "# Use the splitter to generate indices for training and testing sets\n",
    "# Note: GroupShuffleSplit.split returns indices, so we use it to index the arrays\n",
    "for train_val_idx, test_idx in outer_cv.split(X, y, groups):\n",
    "    outer_fold += 1\n",
    "    logger(f\"outer_fold {outer_fold}\", file=log_file_path)\n",
    "\n",
    "    # Convert indices back to DataFrame for easy manipulation\n",
    "    df_train_val = dataframe.iloc[train_val_idx]\n",
    "    df_test = dataframe.iloc[test_idx]\n",
    "\n",
    "    ##############################\n",
    "    # ASSESSING SPLITS BY CAT_ID #\n",
    "    ##############################\n",
    "    \n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test['cat_id'].value_counts()  \n",
    "    \n",
    "    # Log or print the distribution\n",
    "    logger(f\"Train Set Group Distribution:\\n{training_validation_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Group Distribution:\\n{testing_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test['gender'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Training Set Gender Distribution BEFORE SWAP:\\n{training_gender_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Gender Distribution BEFORE SWAP:\\n{testing_gender_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Group by 'age_group' and then list unique 'cat_id' within each age group\n",
    "    unique_cat_ids_per_age_group_train_val = df_train_val.groupby('age_group')['cat_id'].unique()\n",
    "    unique_cat_ids_per_age_group_test = df_test.groupby('age_group')['cat_id'].unique()\n",
    "    \n",
    "    # Log results\n",
    "    logger(f\"Unique Cat IDs per Age Group in Training/Validation Set:\\n{unique_cat_ids_per_age_group_train_val}\", file=log_file_path)\n",
    "    logger(f\"Unique Cat IDs per Age Group in Testing Set:\\n{unique_cat_ids_per_age_group_test}\", file=log_file_path)\n",
    "\n",
    "    # Calculate the count of unique identifiers per age group for training and testing set\n",
    "    counts_train_val = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_train_val.items()}\n",
    "    counts_test = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_test.items()}\n",
    "\n",
    "    # Log the counts of unique identifiers per age group\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Training/Validation Set:\\n{counts_train_val}\", file=log_file_path)\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Testing Set:\\n{counts_test}\", file=log_file_path)\n",
    "\n",
    "    #######################################################\n",
    "    # CONTINUE WITH ENSURING VALID AND APPROPRIATE SPLITS #\n",
    "    #######################################################\n",
    "    \n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    groups_train_val, groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # logging identifier splits \n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "\n",
    "    # # check group splits\n",
    "    # check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # # Specify the cat_ids that must be in the training/validation set\n",
    "    # specific_cat_ids = ['000A', '046A']\n",
    "    \n",
    "    # # Perform the swapping operation\n",
    "    # train_val_idx, test_idx = swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids)\n",
    "    \n",
    "    # # Re-assign the sets based on the updated indices\n",
    "    # X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    # y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    # new_groups_train_val, new_groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # # Find differences for training and test sets\n",
    "    # moved_to_train_val, removed_from_train_val = find_group_differences(groups_train_val, new_groups_train_val)\n",
    "    # moved_to_test, removed_from_test = find_group_differences(groups_test, new_groups_test)\n",
    "    \n",
    "    # # Display the results\n",
    "    # logger(f\"Moved to Training/Validation Set:\\n{moved_to_train_val}\", file=log_file_path)\n",
    "    # logger(f\"Removed from Training/Validation Set:\\n{removed_from_train_val}\", file=log_file_path)\n",
    "    # logger(f\"Moved to Test Set:\\n{moved_to_test}\", file=log_file_path)\n",
    "    # logger(f\"Removed from Test Set\\n{removed_from_test}\", file=log_file_path)\n",
    "\n",
    "    # # Update X_train_val, X_test, y_train_val, y_test, groups_train_val, groups_test based on updated indices\n",
    "    # X_train_val = X[train_val_idx]\n",
    "    # y_train_val = y[train_val_idx]\n",
    "    # groups_train_val = groups[train_val_idx]\n",
    "    \n",
    "    # X_test = X[test_idx]\n",
    "    # y_test = y[test_idx]\n",
    "    # groups_test = groups[test_idx]\n",
    "\n",
    "    # # logging identifier splits again after potential swaps\n",
    "    # unique_train_val_groups = np.unique(groups_train_val)\n",
    "    # unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    # logger(f\"AFTER SWAP - Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    # logger(f\"AFTER SWAP - Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "    \n",
    "    # # Verify the lengths are consistent\n",
    "    # logger(f\"Length of X_train_val:\\n{len(X_train_val)}\", file=log_file_path)\n",
    "    # logger(f\"Length of y_train_val:\\n{len(y_train_val)}\", file=log_file_path)\n",
    "    # logger(f\"Length of groups_train_val:\\n{len(groups_train_val)}\", file=log_file_path)\n",
    "\n",
    "    # # Check group splits once more\n",
    "    # check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Convert the modified indices back to a DataFrame representing the updated df_train_val\n",
    "    df_train_val_updated = dataframe.iloc[train_val_idx].copy()\n",
    "    df_test_updated = dataframe.iloc[test_idx].copy()\n",
    "\n",
    "    ############################\n",
    "    # LOGGING AGE GROUP SPLITS #\n",
    "    ############################\n",
    "\n",
    "    # Get the distribution of age groups of age groups before the update\n",
    "    training_validation_age_group_distribution = df_train_val['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test['age_group'].value_counts()\n",
    "    \n",
    "    # Logthe distribution\n",
    "    logger(f\"Train Age Group Distribution BEFORE SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution BEFORE SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Get the distribution of age groups after the update\n",
    "    training_validation_age_group_distribution = df_train_val_updated['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test_updated['age_group'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Train Age Group Distribution AFTER SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution AFTER SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "    \n",
    "    ########################################################\n",
    "    # TRACKING FINAL CAT_IDs & GENDER AFTER REDISTRIBUTION #\n",
    "    ########################################################\n",
    "\n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val_updated['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test_updated['cat_id'].value_counts()  \n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val_updated['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test_updated['gender'].value_counts()\n",
    "    \n",
    "    logger(f\"\\n Starting training on unseen test set\\n\", file=log_file_path)\n",
    "\n",
    "    ###################\n",
    "    # PREPARING MODEL #\n",
    "    ###################\n",
    "\n",
    "    # Calculate the distribution of age groups in y_train_val\n",
    "    age_group_distribution = Counter(y_train_val)\n",
    "    print(\"Age group distribution:\", age_group_distribution)\n",
    "\n",
    "    # EarlyStopping callback: monitor 'loss' instead of 'val_loss' for the test set\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='loss',  \n",
    "        min_delta=0.001, \n",
    "        patience=30,  \n",
    "        verbose=1,  \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "\n",
    "    # One final shuffle to ensure randomness\n",
    "    outer_shuffle_idx = np.random.permutation(len(X_train_val))\n",
    "    X_train_val = X_train_val[outer_shuffle_idx]\n",
    "    y_train_val = y_train_val[outer_shuffle_idx]\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler_full = StandardScaler().fit(X_train_val)\n",
    "    X_train_full_scaled = scaler_full.transform(X_train_val)\n",
    "    X_test_scaled = scaler_full.transform(X_test)\n",
    "    \n",
    "    # Encode the labels\n",
    "    y_train_full_encoded = y_train_val.astype('float32')\n",
    "    y_test_encoded = y_test.astype('float32')\n",
    "\n",
    "    #######################\n",
    "    # BUILD & TRAIN MODEL #\n",
    "    #######################\n",
    "\n",
    "    # Define optimizers\n",
    "    optimizers = {\n",
    "        'Adamax': Adamax(learning_rate=0.00038188800331973483)\n",
    "    }\n",
    "    \n",
    "    # Full model definition with dynamic number of layers\n",
    "    model_full = Sequential()\n",
    "    model_full.add(Dense(480, activation='relu', input_shape=(X_train_full_scaled.shape[1],)))  # units and input shape from parameters\n",
    "    model_full.add(BatchNormalization())\n",
    "    model_full.add(Dropout(0.27188281261238406))\n",
    "    model_full.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = optimizers['Adamax']  # optimizer selection\n",
    "    \n",
    "    # Compile the model for binary classification\n",
    "    model_full.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model on the full training set\n",
    "    history_full = model_full.fit(X_train_full_scaled, y_train_full_encoded, epochs=300, batch_size=32,\n",
    "                                  verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on the held-out test set\n",
    "    test_loss, test_accuracy = model_full.evaluate(X_test_scaled, y_test_encoded)\n",
    "\n",
    "    # y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    # y_test_pred = np.argmax(y_test_pred_prob, axis=1)  \n",
    "    # y_test_true = np.argmax(y_test_encoded, axis=1)    \n",
    "\n",
    "    # Predict probabilities for the test set\n",
    "    y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    \n",
    "    # Convert probabilities to class labels (0 or 1) using a threshold of 0.5\n",
    "    y_test_pred = (y_test_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # y_test_encoded should be a 1D array of 0s and 1s if prepared as suggested for binary classification\n",
    "    y_test_true = y_test_encoded\n",
    "\n",
    "    ################################\n",
    "    # LOG MAJORITY VOTE PER CAT_ID #\n",
    "    ################################\n",
    "\n",
    "    # Convert numeric predictions back to age group labels\n",
    "    predicted_age_groups = y_test_pred\n",
    "    actual_labels = y_test_true\n",
    "    \n",
    "    # Map predictions and actual labels back to cat_ids\n",
    "    test_results = pd.DataFrame({\n",
    "        'cat_id': df_test_updated['cat_id'],\n",
    "        'predicted_age_group': predicted_age_groups,\n",
    "        'actual_age_group': actual_labels\n",
    "    })\n",
    "    \n",
    "    # Group by cat_id and aggregate predicted age groups\n",
    "    majority_votes = test_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "    actual_groups = test_results.groupby('cat_id')['actual_age_group'].first()\n",
    "    \n",
    "    # Calculate the accuracy of majority voting\n",
    "    correct_predictions = (majority_votes == actual_groups).sum()\n",
    "    total_cats = len(actual_groups)\n",
    "    majority_vote_accuracy = correct_predictions / total_cats\n",
    "    \n",
    "    # Log the accuracy of the majority voting\n",
    "    logger(f\"Majority Vote Accuracy for cat_id for this fold: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)\n",
    "\n",
    "    ####################################################\n",
    "    # COLLECT PREDICTIONS FOR GENDER & CAT_ID ANALYSIS #\n",
    "    ####################################################\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'Before appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Extend lists with current fold results\n",
    "    all_cat_ids.extend(df_test_updated['cat_id'].tolist())\n",
    "    all_predicted_age_groups.extend(predicted_age_groups)\n",
    "    all_actual_age_groups.extend(actual_labels)\n",
    "    all_gender.extend(df_test_updated['gender'].tolist())\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'After appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    test_precision = precision_score(y_test_true, y_test_pred, average='macro')  # Use 'macro' for imbalanced datasets\n",
    "    test_recall = recall_score(y_test_true, y_test_pred, average='macro')\n",
    "    test_f1 = f1_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "    # prepare averages of outer metrics\n",
    "    unseen_f1.append(test_f1)\n",
    "    unseen_losses.append(test_loss)\n",
    "    unseen_accuracies.append(test_accuracy)\n",
    "    unseen_precisions.append(test_precision)\n",
    "    unseen_recalls.append(test_recall)\n",
    "\n",
    "    # Print final test results\n",
    "    logger(f\"Final Test Results - Loss: {test_loss}, Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}\", file=log_file_path)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    logger(f\"Confusion Matrix:\\n {cm}\", file=log_file_path)\n",
    "\n",
    "# Calculate the overall average metrics\n",
    "unseen_set_avg_f1 = np.mean(unseen_f1)\n",
    "unseen_set_avg_loss = np.mean(unseen_losses)\n",
    "unseen_set_avg_acc = np.mean(unseen_accuracies)\n",
    "unseen_set_avg_precision = np.mean(unseen_precisions)\n",
    "unseen_set_avg_recall = np.mean(unseen_recalls)\n",
    "\n",
    "logger(f\"\\nFinal Average F1-Score across all UNSEEN TEST sets: {unseen_set_avg_f1}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Loss across all UNSEEN TEST sets: {unseen_set_avg_loss}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Accuracy across all UNSEEN TEST sets: {unseen_set_avg_acc}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Precision across all UNSEEN TEST sets: {unseen_set_avg_precision}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Recall across all UNSEEN TEST sets: {unseen_set_avg_recall}\\n\", file=log_file_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90d80b-198d-4293-a1a0-73a65f6588d0",
   "metadata": {},
   "source": [
    "## Majority Voting on Total Entries per cat_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e9dd5399-64d4-435b-9e73-cb31f16d042d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking - Cat IDs: 349, Predictions: 349, Actuals: 349, Gender: 349\n"
     ]
    }
   ],
   "source": [
    "# Debugging print statements\n",
    "print(f'Checking - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "9d9869f0-e23f-4453-a329-395fa44f1208",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create results df\n",
    "full_results = pd.DataFrame({\n",
    "    'cat_id': all_cat_ids,\n",
    "    'predicted_age_group': all_predicted_age_groups,\n",
    "    'actual_age_group': all_actual_age_groups,\n",
    "    'all_gender': all_gender\n",
    "})\n",
    "\n",
    "# create a correct majority prediction column\n",
    "full_results['correct'] = full_results['predicted_age_group'] == full_results['actual_age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a7f81185-7b51-497f-98cb-80c4b8f35388",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Majority Vote Accuracy for cat_id: 0.89 (34/38)\n"
     ]
    }
   ],
   "source": [
    "# Group by cat_id and aggregate predicted age groups\n",
    "majority_votes = full_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first()\n",
    "\n",
    "# Calculate the accuracy of majority voting\n",
    "correct_predictions = (majority_votes == actual_groups).sum()\n",
    "total_cats = len(actual_groups)\n",
    "majority_vote_accuracy = correct_predictions / total_cats\n",
    "\n",
    "logger(f\"Overall Majority Vote Accuracy for cat_id: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "adbd2ca0-3dea-4b42-bfad-93138cb1ae30",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Detailed df with predictions, actual labels, and comparison including majority vote\n",
    "detailed_results = full_results.groupby('cat_id').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Predictions': list(x['predicted_age_group']),\n",
    "        'Majority Vote': x['predicted_age_group'].mode()[0],\n",
    "        'Actual Age Group': x['actual_age_group'].iloc[0],\n",
    "        'Correct Majority Vote': x['predicted_age_group'].mode()[0] == x['actual_age_group'].iloc[0]\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Convert to DataFrame for better formatting and display\n",
    "detailed_results = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b1ea4fe7-6ee1-4185-a009-b864d9aa6b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Majority Vote</th>\n",
       "      <th>Actual Age Group</th>\n",
       "      <th>Correct Majority Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>011A</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>106A</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>057A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>059A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>090A</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>094A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>097A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>104A</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>108A</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>055A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>109A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>110A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>111A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>113A</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>115A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>116A</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>014B</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>056A</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>054A</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>051B</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>016A</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>024A</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>040A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>041A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>042A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>043A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>044A</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>045A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>117A</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>047A</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>048A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>049A</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>050A</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>051A</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>093A</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>061A</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>058A</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>046A</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat_id                                        Predictions  Majority Vote  Actual Age Group  Correct Majority Vote\n",
       "0    011A                                             [1, 1]              1               1.0                   True\n",
       "29   106A         [0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1]              1               1.0                   True\n",
       "20   057A  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              1               1.0                   True\n",
       "22   059A         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "24   090A                                                [1]              1               1.0                   True\n",
       "26   094A                           [1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "27   097A   [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]              1               1.0                   True\n",
       "28   104A                                       [1, 1, 1, 1]              1               1.0                   True\n",
       "30   108A                                 [0, 1, 1, 1, 1, 0]              1               1.0                   True\n",
       "18   055A  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              1               1.0                   True\n",
       "31   109A                                 [0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "32   110A                                                [0]              0               0.0                   True\n",
       "33   111A            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "34   113A                                          [1, 1, 1]              1               1.0                   True\n",
       "35   115A                                                [0]              0               0.0                   True\n",
       "36   116A               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "1    014B                     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]              0               0.0                   True\n",
       "19   056A                                          [1, 1, 1]              1               1.0                   True\n",
       "17   054A                                             [1, 1]              1               1.0                   True\n",
       "16   051B                        [1, 1, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "2    016A                     [1, 1, 0, 1, 1, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "3    024A                                                [1]              1               1.0                   True\n",
       "4    040A                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "5    041A                                                [0]              0               0.0                   True\n",
       "6    042A         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "7    043A                                                [0]              0               0.0                   True\n",
       "8    044A                                    [0, 0, 0, 0, 0]              0               0.0                   True\n",
       "9    045A                        [0, 0, 0, 0, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "37   117A                              [1, 1, 1, 0, 1, 1, 1]              1               1.0                   True\n",
       "11   047A  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              0               0.0                   True\n",
       "12   048A                                                [0]              0               0.0                   True\n",
       "13   049A                                                [0]              0               0.0                   True\n",
       "14   050A                              [0, 1, 0, 0, 0, 0, 0]              0               0.0                   True\n",
       "15   051A               [1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1]              1               1.0                   True\n",
       "25   093A                                             [0, 0]              0               1.0                  False\n",
       "23   061A                                             [0, 0]              0               1.0                  False\n",
       "21   058A                                          [1, 0, 0]              0               1.0                  False\n",
       "10   046A  [1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, ...              1               0.0                  False"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "sorted_detailed_results = detailed_results.sort_values(by='Correct Majority Vote', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "e03366c5-a807-4159-b0c1-8dc88c04d91e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Majority Votes per Class:\n",
      "actual_age_group\n",
      "0.0    15\n",
      "1.0    19\n",
      "Name: Majority_Correct, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create df for majority votes\n",
    "majority_df = majority_votes.reset_index()\n",
    "majority_df.columns = ['cat_id', 'Majority_Vote']\n",
    "\n",
    "# Get actual groups for each cat_id\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first().reset_index()\n",
    "\n",
    "# Merge majority votes with actual groups\n",
    "majority_with_actual = pd.merge(majority_df, actual_groups, on='cat_id')\n",
    "\n",
    "# Add a column to check if the majority vote was correct\n",
    "majority_with_actual['Majority_Correct'] = majority_with_actual['Majority_Vote'] == majority_with_actual['actual_age_group']\n",
    "\n",
    "# Count correct majority votes per class\n",
    "correct_majority_votes_per_class = majority_with_actual.groupby('actual_age_group')['Majority_Correct'].sum()\n",
    "\n",
    "print(\"Correct Majority Votes per Class:\")\n",
    "print(correct_majority_votes_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "0ae8f86b-0e19-49df-a07c-f64383bce76b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics for Majority Votes:\n",
      "   actual_age_group  total_count  correct_count   accuracy\n",
      "0               0.0           16             15  93.750000\n",
      "1               1.0           22             19  86.363636\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = majority_with_actual.groupby('actual_age_group').agg(\n",
    "    total_count=('Majority_Correct', 'size'),  # Total number of cases per class\n",
    "    correct_count=('Majority_Correct', 'sum')  # Sum of correct predictions per class\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log detailed stats\n",
    "print(\"Detailed Class Statistics for Majority Votes:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6350c1b2-050d-4bf3-98f1-5a80b3078d3a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics for Majority Votes\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Accuracy of Majority Votes by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ea2c7-0827-4ffa-9777-ad2891e5f49b",
   "metadata": {},
   "source": [
    "## Detailed Class Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "94fbe612-c62e-4abe-8ec3-d75940a993cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics:\n",
      "   actual_age_group  total_count  correct_count   accuracy\n",
      "0               0.0          171            133  77.777778\n",
      "1               1.0          178            154  86.516854\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = full_results.groupby('actual_age_group').agg(\n",
    "    total_count=('correct', 'size'),\n",
    "    correct_count=('correct', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log the detailed stats\n",
    "print(\"Detailed Class Statistics:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "50e84f5a-909e-47ca-93ca-2e92abf7ded1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics (Overall)\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Overall Accuracy by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416ac46e-4cc6-4237-925c-524d47e83b46",
   "metadata": {},
   "source": [
    "## Gender Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "1743599c-0d3f-4b10-a095-02c36218c679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Gender:\n",
      "  all_gender  count  correct  accuracy\n",
      "0          F     67       61     91.04\n",
      "1          M     58       50     86.21\n",
      "2          X    224      176     78.57\n"
     ]
    }
   ],
   "source": [
    "# Group by gender and calculate the total count, correct predictions, and accuracy\n",
    "gender_stats = full_results.groupby('all_gender').agg(\n",
    "    count=('cat_id', 'size'),  # Total number of cases per gender\n",
    "    correct=('correct', 'sum')  # Sum of correct predictions per gender\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each gender\n",
    "gender_stats['accuracy'] = (gender_stats['correct'] / gender_stats['count'] * 100).round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy by Gender:\")\n",
    "print(gender_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b8546267-aa7a-4e4b-b60e-810f836ebf8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Accuracy by Gender\n",
    "styled_barplot(gender_stats, 'all_gender', 'accuracy', \n",
    "               'Accuracy by Gender', \n",
    "               'Gender', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a613636d-22ae-4629-ac86-daf482925194",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
