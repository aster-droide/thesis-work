{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17da2043-9a5b-40fe-b3cb-f755b9a98deb",
   "metadata": {},
   "source": [
    "# VGGIsh Multi Seed Validation\n",
    "#### 5 Random (but reproducible) seeds are selected for 5 different runs of train/test\n",
    "#### Models have been optimised and verified on validation sets thoroughly, running a final train/test evaluation here\n",
    "#### The setup:\n",
    "\n",
    "- 4 fold StratifiedGroupKFold for stratification and ensuring each cat_id group only appears in one set at a time\n",
    "- Final scores averaged over the 4 folds\n",
    "- For each seed run we will explore the cat_id predictions through majority voting\n",
    "- For each run we will explore the potential impact of gender\n",
    "\n",
    "The dataset is highly unbalanced, resources for an unbiased estimate have been implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ac1e09ae-387c-4347-b6f5-8d09dd1bf3f2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam, Adamax, SGD, RMSprop, AdamW\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from focal_loss import SparseCategoricalFocalLoss\n",
    "import shap\n",
    "from keras.regularizers import l1, l2, L1L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d005cfd2-3eda-44c4-bbb5-af343e979bc2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seeds: [7270  860 5390 5191 5734]\n"
     ]
    }
   ],
   "source": [
    "# Set an initial seed for reproducibility\n",
    "np.random.seed(42)  \n",
    "\n",
    "# Generate a list of 5 random seeds\n",
    "random_seeds = np.random.randint(0, 10000, size=5)\n",
    "print(\"Random Seeds:\", random_seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae122a-9f9c-47a3-8835-2d46d2f8e2f9",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d5097e68-5153-440c-9294-dfa9e6061652",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def check_initial_group_split(groups_train, groups_test):\n",
    "    \"\"\"\n",
    "    Check if any group is present in both the train and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - groups_train: Array of group identifiers for the train set\n",
    "    - groups_test: Array of group identifiers for the test set\n",
    "\n",
    "    Returns:\n",
    "    - Prints out any groups found in both sets and the count of such groups\n",
    "    \"\"\"\n",
    "    train_groups = set(groups_train)\n",
    "    test_groups = set(groups_test)\n",
    "    common_groups = train_groups.intersection(test_groups)\n",
    "\n",
    "    if common_groups:\n",
    "        print(f\"Warning: Found {len(common_groups)} common groups in both train/validation and test sets: {common_groups}\")\n",
    "    else:\n",
    "        print(\"No common groups found between train and test sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "88dfe2de-bb1e-4d49-9260-e056c39627bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to perform the swaps based on cat_id, ensuring swaps within the same age_group\n",
    "def swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids):\n",
    "    for cat_id in specific_cat_ids:\n",
    "        # Check if the specific cat_id is not in the training set\n",
    "        if cat_id not in dataframe.iloc[train_val_idx]['cat_id'].values:\n",
    "            # Get the age_group of this cat_id\n",
    "            age_group = dataframe[dataframe['cat_id'] == cat_id]['age_group'].iloc[0]\n",
    "                \n",
    "            # Find a different cat_id within the same age_group in the train set that is not in the test set\n",
    "            other_cat_ids_in_age_group = dataframe[(dataframe['age_group'] == age_group) & \n",
    "                                                   (dataframe['cat_id'] != cat_id) &\n",
    "                                                   (~dataframe['cat_id'].isin(dataframe.iloc[test_idx]['cat_id']))]['cat_id'].unique()\n",
    "            \n",
    "            # Choose one other cat_id for swapping\n",
    "            if len(other_cat_ids_in_age_group) > 0:\n",
    "                other_cat_id = np.random.choice(other_cat_ids_in_age_group)\n",
    "\n",
    "                # Find all instances of the other_cat_id in the train set\n",
    "                other_cat_id_train_val_indices = train_val_idx[dataframe.iloc[train_val_idx]['cat_id'] == other_cat_id]\n",
    "                \n",
    "                # Find all instances of the specific cat_id in the test set\n",
    "                cat_id_test_indices = test_idx[dataframe.iloc[test_idx]['cat_id'] == cat_id]\n",
    "                \n",
    "                # Swap the indices\n",
    "                train_val_idx = np.setdiff1d(train_val_idx, other_cat_id_train_val_indices, assume_unique=True)\n",
    "                test_idx = np.setdiff1d(test_idx, cat_id_test_indices, assume_unique=True)\n",
    "\n",
    "                train_val_idx = np.concatenate((train_val_idx, cat_id_test_indices))\n",
    "                test_idx = np.concatenate((test_idx, other_cat_id_train_val_indices))\n",
    "            else:\n",
    "                print(f\"No alternative cat_id found in the same age_group as {cat_id} for swapping.\")\n",
    "                \n",
    "    return train_val_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2e6c2d87-cfab-493e-bca8-b3b8976a2bda",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to identify differences in groups\n",
    "def find_group_differences(original, new):\n",
    "    # Convert numpy arrays to sets for easy difference computation\n",
    "    original_set = set(original)\n",
    "    new_set = set(new)\n",
    "    # Find differences\n",
    "    moved_to_new = new_set - original_set\n",
    "    moved_to_original = original_set - new_set\n",
    "    return moved_to_new, moved_to_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6164b1c3-75dd-4549-aafd-cb6106297941",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create custom logger function for local logs & stored in a .txt\n",
    "def logger(message, file=None):\n",
    "    print(message)\n",
    "    if file is not None:\n",
    "        with open(file, \"a\") as log_file:\n",
    "            log_file.write(message + \"\\n\")\n",
    "\n",
    "log_file_path = \"multi-seed-val-D13.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "899fb535-0e25-4c7b-b6a5-13231e26c502",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\", palette=\"deep\")\n",
    "\n",
    "# Define a custom color palette\n",
    "colors = [\"#6aabd1\", \"#b6e2d3\", \"#dac292\"] \n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "\n",
    "# Function to create bar plots with enhanced style\n",
    "def styled_barplot(data, x, y, title, xlabel, ylabel):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    bar_plot = sns.barplot(x=x, y=y, data=data, errorbar=None, width=0.5)  \n",
    "    plt.title(title, fontsize=16, fontweight='bold', color=\"#333333\")\n",
    "    plt.xlabel(xlabel, fontsize=14, fontweight='bold', color=\"#333333\")\n",
    "    plt.ylabel(ylabel, fontsize=14, fontweight='bold', color=\"#333333\")\n",
    "    plt.xticks(fontsize=12, color=\"#333333\")\n",
    "    plt.yticks(fontsize=12, color=\"#333333\")\n",
    "    plt.ylim(0, 100) \n",
    "\n",
    "    # Adding value labels on top of each bar\n",
    "    for p in bar_plot.patches:\n",
    "        height = p.get_height()\n",
    "        # Annotate the height value on the bar\n",
    "        bar_plot.annotate(f'{height:.1f}', \n",
    "                          (p.get_x() + p.get_width() / 2., height), \n",
    "                          ha='center', va='center', \n",
    "                          xytext=(0, 9), \n",
    "                          textcoords='offset points', fontsize=12, color=\"#333333\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936a24a-13bd-4bc3-be13-0b210a09b5da",
   "metadata": {},
   "source": [
    "# RANDOM SEED 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70136a37-0507-4c2e-8307-c2dd905432e8",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "14bb802b-f4bd-4464-a5fd-1977438428b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult     588\n",
      "senior    178\n",
      "kitten    171\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(int(random_seeds[0])) \n",
    "np.random.seed(int(random_seeds[0]))\n",
    "tf.random.set_seed(int(random_seeds[0]))\n",
    "\n",
    "# Load datasets\n",
    "dataframe = pd.read_csv('/Users/astrid/PycharmProjects/audioset-thesis-work/audioset/vggish/embeddings/8april_looped_embeddings.csv')\n",
    "\n",
    "dataframe.drop('mean_freq', axis=1, inplace=True)\n",
    "\n",
    "def assign_age_group(age, age_groups):\n",
    "    for group_name, age_range in age_groups.items():\n",
    "        if age_range[0] <= age < age_range[1]:\n",
    "            return group_name\n",
    "    return 'Unknown'  # For any age that doesn't fit the defined groups\n",
    "\n",
    "# Define age groups\n",
    "age_groups = {\n",
    "    'kitten': (0, 0.5),\n",
    "    'adult': (0.5, 12),\n",
    "    'senior': (12, 20)\n",
    "}\n",
    "\n",
    "# Create a new column for the age group\n",
    "dataframe['age_group'] = dataframe['target'].apply(assign_age_group, age_groups=age_groups)\n",
    "\n",
    "print(dataframe['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6ce97c28-4210-4150-a60b-acdbf0e7716c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = dataframe.iloc[:, :-4].values  # all columns except the last four\n",
    "\n",
    "# Encode the 'age_group' column as integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y = label_encoder.fit_transform(dataframe['age_group'].values)\n",
    "\n",
    "# Use the encoded labels for splitting and one-hot encoding\n",
    "y = encoded_y  \n",
    "\n",
    "# Convert 'cat_id' column to numpy array to be used as groups array for GroupKFold\n",
    "groups = dataframe['cat_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c26f17c3-4d21-4537-a090-9ca00f2be51a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f91a9c3-3474-4e83-8a5b-c5eb4a9a9223",
   "metadata": {},
   "source": [
    "## Run Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f4605c0b-f99d-48c3-8c2a-d87dd22c8946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_fold 1\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "000A    39\n",
      "002B    32\n",
      "047A    28\n",
      "057A    27\n",
      "074A    25\n",
      "020A    23\n",
      "067A    19\n",
      "000B    19\n",
      "029A    17\n",
      "019A    17\n",
      "097A    16\n",
      "101A    15\n",
      "106A    14\n",
      "059A    14\n",
      "042A    14\n",
      "097B    14\n",
      "028A    13\n",
      "111A    13\n",
      "002A    13\n",
      "116A    12\n",
      "051A    12\n",
      "039A    12\n",
      "036A    11\n",
      "068A    11\n",
      "063A    11\n",
      "005A    10\n",
      "071A    10\n",
      "040A    10\n",
      "014B    10\n",
      "051B     9\n",
      "033A     9\n",
      "065A     9\n",
      "022A     9\n",
      "072A     9\n",
      "095A     8\n",
      "010A     8\n",
      "013B     8\n",
      "099A     7\n",
      "031A     7\n",
      "027A     7\n",
      "050A     7\n",
      "109A     6\n",
      "023A     6\n",
      "007A     6\n",
      "108A     6\n",
      "037A     6\n",
      "075A     5\n",
      "021A     5\n",
      "023B     5\n",
      "025C     5\n",
      "070A     5\n",
      "034A     5\n",
      "044A     5\n",
      "026A     4\n",
      "035A     4\n",
      "105A     4\n",
      "052A     4\n",
      "003A     4\n",
      "062A     4\n",
      "012A     3\n",
      "064A     3\n",
      "006A     3\n",
      "113A     3\n",
      "014A     3\n",
      "061A     2\n",
      "018A     2\n",
      "038A     2\n",
      "054A     2\n",
      "087A     2\n",
      "025B     2\n",
      "011A     2\n",
      "102A     2\n",
      "043A     1\n",
      "090A     1\n",
      "100A     1\n",
      "115A     1\n",
      "004A     1\n",
      "019B     1\n",
      "088A     1\n",
      "049A     1\n",
      "048A     1\n",
      "066A     1\n",
      "096A     1\n",
      "026C     1\n",
      "041A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "103A    33\n",
      "055A    20\n",
      "001A    14\n",
      "025A    11\n",
      "016A    10\n",
      "045A     9\n",
      "015A     9\n",
      "094A     8\n",
      "117A     7\n",
      "008A     6\n",
      "053A     6\n",
      "104A     4\n",
      "009A     4\n",
      "060A     3\n",
      "056A     3\n",
      "058A     3\n",
      "093A     2\n",
      "032A     2\n",
      "069A     2\n",
      "073A     1\n",
      "076A     1\n",
      "092A     1\n",
      "091A     1\n",
      "110A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    325\n",
      "M    253\n",
      "F    197\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "M    84\n",
      "F    55\n",
      "X    23\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 000A, 033A, 071A, 097B, 028A, 019A, 074...\n",
      "kitten    [044A, 014B, 111A, 040A, 046A, 047A, 042A, 109...\n",
      "senior    [097A, 057A, 106A, 059A, 113A, 116A, 051B, 054...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [015A, 001A, 103A, 091A, 009A, 025A, 069A, 032...\n",
      "kitten                                         [045A, 110A]\n",
      "senior    [093A, 104A, 055A, 117A, 056A, 058A, 016A, 094...\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 60, 'kitten': 14, 'senior': 13}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 14, 'kitten': 2, 'senior': 9}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '002A' '002B' '003A' '004A' '005A' '006A' '007A' '010A'\n",
      " '011A' '012A' '013B' '014A' '014B' '018A' '019A' '019B' '020A' '021A'\n",
      " '022A' '023A' '023B' '025B' '025C' '026A' '026B' '026C' '027A' '028A'\n",
      " '029A' '031A' '033A' '034A' '035A' '036A' '037A' '038A' '039A' '040A'\n",
      " '041A' '042A' '043A' '044A' '046A' '047A' '048A' '049A' '050A' '051A'\n",
      " '051B' '052A' '054A' '057A' '059A' '061A' '062A' '063A' '064A' '065A'\n",
      " '066A' '067A' '068A' '070A' '071A' '072A' '074A' '075A' '087A' '088A'\n",
      " '090A' '095A' '096A' '097A' '097B' '099A' '100A' '101A' '102A' '105A'\n",
      " '106A' '108A' '109A' '111A' '113A' '115A' '116A']\n",
      "Unique Test Group IDs:\n",
      "['001A' '008A' '009A' '015A' '016A' '024A' '025A' '032A' '045A' '053A'\n",
      " '055A' '056A' '058A' '060A' '069A' '073A' '076A' '091A' '092A' '093A'\n",
      " '094A' '103A' '104A' '110A' '117A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "set()\n",
      "Removed from Training/Validation Set:\n",
      "set()\n",
      "Moved to Test Set:\n",
      "set()\n",
      "Removed from Test Set\n",
      "set()\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '002A' '002B' '003A' '004A' '005A' '006A' '007A' '010A'\n",
      " '011A' '012A' '013B' '014A' '014B' '018A' '019A' '019B' '020A' '021A'\n",
      " '022A' '023A' '023B' '025B' '025C' '026A' '026B' '026C' '027A' '028A'\n",
      " '029A' '031A' '033A' '034A' '035A' '036A' '037A' '038A' '039A' '040A'\n",
      " '041A' '042A' '043A' '044A' '046A' '047A' '048A' '049A' '050A' '051A'\n",
      " '051B' '052A' '054A' '057A' '059A' '061A' '062A' '063A' '064A' '065A'\n",
      " '066A' '067A' '068A' '070A' '071A' '072A' '074A' '075A' '087A' '088A'\n",
      " '090A' '095A' '096A' '097A' '097B' '099A' '100A' '101A' '102A' '105A'\n",
      " '106A' '108A' '109A' '111A' '113A' '115A' '116A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['001A' '008A' '009A' '015A' '016A' '024A' '025A' '032A' '045A' '053A'\n",
      " '055A' '056A' '058A' '060A' '069A' '073A' '076A' '091A' '092A' '093A'\n",
      " '094A' '103A' '104A' '110A' '117A']\n",
      "Length of X_train_val:\n",
      "775\n",
      "Length of y_train_val:\n",
      "775\n",
      "Length of groups_train_val:\n",
      "775\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     494\n",
      "kitten    161\n",
      "senior    120\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     94\n",
      "senior    58\n",
      "kitten    10\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     494\n",
      "kitten    161\n",
      "senior    120\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     94\n",
      "senior    58\n",
      "kitten    10\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 494, 1: 161, 2: 120})\n",
      "Epoch 1/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.1933 - accuracy: 0.4335\n",
      "Epoch 2/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.8431 - accuracy: 0.5535\n",
      "Epoch 3/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7451 - accuracy: 0.6194\n",
      "Epoch 4/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.6413\n",
      "Epoch 5/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6437 - accuracy: 0.6477\n",
      "Epoch 6/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6724 - accuracy: 0.6310\n",
      "Epoch 7/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.6632\n",
      "Epoch 8/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.6542\n",
      "Epoch 9/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6058 - accuracy: 0.6800\n",
      "Epoch 10/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.7187\n",
      "Epoch 11/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.6852\n",
      "Epoch 12/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5478 - accuracy: 0.6877\n",
      "Epoch 13/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5288 - accuracy: 0.7071\n",
      "Epoch 14/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.7252\n",
      "Epoch 15/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7394\n",
      "Epoch 16/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7368\n",
      "Epoch 17/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7226\n",
      "Epoch 18/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.7316\n",
      "Epoch 19/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.7561\n",
      "Epoch 20/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7729\n",
      "Epoch 21/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.7329\n",
      "Epoch 22/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7626\n",
      "Epoch 23/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7677\n",
      "Epoch 24/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7768\n",
      "Epoch 25/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7729\n",
      "Epoch 26/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.7613\n",
      "Epoch 27/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7729\n",
      "Epoch 28/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4034 - accuracy: 0.7897\n",
      "Epoch 29/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7652\n",
      "Epoch 30/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.7729\n",
      "Epoch 31/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.7794\n",
      "Epoch 32/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.7858\n",
      "Epoch 33/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.7974\n",
      "Epoch 34/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.7961\n",
      "Epoch 35/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4018 - accuracy: 0.7910\n",
      "Epoch 36/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4217 - accuracy: 0.7729\n",
      "Epoch 37/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8039\n",
      "Epoch 38/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.8103\n",
      "Epoch 39/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8116\n",
      "Epoch 40/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3684 - accuracy: 0.8142\n",
      "Epoch 41/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8103\n",
      "Epoch 42/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3483 - accuracy: 0.8142\n",
      "Epoch 43/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8116\n",
      "Epoch 44/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8013\n",
      "Epoch 45/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.7974\n",
      "Epoch 46/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8245\n",
      "Epoch 47/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8052\n",
      "Epoch 48/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3408 - accuracy: 0.8077\n",
      "Epoch 49/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8297\n",
      "Epoch 50/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3413 - accuracy: 0.8142\n",
      "Epoch 51/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3225 - accuracy: 0.8310\n",
      "Epoch 52/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8426\n",
      "Epoch 53/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8219\n",
      "Epoch 54/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.8116\n",
      "Epoch 55/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3222 - accuracy: 0.8310\n",
      "Epoch 56/1500\n",
      "25/25 [==============================] - 0s 976us/step - loss: 0.3187 - accuracy: 0.8258\n",
      "Epoch 57/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3849 - accuracy: 0.8039\n",
      "Epoch 58/1500\n",
      "25/25 [==============================] - 0s 961us/step - loss: 0.3195 - accuracy: 0.8387\n",
      "Epoch 59/1500\n",
      "25/25 [==============================] - 0s 977us/step - loss: 0.3206 - accuracy: 0.8284\n",
      "Epoch 60/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2775 - accuracy: 0.8606\n",
      "Epoch 61/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8219\n",
      "Epoch 62/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2970 - accuracy: 0.8335\n",
      "Epoch 63/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8516\n",
      "Epoch 64/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3070 - accuracy: 0.8335\n",
      "Epoch 65/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8413\n",
      "Epoch 66/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2696 - accuracy: 0.8555\n",
      "Epoch 67/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2771 - accuracy: 0.8529\n",
      "Epoch 68/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.8413\n",
      "Epoch 69/1500\n",
      "25/25 [==============================] - 0s 997us/step - loss: 0.2927 - accuracy: 0.8477\n",
      "Epoch 70/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8284\n",
      "Epoch 71/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2550 - accuracy: 0.8671\n",
      "Epoch 72/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2808 - accuracy: 0.8594\n",
      "Epoch 73/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2696 - accuracy: 0.8542\n",
      "Epoch 74/1500\n",
      "25/25 [==============================] - 0s 992us/step - loss: 0.2767 - accuracy: 0.8529\n",
      "Epoch 75/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 0.8503\n",
      "Epoch 76/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2793 - accuracy: 0.8465\n",
      "Epoch 77/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2722 - accuracy: 0.8516\n",
      "Epoch 78/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2787 - accuracy: 0.8465\n",
      "Epoch 79/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2697 - accuracy: 0.8529\n",
      "Epoch 80/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.8503\n",
      "Epoch 81/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2676 - accuracy: 0.8632\n",
      "Epoch 82/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2811 - accuracy: 0.8684\n",
      "Epoch 83/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2565 - accuracy: 0.8619\n",
      "Epoch 84/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2603 - accuracy: 0.8568\n",
      "Epoch 85/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2845 - accuracy: 0.8568\n",
      "Epoch 86/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.8542\n",
      "Epoch 87/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8477\n",
      "Epoch 88/1500\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.2709 - accuracy: 0.8555\n",
      "Epoch 89/1500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8348\n",
      "Epoch 90/1500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.8581\n",
      "Epoch 91/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.8723\n",
      "Epoch 92/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2291 - accuracy: 0.8774\n",
      "Epoch 93/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2752 - accuracy: 0.8594\n",
      "Epoch 94/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.8735\n",
      "Epoch 95/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.8761\n",
      "Epoch 96/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.8735\n",
      "Epoch 97/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.8632\n",
      "Epoch 98/1500\n",
      "25/25 [==============================] - 0s 994us/step - loss: 0.2660 - accuracy: 0.8697\n",
      "Epoch 99/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.8839\n",
      "Epoch 100/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.8852\n",
      "Epoch 101/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.8761\n",
      "Epoch 102/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2333 - accuracy: 0.8826\n",
      "Epoch 103/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2530 - accuracy: 0.8800\n",
      "Epoch 104/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.8839\n",
      "Epoch 105/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.8942\n",
      "Epoch 106/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.8942\n",
      "Epoch 107/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2081 - accuracy: 0.8903\n",
      "Epoch 108/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.8710\n",
      "Epoch 109/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.8787\n",
      "Epoch 110/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.8903\n",
      "Epoch 111/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.8877\n",
      "Epoch 112/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.8877\n",
      "Epoch 113/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2439 - accuracy: 0.8684\n",
      "Epoch 114/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2577 - accuracy: 0.8723\n",
      "Epoch 115/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.8787\n",
      "Epoch 116/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.8865\n",
      "Epoch 117/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2005 - accuracy: 0.8826\n",
      "Epoch 118/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2132 - accuracy: 0.8903\n",
      "Epoch 119/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.8787\n",
      "Epoch 120/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.8942\n",
      "Epoch 121/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2045 - accuracy: 0.8903\n",
      "Epoch 122/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2082 - accuracy: 0.8955\n",
      "Epoch 123/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.9032\n",
      "Epoch 124/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2120 - accuracy: 0.8852\n",
      "Epoch 125/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.8994\n",
      "Epoch 126/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2091 - accuracy: 0.8903\n",
      "Epoch 127/1500\n",
      "25/25 [==============================] - 0s 994us/step - loss: 0.2197 - accuracy: 0.8903\n",
      "Epoch 128/1500\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.2343 - accuracy: 0.8735\n",
      "Epoch 129/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.8981\n",
      "Epoch 130/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.8903\n",
      "Epoch 131/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.8994\n",
      "Epoch 132/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.8890\n",
      "Epoch 133/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.9006\n",
      "Epoch 134/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2007 - accuracy: 0.8994\n",
      "Epoch 135/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.8903\n",
      "Epoch 136/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.8929\n",
      "Epoch 137/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2100 - accuracy: 0.8903\n",
      "Epoch 138/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2044 - accuracy: 0.8994\n",
      "Epoch 139/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.9006\n",
      "Epoch 140/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.8942\n",
      "Epoch 141/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.9110\n",
      "Epoch 142/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.9006\n",
      "Epoch 143/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.9110\n",
      "Epoch 144/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.8955\n",
      "Epoch 145/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.9135\n",
      "Epoch 146/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.8994\n",
      "Epoch 147/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.9019\n",
      "Epoch 148/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.9032\n",
      "Epoch 149/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.8994\n",
      "Epoch 150/1500\n",
      "25/25 [==============================] - 0s 971us/step - loss: 0.1857 - accuracy: 0.9174\n",
      "Epoch 151/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1698 - accuracy: 0.9135\n",
      "Epoch 152/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.9019\n",
      "Epoch 153/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1699 - accuracy: 0.9045\n",
      "Epoch 154/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9265\n",
      "Epoch 155/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.8955\n",
      "Epoch 156/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.9097\n",
      "Epoch 157/1500\n",
      "25/25 [==============================] - 0s 983us/step - loss: 0.1866 - accuracy: 0.9058\n",
      "Epoch 158/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1664 - accuracy: 0.9252\n",
      "Epoch 159/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9265\n",
      "Epoch 160/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.9006\n",
      "Epoch 161/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9084\n",
      "Epoch 162/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1907 - accuracy: 0.9071\n",
      "Epoch 163/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9213\n",
      "Epoch 164/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.9058\n",
      "Epoch 165/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.9071\n",
      "Epoch 166/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.9161\n",
      "Epoch 167/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9213\n",
      "Epoch 168/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9045\n",
      "Epoch 169/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1740 - accuracy: 0.9174\n",
      "Epoch 170/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.9161\n",
      "Epoch 171/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.9019\n",
      "Epoch 172/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1738 - accuracy: 0.9123\n",
      "Epoch 173/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1661 - accuracy: 0.9316\n",
      "Epoch 174/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9174\n",
      "Epoch 175/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1781 - accuracy: 0.9097\n",
      "Epoch 176/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9110\n",
      "Epoch 177/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9226\n",
      "Epoch 178/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9265\n",
      "Epoch 179/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9252\n",
      "Epoch 180/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1630 - accuracy: 0.9135\n",
      "Epoch 181/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.9135\n",
      "Epoch 182/1500\n",
      "25/25 [==============================] - 0s 991us/step - loss: 0.1787 - accuracy: 0.9084\n",
      "Epoch 183/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9213\n",
      "Epoch 184/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1632 - accuracy: 0.9226\n",
      "Epoch 185/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9252\n",
      "Epoch 186/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1739 - accuracy: 0.9148\n",
      "Epoch 187/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.9058\n",
      "Epoch 188/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.9316\n",
      "Epoch 189/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9187\n",
      "Epoch 190/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9226\n",
      "Epoch 191/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1718 - accuracy: 0.9058\n",
      "Epoch 192/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.9097\n",
      "Epoch 193/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9316\n",
      "Epoch 194/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2148 - accuracy: 0.8994\n",
      "Epoch 195/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9174\n",
      "Epoch 196/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1645 - accuracy: 0.9148\n",
      "Epoch 197/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1423 - accuracy: 0.9316\n",
      "Epoch 198/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9200\n",
      "Epoch 199/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9290\n",
      "Epoch 200/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9265\n",
      "Epoch 201/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9303\n",
      "Epoch 202/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9303\n",
      "Epoch 203/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9368\n",
      "Epoch 204/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9200\n",
      "Epoch 205/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9058\n",
      "Epoch 206/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9303\n",
      "Epoch 207/1500\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.1155 - accuracy: 0.9062Restoring model weights from the end of the best epoch: 177.\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.9058\n",
      "Epoch 207: early stopping\n",
      "6/6 [==============================] - 0s 787us/step - loss: 1.0560 - accuracy: 0.6420\n",
      "6/6 [==============================] - 0s 653us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.72 (18/25)\n",
      "Before appending - Cat IDs: 0, Predictions: 0, Actuals: 0, Gender: 0\n",
      "After appending - Cat IDs: 162, Predictions: 162, Actuals: 162, Gender: 162\n",
      "Final Test Results - Loss: 1.0559931993484497, Accuracy: 0.6419752836227417, Precision: 0.6166417346265823, Recall: 0.7326974810467107, F1 Score: 0.656484441430678\n",
      "Confusion Matrix:\n",
      " [[64  7 23]\n",
      " [ 0 10  0]\n",
      " [28  0 30]]\n",
      "outer_fold 2\n",
      "Train Set Group Distribution:\n",
      "000A    39\n",
      "103A    33\n",
      "002B    32\n",
      "047A    28\n",
      "074A    25\n",
      "020A    23\n",
      "055A    20\n",
      "067A    19\n",
      "019A    17\n",
      "097A    16\n",
      "101A    15\n",
      "059A    14\n",
      "042A    14\n",
      "001A    14\n",
      "097B    14\n",
      "111A    13\n",
      "002A    13\n",
      "051A    12\n",
      "116A    12\n",
      "063A    11\n",
      "025A    11\n",
      "040A    10\n",
      "014B    10\n",
      "016A    10\n",
      "033A     9\n",
      "072A     9\n",
      "065A     9\n",
      "045A     9\n",
      "015A     9\n",
      "094A     8\n",
      "050A     7\n",
      "117A     7\n",
      "099A     7\n",
      "027A     7\n",
      "031A     7\n",
      "053A     6\n",
      "109A     6\n",
      "008A     6\n",
      "023A     6\n",
      "108A     6\n",
      "007A     6\n",
      "021A     5\n",
      "034A     5\n",
      "025C     5\n",
      "023B     5\n",
      "075A     5\n",
      "052A     4\n",
      "104A     4\n",
      "026A     4\n",
      "035A     4\n",
      "009A     4\n",
      "062A     4\n",
      "003A     4\n",
      "012A     3\n",
      "060A     3\n",
      "064A     3\n",
      "006A     3\n",
      "056A     3\n",
      "058A     3\n",
      "113A     3\n",
      "038A     2\n",
      "069A     2\n",
      "093A     2\n",
      "087A     2\n",
      "061A     2\n",
      "102A     2\n",
      "011A     2\n",
      "032A     2\n",
      "018A     2\n",
      "115A     1\n",
      "110A     1\n",
      "019B     1\n",
      "090A     1\n",
      "004A     1\n",
      "073A     1\n",
      "066A     1\n",
      "091A     1\n",
      "026C     1\n",
      "041A     1\n",
      "092A     1\n",
      "076A     1\n",
      "043A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "046A    63\n",
      "057A    27\n",
      "000B    19\n",
      "029A    17\n",
      "106A    14\n",
      "028A    13\n",
      "039A    12\n",
      "036A    11\n",
      "068A    11\n",
      "071A    10\n",
      "005A    10\n",
      "051B     9\n",
      "022A     9\n",
      "010A     8\n",
      "013B     8\n",
      "095A     8\n",
      "037A     6\n",
      "044A     5\n",
      "070A     5\n",
      "105A     4\n",
      "014A     3\n",
      "054A     2\n",
      "025B     2\n",
      "096A     1\n",
      "049A     1\n",
      "048A     1\n",
      "088A     1\n",
      "100A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "M    264\n",
      "X    198\n",
      "F    193\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    150\n",
      "M     73\n",
      "F     59\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 000A, 033A, 015A, 001A, 103A, 097B, 019...\n",
      "kitten    [014B, 111A, 040A, 047A, 042A, 109A, 050A, 043...\n",
      "senior    [093A, 097A, 104A, 055A, 059A, 113A, 116A, 117...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [071A, 028A, 022A, 029A, 095A, 005A, 039A, 013...\n",
      "kitten                             [044A, 046A, 049A, 048A]\n",
      "senior                             [057A, 106A, 051B, 054A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 53, 'kitten': 12, 'senior': 18}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 21, 'kitten': 4, 'senior': 4}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '001A' '002A' '002B' '003A' '004A' '006A' '007A' '008A' '009A'\n",
      " '011A' '012A' '014B' '015A' '016A' '018A' '019A' '019B' '020A' '021A'\n",
      " '023A' '023B' '024A' '025A' '025C' '026A' '026C' '027A' '031A' '032A'\n",
      " '033A' '034A' '035A' '038A' '040A' '041A' '042A' '043A' '045A' '047A'\n",
      " '050A' '051A' '052A' '053A' '055A' '056A' '058A' '059A' '060A' '061A'\n",
      " '062A' '063A' '064A' '065A' '066A' '067A' '069A' '072A' '073A' '074A'\n",
      " '075A' '076A' '087A' '090A' '091A' '092A' '093A' '094A' '097A' '097B'\n",
      " '099A' '101A' '102A' '103A' '104A' '108A' '109A' '110A' '111A' '113A'\n",
      " '115A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['000B' '005A' '010A' '013B' '014A' '022A' '025B' '026B' '028A' '029A'\n",
      " '036A' '037A' '039A' '044A' '046A' '048A' '049A' '051B' '054A' '057A'\n",
      " '068A' '070A' '071A' '088A' '095A' '096A' '100A' '105A' '106A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "{'046A'}\n",
      "Removed from Training/Validation Set:\n",
      "{'110A'}\n",
      "Moved to Test Set:\n",
      "{'110A'}\n",
      "Removed from Test Set\n",
      "{'046A'}\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '001A' '002A' '002B' '003A' '004A' '006A' '007A' '008A' '009A'\n",
      " '011A' '012A' '014B' '015A' '016A' '018A' '019A' '019B' '020A' '021A'\n",
      " '023A' '023B' '024A' '025A' '025C' '026A' '026C' '027A' '031A' '032A'\n",
      " '033A' '034A' '035A' '038A' '040A' '041A' '042A' '043A' '045A' '046A'\n",
      " '047A' '050A' '051A' '052A' '053A' '055A' '056A' '058A' '059A' '060A'\n",
      " '061A' '062A' '063A' '064A' '065A' '066A' '067A' '069A' '072A' '073A'\n",
      " '074A' '075A' '076A' '087A' '090A' '091A' '092A' '093A' '094A' '097A'\n",
      " '097B' '099A' '101A' '102A' '103A' '104A' '108A' '109A' '111A' '113A'\n",
      " '115A' '116A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['000B' '005A' '010A' '013B' '014A' '022A' '025B' '026B' '028A' '029A'\n",
      " '036A' '037A' '039A' '044A' '048A' '049A' '051B' '054A' '057A' '068A'\n",
      " '070A' '071A' '088A' '095A' '096A' '100A' '105A' '106A' '110A']\n",
      "Length of X_train_val:\n",
      "717\n",
      "Length of y_train_val:\n",
      "717\n",
      "Length of groups_train_val:\n",
      "717\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     428\n",
      "senior    126\n",
      "kitten    101\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     160\n",
      "kitten     70\n",
      "senior     52\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     428\n",
      "kitten    163\n",
      "senior    126\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     160\n",
      "senior     52\n",
      "kitten      8\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 428, 1: 163, 2: 126})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.1408 - accuracy: 0.4686\n",
      "Epoch 2/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8076 - accuracy: 0.6053\n",
      "Epoch 3/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7571 - accuracy: 0.6151\n",
      "Epoch 4/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.6430\n",
      "Epoch 5/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.6179\n",
      "Epoch 6/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6328 - accuracy: 0.6569\n",
      "Epoch 7/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6318 - accuracy: 0.6667\n",
      "Epoch 8/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5894 - accuracy: 0.6834\n",
      "Epoch 9/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.6960\n",
      "Epoch 10/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.7127\n",
      "Epoch 11/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.7392\n",
      "Epoch 12/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.7294\n",
      "Epoch 13/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.7280\n",
      "Epoch 14/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.7364\n",
      "Epoch 15/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7392\n",
      "Epoch 16/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.7490\n",
      "Epoch 17/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7503\n",
      "Epoch 18/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7699\n",
      "Epoch 19/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.7727\n",
      "Epoch 20/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4302 - accuracy: 0.7643\n",
      "Epoch 21/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7866\n",
      "Epoch 22/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.7810\n",
      "Epoch 23/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.7782\n",
      "Epoch 24/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3824 - accuracy: 0.8075\n",
      "Epoch 25/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3970 - accuracy: 0.7964\n",
      "Epoch 26/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.7992\n",
      "Epoch 27/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3914 - accuracy: 0.8061\n",
      "Epoch 28/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.8006\n",
      "Epoch 29/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8103\n",
      "Epoch 30/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.7950\n",
      "Epoch 31/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8187\n",
      "Epoch 32/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3841 - accuracy: 0.8271\n",
      "Epoch 33/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.8103\n",
      "Epoch 34/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8229\n",
      "Epoch 35/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8271\n",
      "Epoch 36/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3685 - accuracy: 0.8285\n",
      "Epoch 37/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.8229\n",
      "Epoch 38/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8271\n",
      "Epoch 39/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8410\n",
      "Epoch 40/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3255 - accuracy: 0.8368\n",
      "Epoch 41/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8145\n",
      "Epoch 42/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8368\n",
      "Epoch 43/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3585 - accuracy: 0.8187\n",
      "Epoch 44/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8271\n",
      "Epoch 45/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8326\n",
      "Epoch 46/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8326\n",
      "Epoch 47/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3178 - accuracy: 0.8550\n",
      "Epoch 48/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3188 - accuracy: 0.8368\n",
      "Epoch 49/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8340\n",
      "Epoch 50/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8438\n",
      "Epoch 51/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3046 - accuracy: 0.8424\n",
      "Epoch 52/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3027 - accuracy: 0.8563\n",
      "Epoch 53/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3121 - accuracy: 0.8480\n",
      "Epoch 54/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2772 - accuracy: 0.8647\n",
      "Epoch 55/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3033 - accuracy: 0.8647\n",
      "Epoch 56/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2838 - accuracy: 0.8675\n",
      "Epoch 57/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2789 - accuracy: 0.8717\n",
      "Epoch 58/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2920 - accuracy: 0.8536\n",
      "Epoch 59/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.8536\n",
      "Epoch 60/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2711 - accuracy: 0.8563\n",
      "Epoch 61/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.8689\n",
      "Epoch 62/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2830 - accuracy: 0.8577\n",
      "Epoch 63/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2544 - accuracy: 0.8717\n",
      "Epoch 64/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2739 - accuracy: 0.8508\n",
      "Epoch 65/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2689 - accuracy: 0.8675\n",
      "Epoch 66/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2667 - accuracy: 0.8689\n",
      "Epoch 67/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2759 - accuracy: 0.8801\n",
      "Epoch 68/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.8647\n",
      "Epoch 69/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2668 - accuracy: 0.8745\n",
      "Epoch 70/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.8801\n",
      "Epoch 71/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.8787\n",
      "Epoch 72/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2404 - accuracy: 0.8815\n",
      "Epoch 73/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.8717\n",
      "Epoch 74/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2673 - accuracy: 0.8717\n",
      "Epoch 75/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.8815\n",
      "Epoch 76/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2682 - accuracy: 0.8787\n",
      "Epoch 77/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2421 - accuracy: 0.8745\n",
      "Epoch 78/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.8773\n",
      "Epoch 79/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.8884\n",
      "Epoch 80/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.8842\n",
      "Epoch 81/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.8815\n",
      "Epoch 82/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.8842\n",
      "Epoch 83/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.8828\n",
      "Epoch 84/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.8968\n",
      "Epoch 85/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2555 - accuracy: 0.8801\n",
      "Epoch 86/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.8842\n",
      "Epoch 87/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2105 - accuracy: 0.9024\n",
      "Epoch 88/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.8968\n",
      "Epoch 89/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.8856\n",
      "Epoch 90/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.9066\n",
      "Epoch 91/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.9010\n",
      "Epoch 92/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2344 - accuracy: 0.8912\n",
      "Epoch 93/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.8801\n",
      "Epoch 94/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2096 - accuracy: 0.8954\n",
      "Epoch 95/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.8968\n",
      "Epoch 96/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.9107\n",
      "Epoch 97/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.8926\n",
      "Epoch 98/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2233 - accuracy: 0.8968\n",
      "Epoch 99/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.9066\n",
      "Epoch 100/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 0.8801\n",
      "Epoch 101/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.8912\n",
      "Epoch 102/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.9024\n",
      "Epoch 103/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.8912\n",
      "Epoch 104/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.9038\n",
      "Epoch 105/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2055 - accuracy: 0.9052\n",
      "Epoch 106/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9177\n",
      "Epoch 107/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9177\n",
      "Epoch 108/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2083 - accuracy: 0.9093\n",
      "Epoch 109/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.9024\n",
      "Epoch 110/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.9010\n",
      "Epoch 111/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.9219\n",
      "Epoch 112/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1971 - accuracy: 0.9066\n",
      "Epoch 113/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9275\n",
      "Epoch 114/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 0.9275\n",
      "Epoch 115/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.9135\n",
      "Epoch 116/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.9233\n",
      "Epoch 117/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9358\n",
      "Epoch 118/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9205\n",
      "Epoch 119/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9135\n",
      "Epoch 120/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1736 - accuracy: 0.9121\n",
      "Epoch 121/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9135\n",
      "Epoch 122/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.9233\n",
      "Epoch 123/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1915 - accuracy: 0.9121\n",
      "Epoch 124/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.9177\n",
      "Epoch 125/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.9135\n",
      "Epoch 126/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.9219\n",
      "Epoch 127/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.9121\n",
      "Epoch 128/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9219\n",
      "Epoch 129/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.9079\n",
      "Epoch 130/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.9331\n",
      "Epoch 131/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.9372\n",
      "Epoch 132/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9386\n",
      "Epoch 133/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.9233\n",
      "Epoch 134/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.9066\n",
      "Epoch 135/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9177\n",
      "Epoch 136/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1635 - accuracy: 0.9233\n",
      "Epoch 137/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9317\n",
      "Epoch 138/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9289\n",
      "Epoch 139/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9219\n",
      "Epoch 140/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.9289\n",
      "Epoch 141/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.9079\n",
      "Epoch 142/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9177\n",
      "Epoch 143/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.9163\n",
      "Epoch 144/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9289\n",
      "Epoch 145/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9275\n",
      "Epoch 146/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9303\n",
      "Epoch 147/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9191\n",
      "Epoch 148/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9261\n",
      "Epoch 149/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1680 - accuracy: 0.9191\n",
      "Epoch 150/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9386\n",
      "Epoch 151/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9428\n",
      "Epoch 152/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9331\n",
      "Epoch 153/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9163\n",
      "Epoch 154/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9331\n",
      "Epoch 155/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.9372\n",
      "Epoch 156/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9317\n",
      "Epoch 157/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9358\n",
      "Epoch 158/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.9303\n",
      "Epoch 159/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9400\n",
      "Epoch 160/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9233\n",
      "Epoch 161/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.9344\n",
      "Epoch 162/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9456\n",
      "Epoch 163/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9358\n",
      "Epoch 164/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9386\n",
      "Epoch 165/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9456\n",
      "Epoch 166/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.9428\n",
      "Epoch 167/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.9372\n",
      "Epoch 168/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9317\n",
      "Epoch 169/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9275\n",
      "Epoch 170/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9456\n",
      "Epoch 171/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9317\n",
      "Epoch 172/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.9442\n",
      "Epoch 173/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1680 - accuracy: 0.9233\n",
      "Epoch 174/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9554\n",
      "Epoch 175/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1495 - accuracy: 0.9442\n",
      "Epoch 176/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1501 - accuracy: 0.9219\n",
      "Epoch 177/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9456\n",
      "Epoch 178/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9484\n",
      "Epoch 179/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1445 - accuracy: 0.9414\n",
      "Epoch 180/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9303\n",
      "Epoch 181/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9303\n",
      "Epoch 182/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9414\n",
      "Epoch 183/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9484\n",
      "Epoch 184/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9442\n",
      "Epoch 185/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.9512\n",
      "Epoch 186/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.9400\n",
      "Epoch 187/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9400\n",
      "Epoch 188/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9442\n",
      "Epoch 189/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9428\n",
      "Epoch 190/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9470\n",
      "Epoch 191/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.9442\n",
      "Epoch 192/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9526\n",
      "Epoch 193/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9554\n",
      "Epoch 194/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9317\n",
      "Epoch 195/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9470\n",
      "Epoch 196/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9498\n",
      "Epoch 197/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9456\n",
      "Epoch 198/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9512\n",
      "Epoch 199/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9414\n",
      "Epoch 200/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9609\n",
      "Epoch 201/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.9400\n",
      "Epoch 202/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9484\n",
      "Epoch 203/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9456\n",
      "Epoch 204/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9568\n",
      "Epoch 205/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9498\n",
      "Epoch 206/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9386\n",
      "Epoch 207/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9498\n",
      "Epoch 208/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9386\n",
      "Epoch 209/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9456\n",
      "Epoch 210/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9386\n",
      "Epoch 211/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9498\n",
      "Epoch 212/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.9637\n",
      "Epoch 213/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9540\n",
      "Epoch 214/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9442\n",
      "Epoch 215/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9512\n",
      "Epoch 216/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1037 - accuracy: 0.9596\n",
      "Epoch 217/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9484\n",
      "Epoch 218/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9512\n",
      "Epoch 219/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9568\n",
      "Epoch 220/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.9554\n",
      "Epoch 221/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9665\n",
      "Epoch 222/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9582\n",
      "Epoch 223/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.9498\n",
      "Epoch 224/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9414\n",
      "Epoch 225/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9540\n",
      "Epoch 226/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9651\n",
      "Epoch 227/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9596\n",
      "Epoch 228/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.9609\n",
      "Epoch 229/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0999 - accuracy: 0.9596\n",
      "Epoch 230/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9568\n",
      "Epoch 231/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9582\n",
      "Epoch 232/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9512\n",
      "Epoch 233/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9512\n",
      "Epoch 234/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1027 - accuracy: 0.9596\n",
      "Epoch 235/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9582\n",
      "Epoch 236/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9540\n",
      "Epoch 237/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9582\n",
      "Epoch 238/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9568\n",
      "Epoch 239/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9665\n",
      "Epoch 240/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.9623\n",
      "Epoch 241/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9498\n",
      "Epoch 242/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9568\n",
      "Epoch 243/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9414\n",
      "Epoch 244/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9442\n",
      "Epoch 245/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9414\n",
      "Epoch 246/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.9596\n",
      "Epoch 247/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9428\n",
      "Epoch 248/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.9665\n",
      "Epoch 249/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9651\n",
      "Epoch 250/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0969 - accuracy: 0.9637\n",
      "Epoch 251/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9428\n",
      "Epoch 252/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9498\n",
      "Epoch 253/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9512\n",
      "Epoch 254/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9470\n",
      "Epoch 255/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9568\n",
      "Epoch 256/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0943 - accuracy: 0.9623\n",
      "Epoch 257/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9609\n",
      "Epoch 258/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0734 - accuracy: 0.9763\n",
      "Epoch 259/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9637\n",
      "Epoch 260/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9679\n",
      "Epoch 261/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9609\n",
      "Epoch 262/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9540\n",
      "Epoch 263/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9498\n",
      "Epoch 264/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0866 - accuracy: 0.9637\n",
      "Epoch 265/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9623\n",
      "Epoch 266/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9651\n",
      "Epoch 267/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9665\n",
      "Epoch 268/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9582\n",
      "Epoch 269/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9582\n",
      "Epoch 270/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0815 - accuracy: 0.9637\n",
      "Epoch 271/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9679\n",
      "Epoch 272/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0803 - accuracy: 0.9735\n",
      "Epoch 273/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0890 - accuracy: 0.9651\n",
      "Epoch 274/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9721\n",
      "Epoch 275/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.9707\n",
      "Epoch 276/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9721\n",
      "Epoch 277/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9623\n",
      "Epoch 278/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.9665\n",
      "Epoch 279/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9623\n",
      "Epoch 280/1500\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0745 - accuracy: 0.9665\n",
      "Epoch 281/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9609\n",
      "Epoch 282/1500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0801 - accuracy: 0.9651\n",
      "Epoch 283/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.9484\n",
      "Epoch 284/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0982 - accuracy: 0.9568\n",
      "Epoch 285/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9582\n",
      "Epoch 286/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9735\n",
      "Epoch 287/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9651\n",
      "Epoch 288/1500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.1069 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 258.\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1035 - accuracy: 0.9637\n",
      "Epoch 288: early stopping\n",
      "7/7 [==============================] - 0s 854us/step - loss: 0.9139 - accuracy: 0.7091\n",
      "7/7 [==============================] - 0s 698us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.72 (21/29)\n",
      "Before appending - Cat IDs: 162, Predictions: 162, Actuals: 162, Gender: 162\n",
      "After appending - Cat IDs: 382, Predictions: 382, Actuals: 382, Gender: 382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Results - Loss: 0.9139342308044434, Accuracy: 0.7090908885002136, Precision: 0.7442328042328041, Recall: 0.7145833333333332, F1 Score: 0.7263518778245285\n",
      "Confusion Matrix:\n",
      " [[123   0  37]\n",
      " [  1   7   0]\n",
      " [ 26   0  26]]\n",
      "outer_fold 3\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "000A    39\n",
      "103A    33\n",
      "057A    27\n",
      "055A    20\n",
      "000B    19\n",
      "029A    17\n",
      "101A    15\n",
      "001A    14\n",
      "106A    14\n",
      "042A    14\n",
      "028A    13\n",
      "111A    13\n",
      "039A    12\n",
      "068A    11\n",
      "063A    11\n",
      "036A    11\n",
      "025A    11\n",
      "005A    10\n",
      "016A    10\n",
      "040A    10\n",
      "014B    10\n",
      "071A    10\n",
      "051B     9\n",
      "022A     9\n",
      "065A     9\n",
      "045A     9\n",
      "015A     9\n",
      "010A     8\n",
      "095A     8\n",
      "094A     8\n",
      "013B     8\n",
      "031A     7\n",
      "117A     7\n",
      "053A     6\n",
      "108A     6\n",
      "008A     6\n",
      "109A     6\n",
      "007A     6\n",
      "037A     6\n",
      "070A     5\n",
      "021A     5\n",
      "044A     5\n",
      "023B     5\n",
      "035A     4\n",
      "026A     4\n",
      "105A     4\n",
      "062A     4\n",
      "009A     4\n",
      "104A     4\n",
      "058A     3\n",
      "064A     3\n",
      "014A     3\n",
      "060A     3\n",
      "056A     3\n",
      "113A     3\n",
      "025B     2\n",
      "011A     2\n",
      "061A     2\n",
      "102A     2\n",
      "054A     2\n",
      "093A     2\n",
      "038A     2\n",
      "087A     2\n",
      "032A     2\n",
      "069A     2\n",
      "049A     1\n",
      "088A     1\n",
      "024A     1\n",
      "100A     1\n",
      "110A     1\n",
      "091A     1\n",
      "004A     1\n",
      "092A     1\n",
      "048A     1\n",
      "066A     1\n",
      "076A     1\n",
      "096A     1\n",
      "043A     1\n",
      "073A     1\n",
      "041A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "002B    32\n",
      "047A    28\n",
      "074A    25\n",
      "020A    23\n",
      "067A    19\n",
      "019A    17\n",
      "097A    16\n",
      "059A    14\n",
      "097B    14\n",
      "002A    13\n",
      "116A    12\n",
      "051A    12\n",
      "072A     9\n",
      "033A     9\n",
      "027A     7\n",
      "099A     7\n",
      "050A     7\n",
      "023A     6\n",
      "034A     5\n",
      "025C     5\n",
      "075A     5\n",
      "052A     4\n",
      "003A     4\n",
      "012A     3\n",
      "006A     3\n",
      "018A     2\n",
      "026C     1\n",
      "019B     1\n",
      "115A     1\n",
      "090A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    250\n",
      "F    202\n",
      "M    180\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "M    157\n",
      "X     98\n",
      "F     50\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [000A, 015A, 001A, 103A, 071A, 028A, 062A, 101...\n",
      "kitten    [044A, 014B, 111A, 040A, 046A, 042A, 109A, 043...\n",
      "senior    [093A, 057A, 106A, 104A, 055A, 113A, 051B, 054...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [006A, 033A, 097B, 019A, 074A, 067A, 020A, 002...\n",
      "kitten                                   [047A, 050A, 115A]\n",
      "senior                       [097A, 059A, 116A, 051A, 090A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 52, 'kitten': 13, 'senior': 17}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 22, 'kitten': 3, 'senior': 5}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '004A' '005A' '007A' '008A' '009A' '010A' '011A'\n",
      " '013B' '014A' '014B' '015A' '016A' '021A' '022A' '023B' '024A' '025A'\n",
      " '025B' '026A' '026B' '028A' '029A' '031A' '032A' '035A' '036A' '037A'\n",
      " '038A' '039A' '040A' '041A' '042A' '043A' '044A' '045A' '046A' '048A'\n",
      " '049A' '051B' '053A' '054A' '055A' '056A' '057A' '058A' '060A' '061A'\n",
      " '062A' '063A' '064A' '065A' '066A' '068A' '069A' '070A' '071A' '073A'\n",
      " '076A' '087A' '088A' '091A' '092A' '093A' '094A' '095A' '096A' '100A'\n",
      " '101A' '102A' '103A' '104A' '105A' '106A' '108A' '109A' '110A' '111A'\n",
      " '113A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['002A' '002B' '003A' '006A' '012A' '018A' '019A' '019B' '020A' '023A'\n",
      " '025C' '026C' '027A' '033A' '034A' '047A' '050A' '051A' '052A' '059A'\n",
      " '067A' '072A' '074A' '075A' '090A' '097A' '097B' '099A' '115A' '116A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "set()\n",
      "Removed from Training/Validation Set:\n",
      "set()\n",
      "Moved to Test Set:\n",
      "set()\n",
      "Removed from Test Set\n",
      "set()\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '004A' '005A' '007A' '008A' '009A' '010A' '011A'\n",
      " '013B' '014A' '014B' '015A' '016A' '021A' '022A' '023B' '024A' '025A'\n",
      " '025B' '026A' '026B' '028A' '029A' '031A' '032A' '035A' '036A' '037A'\n",
      " '038A' '039A' '040A' '041A' '042A' '043A' '044A' '045A' '046A' '048A'\n",
      " '049A' '051B' '053A' '054A' '055A' '056A' '057A' '058A' '060A' '061A'\n",
      " '062A' '063A' '064A' '065A' '066A' '068A' '069A' '070A' '071A' '073A'\n",
      " '076A' '087A' '088A' '091A' '092A' '093A' '094A' '095A' '096A' '100A'\n",
      " '101A' '102A' '103A' '104A' '105A' '106A' '108A' '109A' '110A' '111A'\n",
      " '113A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['002A' '002B' '003A' '006A' '012A' '018A' '019A' '019B' '020A' '023A'\n",
      " '025C' '026C' '027A' '033A' '034A' '047A' '050A' '051A' '052A' '059A'\n",
      " '067A' '072A' '074A' '075A' '090A' '097A' '097B' '099A' '115A' '116A']\n",
      "Length of X_train_val:\n",
      "632\n",
      "Length of y_train_val:\n",
      "632\n",
      "Length of groups_train_val:\n",
      "632\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     374\n",
      "kitten    135\n",
      "senior    123\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     214\n",
      "senior     55\n",
      "kitten     36\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     374\n",
      "kitten    135\n",
      "senior    123\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     214\n",
      "senior     55\n",
      "kitten     36\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 374, 1: 135, 2: 123})\n",
      "Epoch 1/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.1289 - accuracy: 0.4731\n",
      "Epoch 2/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.8700 - accuracy: 0.5269\n",
      "Epoch 3/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.7774 - accuracy: 0.5807\n",
      "Epoch 4/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.7528 - accuracy: 0.5965\n",
      "Epoch 5/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.7109 - accuracy: 0.6250\n",
      "Epoch 6/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.6440\n",
      "Epoch 7/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6362 - accuracy: 0.6677\n",
      "Epoch 8/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.6551\n",
      "Epoch 9/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6222 - accuracy: 0.6677\n",
      "Epoch 10/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.6867\n",
      "Epoch 11/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5499 - accuracy: 0.7136\n",
      "Epoch 12/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5557 - accuracy: 0.7168\n",
      "Epoch 13/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.7073\n",
      "Epoch 14/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.7263\n",
      "Epoch 15/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7278\n",
      "Epoch 16/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5280 - accuracy: 0.6946\n",
      "Epoch 17/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5159 - accuracy: 0.7373\n",
      "Epoch 18/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7468\n",
      "Epoch 19/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.7104\n",
      "Epoch 20/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.7073\n",
      "Epoch 21/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7453\n",
      "Epoch 22/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7231\n",
      "Epoch 23/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.7342\n",
      "Epoch 24/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7484\n",
      "Epoch 25/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7674\n",
      "Epoch 26/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7595\n",
      "Epoch 27/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7642\n",
      "Epoch 28/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.7769\n",
      "Epoch 29/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7706\n",
      "Epoch 30/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.7801\n",
      "Epoch 31/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7848\n",
      "Epoch 32/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.8038\n",
      "Epoch 33/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.7769\n",
      "Epoch 34/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7722\n",
      "Epoch 35/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.7848\n",
      "Epoch 36/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.7880\n",
      "Epoch 37/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7769\n",
      "Epoch 38/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.7848\n",
      "Epoch 39/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3774 - accuracy: 0.8196\n",
      "Epoch 40/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.8165\n",
      "Epoch 41/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8133\n",
      "Epoch 42/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3978 - accuracy: 0.7943\n",
      "Epoch 43/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4116 - accuracy: 0.7753\n",
      "Epoch 44/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8085\n",
      "Epoch 45/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8244\n",
      "Epoch 46/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8070\n",
      "Epoch 47/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3928 - accuracy: 0.8006\n",
      "Epoch 48/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8070\n",
      "Epoch 49/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8196\n",
      "Epoch 50/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8244\n",
      "Epoch 51/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8418\n",
      "Epoch 52/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3156 - accuracy: 0.8228\n",
      "Epoch 53/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8339\n",
      "Epoch 54/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8180\n",
      "Epoch 55/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8180\n",
      "Epoch 56/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8386\n",
      "Epoch 57/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8180\n",
      "Epoch 58/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8149\n",
      "Epoch 59/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8354\n",
      "Epoch 60/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8228\n",
      "Epoch 61/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 0.8418\n",
      "Epoch 62/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3390 - accuracy: 0.8180\n",
      "Epoch 63/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8212\n",
      "Epoch 64/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.8339\n",
      "Epoch 65/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8560\n",
      "Epoch 66/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2962 - accuracy: 0.8307\n",
      "Epoch 67/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3107 - accuracy: 0.8449\n",
      "Epoch 68/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2668 - accuracy: 0.8576\n",
      "Epoch 69/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2903 - accuracy: 0.8671\n",
      "Epoch 70/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.8671\n",
      "Epoch 71/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3187 - accuracy: 0.8402\n",
      "Epoch 72/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2969 - accuracy: 0.8592\n",
      "Epoch 73/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3006 - accuracy: 0.8560\n",
      "Epoch 74/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8418\n",
      "Epoch 75/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2894 - accuracy: 0.8528\n",
      "Epoch 76/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2820 - accuracy: 0.8449\n",
      "Epoch 77/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2958 - accuracy: 0.8528\n",
      "Epoch 78/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.8434\n",
      "Epoch 79/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.8497\n",
      "Epoch 80/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2695 - accuracy: 0.8782\n",
      "Epoch 81/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.8797\n",
      "Epoch 82/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2993 - accuracy: 0.8513\n",
      "Epoch 83/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2851 - accuracy: 0.8623\n",
      "Epoch 84/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2865 - accuracy: 0.8386\n",
      "Epoch 85/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3017 - accuracy: 0.8592\n",
      "Epoch 86/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2524 - accuracy: 0.8750\n",
      "Epoch 87/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.8782\n",
      "Epoch 88/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2729 - accuracy: 0.8703\n",
      "Epoch 89/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2599 - accuracy: 0.8750\n",
      "Epoch 90/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2581 - accuracy: 0.8718\n",
      "Epoch 91/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.8718\n",
      "Epoch 92/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2625 - accuracy: 0.8623\n",
      "Epoch 93/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2518 - accuracy: 0.8750\n",
      "Epoch 94/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2865 - accuracy: 0.8671\n",
      "Epoch 95/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2572 - accuracy: 0.8766\n",
      "Epoch 96/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2559 - accuracy: 0.8703\n",
      "Epoch 97/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 0.8576\n",
      "Epoch 98/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.8734\n",
      "Epoch 99/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.8623\n",
      "Epoch 100/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9035\n",
      "Epoch 101/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.8861\n",
      "Epoch 102/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.8734\n",
      "Epoch 103/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.8987\n",
      "Epoch 104/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.8845\n",
      "Epoch 105/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2358 - accuracy: 0.8845\n",
      "Epoch 106/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.8861\n",
      "Epoch 107/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2421 - accuracy: 0.8734\n",
      "Epoch 108/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.8766\n",
      "Epoch 109/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.9003\n",
      "Epoch 110/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2287 - accuracy: 0.8877\n",
      "Epoch 111/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9035\n",
      "Epoch 112/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.9114\n",
      "Epoch 113/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.9082\n",
      "Epoch 114/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2304 - accuracy: 0.8940\n",
      "Epoch 115/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.9114\n",
      "Epoch 116/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 0.8987\n",
      "Epoch 117/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.8845\n",
      "Epoch 118/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.8892\n",
      "Epoch 119/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.9051\n",
      "Epoch 120/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 0.8861\n",
      "Epoch 121/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.8782\n",
      "Epoch 122/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.8813\n",
      "Epoch 123/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9051\n",
      "Epoch 124/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.8940\n",
      "Epoch 125/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2132 - accuracy: 0.8972\n",
      "Epoch 126/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.9193\n",
      "Epoch 127/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.8892\n",
      "Epoch 128/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.8845\n",
      "Epoch 129/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.9019\n",
      "Epoch 130/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.9114\n",
      "Epoch 131/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2050 - accuracy: 0.9114\n",
      "Epoch 132/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.9019\n",
      "Epoch 133/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.9114\n",
      "Epoch 134/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2055 - accuracy: 0.9098\n",
      "Epoch 135/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.9082\n",
      "Epoch 136/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.8956\n",
      "Epoch 137/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.9051\n",
      "Epoch 138/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.8940\n",
      "Epoch 139/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2048 - accuracy: 0.9003\n",
      "Epoch 140/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.9066\n",
      "Epoch 141/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9066\n",
      "Epoch 142/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.8924\n",
      "Epoch 143/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9035\n",
      "Epoch 144/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1735 - accuracy: 0.9082\n",
      "Epoch 145/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.9161\n",
      "Epoch 146/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.8987\n",
      "Epoch 147/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9114\n",
      "Epoch 148/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.9225\n",
      "Epoch 149/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9019\n",
      "Epoch 150/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.9098\n",
      "Epoch 151/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9193\n",
      "Epoch 152/1500\n",
      "20/20 [==============================] - 0s 985us/step - loss: 0.1973 - accuracy: 0.9051\n",
      "Epoch 153/1500\n",
      "20/20 [==============================] - 0s 987us/step - loss: 0.1578 - accuracy: 0.9320\n",
      "Epoch 154/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.9098\n",
      "Epoch 155/1500\n",
      "20/20 [==============================] - 0s 999us/step - loss: 0.1835 - accuracy: 0.9241\n",
      "Epoch 156/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.9161\n",
      "Epoch 157/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9335\n",
      "Epoch 158/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2080 - accuracy: 0.8972\n",
      "Epoch 159/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.9225\n",
      "Epoch 160/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9161\n",
      "Epoch 161/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.9209\n",
      "Epoch 162/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9114\n",
      "Epoch 163/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.8987\n",
      "Epoch 164/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9351\n",
      "Epoch 165/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9335\n",
      "Epoch 166/1500\n",
      "20/20 [==============================] - 0s 1000us/step - loss: 0.1481 - accuracy: 0.9272\n",
      "Epoch 167/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9225\n",
      "Epoch 168/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9288\n",
      "Epoch 169/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9335\n",
      "Epoch 170/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9241\n",
      "Epoch 171/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1680 - accuracy: 0.9193\n",
      "Epoch 172/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1377 - accuracy: 0.9351\n",
      "Epoch 173/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9177\n",
      "Epoch 174/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.9051\n",
      "Epoch 175/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.9051\n",
      "Epoch 176/1500\n",
      "20/20 [==============================] - 0s 991us/step - loss: 0.1775 - accuracy: 0.9193\n",
      "Epoch 177/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9288\n",
      "Epoch 178/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1728 - accuracy: 0.9114\n",
      "Epoch 179/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9335\n",
      "Epoch 180/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1720 - accuracy: 0.9241\n",
      "Epoch 181/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.9225\n",
      "Epoch 182/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 0.9241\n",
      "Epoch 183/1500\n",
      "20/20 [==============================] - 0s 994us/step - loss: 0.1445 - accuracy: 0.9399\n",
      "Epoch 184/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9082\n",
      "Epoch 185/1500\n",
      "20/20 [==============================] - 0s 998us/step - loss: 0.1526 - accuracy: 0.9288\n",
      "Epoch 186/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9415\n",
      "Epoch 187/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.9304\n",
      "Epoch 188/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9320\n",
      "Epoch 189/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9351\n",
      "Epoch 190/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9415\n",
      "Epoch 191/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9335\n",
      "Epoch 192/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9114\n",
      "Epoch 193/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9320\n",
      "Epoch 194/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1556 - accuracy: 0.9320\n",
      "Epoch 195/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.9225\n",
      "Epoch 196/1500\n",
      "20/20 [==============================] - 0s 998us/step - loss: 0.1496 - accuracy: 0.9225\n",
      "Epoch 197/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9320\n",
      "Epoch 198/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9399\n",
      "Epoch 199/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9225\n",
      "Epoch 200/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 0.9446\n",
      "Epoch 201/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9288\n",
      "Epoch 202/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9494\n",
      "Epoch 203/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1311 - accuracy: 0.9399\n",
      "Epoch 204/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9304\n",
      "Epoch 205/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1726 - accuracy: 0.9209\n",
      "Epoch 206/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.9446\n",
      "Epoch 207/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9494\n",
      "Epoch 208/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1395 - accuracy: 0.9367\n",
      "Epoch 209/1500\n",
      "20/20 [==============================] - 0s 999us/step - loss: 0.1344 - accuracy: 0.9415\n",
      "Epoch 210/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.9130\n",
      "Epoch 211/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9462\n",
      "Epoch 212/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9335\n",
      "Epoch 213/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.9509\n",
      "Epoch 214/1500\n",
      "20/20 [==============================] - 0s 995us/step - loss: 0.1343 - accuracy: 0.9367\n",
      "Epoch 215/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9415\n",
      "Epoch 216/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.9399\n",
      "Epoch 217/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.9367\n",
      "Epoch 218/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9494\n",
      "Epoch 219/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.9478\n",
      "Epoch 220/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9430\n",
      "Epoch 221/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9272\n",
      "Epoch 222/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9399\n",
      "Epoch 223/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9509\n",
      "Epoch 224/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1389 - accuracy: 0.9399\n",
      "Epoch 225/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9367\n",
      "Epoch 226/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9446\n",
      "Epoch 227/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9446\n",
      "Epoch 228/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9367\n",
      "Epoch 229/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9462\n",
      "Epoch 230/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9573\n",
      "Epoch 231/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9462\n",
      "Epoch 232/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1257 - accuracy: 0.9415\n",
      "Epoch 233/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9525\n",
      "Epoch 234/1500\n",
      "20/20 [==============================] - 0s 984us/step - loss: 0.1364 - accuracy: 0.9320\n",
      "Epoch 235/1500\n",
      "20/20 [==============================] - 0s 987us/step - loss: 0.1318 - accuracy: 0.9415\n",
      "Epoch 236/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9225\n",
      "Epoch 237/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9541\n",
      "Epoch 238/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9494\n",
      "Epoch 239/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9430\n",
      "Epoch 240/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9589\n",
      "Epoch 241/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9446\n",
      "Epoch 242/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9415\n",
      "Epoch 243/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9304\n",
      "Epoch 244/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9399\n",
      "Epoch 245/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9288\n",
      "Epoch 246/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9446\n",
      "Epoch 247/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9494\n",
      "Epoch 248/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9525\n",
      "Epoch 249/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9367\n",
      "Epoch 250/1500\n",
      "20/20 [==============================] - 0s 984us/step - loss: 0.1190 - accuracy: 0.9541\n",
      "Epoch 251/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9478\n",
      "Epoch 252/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9620\n",
      "Epoch 253/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.9541\n",
      "Epoch 254/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9415\n",
      "Epoch 255/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9494\n",
      "Epoch 256/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9478\n",
      "Epoch 257/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9430\n",
      "Epoch 258/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9430\n",
      "Epoch 259/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9652\n",
      "Epoch 260/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9256\n",
      "Epoch 261/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9446\n",
      "Epoch 262/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9573\n",
      "Epoch 263/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9509\n",
      "Epoch 264/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9462\n",
      "Epoch 265/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9494\n",
      "Epoch 266/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9636\n",
      "Epoch 267/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9525\n",
      "Epoch 268/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9478\n",
      "Epoch 269/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9430\n",
      "Epoch 270/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.9446\n",
      "Epoch 271/1500\n",
      "20/20 [==============================] - 0s 995us/step - loss: 0.1224 - accuracy: 0.9462\n",
      "Epoch 272/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9604\n",
      "Epoch 273/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9335\n",
      "Epoch 274/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9604\n",
      "Epoch 275/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9478\n",
      "Epoch 276/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9462\n",
      "Epoch 277/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9573\n",
      "Epoch 278/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9604\n",
      "Epoch 279/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9589\n",
      "Epoch 280/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9478\n",
      "Epoch 281/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9525\n",
      "Epoch 282/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9509\n",
      "Epoch 283/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9430\n",
      "Epoch 284/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9573\n",
      "Epoch 285/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9525\n",
      "Epoch 286/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9604\n",
      "Epoch 287/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9541\n",
      "Epoch 288/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9478\n",
      "Epoch 289/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9494\n",
      "Epoch 290/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9668\n",
      "Epoch 291/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0915 - accuracy: 0.9589\n",
      "Epoch 292/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9636\n",
      "Epoch 293/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9399\n",
      "Epoch 294/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9573\n",
      "Epoch 295/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9494\n",
      "Epoch 296/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9589\n",
      "Epoch 297/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9589\n",
      "Epoch 298/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9573\n",
      "Epoch 299/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9589\n",
      "Epoch 300/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9541\n",
      "Epoch 301/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9541\n",
      "Epoch 302/1500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1112 - accuracy: 0.9509\n",
      "Epoch 303/1500\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.0984 - accuracy: 0.9589\n",
      "Epoch 304/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9494\n",
      "Epoch 305/1500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.9636\n",
      "Epoch 306/1500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.9604\n",
      "Epoch 307/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9525\n",
      "Epoch 308/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9589\n",
      "Epoch 309/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9557\n",
      "Epoch 310/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9573\n",
      "Epoch 311/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.9731\n",
      "Epoch 312/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9541\n",
      "Epoch 313/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9494\n",
      "Epoch 314/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9525\n",
      "Epoch 315/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9652\n",
      "Epoch 316/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.9684\n",
      "Epoch 317/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9541\n",
      "Epoch 318/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9415\n",
      "Epoch 319/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9462\n",
      "Epoch 320/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9478\n",
      "Epoch 321/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0892 - accuracy: 0.9541\n",
      "Epoch 322/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1271 - accuracy: 0.9446\n",
      "Epoch 323/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9494\n",
      "Epoch 324/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9462\n",
      "Epoch 325/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9478\n",
      "Epoch 326/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0663 - accuracy: 0.9747\n",
      "Epoch 327/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9541\n",
      "Epoch 328/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9557\n",
      "Epoch 329/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9589\n",
      "Epoch 330/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0831 - accuracy: 0.9715\n",
      "Epoch 331/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9620\n",
      "Epoch 332/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9509\n",
      "Epoch 333/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9573\n",
      "Epoch 334/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.9699\n",
      "Epoch 335/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0973 - accuracy: 0.9573\n",
      "Epoch 336/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.9525\n",
      "Epoch 337/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9573\n",
      "Epoch 338/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9573\n",
      "Epoch 339/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9589\n",
      "Epoch 340/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0806 - accuracy: 0.9715\n",
      "Epoch 341/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.9589\n",
      "Epoch 342/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9573\n",
      "Epoch 343/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9557\n",
      "Epoch 344/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9494\n",
      "Epoch 345/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9573\n",
      "Epoch 346/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9636\n",
      "Epoch 347/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9699\n",
      "Epoch 348/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9541\n",
      "Epoch 349/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1014 - accuracy: 0.9525\n",
      "Epoch 350/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.9573\n",
      "Epoch 351/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.9620\n",
      "Epoch 352/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9636\n",
      "Epoch 353/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9684\n",
      "Epoch 354/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 0.9763\n",
      "Epoch 355/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.9731\n",
      "Epoch 356/1500\n",
      "20/20 [==============================] - 0s 999us/step - loss: 0.0832 - accuracy: 0.9636\n",
      "Epoch 357/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9636\n",
      "Epoch 358/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9446\n",
      "Epoch 359/1500\n",
      "20/20 [==============================] - 0s 980us/step - loss: 0.0963 - accuracy: 0.9604\n",
      "Epoch 360/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 0.9652\n",
      "Epoch 361/1500\n",
      "20/20 [==============================] - 0s 983us/step - loss: 0.0964 - accuracy: 0.9604\n",
      "Epoch 362/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9652\n",
      "Epoch 363/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.9636\n",
      "Epoch 364/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9684\n",
      "Epoch 365/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9557\n",
      "Epoch 366/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9731\n",
      "Epoch 367/1500\n",
      "20/20 [==============================] - 0s 989us/step - loss: 0.0807 - accuracy: 0.9699\n",
      "Epoch 368/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9715\n",
      "Epoch 369/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.9604\n",
      "Epoch 370/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9636\n",
      "Epoch 371/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9873\n",
      "Epoch 372/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.9778\n",
      "Epoch 373/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9589\n",
      "Epoch 374/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9589\n",
      "Epoch 375/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9636\n",
      "Epoch 376/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9604\n",
      "Epoch 377/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9747\n",
      "Epoch 378/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9684\n",
      "Epoch 379/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0789 - accuracy: 0.9652\n",
      "Epoch 380/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9604\n",
      "Epoch 381/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9652\n",
      "Epoch 382/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9731\n",
      "Epoch 383/1500\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9763\n",
      "Epoch 384/1500\n",
      " 1/20 [>.............................] - ETA: 0s - loss: 0.1169 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 354.\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9699\n",
      "Epoch 384: early stopping\n",
      "10/10 [==============================] - 0s 703us/step - loss: 0.7139 - accuracy: 0.7705\n",
      "10/10 [==============================] - 0s 585us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.80 (24/30)\n",
      "Before appending - Cat IDs: 382, Predictions: 382, Actuals: 382, Gender: 382\n",
      "After appending - Cat IDs: 687, Predictions: 687, Actuals: 687, Gender: 687\n",
      "Final Test Results - Loss: 0.7138757705688477, Accuracy: 0.7704917788505554, Precision: 0.7127390066941918, Recall: 0.7411875767015954, F1 Score: 0.7252916377916377\n",
      "Confusion Matrix:\n",
      " [[173   8  33]\n",
      " [  6  30   0]\n",
      " [ 23   0  32]]\n",
      "outer_fold 4\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "103A    33\n",
      "002B    32\n",
      "047A    28\n",
      "057A    27\n",
      "074A    25\n",
      "020A    23\n",
      "055A    20\n",
      "000B    19\n",
      "067A    19\n",
      "029A    17\n",
      "019A    17\n",
      "097A    16\n",
      "001A    14\n",
      "097B    14\n",
      "059A    14\n",
      "106A    14\n",
      "028A    13\n",
      "002A    13\n",
      "116A    12\n",
      "039A    12\n",
      "051A    12\n",
      "025A    11\n",
      "036A    11\n",
      "068A    11\n",
      "005A    10\n",
      "071A    10\n",
      "016A    10\n",
      "072A     9\n",
      "022A     9\n",
      "045A     9\n",
      "015A     9\n",
      "033A     9\n",
      "051B     9\n",
      "094A     8\n",
      "095A     8\n",
      "010A     8\n",
      "013B     8\n",
      "099A     7\n",
      "050A     7\n",
      "117A     7\n",
      "027A     7\n",
      "037A     6\n",
      "008A     6\n",
      "023A     6\n",
      "053A     6\n",
      "025C     5\n",
      "075A     5\n",
      "044A     5\n",
      "034A     5\n",
      "070A     5\n",
      "009A     4\n",
      "052A     4\n",
      "105A     4\n",
      "104A     4\n",
      "003A     4\n",
      "060A     3\n",
      "058A     3\n",
      "012A     3\n",
      "006A     3\n",
      "014A     3\n",
      "056A     3\n",
      "018A     2\n",
      "093A     2\n",
      "054A     2\n",
      "032A     2\n",
      "069A     2\n",
      "025B     2\n",
      "073A     1\n",
      "091A     1\n",
      "024A     1\n",
      "090A     1\n",
      "100A     1\n",
      "110A     1\n",
      "115A     1\n",
      "048A     1\n",
      "019B     1\n",
      "088A     1\n",
      "026C     1\n",
      "092A     1\n",
      "049A     1\n",
      "076A     1\n",
      "096A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "000A    39\n",
      "101A    15\n",
      "042A    14\n",
      "111A    13\n",
      "063A    11\n",
      "040A    10\n",
      "014B    10\n",
      "065A     9\n",
      "031A     7\n",
      "109A     6\n",
      "108A     6\n",
      "007A     6\n",
      "023B     5\n",
      "021A     5\n",
      "026A     4\n",
      "062A     4\n",
      "035A     4\n",
      "113A     3\n",
      "064A     3\n",
      "087A     2\n",
      "038A     2\n",
      "011A     2\n",
      "061A     2\n",
      "102A     2\n",
      "043A     1\n",
      "041A     1\n",
      "066A     1\n",
      "004A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "M    314\n",
      "X    271\n",
      "F    164\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "F    88\n",
      "X    77\n",
      "M    23\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 033A, 015A, 001A, 103A, 071A, 097B, 028...\n",
      "kitten    [044A, 046A, 047A, 050A, 049A, 045A, 048A, 115...\n",
      "senior    [093A, 097A, 057A, 106A, 104A, 055A, 059A, 116...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [000A, 062A, 101A, 065A, 063A, 038A, 007A, 087...\n",
      "kitten           [014B, 111A, 040A, 042A, 109A, 043A, 041A]\n",
      "senior                             [113A, 108A, 011A, 061A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 57, 'kitten': 9, 'senior': 18}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 17, 'kitten': 7, 'senior': 4}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000B' '001A' '002A' '002B' '003A' '005A' '006A' '008A' '009A' '010A'\n",
      " '012A' '013B' '014A' '015A' '016A' '018A' '019A' '019B' '020A' '022A'\n",
      " '023A' '024A' '025A' '025B' '025C' '026B' '026C' '027A' '028A' '029A'\n",
      " '032A' '033A' '034A' '036A' '037A' '039A' '044A' '045A' '046A' '047A'\n",
      " '048A' '049A' '050A' '051A' '051B' '052A' '053A' '054A' '055A' '056A'\n",
      " '057A' '058A' '059A' '060A' '067A' '068A' '069A' '070A' '071A' '072A'\n",
      " '073A' '074A' '075A' '076A' '088A' '090A' '091A' '092A' '093A' '094A'\n",
      " '095A' '096A' '097A' '097B' '099A' '100A' '103A' '104A' '105A' '106A'\n",
      " '110A' '115A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['000A' '004A' '007A' '011A' '014B' '021A' '023B' '026A' '031A' '035A'\n",
      " '038A' '040A' '041A' '042A' '043A' '061A' '062A' '063A' '064A' '065A'\n",
      " '066A' '087A' '101A' '102A' '108A' '109A' '111A' '113A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "{'000A'}\n",
      "Removed from Training/Validation Set:\n",
      "{'072A'}\n",
      "Moved to Test Set:\n",
      "{'072A'}\n",
      "Removed from Test Set\n",
      "{'000A'}\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '002B' '003A' '005A' '006A' '008A' '009A'\n",
      " '010A' '012A' '013B' '014A' '015A' '016A' '018A' '019A' '019B' '020A'\n",
      " '022A' '023A' '024A' '025A' '025B' '025C' '026B' '026C' '027A' '028A'\n",
      " '029A' '032A' '033A' '034A' '036A' '037A' '039A' '044A' '045A' '046A'\n",
      " '047A' '048A' '049A' '050A' '051A' '051B' '052A' '053A' '054A' '055A'\n",
      " '056A' '057A' '058A' '059A' '060A' '067A' '068A' '069A' '070A' '071A'\n",
      " '073A' '074A' '075A' '076A' '088A' '090A' '091A' '092A' '093A' '094A'\n",
      " '095A' '096A' '097A' '097B' '099A' '100A' '103A' '104A' '105A' '106A'\n",
      " '110A' '115A' '116A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['004A' '007A' '011A' '014B' '021A' '023B' '026A' '031A' '035A' '038A'\n",
      " '040A' '041A' '042A' '043A' '061A' '062A' '063A' '064A' '065A' '066A'\n",
      " '072A' '087A' '101A' '102A' '108A' '109A' '111A' '113A']\n",
      "Length of X_train_val:\n",
      "779\n",
      "Length of y_train_val:\n",
      "779\n",
      "Length of groups_train_val:\n",
      "779\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     468\n",
      "senior    165\n",
      "kitten    116\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     120\n",
      "kitten     55\n",
      "senior     13\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     498\n",
      "senior    165\n",
      "kitten    116\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     90\n",
      "kitten    55\n",
      "senior    13\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age group distribution: Counter({0: 498, 2: 165, 1: 116})\n",
      "Epoch 1/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.0232 - accuracy: 0.4929\n",
      "Epoch 2/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.8445 - accuracy: 0.5083\n",
      "Epoch 3/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7387 - accuracy: 0.5777\n",
      "Epoch 4/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7595 - accuracy: 0.5751\n",
      "Epoch 5/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7139 - accuracy: 0.6059\n",
      "Epoch 6/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.6123\n",
      "Epoch 7/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.6406\n",
      "Epoch 8/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6118 - accuracy: 0.6611\n",
      "Epoch 9/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.6701\n",
      "Epoch 10/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.6637\n",
      "Epoch 11/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.6919\n",
      "Epoch 12/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.6868\n",
      "Epoch 13/1500\n",
      "25/25 [==============================] - 0s 998us/step - loss: 0.5756 - accuracy: 0.6881\n",
      "Epoch 14/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5771 - accuracy: 0.6919\n",
      "Epoch 15/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5341 - accuracy: 0.7035\n",
      "Epoch 16/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.7266\n",
      "Epoch 17/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.7202\n",
      "Epoch 18/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7176\n",
      "Epoch 19/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7163\n",
      "Epoch 20/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.7368\n",
      "Epoch 21/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7407\n",
      "Epoch 22/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7291\n",
      "Epoch 23/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7433\n",
      "Epoch 24/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7407\n",
      "Epoch 25/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7394\n",
      "Epoch 26/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7458\n",
      "Epoch 27/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7599\n",
      "Epoch 28/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7304\n",
      "Epoch 29/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7664\n",
      "Epoch 30/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7599\n",
      "Epoch 31/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7612\n",
      "Epoch 32/1500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.7997\n",
      "Epoch 33/1500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.7741\n",
      "Epoch 34/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3973 - accuracy: 0.7805\n",
      "Epoch 35/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8087\n",
      "Epoch 36/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.7728\n",
      "Epoch 37/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8100\n",
      "Epoch 38/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.7985\n",
      "Epoch 39/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4036 - accuracy: 0.7779\n",
      "Epoch 40/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8100\n",
      "Epoch 41/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.8126\n",
      "Epoch 42/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8074\n",
      "Epoch 43/1500\n",
      "25/25 [==============================] - 0s 955us/step - loss: 0.3658 - accuracy: 0.8036\n",
      "Epoch 44/1500\n",
      "25/25 [==============================] - 0s 991us/step - loss: 0.3865 - accuracy: 0.8049\n",
      "Epoch 45/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8151\n",
      "Epoch 46/1500\n",
      "25/25 [==============================] - 0s 996us/step - loss: 0.3514 - accuracy: 0.8139\n",
      "Epoch 47/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8151\n",
      "Epoch 48/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8126\n",
      "Epoch 49/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.7997\n",
      "Epoch 50/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8177\n",
      "Epoch 51/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3239 - accuracy: 0.8293\n",
      "Epoch 52/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8177\n",
      "Epoch 53/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3521 - accuracy: 0.8100\n",
      "Epoch 54/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3805 - accuracy: 0.7818\n",
      "Epoch 55/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.8062\n",
      "Epoch 56/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8190\n",
      "Epoch 57/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3042 - accuracy: 0.8383\n",
      "Epoch 58/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3112 - accuracy: 0.8254\n",
      "Epoch 59/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2937 - accuracy: 0.8370\n",
      "Epoch 60/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8241\n",
      "Epoch 61/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3131 - accuracy: 0.8395\n",
      "Epoch 62/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8383\n",
      "Epoch 63/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.8254\n",
      "Epoch 64/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8126\n",
      "Epoch 65/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3192 - accuracy: 0.8331\n",
      "Epoch 66/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8164\n",
      "Epoch 67/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3034 - accuracy: 0.8331\n",
      "Epoch 68/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2762 - accuracy: 0.8678\n",
      "Epoch 69/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3063 - accuracy: 0.8434\n",
      "Epoch 70/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2999 - accuracy: 0.8498\n",
      "Epoch 71/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3015 - accuracy: 0.8383\n",
      "Epoch 72/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2828 - accuracy: 0.8460\n",
      "Epoch 73/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.8306\n",
      "Epoch 74/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2840 - accuracy: 0.8562\n",
      "Epoch 75/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2814 - accuracy: 0.8575\n",
      "Epoch 76/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.8562\n",
      "Epoch 77/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2922 - accuracy: 0.8460\n",
      "Epoch 78/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2785 - accuracy: 0.8472\n",
      "Epoch 79/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.8626\n",
      "Epoch 80/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.8601\n",
      "Epoch 81/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2838 - accuracy: 0.8370\n",
      "Epoch 82/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2725 - accuracy: 0.8639\n",
      "Epoch 83/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2944 - accuracy: 0.8408\n",
      "Epoch 84/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 0.8562\n",
      "Epoch 85/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2835 - accuracy: 0.8383\n",
      "Epoch 86/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.8716\n",
      "Epoch 87/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2762 - accuracy: 0.8472\n",
      "Epoch 88/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2776 - accuracy: 0.8626\n",
      "Epoch 89/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.8485\n",
      "Epoch 90/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.8729\n",
      "Epoch 91/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2498 - accuracy: 0.8652\n",
      "Epoch 92/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.8665\n",
      "Epoch 93/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2532 - accuracy: 0.8703\n",
      "Epoch 94/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2939 - accuracy: 0.8344\n",
      "Epoch 95/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2573 - accuracy: 0.8614\n",
      "Epoch 96/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.8858\n",
      "Epoch 97/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2385 - accuracy: 0.8845\n",
      "Epoch 98/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.8793\n",
      "Epoch 99/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.8883\n",
      "Epoch 100/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2617 - accuracy: 0.8716\n",
      "Epoch 101/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.8768\n",
      "Epoch 102/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.8870\n",
      "Epoch 103/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.8883\n",
      "Epoch 104/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2632 - accuracy: 0.8639\n",
      "Epoch 105/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.8870\n",
      "Epoch 106/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2572 - accuracy: 0.8742\n",
      "Epoch 107/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2536 - accuracy: 0.8768\n",
      "Epoch 108/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2577 - accuracy: 0.8665\n",
      "Epoch 109/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.8768\n",
      "Epoch 110/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.8780\n",
      "Epoch 111/1500\n",
      "25/25 [==============================] - 0s 998us/step - loss: 0.2117 - accuracy: 0.8858\n",
      "Epoch 112/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2396 - accuracy: 0.8832\n",
      "Epoch 113/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.8780\n",
      "Epoch 114/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2420 - accuracy: 0.8819\n",
      "Epoch 115/1500\n",
      "25/25 [==============================] - 0s 984us/step - loss: 0.2385 - accuracy: 0.8729\n",
      "Epoch 116/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.8883\n",
      "Epoch 117/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.8960\n",
      "Epoch 118/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.8780\n",
      "Epoch 119/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.8793\n",
      "Epoch 120/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.8973\n",
      "Epoch 121/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2030 - accuracy: 0.8986\n",
      "Epoch 122/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2337 - accuracy: 0.8780\n",
      "Epoch 123/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.8986\n",
      "Epoch 124/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.9012\n",
      "Epoch 125/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.8935\n",
      "Epoch 126/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2014 - accuracy: 0.8883\n",
      "Epoch 127/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2018 - accuracy: 0.9050\n",
      "Epoch 128/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.8960\n",
      "Epoch 129/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.8986\n",
      "Epoch 130/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.8780\n",
      "Epoch 131/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.8883\n",
      "Epoch 132/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.8999\n",
      "Epoch 133/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.8960\n",
      "Epoch 134/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.9089\n",
      "Epoch 135/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2086 - accuracy: 0.8870\n",
      "Epoch 136/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.9153\n",
      "Epoch 137/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.8806\n",
      "Epoch 138/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.9089\n",
      "Epoch 139/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.8999\n",
      "Epoch 140/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.9191\n",
      "Epoch 141/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.9101\n",
      "Epoch 142/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.8986\n",
      "Epoch 143/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9166\n",
      "Epoch 144/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.8960\n",
      "Epoch 145/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.9089\n",
      "Epoch 146/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2030 - accuracy: 0.8960\n",
      "Epoch 147/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.9050\n",
      "Epoch 148/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.9050\n",
      "Epoch 149/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1713 - accuracy: 0.9178\n",
      "Epoch 150/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2055 - accuracy: 0.9114\n",
      "Epoch 151/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2093 - accuracy: 0.8986\n",
      "Epoch 152/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.9127\n",
      "Epoch 153/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1727 - accuracy: 0.9050\n",
      "Epoch 154/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.9076\n",
      "Epoch 155/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1615 - accuracy: 0.9217\n",
      "Epoch 156/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.9127\n",
      "Epoch 157/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2068 - accuracy: 0.9050\n",
      "Epoch 158/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.8999\n",
      "Epoch 159/1500\n",
      "25/25 [==============================] - 0s 983us/step - loss: 0.1756 - accuracy: 0.9114\n",
      "Epoch 160/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.9204\n",
      "Epoch 161/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9012\n",
      "Epoch 162/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.9063\n",
      "Epoch 163/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.9166\n",
      "Epoch 164/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9294\n",
      "Epoch 165/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1636 - accuracy: 0.9153\n",
      "Epoch 166/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9114\n",
      "Epoch 167/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.9114\n",
      "Epoch 168/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.9063\n",
      "Epoch 169/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9089\n",
      "Epoch 170/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.9050\n",
      "Epoch 171/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.9114\n",
      "Epoch 172/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.9114\n",
      "Epoch 173/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1718 - accuracy: 0.9178\n",
      "Epoch 174/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.9178\n",
      "Epoch 175/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9204\n",
      "Epoch 176/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1693 - accuracy: 0.9217\n",
      "Epoch 177/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1442 - accuracy: 0.9345\n",
      "Epoch 178/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.9127\n",
      "Epoch 179/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9230\n",
      "Epoch 180/1500\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.1733 - accuracy: 0.9140\n",
      "Epoch 181/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9320\n",
      "Epoch 182/1500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1965 - accuracy: 0.9037\n",
      "Epoch 183/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9268\n",
      "Epoch 184/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9178\n",
      "Epoch 185/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9255\n",
      "Epoch 186/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9217\n",
      "Epoch 187/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.9037\n",
      "Epoch 188/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.9089\n",
      "Epoch 189/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9243\n",
      "Epoch 190/1500\n",
      "25/25 [==============================] - 0s 996us/step - loss: 0.1392 - accuracy: 0.9345\n",
      "Epoch 191/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1476 - accuracy: 0.9268\n",
      "Epoch 192/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9435\n",
      "Epoch 193/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1640 - accuracy: 0.9178\n",
      "Epoch 194/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9307\n",
      "Epoch 195/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9166\n",
      "Epoch 196/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9243\n",
      "Epoch 197/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9320\n",
      "Epoch 198/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.9384\n",
      "Epoch 199/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9332\n",
      "Epoch 200/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1558 - accuracy: 0.9320\n",
      "Epoch 201/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9268\n",
      "Epoch 202/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9230\n",
      "Epoch 203/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9217\n",
      "Epoch 204/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9204\n",
      "Epoch 205/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9384\n",
      "Epoch 206/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9191\n",
      "Epoch 207/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9178\n",
      "Epoch 208/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9332\n",
      "Epoch 209/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1377 - accuracy: 0.9332\n",
      "Epoch 210/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9191\n",
      "Epoch 211/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9371\n",
      "Epoch 212/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9397\n",
      "Epoch 213/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9358\n",
      "Epoch 214/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9281\n",
      "Epoch 215/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9345\n",
      "Epoch 216/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9384\n",
      "Epoch 217/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9243\n",
      "Epoch 218/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.9435\n",
      "Epoch 219/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9320\n",
      "Epoch 220/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9281\n",
      "Epoch 221/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9435\n",
      "Epoch 222/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9371\n",
      "Epoch 223/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9268\n",
      "Epoch 224/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9345\n",
      "Epoch 225/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9358\n",
      "Epoch 226/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.9345\n",
      "Epoch 227/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9397\n",
      "Epoch 228/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.9384\n",
      "Epoch 229/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9397\n",
      "Epoch 230/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9448\n",
      "Epoch 231/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9461\n",
      "Epoch 232/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.9345\n",
      "Epoch 233/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9461\n",
      "Epoch 234/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9127\n",
      "Epoch 235/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1695 - accuracy: 0.9114\n",
      "Epoch 236/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9397\n",
      "Epoch 237/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9435\n",
      "Epoch 238/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9474\n",
      "Epoch 239/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9281\n",
      "Epoch 240/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9320\n",
      "Epoch 241/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9281\n",
      "Epoch 242/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9268\n",
      "Epoch 243/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9243\n",
      "Epoch 244/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9230\n",
      "Epoch 245/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9345\n",
      "Epoch 246/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9320\n",
      "Epoch 247/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9397\n",
      "Epoch 248/1500\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.2845 - accuracy: 0.8750Restoring model weights from the end of the best epoch: 218.\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9384\n",
      "Epoch 248: early stopping\n",
      "5/5 [==============================] - 0s 912us/step - loss: 0.5417 - accuracy: 0.7785\n",
      "5/5 [==============================] - 0s 683us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.75 (21/28)\n",
      "Before appending - Cat IDs: 687, Predictions: 687, Actuals: 687, Gender: 687\n",
      "After appending - Cat IDs: 845, Predictions: 845, Actuals: 845, Gender: 845\n",
      "Final Test Results - Loss: 0.5416556000709534, Accuracy: 0.7784810066223145, Precision: 0.6951985000407598, Recall: 0.7347578347578348, F1 Score: 0.6991458058257659\n",
      "Confusion Matrix:\n",
      " [[71  3 16]\n",
      " [11 44  0]\n",
      " [ 5  0  8]]\n",
      "\n",
      "Final Average F1-Score across all UNSEEN TEST sets: 0.7018184407181525\n",
      "\n",
      "Final Average Loss across all UNSEEN TEST sets: 0.8063647001981735\n",
      "\n",
      "Final Average Accuracy across all UNSEEN TEST sets: 0.7250097393989563\n",
      "\n",
      "Final Average Precision across all UNSEEN TEST sets: 0.6922030113985845\n",
      "\n",
      "Final Average Recall across all UNSEEN TEST sets: 0.7308065564598686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "all_cat_ids = []\n",
    "all_predicted_age_groups = []\n",
    "all_actual_age_groups = []\n",
    "all_gender = []\n",
    "\n",
    "# Define the StratifiedGroupKFold splitter for 4 fold CV with random shuffling\n",
    "outer_cv = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=int(random_seeds[0]))\n",
    "\n",
    "# unseen test set metrics\n",
    "unseen_losses, unseen_accuracies, unseen_precisions, unseen_recalls, unseen_f1 = [], [], [], [], []\n",
    "\n",
    "outer_fold = 0\n",
    "\n",
    "# Use the splitter to generate indices for training and testing sets\n",
    "# Note: GroupShuffleSplit.split returns indices, so we use it to index the arrays\n",
    "for train_val_idx, test_idx in outer_cv.split(X, y, groups):\n",
    "    outer_fold += 1\n",
    "    logger(f\"outer_fold {outer_fold}\", file=log_file_path)\n",
    "\n",
    "    # Convert indices back to DataFrame for easy manipulation\n",
    "    df_train_val = dataframe.iloc[train_val_idx]\n",
    "    df_test = dataframe.iloc[test_idx]\n",
    "\n",
    "    ##############################\n",
    "    # ASSESSING SPLITS BY CAT_ID #\n",
    "    ##############################\n",
    "    \n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test['cat_id'].value_counts()  \n",
    "    \n",
    "    # Log or print the distribution\n",
    "    logger(f\"Train Set Group Distribution:\\n{training_validation_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Group Distribution:\\n{testing_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test['gender'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Training Set Gender Distribution BEFORE SWAP:\\n{training_gender_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Gender Distribution BEFORE SWAP:\\n{testing_gender_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Group by 'age_group' and then list unique 'cat_id' within each age group\n",
    "    unique_cat_ids_per_age_group_train_val = df_train_val.groupby('age_group')['cat_id'].unique()\n",
    "    unique_cat_ids_per_age_group_test = df_test.groupby('age_group')['cat_id'].unique()\n",
    "    \n",
    "    # Log results\n",
    "    logger(f\"Unique Cat IDs per Age Group in Training/Validation Set:\\n{unique_cat_ids_per_age_group_train_val}\", file=log_file_path)\n",
    "    logger(f\"Unique Cat IDs per Age Group in Testing Set:\\n{unique_cat_ids_per_age_group_test}\", file=log_file_path)\n",
    "\n",
    "    # Calculate the count of unique identifiers per age group for training and testing set\n",
    "    counts_train_val = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_train_val.items()}\n",
    "    counts_test = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_test.items()}\n",
    "\n",
    "    # Log the counts of unique identifiers per age group\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Training/Validation Set:\\n{counts_train_val}\", file=log_file_path)\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Testing Set:\\n{counts_test}\", file=log_file_path)\n",
    "\n",
    "    #######################################################\n",
    "    # CONTINUE WITH ENSURING VALID AND APPROPRIATE SPLITS #\n",
    "    #######################################################\n",
    "    \n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    groups_train_val, groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # logging identifier splits \n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "\n",
    "    # check group splits\n",
    "    check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Specify the cat_ids that must be in the training/validation set\n",
    "    specific_cat_ids = ['000A', '046A']\n",
    "    \n",
    "    # Perform the swapping operation\n",
    "    train_val_idx, test_idx = swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids)\n",
    "    \n",
    "    # Re-assign the sets based on the updated indices\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    new_groups_train_val, new_groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # Find differences for training and test sets\n",
    "    moved_to_train_val, removed_from_train_val = find_group_differences(groups_train_val, new_groups_train_val)\n",
    "    moved_to_test, removed_from_test = find_group_differences(groups_test, new_groups_test)\n",
    "    \n",
    "    # Display the results\n",
    "    logger(f\"Moved to Training/Validation Set:\\n{moved_to_train_val}\", file=log_file_path)\n",
    "    logger(f\"Removed from Training/Validation Set:\\n{removed_from_train_val}\", file=log_file_path)\n",
    "    logger(f\"Moved to Test Set:\\n{moved_to_test}\", file=log_file_path)\n",
    "    logger(f\"Removed from Test Set\\n{removed_from_test}\", file=log_file_path)\n",
    "\n",
    "    # Update X_train_val, X_test, y_train_val, y_test, groups_train_val, groups_test based on updated indices\n",
    "    X_train_val = X[train_val_idx]\n",
    "    y_train_val = y[train_val_idx]\n",
    "    groups_train_val = groups[train_val_idx]\n",
    "    \n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    groups_test = groups[test_idx]\n",
    "\n",
    "    # logging identifier splits again after potential swaps\n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"AFTER SWAP - Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"AFTER SWAP - Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "    \n",
    "    # Verify the lengths are consistent\n",
    "    logger(f\"Length of X_train_val:\\n{len(X_train_val)}\", file=log_file_path)\n",
    "    logger(f\"Length of y_train_val:\\n{len(y_train_val)}\", file=log_file_path)\n",
    "    logger(f\"Length of groups_train_val:\\n{len(groups_train_val)}\", file=log_file_path)\n",
    "\n",
    "    # Check group splits once more\n",
    "    check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Convert the modified indices back to a DataFrame representing the updated df_train_val\n",
    "    df_train_val_updated = dataframe.iloc[train_val_idx].copy()\n",
    "    df_test_updated = dataframe.iloc[test_idx].copy()\n",
    "\n",
    "    ############################\n",
    "    # LOGGING AGE GROUP SPLITS #\n",
    "    ############################\n",
    "\n",
    "    # Get the distribution of age groups of age groups before the update\n",
    "    training_validation_age_group_distribution = df_train_val['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test['age_group'].value_counts()\n",
    "    \n",
    "    # Logthe distribution\n",
    "    logger(f\"Train Age Group Distribution BEFORE SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution BEFORE SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Get the distribution of age groups after the update\n",
    "    training_validation_age_group_distribution = df_train_val_updated['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test_updated['age_group'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Train Age Group Distribution AFTER SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution AFTER SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "    \n",
    "    ########################################################\n",
    "    # TRACKING FINAL CAT_IDs & GENDER AFTER REDISTRIBUTION #\n",
    "    ########################################################\n",
    "\n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val_updated['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test_updated['cat_id'].value_counts()  \n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val_updated['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test_updated['gender'].value_counts()\n",
    "    \n",
    "    logger(f\"\\n Starting training on unseen test set\\n\", file=log_file_path)\n",
    "\n",
    "    ###################\n",
    "    # PREPARING MODEL #\n",
    "    ###################\n",
    "\n",
    "    # Calculate the distribution of age groups in y_train_val\n",
    "    age_group_distribution = Counter(y_train_val)\n",
    "    print(\"Age group distribution:\", age_group_distribution)\n",
    "\n",
    "    # EarlyStopping callback: monitor 'loss' instead of 'val_loss' for the test set\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='loss',  \n",
    "        min_delta=0.001, \n",
    "        patience=30,  \n",
    "        verbose=1,  \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "\n",
    "    # One final shuffle to ensure randomness\n",
    "    outer_shuffle_idx = np.random.permutation(len(X_train_val))\n",
    "    X_train_val = X_train_val[outer_shuffle_idx]\n",
    "    y_train_val = y_train_val[outer_shuffle_idx]\n",
    "\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train_val),\n",
    "        y=y_train_val\n",
    "    )\n",
    "    weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "    # Scale the features\n",
    "    scaler_full = StandardScaler().fit(X_train_val)\n",
    "    X_train_full_scaled = scaler_full.transform(X_train_val)\n",
    "    X_test_scaled = scaler_full.transform(X_test)\n",
    "    \n",
    "    # Encode the labels\n",
    "    y_train_full_encoded = to_categorical(y_train_val)\n",
    "    y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "    #######################\n",
    "    # BUILD & TRAIN MODEL #\n",
    "    #######################\n",
    "\n",
    "    optimizers = {\n",
    "        'Adamax': Adamax(learning_rate=0.00038188800331973483)\n",
    "    }\n",
    "    \n",
    "    # Full model definition with dynamic number of layers\n",
    "    model_full = Sequential()\n",
    "    model_full.add(Dense(480, activation='relu', input_shape=(X_train_full_scaled.shape[1],)))  # units_l0 and activation from parameters\n",
    "    model_full.add(BatchNormalization())\n",
    "    model_full.add(Dropout(0.27188281261238406))  \n",
    "    model_full.add(Dense(3, activation='softmax'))  \n",
    "    \n",
    "    optimizer = optimizers['Adamax']  # optimizer_key from parameters\n",
    "    \n",
    "    # Compile the model\n",
    "    model_full.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model on the full training set\n",
    "    history_full = model_full.fit(X_train_full_scaled, y_train_full_encoded, epochs=1500, batch_size=32,\n",
    "                                  verbose=1, callbacks=[early_stopping], class_weight=weight_dict)\n",
    "    \n",
    "    # Evaluate the model on the held-out test set\n",
    "    test_loss, test_accuracy = model_full.evaluate(X_test_scaled, y_test_encoded)\n",
    "\n",
    "    y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    y_test_pred = np.argmax(y_test_pred_prob, axis=1)  \n",
    "    y_test_true = np.argmax(y_test_encoded, axis=1)    \n",
    "\n",
    "    ################################\n",
    "    # LOG MAJORITY VOTE PER CAT_ID #\n",
    "    ################################\n",
    "\n",
    "    # Convert numeric predictions back to age group labels\n",
    "    predicted_age_groups = label_encoder.inverse_transform(y_test_pred)\n",
    "    actual_labels = label_encoder.inverse_transform(y_test_true)\n",
    "    \n",
    "    # Map predictions and actual labels back to cat_ids\n",
    "    test_results = pd.DataFrame({\n",
    "        'cat_id': df_test_updated['cat_id'],\n",
    "        'predicted_age_group': predicted_age_groups,\n",
    "        'actual_age_group': actual_labels\n",
    "    })\n",
    "    \n",
    "    # Group by cat_id and aggregate predicted age groups\n",
    "    majority_votes = test_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "    actual_groups = test_results.groupby('cat_id')['actual_age_group'].first()\n",
    "    \n",
    "    # Calculate the accuracy of majority voting\n",
    "    correct_predictions = (majority_votes == actual_groups).sum()\n",
    "    total_cats = len(actual_groups)\n",
    "    majority_vote_accuracy = correct_predictions / total_cats\n",
    "    \n",
    "    # Log the accuracy of the majority voting\n",
    "    logger(f\"Majority Vote Accuracy for cat_id for this fold: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)\n",
    "\n",
    "    ####################################################\n",
    "    # COLLECT PREDICTIONS FOR GENDER & CAT_ID ANALYSIS #\n",
    "    ####################################################\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'Before appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Extend lists with current fold results\n",
    "    all_cat_ids.extend(df_test_updated['cat_id'].tolist())\n",
    "    all_predicted_age_groups.extend(predicted_age_groups)\n",
    "    all_actual_age_groups.extend(actual_labels)\n",
    "    all_gender.extend(df_test_updated['gender'].tolist())\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'After appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    test_precision = precision_score(y_test_true, y_test_pred, average='macro')  # Use 'macro' for imbalanced datasets\n",
    "    test_recall = recall_score(y_test_true, y_test_pred, average='macro')\n",
    "    test_f1 = f1_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "    # prepare averages of outer metrics\n",
    "    unseen_f1.append(test_f1)\n",
    "    unseen_losses.append(test_loss)\n",
    "    unseen_accuracies.append(test_accuracy)\n",
    "    unseen_precisions.append(test_precision)\n",
    "    unseen_recalls.append(test_recall)\n",
    "\n",
    "    # Print final test results\n",
    "    logger(f\"Final Test Results - Loss: {test_loss}, Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}\", file=log_file_path)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    logger(f\"Confusion Matrix:\\n {cm}\", file=log_file_path)\n",
    "\n",
    "# Calculate the overall average metrics\n",
    "unseen_set_avg_f1 = np.mean(unseen_f1)\n",
    "unseen_set_avg_loss = np.mean(unseen_losses)\n",
    "unseen_set_avg_acc = np.mean(unseen_accuracies)\n",
    "unseen_set_avg_precision = np.mean(unseen_precisions)\n",
    "unseen_set_avg_recall = np.mean(unseen_recalls)\n",
    "\n",
    "logger(f\"\\nFinal Average F1-Score across all UNSEEN TEST sets: {unseen_set_avg_f1}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Loss across all UNSEEN TEST sets: {unseen_set_avg_loss}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Accuracy across all UNSEEN TEST sets: {unseen_set_avg_acc}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Precision across all UNSEEN TEST sets: {unseen_set_avg_precision}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Recall across all UNSEEN TEST sets: {unseen_set_avg_recall}\\n\", file=log_file_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79e793-c694-4bc7-8cc6-05e124ddf71f",
   "metadata": {},
   "source": [
    "## Majority Voting on Total Entries per cat_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2c3c239d-6215-4589-a583-b37a18ca22cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking - Cat IDs: 845, Predictions: 845, Actuals: 845, Gender: 845\n"
     ]
    }
   ],
   "source": [
    "# Debugging print statements\n",
    "print(f'Checking - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "99978976-e4a9-4c04-a6b2-6b14a3111277",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create results df\n",
    "full_results = pd.DataFrame({\n",
    "    'cat_id': all_cat_ids,\n",
    "    'predicted_age_group': all_predicted_age_groups,\n",
    "    'actual_age_group': all_actual_age_groups,\n",
    "    'all_gender': all_gender\n",
    "})\n",
    "\n",
    "# create a correct majority prediction column\n",
    "full_results['correct'] = full_results['predicted_age_group'] == full_results['actual_age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "189b812b-d37f-462f-a99f-6de8e4a7899f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Majority Vote Accuracy for cat_id: 0.75 (82/110)\n"
     ]
    }
   ],
   "source": [
    "# Group by cat_id and aggregate predicted age groups\n",
    "majority_votes = full_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first()\n",
    "\n",
    "# Calculate the accuracy of majority voting\n",
    "correct_predictions = (majority_votes == actual_groups).sum()\n",
    "total_cats = len(actual_groups)\n",
    "majority_vote_accuracy = correct_predictions / total_cats\n",
    "\n",
    "logger(f\"Overall Majority Vote Accuracy for cat_id: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "907d957f-7340-4a76-b3fa-7cf166f43049",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Detailed df with predictions, actual labels, and comparison including majority vote\n",
    "detailed_results = full_results.groupby('cat_id').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Predictions': list(x['predicted_age_group']),\n",
    "        'Majority Vote': x['predicted_age_group'].mode()[0],\n",
    "        'Actual Age Group': x['actual_age_group'].iloc[0],\n",
    "        'Correct Majority Vote': x['predicted_age_group'].mode()[0] == x['actual_age_group'].iloc[0]\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Convert to DataFrame for better formatting and display\n",
    "detailed_results = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7016fa20-094f-409a-9a2f-b6d6793aed03",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Majority Vote</th>\n",
       "      <th>Actual Age Group</th>\n",
       "      <th>Correct Majority Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000B</td>\n",
       "      <td>[adult, adult, adult, senior, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>057A</td>\n",
       "      <td>[adult, adult, adult, senior, senior, senior, ...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>072A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>071A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>070A</td>\n",
       "      <td>[adult, adult, adult, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>069A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>068A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>067A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>066A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>064A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>062A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>056A</td>\n",
       "      <td>[adult, senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>074A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>053A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>051B</td>\n",
       "      <td>[senior, adult, senior, adult, senior, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>051A</td>\n",
       "      <td>[senior, senior, adult, adult, senior, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001A</td>\n",
       "      <td>[adult, adult, senior, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>049A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>047A</td>\n",
       "      <td>[adult, kitten, kitten, kitten, kitten, kitten...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>045A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>044A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>043A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>073A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>075A</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>041A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>101A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>116A</td>\n",
       "      <td>[senior, senior, senior, senior, adult, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>115A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>113A</td>\n",
       "      <td>[senior, senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>111A</td>\n",
       "      <td>[kitten, adult, kitten, kitten, kitten, kitten...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>110A</td>\n",
       "      <td>[kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>105A</td>\n",
       "      <td>[senior, adult, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>104A</td>\n",
       "      <td>[senior, senior, senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>103A</td>\n",
       "      <td>[adult, adult, adult, adult, senior, senior, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>102A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>100A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>087A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>099A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>097B</td>\n",
       "      <td>[adult, adult, kitten, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>097A</td>\n",
       "      <td>[adult, senior, senior, adult, adult, senior, ...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>096A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>094A</td>\n",
       "      <td>[senior, senior, adult, senior, senior, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>092A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>091A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>090A</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>088A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>042A</td>\n",
       "      <td>[adult, kitten, kitten, kitten, kitten, kitten...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>050A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>040A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>026A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>025A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>023B</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>039A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>022A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>021A</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>020A</td>\n",
       "      <td>[adult, adult, senior, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>019A</td>\n",
       "      <td>[adult, adult, adult, adult, kitten, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>018A</td>\n",
       "      <td>[adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>015A</td>\n",
       "      <td>[adult, senior, adult, adult, senior, adult, s...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>014B</td>\n",
       "      <td>[kitten, kitten, kitten, adult, kitten, kitten...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>014A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>013B</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>010A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>009A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>008A</td>\n",
       "      <td>[adult, adult, adult, kitten, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>007A</td>\n",
       "      <td>[adult, senior, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>006A</td>\n",
       "      <td>[adult, senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>004A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003A</td>\n",
       "      <td>[adult, senior, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002B</td>\n",
       "      <td>[adult, adult, adult, senior, adult, adult, se...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002A</td>\n",
       "      <td>[adult, adult, adult, adult, kitten, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>025C</td>\n",
       "      <td>[senior, senior, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>023A</td>\n",
       "      <td>[adult, kitten, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>117A</td>\n",
       "      <td>[senior, senior, senior, adult, senior, adult,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>034A</td>\n",
       "      <td>[adult, adult, adult, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>037A</td>\n",
       "      <td>[adult, senior, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>029A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>032A</td>\n",
       "      <td>[kitten, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>028A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>033A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>031A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>035A</td>\n",
       "      <td>[senior, adult, senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>011A</td>\n",
       "      <td>[senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>052A</td>\n",
       "      <td>[adult, senior, senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>106A</td>\n",
       "      <td>[adult, senior, senior, senior, adult, adult, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>108A</td>\n",
       "      <td>[senior, adult, adult, senior, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>109A</td>\n",
       "      <td>[adult, adult, adult, kitten, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>005A</td>\n",
       "      <td>[senior, senior, senior, senior, senior, senio...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>048A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>036A</td>\n",
       "      <td>[senior, senior, senior, adult, adult, adult, ...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>038A</td>\n",
       "      <td>[kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>012A</td>\n",
       "      <td>[senior, adult, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>026B</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>054A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>060A</td>\n",
       "      <td>[kitten, kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>025B</td>\n",
       "      <td>[senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>026C</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>024A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>063A</td>\n",
       "      <td>[senior, senior, senior, adult, senior, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>027A</td>\n",
       "      <td>[adult, senior, senior, adult, senior, adult, ...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>061A</td>\n",
       "      <td>[adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>076A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>065A</td>\n",
       "      <td>[senior, adult, adult, adult, senior, senior, ...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>059A</td>\n",
       "      <td>[adult, adult, adult, adult, senior, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>019B</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>058A</td>\n",
       "      <td>[senior, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>016A</td>\n",
       "      <td>[adult, adult, adult, adult, senior, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>093A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>095A</td>\n",
       "      <td>[senior, adult, adult, senior, senior, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>055A</td>\n",
       "      <td>[adult, senior, senior, adult, adult, senior, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat_id                                        Predictions Majority Vote Actual Age Group  Correct Majority Vote\n",
       "0     000B  [adult, adult, adult, senior, adult, adult, ad...         adult            adult                   True\n",
       "63    057A  [adult, adult, adult, senior, senior, senior, ...        senior           senior                   True\n",
       "78    072A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "77    071A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "76    070A               [adult, adult, adult, adult, senior]         adult            adult                   True\n",
       "75    069A                                     [adult, adult]         adult            adult                   True\n",
       "74    068A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "73    067A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "72    066A                                            [adult]         adult            adult                   True\n",
       "70    064A                              [adult, adult, adult]         adult            adult                   True\n",
       "68    062A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "62    056A                            [adult, senior, senior]        senior           senior                   True\n",
       "80    074A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "59    053A        [adult, adult, adult, adult, adult, senior]         adult            adult                   True\n",
       "57    051B  [senior, adult, senior, adult, senior, senior,...        senior           senior                   True\n",
       "56    051A  [senior, senior, adult, adult, senior, senior,...        senior           senior                   True\n",
       "1     001A  [adult, adult, senior, adult, adult, adult, ad...         adult            adult                   True\n",
       "54    049A                                           [kitten]        kitten           kitten                   True\n",
       "52    047A  [adult, kitten, kitten, kitten, kitten, kitten...        kitten           kitten                   True\n",
       "51    045A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "50    044A           [kitten, kitten, kitten, kitten, kitten]        kitten           kitten                   True\n",
       "49    043A                                           [kitten]        kitten           kitten                   True\n",
       "79    073A                                            [adult]         adult            adult                   True\n",
       "81    075A                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "47    041A                                           [kitten]        kitten           kitten                   True\n",
       "96    101A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "108   116A  [senior, senior, senior, senior, adult, senior...        senior           senior                   True\n",
       "107   115A                                           [kitten]        kitten           kitten                   True\n",
       "106   113A                           [senior, senior, senior]        senior           senior                   True\n",
       "105   111A  [kitten, adult, kitten, kitten, kitten, kitten...        kitten           kitten                   True\n",
       "104   110A                                   [kitten, kitten]        kitten           kitten                   True\n",
       "100   105A                     [senior, adult, adult, senior]         adult            adult                   True\n",
       "99    104A                   [senior, senior, senior, senior]        senior           senior                   True\n",
       "98    103A  [adult, adult, adult, adult, senior, senior, a...         adult            adult                   True\n",
       "97    102A                                     [adult, adult]         adult            adult                   True\n",
       "95    100A                                            [adult]         adult            adult                   True\n",
       "83    087A                                     [adult, adult]         adult            adult                   True\n",
       "94    099A  [adult, adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "93    097B  [adult, adult, kitten, adult, adult, adult, ad...         adult            adult                   True\n",
       "92    097A  [adult, senior, senior, adult, adult, senior, ...        senior           senior                   True\n",
       "91    096A                                            [adult]         adult            adult                   True\n",
       "89    094A  [senior, senior, adult, senior, senior, senior...        senior           senior                   True\n",
       "87    092A                                            [adult]         adult            adult                   True\n",
       "86    091A                                            [adult]         adult            adult                   True\n",
       "85    090A                                           [senior]        senior           senior                   True\n",
       "84    088A                                            [adult]         adult            adult                   True\n",
       "48    042A  [adult, kitten, kitten, kitten, kitten, kitten...        kitten           kitten                   True\n",
       "55    050A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "46    040A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "31    026A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "28    025A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "26    023B                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "45    039A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "24    022A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "23    021A                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "22    020A  [adult, adult, senior, adult, adult, adult, ad...         adult            adult                   True\n",
       "20    019A  [adult, adult, adult, adult, kitten, adult, ad...         adult            adult                   True\n",
       "19    018A                                    [adult, senior]         adult            adult                   True\n",
       "17    015A  [adult, senior, adult, adult, senior, adult, s...         adult            adult                   True\n",
       "16    014B  [kitten, kitten, kitten, adult, kitten, kitten...        kitten           kitten                   True\n",
       "15    014A                              [adult, adult, adult]         adult            adult                   True\n",
       "14    013B  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "11    010A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "10    009A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "9     008A        [adult, adult, adult, kitten, adult, adult]         adult            adult                   True\n",
       "8     007A        [adult, senior, adult, adult, adult, adult]         adult            adult                   True\n",
       "7     006A                             [adult, senior, adult]         adult            adult                   True\n",
       "5     004A                                            [adult]         adult            adult                   True\n",
       "4     003A                     [adult, senior, adult, senior]         adult            adult                   True\n",
       "3     002B  [adult, adult, adult, senior, adult, adult, se...         adult            adult                   True\n",
       "2     002A  [adult, adult, adult, adult, kitten, adult, ad...         adult            adult                   True\n",
       "30    025C              [senior, senior, adult, adult, adult]         adult            adult                   True\n",
       "25    023A        [adult, kitten, adult, adult, adult, adult]         adult            adult                   True\n",
       "109   117A  [senior, senior, senior, adult, senior, adult,...        senior           senior                   True\n",
       "40    034A               [adult, adult, adult, adult, senior]         adult            adult                   True\n",
       "43    037A        [adult, senior, adult, adult, adult, adult]         adult            adult                   True\n",
       "36    029A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "38    032A                                    [kitten, adult]         adult            adult                   True\n",
       "35    028A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "39    033A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "37    031A  [adult, adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "41    035A                     [senior, adult, senior, adult]         adult            adult                   True\n",
       "12    011A                                    [senior, adult]         adult           senior                  False\n",
       "58    052A                    [adult, senior, senior, senior]        senior            adult                  False\n",
       "101   106A  [adult, senior, senior, senior, adult, adult, ...         adult           senior                  False\n",
       "102   108A      [senior, adult, adult, senior, adult, senior]         adult           senior                  False\n",
       "103   109A        [adult, adult, adult, kitten, adult, adult]         adult           kitten                  False\n",
       "6     005A  [senior, senior, senior, senior, senior, senio...        senior            adult                  False\n",
       "53    048A                                            [adult]         adult           kitten                  False\n",
       "42    036A  [senior, senior, senior, adult, adult, adult, ...        senior            adult                  False\n",
       "44    038A                                   [kitten, kitten]        kitten            adult                  False\n",
       "13    012A                            [senior, adult, senior]        senior            adult                  False\n",
       "32    026B                                           [senior]        senior            adult                  False\n",
       "60    054A                                     [adult, adult]         adult           senior                  False\n",
       "66    060A                           [kitten, kitten, kitten]        kitten            adult                  False\n",
       "29    025B                                   [senior, senior]        senior            adult                  False\n",
       "33    026C                                           [kitten]        kitten            adult                  False\n",
       "27    024A                                            [adult]         adult           senior                  False\n",
       "69    063A  [senior, senior, senior, adult, senior, senior...        senior            adult                  False\n",
       "34    027A  [adult, senior, senior, adult, senior, adult, ...        senior            adult                  False\n",
       "67    061A                                    [adult, senior]         adult           senior                  False\n",
       "82    076A                                           [kitten]        kitten            adult                  False\n",
       "71    065A  [senior, adult, adult, adult, senior, senior, ...        senior            adult                  False\n",
       "65    059A  [adult, adult, adult, adult, senior, adult, ad...         adult           senior                  False\n",
       "21    019B                                           [senior]        senior            adult                  False\n",
       "64    058A                             [senior, adult, adult]         adult           senior                  False\n",
       "18    016A  [adult, adult, adult, adult, senior, adult, ad...         adult           senior                  False\n",
       "88    093A                                     [adult, adult]         adult           senior                  False\n",
       "90    095A  [senior, adult, adult, senior, senior, senior,...        senior            adult                  False\n",
       "61    055A  [adult, senior, senior, adult, adult, senior, ...         adult           senior                  False"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "sorted_detailed_results = detailed_results.sort_values(by='Correct Majority Vote', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "994531fd-e6fb-4491-9eab-86e41ac1ed3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Majority Votes per Class:\n",
      "actual_age_group\n",
      "adult     58\n",
      "kitten    13\n",
      "senior    11\n",
      "Name: Majority_Correct, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create df for majority votes\n",
    "majority_df = majority_votes.reset_index()\n",
    "majority_df.columns = ['cat_id', 'Majority_Vote']\n",
    "\n",
    "# Get actual groups for each cat_id\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first().reset_index()\n",
    "\n",
    "# Merge majority votes with actual groups\n",
    "majority_with_actual = pd.merge(majority_df, actual_groups, on='cat_id')\n",
    "\n",
    "# Add a column to check if the majority vote was correct\n",
    "majority_with_actual['Majority_Correct'] = majority_with_actual['Majority_Vote'] == majority_with_actual['actual_age_group']\n",
    "\n",
    "# Count correct majority votes per class\n",
    "correct_majority_votes_per_class = majority_with_actual.groupby('actual_age_group')['Majority_Correct'].sum()\n",
    "\n",
    "print(\"Correct Majority Votes per Class:\")\n",
    "print(correct_majority_votes_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "229af3e2-6a64-4f3d-a594-e04108fce87f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics for Majority Votes:\n",
      "  actual_age_group  total_count  correct_count   accuracy\n",
      "0            adult           73             58  79.452055\n",
      "1           kitten           15             13  86.666667\n",
      "2           senior           22             11  50.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = majority_with_actual.groupby('actual_age_group').agg(\n",
    "    total_count=('Majority_Correct', 'size'),  # Total number of cases per class\n",
    "    correct_count=('Majority_Correct', 'sum')  # Sum of correct predictions per class\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log detailed stats\n",
    "print(\"Detailed Class Statistics for Majority Votes:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3960450a-db52-4464-a965-00f1e600bda5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics for Majority Votes\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Accuracy of Majority Votes by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bbf768-64c2-48ec-80e3-3a961b0b12a6",
   "metadata": {},
   "source": [
    "## Detailed Class Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fe16003e-4015-4d28-ae37-ca0c94952758",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics:\n",
      "  actual_age_group  total_count  correct_count   accuracy\n",
      "0            adult          558            431  77.240143\n",
      "1           kitten          109             91  83.486239\n",
      "2           senior          178             96  53.932584\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = full_results.groupby('actual_age_group').agg(\n",
    "    total_count=('correct', 'size'),\n",
    "    correct_count=('correct', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log the detailed stats\n",
    "print(\"Detailed Class Statistics:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5b5b8766-b4bd-4dd2-92e2-6513741b03ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics (Overall)\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Overall Accuracy by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efa447-1e32-42df-8664-a3f1f0e0f812",
   "metadata": {},
   "source": [
    "## Gender Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5eecd6a6-4094-4747-8029-f795a87f8ff0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Gender:\n",
      "  all_gender  count  correct  accuracy\n",
      "0          F    213      167     78.40\n",
      "1          M    337      229     67.95\n",
      "2          X    295      222     75.25\n"
     ]
    }
   ],
   "source": [
    "# Group by gender and calculate the total count, correct predictions, and accuracy\n",
    "gender_stats = full_results.groupby('all_gender').agg(\n",
    "    count=('cat_id', 'size'),  # Total number of cases per gender\n",
    "    correct=('correct', 'sum')  # Sum of correct predictions per gender\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each gender\n",
    "gender_stats['accuracy'] = (gender_stats['correct'] / gender_stats['count'] * 100).round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy by Gender:\")\n",
    "print(gender_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "115592e9-47eb-42fe-8cb5-26beeb7328ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Accuracy by Gender\n",
    "styled_barplot(gender_stats, 'all_gender', 'accuracy', \n",
    "               'Accuracy by Gender', \n",
    "               'Gender', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae066af0-659b-43f0-924c-2c50be0e6c40",
   "metadata": {},
   "source": [
    "# RANDOM SEED 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cc76296a-4029-447e-b12c-41520160251a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult     588\n",
      "senior    178\n",
      "kitten    171\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(int(random_seeds[1]))\n",
    "np.random.seed(int(random_seeds[1]))\n",
    "tf.random.set_seed(int(random_seeds[1]))\n",
    "\n",
    "# Load datasets\n",
    "dataframe = pd.read_csv('/Users/astrid/PycharmProjects/audioset-thesis-work/audioset/vggish/embeddings/8april_looped_embeddings.csv')\n",
    "\n",
    "dataframe.drop('mean_freq', axis=1, inplace=True)\n",
    "\n",
    "def assign_age_group(age, age_groups):\n",
    "    for group_name, age_range in age_groups.items():\n",
    "        if age_range[0] <= age < age_range[1]:\n",
    "            return group_name\n",
    "    return 'Unknown'  # For any age that doesn't fit the defined groups\n",
    "\n",
    "# Define age groups\n",
    "age_groups = {\n",
    "    'kitten': (0, 0.5),\n",
    "    'adult': (0.5, 12),\n",
    "    'senior': (12, 20)\n",
    "}\n",
    "\n",
    "# Create a new column for the age group\n",
    "dataframe['age_group'] = dataframe['target'].apply(assign_age_group, age_groups=age_groups)\n",
    "\n",
    "print(dataframe['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "093977a2-1813-4a02-9573-f757b3d2a567",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = dataframe.iloc[:, :-4].values  # all columns except the last four\n",
    "\n",
    "# Encode the 'age_group' column as integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y = label_encoder.fit_transform(dataframe['age_group'].values)\n",
    "\n",
    "# Use the encoded labels for splitting and one-hot encoding\n",
    "y = encoded_y  \n",
    "\n",
    "# Convert 'cat_id' column to numpy array to be used as groups array for GroupKFold\n",
    "groups = dataframe['cat_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0c89dbfa-4c9b-4e46-a0d9-f659db30532f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a62fdf-86b5-45e7-9249-73a55985936a",
   "metadata": {},
   "source": [
    "## Run Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ee1b36c7-4a91-4071-a713-c904da913c3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_fold 1\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "000A    39\n",
      "057A    27\n",
      "020A    23\n",
      "055A    20\n",
      "000B    19\n",
      "067A    19\n",
      "019A    17\n",
      "029A    17\n",
      "106A    14\n",
      "097B    14\n",
      "001A    14\n",
      "059A    14\n",
      "028A    13\n",
      "002A    13\n",
      "039A    12\n",
      "116A    12\n",
      "063A    11\n",
      "025A    11\n",
      "005A    10\n",
      "040A    10\n",
      "016A    10\n",
      "071A    10\n",
      "022A     9\n",
      "051B     9\n",
      "072A     9\n",
      "065A     9\n",
      "045A     9\n",
      "033A     9\n",
      "013B     8\n",
      "094A     8\n",
      "010A     8\n",
      "095A     8\n",
      "027A     7\n",
      "117A     7\n",
      "031A     7\n",
      "109A     6\n",
      "108A     6\n",
      "053A     6\n",
      "008A     6\n",
      "023A     6\n",
      "037A     6\n",
      "007A     6\n",
      "034A     5\n",
      "025C     5\n",
      "070A     5\n",
      "023B     5\n",
      "044A     5\n",
      "075A     5\n",
      "035A     4\n",
      "062A     4\n",
      "026A     4\n",
      "105A     4\n",
      "104A     4\n",
      "052A     4\n",
      "009A     4\n",
      "060A     3\n",
      "012A     3\n",
      "006A     3\n",
      "064A     3\n",
      "058A     3\n",
      "054A     2\n",
      "061A     2\n",
      "087A     2\n",
      "069A     2\n",
      "032A     2\n",
      "011A     2\n",
      "018A     2\n",
      "025B     2\n",
      "093A     2\n",
      "088A     1\n",
      "091A     1\n",
      "100A     1\n",
      "090A     1\n",
      "019B     1\n",
      "115A     1\n",
      "066A     1\n",
      "004A     1\n",
      "048A     1\n",
      "073A     1\n",
      "026C     1\n",
      "076A     1\n",
      "041A     1\n",
      "092A     1\n",
      "049A     1\n",
      "043A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "103A    33\n",
      "002B    32\n",
      "047A    28\n",
      "074A    25\n",
      "097A    16\n",
      "101A    15\n",
      "042A    14\n",
      "111A    13\n",
      "051A    12\n",
      "068A    11\n",
      "036A    11\n",
      "014B    10\n",
      "015A     9\n",
      "099A     7\n",
      "050A     7\n",
      "021A     5\n",
      "003A     4\n",
      "056A     3\n",
      "014A     3\n",
      "113A     3\n",
      "038A     2\n",
      "102A     2\n",
      "096A     1\n",
      "110A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    233\n",
      "M    226\n",
      "F    210\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    115\n",
      "M    111\n",
      "F     42\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 000A, 033A, 001A, 071A, 097B, 028A, 019...\n",
      "kitten    [044A, 040A, 046A, 109A, 043A, 049A, 041A, 045...\n",
      "senior    [093A, 057A, 106A, 104A, 055A, 059A, 116A, 051...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [015A, 103A, 074A, 002B, 101A, 038A, 099A, 014...\n",
      "kitten                 [014B, 111A, 047A, 042A, 050A, 110A]\n",
      "senior                       [097A, 113A, 056A, 051A, 024A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 60, 'kitten': 10, 'senior': 17}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 14, 'kitten': 6, 'senior': 5}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '004A' '005A' '006A' '007A' '008A' '009A'\n",
      " '010A' '011A' '012A' '013B' '016A' '018A' '019A' '019B' '020A' '022A'\n",
      " '023A' '023B' '025A' '025B' '025C' '026A' '026B' '026C' '027A' '028A'\n",
      " '029A' '031A' '032A' '033A' '034A' '035A' '037A' '039A' '040A' '041A'\n",
      " '043A' '044A' '045A' '046A' '048A' '049A' '051B' '052A' '053A' '054A'\n",
      " '055A' '057A' '058A' '059A' '060A' '061A' '062A' '063A' '064A' '065A'\n",
      " '066A' '067A' '069A' '070A' '071A' '072A' '073A' '075A' '076A' '087A'\n",
      " '088A' '090A' '091A' '092A' '093A' '094A' '095A' '097B' '100A' '104A'\n",
      " '105A' '106A' '108A' '109A' '115A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['002B' '003A' '014A' '014B' '015A' '021A' '024A' '036A' '038A' '042A'\n",
      " '047A' '050A' '051A' '056A' '068A' '074A' '096A' '097A' '099A' '101A'\n",
      " '102A' '103A' '110A' '111A' '113A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "set()\n",
      "Removed from Training/Validation Set:\n",
      "set()\n",
      "Moved to Test Set:\n",
      "set()\n",
      "Removed from Test Set\n",
      "set()\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '004A' '005A' '006A' '007A' '008A' '009A'\n",
      " '010A' '011A' '012A' '013B' '016A' '018A' '019A' '019B' '020A' '022A'\n",
      " '023A' '023B' '025A' '025B' '025C' '026A' '026B' '026C' '027A' '028A'\n",
      " '029A' '031A' '032A' '033A' '034A' '035A' '037A' '039A' '040A' '041A'\n",
      " '043A' '044A' '045A' '046A' '048A' '049A' '051B' '052A' '053A' '054A'\n",
      " '055A' '057A' '058A' '059A' '060A' '061A' '062A' '063A' '064A' '065A'\n",
      " '066A' '067A' '069A' '070A' '071A' '072A' '073A' '075A' '076A' '087A'\n",
      " '088A' '090A' '091A' '092A' '093A' '094A' '095A' '097B' '100A' '104A'\n",
      " '105A' '106A' '108A' '109A' '115A' '116A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['002B' '003A' '014A' '014B' '015A' '021A' '024A' '036A' '038A' '042A'\n",
      " '047A' '050A' '051A' '056A' '068A' '074A' '096A' '097A' '099A' '101A'\n",
      " '102A' '103A' '110A' '111A' '113A']\n",
      "Length of X_train_val:\n",
      "669\n",
      "Length of y_train_val:\n",
      "669\n",
      "Length of groups_train_val:\n",
      "669\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     428\n",
      "senior    143\n",
      "kitten     98\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     160\n",
      "kitten     73\n",
      "senior     35\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     428\n",
      "senior    143\n",
      "kitten     98\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     160\n",
      "kitten     73\n",
      "senior     35\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 428, 2: 143, 1: 98})\n",
      "Epoch 1/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 1.1838 - accuracy: 0.3991\n",
      "Epoch 2/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8832 - accuracy: 0.5262\n",
      "Epoch 3/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7832 - accuracy: 0.5217\n",
      "Epoch 4/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7870 - accuracy: 0.5381\n",
      "Epoch 5/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.5770\n",
      "Epoch 6/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7301 - accuracy: 0.5695\n",
      "Epoch 7/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6701 - accuracy: 0.6069\n",
      "Epoch 8/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6371 - accuracy: 0.6203\n",
      "Epoch 9/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5862 - accuracy: 0.6457\n",
      "Epoch 10/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.6442\n",
      "Epoch 11/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6083 - accuracy: 0.6203\n",
      "Epoch 12/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5369 - accuracy: 0.6801\n",
      "Epoch 13/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5337 - accuracy: 0.6921\n",
      "Epoch 14/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5345 - accuracy: 0.6667\n",
      "Epoch 15/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.6876\n",
      "Epoch 16/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5593 - accuracy: 0.6876\n",
      "Epoch 17/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7085\n",
      "Epoch 18/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7384\n",
      "Epoch 19/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.7205\n",
      "Epoch 20/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7309\n",
      "Epoch 21/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7623\n",
      "Epoch 22/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7459\n",
      "Epoch 23/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7519\n",
      "Epoch 24/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7474\n",
      "Epoch 25/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7399\n",
      "Epoch 26/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4156 - accuracy: 0.7758\n",
      "Epoch 27/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.7578\n",
      "Epoch 28/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.7564\n",
      "Epoch 29/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7728\n",
      "Epoch 30/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.7743\n",
      "Epoch 31/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4015 - accuracy: 0.7848\n",
      "Epoch 32/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3818 - accuracy: 0.7907\n",
      "Epoch 33/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3972 - accuracy: 0.7833\n",
      "Epoch 34/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.7728\n",
      "Epoch 35/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3818 - accuracy: 0.7937\n",
      "Epoch 36/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.7967\n",
      "Epoch 37/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3706 - accuracy: 0.7892\n",
      "Epoch 38/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8057\n",
      "Epoch 39/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.8102\n",
      "Epoch 40/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3742 - accuracy: 0.8027\n",
      "Epoch 41/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.7937\n",
      "Epoch 42/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.8132\n",
      "Epoch 43/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3412 - accuracy: 0.8191\n",
      "Epoch 44/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3421 - accuracy: 0.8161\n",
      "Epoch 45/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8057\n",
      "Epoch 46/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8102\n",
      "Epoch 47/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8206\n",
      "Epoch 48/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3217 - accuracy: 0.8132\n",
      "Epoch 49/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3129 - accuracy: 0.8296\n",
      "Epoch 50/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2925 - accuracy: 0.8445\n",
      "Epoch 51/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3492 - accuracy: 0.8176\n",
      "Epoch 52/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3101 - accuracy: 0.8281\n",
      "Epoch 53/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8221\n",
      "Epoch 54/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.8191\n",
      "Epoch 55/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3226 - accuracy: 0.8281\n",
      "Epoch 56/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3151 - accuracy: 0.8281\n",
      "Epoch 57/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8356\n",
      "Epoch 58/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2966 - accuracy: 0.8326\n",
      "Epoch 59/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8117\n",
      "Epoch 60/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3225 - accuracy: 0.8371\n",
      "Epoch 61/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2867 - accuracy: 0.8535\n",
      "Epoch 62/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2804 - accuracy: 0.8744\n",
      "Epoch 63/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2872 - accuracy: 0.8430\n",
      "Epoch 64/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.8371\n",
      "Epoch 65/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2790 - accuracy: 0.8430\n",
      "Epoch 66/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2605 - accuracy: 0.8729\n",
      "Epoch 67/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2665 - accuracy: 0.8535\n",
      "Epoch 68/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2744 - accuracy: 0.8505\n",
      "Epoch 69/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2954 - accuracy: 0.8520\n",
      "Epoch 70/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2716 - accuracy: 0.8625\n",
      "Epoch 71/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2820 - accuracy: 0.8445\n",
      "Epoch 72/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2643 - accuracy: 0.8550\n",
      "Epoch 73/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2934 - accuracy: 0.8475\n",
      "Epoch 74/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2653 - accuracy: 0.8550\n",
      "Epoch 75/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2642 - accuracy: 0.8685\n",
      "Epoch 76/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.8774\n",
      "Epoch 77/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.8640\n",
      "Epoch 78/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2543 - accuracy: 0.8490\n",
      "Epoch 79/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2607 - accuracy: 0.8550\n",
      "Epoch 80/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2714 - accuracy: 0.8565\n",
      "Epoch 81/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2692 - accuracy: 0.8640\n",
      "Epoch 82/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.8864\n",
      "Epoch 83/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.8700\n",
      "Epoch 84/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.8714\n",
      "Epoch 85/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.8625\n",
      "Epoch 86/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.8700\n",
      "Epoch 87/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.8894\n",
      "Epoch 88/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.8789\n",
      "Epoch 89/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2152 - accuracy: 0.8924\n",
      "Epoch 90/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.8685\n",
      "Epoch 91/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2371 - accuracy: 0.8864\n",
      "Epoch 92/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2527 - accuracy: 0.8729\n",
      "Epoch 93/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.8879\n",
      "Epoch 94/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.8640\n",
      "Epoch 95/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2356 - accuracy: 0.8670\n",
      "Epoch 96/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2283 - accuracy: 0.8849\n",
      "Epoch 97/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.8744\n",
      "Epoch 98/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.8864\n",
      "Epoch 99/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.8999\n",
      "Epoch 100/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2132 - accuracy: 0.8879\n",
      "Epoch 101/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2332 - accuracy: 0.8834\n",
      "Epoch 102/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.8819\n",
      "Epoch 103/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2102 - accuracy: 0.8864\n",
      "Epoch 104/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.9043\n",
      "Epoch 105/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.8714\n",
      "Epoch 106/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.8849\n",
      "Epoch 107/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.8924\n",
      "Epoch 108/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.8969\n",
      "Epoch 109/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.9028\n",
      "Epoch 110/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2018 - accuracy: 0.8909\n",
      "Epoch 111/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1720 - accuracy: 0.9058\n",
      "Epoch 112/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.8909\n",
      "Epoch 113/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.8954\n",
      "Epoch 114/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.8939\n",
      "Epoch 115/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.8894\n",
      "Epoch 116/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.8894\n",
      "Epoch 117/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9088\n",
      "Epoch 118/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.8984\n",
      "Epoch 119/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.9073\n",
      "Epoch 120/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.8939\n",
      "Epoch 121/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9118\n",
      "Epoch 122/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1727 - accuracy: 0.9118\n",
      "Epoch 123/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1723 - accuracy: 0.9058\n",
      "Epoch 124/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.9148\n",
      "Epoch 125/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2054 - accuracy: 0.8789\n",
      "Epoch 126/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.8984\n",
      "Epoch 127/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.9073\n",
      "Epoch 128/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1467 - accuracy: 0.9372\n",
      "Epoch 129/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.9088\n",
      "Epoch 130/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.9028\n",
      "Epoch 131/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9103\n",
      "Epoch 132/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1954 - accuracy: 0.8909\n",
      "Epoch 133/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.9043\n",
      "Epoch 134/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9253\n",
      "Epoch 135/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1718 - accuracy: 0.9088\n",
      "Epoch 136/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9148\n",
      "Epoch 137/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9178\n",
      "Epoch 138/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1705 - accuracy: 0.9193\n",
      "Epoch 139/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.9238\n",
      "Epoch 140/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1536 - accuracy: 0.9312\n",
      "Epoch 141/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9178\n",
      "Epoch 142/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9283\n",
      "Epoch 143/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9133\n",
      "Epoch 144/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.8999\n",
      "Epoch 145/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9208\n",
      "Epoch 146/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1674 - accuracy: 0.9148\n",
      "Epoch 147/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9253\n",
      "Epoch 148/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9163\n",
      "Epoch 149/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1638 - accuracy: 0.9133\n",
      "Epoch 150/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1721 - accuracy: 0.9163\n",
      "Epoch 151/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9238\n",
      "Epoch 152/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.9088\n",
      "Epoch 153/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.9088\n",
      "Epoch 154/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1576 - accuracy: 0.9163\n",
      "Epoch 155/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.9133\n",
      "Epoch 156/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9193\n",
      "Epoch 157/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9432\n",
      "Epoch 158/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9312\n",
      "Epoch 159/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9327\n",
      "Epoch 160/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.9148\n",
      "Epoch 161/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1495 - accuracy: 0.9223\n",
      "Epoch 162/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1368 - accuracy: 0.9223\n",
      "Epoch 163/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9312\n",
      "Epoch 164/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.8999\n",
      "Epoch 165/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9238\n",
      "Epoch 166/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9163\n",
      "Epoch 167/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9357\n",
      "Epoch 168/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1421 - accuracy: 0.9297\n",
      "Epoch 169/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9178\n",
      "Epoch 170/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9148\n",
      "Epoch 171/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1675 - accuracy: 0.9148\n",
      "Epoch 172/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9208\n",
      "Epoch 173/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9432\n",
      "Epoch 174/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9268\n",
      "Epoch 175/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1434 - accuracy: 0.9253\n",
      "Epoch 176/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.9283\n",
      "Epoch 177/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9387\n",
      "Epoch 178/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.9372\n",
      "Epoch 179/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.9342\n",
      "Epoch 180/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9357\n",
      "Epoch 181/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9327\n",
      "Epoch 182/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9417\n",
      "Epoch 183/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9238\n",
      "Epoch 184/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9387\n",
      "Epoch 185/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9417\n",
      "Epoch 186/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9402\n",
      "Epoch 187/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.9387\n",
      "Epoch 188/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9327\n",
      "Epoch 189/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9372\n",
      "Epoch 190/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9253\n",
      "Epoch 191/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9537\n",
      "Epoch 192/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.9312\n",
      "Epoch 193/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9312\n",
      "Epoch 194/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9208\n",
      "Epoch 195/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9327\n",
      "Epoch 196/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1434 - accuracy: 0.9402\n",
      "Epoch 197/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9268\n",
      "Epoch 198/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9462\n",
      "Epoch 199/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9402\n",
      "Epoch 200/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.9402\n",
      "Epoch 201/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9522\n",
      "Epoch 202/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9297\n",
      "Epoch 203/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.9522\n",
      "Epoch 204/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.9417\n",
      "Epoch 205/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9417\n",
      "Epoch 206/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.9492\n",
      "Epoch 207/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9507\n",
      "Epoch 208/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1301 - accuracy: 0.9253\n",
      "Epoch 209/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9387\n",
      "Epoch 210/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.9417\n",
      "Epoch 211/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.9402\n",
      "Epoch 212/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9387\n",
      "Epoch 213/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.9283\n",
      "Epoch 214/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9312\n",
      "Epoch 215/1500\n",
      " 1/21 [>.............................] - ETA: 0s - loss: 0.0633 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 185.\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.9477\n",
      "Epoch 215: early stopping\n",
      "9/9 [==============================] - 0s 700us/step - loss: 0.7793 - accuracy: 0.6903\n",
      "9/9 [==============================] - 0s 581us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.72 (18/25)\n",
      "Before appending - Cat IDs: 0, Predictions: 0, Actuals: 0, Gender: 0\n",
      "After appending - Cat IDs: 268, Predictions: 268, Actuals: 268, Gender: 268\n",
      "Final Test Results - Loss: 0.7793291807174683, Accuracy: 0.6902984976768494, Precision: 0.6930523028883684, Recall: 0.663303163731246, F1 Score: 0.6467558528428093\n",
      "Confusion Matrix:\n",
      " [[121   2  37]\n",
      " [ 33  40   0]\n",
      " [ 11   0  24]]\n",
      "outer_fold 2\n",
      "Train Set Group Distribution:\n",
      "000A    39\n",
      "103A    33\n",
      "002B    32\n",
      "047A    28\n",
      "057A    27\n",
      "074A    25\n",
      "020A    23\n",
      "055A    20\n",
      "000B    19\n",
      "097A    16\n",
      "101A    15\n",
      "059A    14\n",
      "042A    14\n",
      "097B    14\n",
      "106A    14\n",
      "028A    13\n",
      "002A    13\n",
      "111A    13\n",
      "039A    12\n",
      "116A    12\n",
      "051A    12\n",
      "036A    11\n",
      "068A    11\n",
      "025A    11\n",
      "014B    10\n",
      "040A    10\n",
      "016A    10\n",
      "005A    10\n",
      "071A    10\n",
      "015A     9\n",
      "013B     8\n",
      "094A     8\n",
      "010A     8\n",
      "099A     7\n",
      "050A     7\n",
      "117A     7\n",
      "031A     7\n",
      "027A     7\n",
      "053A     6\n",
      "108A     6\n",
      "023A     6\n",
      "007A     6\n",
      "025C     5\n",
      "044A     5\n",
      "023B     5\n",
      "021A     5\n",
      "070A     5\n",
      "034A     5\n",
      "003A     4\n",
      "009A     4\n",
      "026A     4\n",
      "062A     4\n",
      "035A     4\n",
      "052A     4\n",
      "104A     4\n",
      "058A     3\n",
      "012A     3\n",
      "006A     3\n",
      "014A     3\n",
      "113A     3\n",
      "056A     3\n",
      "018A     2\n",
      "038A     2\n",
      "025B     2\n",
      "054A     2\n",
      "032A     2\n",
      "069A     2\n",
      "102A     2\n",
      "088A     1\n",
      "090A     1\n",
      "110A     1\n",
      "115A     1\n",
      "019B     1\n",
      "073A     1\n",
      "004A     1\n",
      "048A     1\n",
      "066A     1\n",
      "026C     1\n",
      "041A     1\n",
      "092A     1\n",
      "049A     1\n",
      "096A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "046A    63\n",
      "067A    19\n",
      "019A    17\n",
      "029A    17\n",
      "001A    14\n",
      "063A    11\n",
      "033A     9\n",
      "051B     9\n",
      "022A     9\n",
      "072A     9\n",
      "065A     9\n",
      "045A     9\n",
      "095A     8\n",
      "037A     6\n",
      "008A     6\n",
      "109A     6\n",
      "075A     5\n",
      "105A     4\n",
      "064A     3\n",
      "060A     3\n",
      "093A     2\n",
      "087A     2\n",
      "011A     2\n",
      "061A     2\n",
      "076A     1\n",
      "043A     1\n",
      "091A     1\n",
      "100A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "M    238\n",
      "F    229\n",
      "X    221\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    127\n",
      "M     99\n",
      "F     23\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 000A, 015A, 103A, 071A, 097B, 028A, 074...\n",
      "kitten    [044A, 014B, 111A, 040A, 047A, 042A, 050A, 049...\n",
      "senior    [097A, 057A, 106A, 104A, 055A, 059A, 113A, 116...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [033A, 001A, 019A, 067A, 022A, 029A, 095A, 072...\n",
      "kitten                             [046A, 109A, 043A, 045A]\n",
      "senior                             [093A, 051B, 011A, 061A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 53, 'kitten': 12, 'senior': 18}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 21, 'kitten': 4, 'senior': 4}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '002A' '002B' '003A' '004A' '005A' '006A' '007A' '009A'\n",
      " '010A' '012A' '013B' '014A' '014B' '015A' '016A' '018A' '019B' '020A'\n",
      " '021A' '023A' '023B' '024A' '025A' '025B' '025C' '026A' '026C' '027A'\n",
      " '028A' '031A' '032A' '034A' '035A' '036A' '038A' '039A' '040A' '041A'\n",
      " '042A' '044A' '047A' '048A' '049A' '050A' '051A' '052A' '053A' '054A'\n",
      " '055A' '056A' '057A' '058A' '059A' '062A' '066A' '068A' '069A' '070A'\n",
      " '071A' '073A' '074A' '088A' '090A' '092A' '094A' '096A' '097A' '097B'\n",
      " '099A' '101A' '102A' '103A' '104A' '106A' '108A' '110A' '111A' '113A'\n",
      " '115A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['001A' '008A' '011A' '019A' '022A' '026B' '029A' '033A' '037A' '043A'\n",
      " '045A' '046A' '051B' '060A' '061A' '063A' '064A' '065A' '067A' '072A'\n",
      " '075A' '076A' '087A' '091A' '093A' '095A' '100A' '105A' '109A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "{'046A'}\n",
      "Removed from Training/Validation Set:\n",
      "{'040A'}\n",
      "Moved to Test Set:\n",
      "{'040A'}\n",
      "Removed from Test Set\n",
      "{'046A'}\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '002A' '002B' '003A' '004A' '005A' '006A' '007A' '009A'\n",
      " '010A' '012A' '013B' '014A' '014B' '015A' '016A' '018A' '019B' '020A'\n",
      " '021A' '023A' '023B' '024A' '025A' '025B' '025C' '026A' '026C' '027A'\n",
      " '028A' '031A' '032A' '034A' '035A' '036A' '038A' '039A' '041A' '042A'\n",
      " '044A' '046A' '047A' '048A' '049A' '050A' '051A' '052A' '053A' '054A'\n",
      " '055A' '056A' '057A' '058A' '059A' '062A' '066A' '068A' '069A' '070A'\n",
      " '071A' '073A' '074A' '088A' '090A' '092A' '094A' '096A' '097A' '097B'\n",
      " '099A' '101A' '102A' '103A' '104A' '106A' '108A' '110A' '111A' '113A'\n",
      " '115A' '116A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['001A' '008A' '011A' '019A' '022A' '026B' '029A' '033A' '037A' '040A'\n",
      " '043A' '045A' '051B' '060A' '061A' '063A' '064A' '065A' '067A' '072A'\n",
      " '075A' '076A' '087A' '091A' '093A' '095A' '100A' '105A' '109A']\n",
      "Length of X_train_val:\n",
      "741\n",
      "Length of y_train_val:\n",
      "741\n",
      "Length of groups_train_val:\n",
      "741\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     433\n",
      "senior    163\n",
      "kitten     92\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     155\n",
      "kitten     79\n",
      "senior     15\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     433\n",
      "senior    163\n",
      "kitten    145\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     155\n",
      "kitten     26\n",
      "senior     15\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 433, 2: 163, 1: 145})\n",
      "Epoch 1/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 1.0351 - accuracy: 0.4872\n",
      "Epoch 2/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.8167 - accuracy: 0.5668\n",
      "Epoch 3/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.6073\n",
      "Epoch 4/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.7013 - accuracy: 0.6221\n",
      "Epoch 5/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6437\n",
      "Epoch 6/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.6572\n",
      "Epoch 7/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6243 - accuracy: 0.6721\n",
      "Epoch 8/1500\n",
      "24/24 [==============================] - 0s 978us/step - loss: 0.6298 - accuracy: 0.6734\n",
      "Epoch 9/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.6802\n",
      "Epoch 10/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.6964\n",
      "Epoch 11/1500\n",
      "24/24 [==============================] - 0s 991us/step - loss: 0.5904 - accuracy: 0.7072\n",
      "Epoch 12/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.6910\n",
      "Epoch 13/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5471 - accuracy: 0.7341\n",
      "Epoch 14/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.6937\n",
      "Epoch 15/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.7179\n",
      "Epoch 16/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5248 - accuracy: 0.7382\n",
      "Epoch 17/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7544\n",
      "Epoch 18/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.7409\n",
      "Epoch 19/1500\n",
      "24/24 [==============================] - 0s 1000us/step - loss: 0.4983 - accuracy: 0.7314\n",
      "Epoch 20/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7382\n",
      "Epoch 21/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7584\n",
      "Epoch 22/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.7557\n",
      "Epoch 23/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7706\n",
      "Epoch 24/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.7625\n",
      "Epoch 25/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7517\n",
      "Epoch 26/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7746\n",
      "Epoch 27/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7706\n",
      "Epoch 28/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4262 - accuracy: 0.7773\n",
      "Epoch 29/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.7868\n",
      "Epoch 30/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.8070\n",
      "Epoch 31/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7679\n",
      "Epoch 32/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.7868\n",
      "Epoch 33/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.8070\n",
      "Epoch 34/1500\n",
      "24/24 [==============================] - 0s 997us/step - loss: 0.4487 - accuracy: 0.7746\n",
      "Epoch 35/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.7895\n",
      "Epoch 36/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.7908\n",
      "Epoch 37/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8205\n",
      "Epoch 38/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.8151\n",
      "Epoch 39/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3970 - accuracy: 0.8111\n",
      "Epoch 40/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3970 - accuracy: 0.8084\n",
      "Epoch 41/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8165\n",
      "Epoch 42/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8205\n",
      "Epoch 43/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.8124\n",
      "Epoch 44/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4068 - accuracy: 0.8097\n",
      "Epoch 45/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3824 - accuracy: 0.8165\n",
      "Epoch 46/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8340\n",
      "Epoch 47/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8246\n",
      "Epoch 48/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3903 - accuracy: 0.8151\n",
      "Epoch 49/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8340\n",
      "Epoch 50/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.8151\n",
      "Epoch 51/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8219\n",
      "Epoch 52/1500\n",
      "24/24 [==============================] - 0s 990us/step - loss: 0.3406 - accuracy: 0.8259\n",
      "Epoch 53/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8300\n",
      "Epoch 54/1500\n",
      "24/24 [==============================] - 0s 997us/step - loss: 0.3368 - accuracy: 0.8354\n",
      "Epoch 55/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8408\n",
      "Epoch 56/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8273\n",
      "Epoch 57/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8394\n",
      "Epoch 58/1500\n",
      "24/24 [==============================] - 0s 995us/step - loss: 0.3416 - accuracy: 0.8408\n",
      "Epoch 59/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.8327\n",
      "Epoch 60/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2955 - accuracy: 0.8462\n",
      "Epoch 61/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3213 - accuracy: 0.8394\n",
      "Epoch 62/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3012 - accuracy: 0.8583\n",
      "Epoch 63/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.8529\n",
      "Epoch 64/1500\n",
      "24/24 [==============================] - 0s 986us/step - loss: 0.3497 - accuracy: 0.8327\n",
      "Epoch 65/1500\n",
      "24/24 [==============================] - 0s 999us/step - loss: 0.3271 - accuracy: 0.8489\n",
      "Epoch 66/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3188 - accuracy: 0.8516\n",
      "Epoch 67/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3174 - accuracy: 0.8448\n",
      "Epoch 68/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8381\n",
      "Epoch 69/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8516\n",
      "Epoch 70/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3103 - accuracy: 0.8543\n",
      "Epoch 71/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8489\n",
      "Epoch 72/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.8435\n",
      "Epoch 73/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3144 - accuracy: 0.8421\n",
      "Epoch 74/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8421\n",
      "Epoch 75/1500\n",
      "24/24 [==============================] - 0s 991us/step - loss: 0.3084 - accuracy: 0.8529\n",
      "Epoch 76/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2971 - accuracy: 0.8610\n",
      "Epoch 77/1500\n",
      "24/24 [==============================] - 0s 997us/step - loss: 0.3311 - accuracy: 0.8421\n",
      "Epoch 78/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2938 - accuracy: 0.8516\n",
      "Epoch 79/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3112 - accuracy: 0.8475\n",
      "Epoch 80/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2931 - accuracy: 0.8516\n",
      "Epoch 81/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2739 - accuracy: 0.8745\n",
      "Epoch 82/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2697 - accuracy: 0.8758\n",
      "Epoch 83/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2581 - accuracy: 0.8785\n",
      "Epoch 84/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8475\n",
      "Epoch 85/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2864 - accuracy: 0.8637\n",
      "Epoch 86/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2774 - accuracy: 0.8718\n",
      "Epoch 87/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2922 - accuracy: 0.8745\n",
      "Epoch 88/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2668 - accuracy: 0.8623\n",
      "Epoch 89/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2605 - accuracy: 0.8677\n",
      "Epoch 90/1500\n",
      "24/24 [==============================] - 0s 998us/step - loss: 0.2629 - accuracy: 0.8596\n",
      "Epoch 91/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.8880\n",
      "Epoch 92/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2580 - accuracy: 0.8623\n",
      "Epoch 93/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2669 - accuracy: 0.8704\n",
      "Epoch 94/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 0.8731\n",
      "Epoch 95/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2431 - accuracy: 0.8677\n",
      "Epoch 96/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2518 - accuracy: 0.8704\n",
      "Epoch 97/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2702 - accuracy: 0.8623\n",
      "Epoch 98/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2564 - accuracy: 0.8772\n",
      "Epoch 99/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2642 - accuracy: 0.8731\n",
      "Epoch 100/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2814 - accuracy: 0.8664\n",
      "Epoch 101/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2667 - accuracy: 0.8772\n",
      "Epoch 102/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2599 - accuracy: 0.8556\n",
      "Epoch 103/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.8758\n",
      "Epoch 104/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2716 - accuracy: 0.8718\n",
      "Epoch 105/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.8893\n",
      "Epoch 106/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2826 - accuracy: 0.8785\n",
      "Epoch 107/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 0.8745\n",
      "Epoch 108/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.8812\n",
      "Epoch 109/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 0.8677\n",
      "Epoch 110/1500\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.2448 - accuracy: 0.8731\n",
      "Epoch 111/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.8839\n",
      "Epoch 112/1500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2555 - accuracy: 0.8812\n",
      "Epoch 113/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2608 - accuracy: 0.8745\n",
      "Epoch 114/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.8920\n",
      "Epoch 115/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2609 - accuracy: 0.8704\n",
      "Epoch 116/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.8812\n",
      "Epoch 117/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.8826\n",
      "Epoch 118/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2567 - accuracy: 0.8731\n",
      "Epoch 119/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.8853\n",
      "Epoch 120/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.8799\n",
      "Epoch 121/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.8893\n",
      "Epoch 122/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.8947\n",
      "Epoch 123/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.8812\n",
      "Epoch 124/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.8934\n",
      "Epoch 125/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.8907\n",
      "Epoch 126/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2297 - accuracy: 0.8853\n",
      "Epoch 127/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.8988\n",
      "Epoch 128/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.8812\n",
      "Epoch 129/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.9015\n",
      "Epoch 130/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.8880\n",
      "Epoch 131/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.8745\n",
      "Epoch 132/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.8947\n",
      "Epoch 133/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2163 - accuracy: 0.8947\n",
      "Epoch 134/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.8988\n",
      "Epoch 135/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.8934\n",
      "Epoch 136/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.8907\n",
      "Epoch 137/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.8961\n",
      "Epoch 138/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2103 - accuracy: 0.8934\n",
      "Epoch 139/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.8893\n",
      "Epoch 140/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2085 - accuracy: 0.9055\n",
      "Epoch 141/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9001\n",
      "Epoch 142/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2291 - accuracy: 0.9015\n",
      "Epoch 143/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2271 - accuracy: 0.8907\n",
      "Epoch 144/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2416 - accuracy: 0.8853\n",
      "Epoch 145/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9001\n",
      "Epoch 146/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2176 - accuracy: 0.9015\n",
      "Epoch 147/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2343 - accuracy: 0.9015\n",
      "Epoch 148/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.8920\n",
      "Epoch 149/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.8907\n",
      "Epoch 150/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.8893\n",
      "Epoch 151/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.8893\n",
      "Epoch 152/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 0.8920\n",
      "Epoch 153/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.8974\n",
      "Epoch 154/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.9028\n",
      "Epoch 155/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.9042\n",
      "Epoch 156/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.9001\n",
      "Epoch 157/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.9096\n",
      "Epoch 158/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.8785\n",
      "Epoch 159/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.8880\n",
      "Epoch 160/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.8920\n",
      "Epoch 161/1500\n",
      "24/24 [==============================] - 0s 997us/step - loss: 0.2287 - accuracy: 0.8947\n",
      "Epoch 162/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2249 - accuracy: 0.8974\n",
      "Epoch 163/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.9069\n",
      "Epoch 164/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.8961\n",
      "Epoch 165/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.8974\n",
      "Epoch 166/1500\n",
      "24/24 [==============================] - 0s 979us/step - loss: 0.2114 - accuracy: 0.8866\n",
      "Epoch 167/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.9042\n",
      "Epoch 168/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2090 - accuracy: 0.9069\n",
      "Epoch 169/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.9001\n",
      "Epoch 170/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9150\n",
      "Epoch 171/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.9042\n",
      "Epoch 172/1500\n",
      "24/24 [==============================] - 0s 998us/step - loss: 0.2083 - accuracy: 0.8947\n",
      "Epoch 173/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2120 - accuracy: 0.8920\n",
      "Epoch 174/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9015\n",
      "Epoch 175/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.8988\n",
      "Epoch 176/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.9217\n",
      "Epoch 177/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.9069\n",
      "Epoch 178/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.9015\n",
      "Epoch 179/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9096\n",
      "Epoch 180/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.9028\n",
      "Epoch 181/1500\n",
      "24/24 [==============================] - 0s 981us/step - loss: 0.1928 - accuracy: 0.9015\n",
      "Epoch 182/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9123\n",
      "Epoch 183/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.9163\n",
      "Epoch 184/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.9190\n",
      "Epoch 185/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.9136\n",
      "Epoch 186/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9042\n",
      "Epoch 187/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9271\n",
      "Epoch 188/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9271\n",
      "Epoch 189/1500\n",
      "24/24 [==============================] - 0s 970us/step - loss: 0.2013 - accuracy: 0.9150\n",
      "Epoch 190/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1659 - accuracy: 0.9217\n",
      "Epoch 191/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2208 - accuracy: 0.8988\n",
      "Epoch 192/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1731 - accuracy: 0.9285\n",
      "Epoch 193/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9028\n",
      "Epoch 194/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9150\n",
      "Epoch 195/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.9109\n",
      "Epoch 196/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.8988\n",
      "Epoch 197/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9069\n",
      "Epoch 198/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.9150\n",
      "Epoch 199/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.9163\n",
      "Epoch 200/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.9150\n",
      "Epoch 201/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9177\n",
      "Epoch 202/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1971 - accuracy: 0.9123\n",
      "Epoch 203/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1719 - accuracy: 0.9258\n",
      "Epoch 204/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9204\n",
      "Epoch 205/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.9163\n",
      "Epoch 206/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9298\n",
      "Epoch 207/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.9217\n",
      "Epoch 208/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.9163\n",
      "Epoch 209/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.9055\n",
      "Epoch 210/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.9123\n",
      "Epoch 211/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9217\n",
      "Epoch 212/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.9352\n",
      "Epoch 213/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1645 - accuracy: 0.9244\n",
      "Epoch 214/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9190\n",
      "Epoch 215/1500\n",
      "24/24 [==============================] - 0s 1000us/step - loss: 0.1560 - accuracy: 0.9312\n",
      "Epoch 216/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9271\n",
      "Epoch 217/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.9109\n",
      "Epoch 218/1500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2950 - accuracy: 0.7812Restoring model weights from the end of the best epoch: 188.\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.9217\n",
      "Epoch 218: early stopping\n",
      "7/7 [==============================] - 0s 818us/step - loss: 0.8566 - accuracy: 0.6582\n",
      "7/7 [==============================] - 0s 608us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.62 (18/29)\n",
      "Before appending - Cat IDs: 268, Predictions: 268, Actuals: 268, Gender: 268\n",
      "After appending - Cat IDs: 464, Predictions: 464, Actuals: 464, Gender: 464\n",
      "Final Test Results - Loss: 0.8566213250160217, Accuracy: 0.6581632494926453, Precision: 0.5540140922200723, Recall: 0.7235456299972429, F1 Score: 0.573493135993136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[96 20 39]\n",
      " [ 3 23  0]\n",
      " [ 5  0 10]]\n",
      "outer_fold 3\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "000A    39\n",
      "103A    33\n",
      "002B    32\n",
      "047A    28\n",
      "057A    27\n",
      "074A    25\n",
      "055A    20\n",
      "067A    19\n",
      "019A    17\n",
      "029A    17\n",
      "097A    16\n",
      "101A    15\n",
      "001A    14\n",
      "042A    14\n",
      "097B    14\n",
      "111A    13\n",
      "039A    12\n",
      "051A    12\n",
      "036A    11\n",
      "068A    11\n",
      "063A    11\n",
      "040A    10\n",
      "014B    10\n",
      "022A     9\n",
      "072A     9\n",
      "065A     9\n",
      "033A     9\n",
      "051B     9\n",
      "045A     9\n",
      "015A     9\n",
      "094A     8\n",
      "095A     8\n",
      "117A     7\n",
      "050A     7\n",
      "099A     7\n",
      "027A     7\n",
      "031A     7\n",
      "008A     6\n",
      "109A     6\n",
      "053A     6\n",
      "037A     6\n",
      "108A     6\n",
      "023A     6\n",
      "023B     5\n",
      "075A     5\n",
      "021A     5\n",
      "105A     4\n",
      "026A     4\n",
      "062A     4\n",
      "035A     4\n",
      "052A     4\n",
      "003A     4\n",
      "056A     3\n",
      "113A     3\n",
      "064A     3\n",
      "014A     3\n",
      "060A     3\n",
      "012A     3\n",
      "058A     3\n",
      "061A     2\n",
      "011A     2\n",
      "102A     2\n",
      "093A     2\n",
      "038A     2\n",
      "087A     2\n",
      "069A     2\n",
      "041A     1\n",
      "019B     1\n",
      "024A     1\n",
      "100A     1\n",
      "110A     1\n",
      "096A     1\n",
      "076A     1\n",
      "088A     1\n",
      "092A     1\n",
      "004A     1\n",
      "043A     1\n",
      "048A     1\n",
      "073A     1\n",
      "091A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "020A    23\n",
      "000B    19\n",
      "106A    14\n",
      "059A    14\n",
      "028A    13\n",
      "002A    13\n",
      "116A    12\n",
      "025A    11\n",
      "071A    10\n",
      "005A    10\n",
      "016A    10\n",
      "010A     8\n",
      "013B     8\n",
      "007A     6\n",
      "070A     5\n",
      "044A     5\n",
      "034A     5\n",
      "025C     5\n",
      "104A     4\n",
      "009A     4\n",
      "006A     3\n",
      "018A     2\n",
      "054A     2\n",
      "025B     2\n",
      "032A     2\n",
      "049A     1\n",
      "026C     1\n",
      "066A     1\n",
      "115A     1\n",
      "090A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    322\n",
      "M    241\n",
      "F    159\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "M    96\n",
      "F    93\n",
      "X    26\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [000A, 033A, 015A, 001A, 103A, 097B, 019A, 074...\n",
      "kitten    [014B, 111A, 040A, 046A, 047A, 042A, 109A, 050...\n",
      "senior    [093A, 097A, 057A, 055A, 113A, 051B, 117A, 056...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [006A, 071A, 028A, 020A, 034A, 005A, 002A, 009...\n",
      "kitten                                   [044A, 049A, 115A]\n",
      "senior           [106A, 104A, 059A, 116A, 054A, 016A, 090A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 54, 'kitten': 13, 'senior': 15}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 20, 'kitten': 3, 'senior': 7}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '001A' '002B' '003A' '004A' '008A' '011A' '012A' '014A' '014B'\n",
      " '015A' '019A' '019B' '021A' '022A' '023A' '023B' '024A' '026A' '026B'\n",
      " '027A' '029A' '031A' '033A' '035A' '036A' '037A' '038A' '039A' '040A'\n",
      " '041A' '042A' '043A' '045A' '046A' '047A' '048A' '050A' '051A' '051B'\n",
      " '052A' '053A' '055A' '056A' '057A' '058A' '060A' '061A' '062A' '063A'\n",
      " '064A' '065A' '067A' '068A' '069A' '072A' '073A' '074A' '075A' '076A'\n",
      " '087A' '088A' '091A' '092A' '093A' '094A' '095A' '096A' '097A' '097B'\n",
      " '099A' '100A' '101A' '102A' '103A' '105A' '108A' '109A' '110A' '111A'\n",
      " '113A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['000B' '002A' '005A' '006A' '007A' '009A' '010A' '013B' '016A' '018A'\n",
      " '020A' '025A' '025B' '025C' '026C' '028A' '032A' '034A' '044A' '049A'\n",
      " '054A' '059A' '066A' '070A' '071A' '090A' '104A' '106A' '115A' '116A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "set()\n",
      "Removed from Training/Validation Set:\n",
      "set()\n",
      "Moved to Test Set:\n",
      "set()\n",
      "Removed from Test Set\n",
      "set()\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '001A' '002B' '003A' '004A' '008A' '011A' '012A' '014A' '014B'\n",
      " '015A' '019A' '019B' '021A' '022A' '023A' '023B' '024A' '026A' '026B'\n",
      " '027A' '029A' '031A' '033A' '035A' '036A' '037A' '038A' '039A' '040A'\n",
      " '041A' '042A' '043A' '045A' '046A' '047A' '048A' '050A' '051A' '051B'\n",
      " '052A' '053A' '055A' '056A' '057A' '058A' '060A' '061A' '062A' '063A'\n",
      " '064A' '065A' '067A' '068A' '069A' '072A' '073A' '074A' '075A' '076A'\n",
      " '087A' '088A' '091A' '092A' '093A' '094A' '095A' '096A' '097A' '097B'\n",
      " '099A' '100A' '101A' '102A' '103A' '105A' '108A' '109A' '110A' '111A'\n",
      " '113A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['000B' '002A' '005A' '006A' '007A' '009A' '010A' '013B' '016A' '018A'\n",
      " '020A' '025A' '025B' '025C' '026C' '028A' '032A' '034A' '044A' '049A'\n",
      " '054A' '059A' '066A' '070A' '071A' '090A' '104A' '106A' '115A' '116A']\n",
      "Length of X_train_val:\n",
      "722\n",
      "Length of y_train_val:\n",
      "722\n",
      "Length of groups_train_val:\n",
      "722\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     437\n",
      "kitten    164\n",
      "senior    121\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     151\n",
      "senior     57\n",
      "kitten      7\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     437\n",
      "kitten    164\n",
      "senior    121\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     151\n",
      "senior     57\n",
      "kitten      7\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 437, 1: 164, 2: 121})\n",
      "Epoch 1/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.1866 - accuracy: 0.4529\n",
      "Epoch 2/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8286 - accuracy: 0.5720\n",
      "Epoch 3/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7747 - accuracy: 0.5651\n",
      "Epoch 4/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.6136\n",
      "Epoch 5/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6432 - accuracy: 0.6454\n",
      "Epoch 6/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.6551\n",
      "Epoch 7/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.6620\n",
      "Epoch 8/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6745\n",
      "Epoch 9/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.6801\n",
      "Epoch 10/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6107 - accuracy: 0.6967\n",
      "Epoch 11/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7105\n",
      "Epoch 12/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5608 - accuracy: 0.7133\n",
      "Epoch 13/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.7327\n",
      "Epoch 14/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.7188\n",
      "Epoch 15/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7258\n",
      "Epoch 16/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.7507\n",
      "Epoch 17/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7535\n",
      "Epoch 18/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7590\n",
      "Epoch 19/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7479\n",
      "Epoch 20/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4115 - accuracy: 0.7576\n",
      "Epoch 21/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7590\n",
      "Epoch 22/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7798\n",
      "Epoch 23/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7825\n",
      "Epoch 24/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.7867\n",
      "Epoch 25/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.7992\n",
      "Epoch 26/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.7964\n",
      "Epoch 27/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4075 - accuracy: 0.7839\n",
      "Epoch 28/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.7798\n",
      "Epoch 29/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4324 - accuracy: 0.7909\n",
      "Epoch 30/1500\n",
      "23/23 [==============================] - 0s 994us/step - loss: 0.3940 - accuracy: 0.7895\n",
      "Epoch 31/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.8158\n",
      "Epoch 32/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8130\n",
      "Epoch 33/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8172\n",
      "Epoch 34/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.8019\n",
      "Epoch 35/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8338\n",
      "Epoch 36/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3684 - accuracy: 0.8310\n",
      "Epoch 37/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.8172\n",
      "Epoch 38/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8213\n",
      "Epoch 39/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8227\n",
      "Epoch 40/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8338\n",
      "Epoch 41/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.8269\n",
      "Epoch 42/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8269\n",
      "Epoch 43/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.8144\n",
      "Epoch 44/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3090 - accuracy: 0.8476\n",
      "Epoch 45/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8186\n",
      "Epoch 46/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8296\n",
      "Epoch 47/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8310\n",
      "Epoch 48/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.8560\n",
      "Epoch 49/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8283\n",
      "Epoch 50/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8490\n",
      "Epoch 51/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8269\n",
      "Epoch 52/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.8560\n",
      "Epoch 53/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3067 - accuracy: 0.8393\n",
      "Epoch 54/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8393\n",
      "Epoch 55/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.8601\n",
      "Epoch 56/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2703 - accuracy: 0.8698\n",
      "Epoch 57/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2963 - accuracy: 0.8532\n",
      "Epoch 58/1500\n",
      "23/23 [==============================] - 0s 1000us/step - loss: 0.2861 - accuracy: 0.8504\n",
      "Epoch 59/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8449\n",
      "Epoch 60/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8199\n",
      "Epoch 61/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8601\n",
      "Epoch 62/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.8643\n",
      "Epoch 63/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2656 - accuracy: 0.8601\n",
      "Epoch 64/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8740\n",
      "Epoch 65/1500\n",
      "23/23 [==============================] - 0s 987us/step - loss: 0.2789 - accuracy: 0.8726\n",
      "Epoch 66/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2700 - accuracy: 0.8643\n",
      "Epoch 67/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2783 - accuracy: 0.8657\n",
      "Epoch 68/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.8740\n",
      "Epoch 69/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2718 - accuracy: 0.8726\n",
      "Epoch 70/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2760 - accuracy: 0.8684\n",
      "Epoch 71/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2568 - accuracy: 0.8753\n",
      "Epoch 72/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2671 - accuracy: 0.8809\n",
      "Epoch 73/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2527 - accuracy: 0.8753\n",
      "Epoch 74/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.8837\n",
      "Epoch 75/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.8920\n",
      "Epoch 76/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.8920\n",
      "Epoch 77/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2621 - accuracy: 0.8643\n",
      "Epoch 78/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.8809\n",
      "Epoch 79/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.8767\n",
      "Epoch 80/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2711 - accuracy: 0.8712\n",
      "Epoch 81/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2272 - accuracy: 0.8781\n",
      "Epoch 82/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.8684\n",
      "Epoch 83/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2613 - accuracy: 0.8726\n",
      "Epoch 84/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.8837\n",
      "Epoch 85/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.8781\n",
      "Epoch 86/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.8892\n",
      "Epoch 87/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.8961\n",
      "Epoch 88/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.8878\n",
      "Epoch 89/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.8961\n",
      "Epoch 90/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.8989\n",
      "Epoch 91/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.8837\n",
      "Epoch 92/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.8892\n",
      "Epoch 93/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2119 - accuracy: 0.8961\n",
      "Epoch 94/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.8878\n",
      "Epoch 95/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2768 - accuracy: 0.8740\n",
      "Epoch 96/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.8947\n",
      "Epoch 97/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.9017\n",
      "Epoch 98/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.8823\n",
      "Epoch 99/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.8934\n",
      "Epoch 100/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2094 - accuracy: 0.9017\n",
      "Epoch 101/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2332 - accuracy: 0.8975\n",
      "Epoch 102/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2119 - accuracy: 0.9003\n",
      "Epoch 103/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2336 - accuracy: 0.8698\n",
      "Epoch 104/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.9155\n",
      "Epoch 105/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2044 - accuracy: 0.8920\n",
      "Epoch 106/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2604 - accuracy: 0.8934\n",
      "Epoch 107/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2139 - accuracy: 0.8961\n",
      "Epoch 108/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2396 - accuracy: 0.8892\n",
      "Epoch 109/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.8975\n",
      "Epoch 110/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.9058\n",
      "Epoch 111/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.8989\n",
      "Epoch 112/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9127\n",
      "Epoch 113/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.8975\n",
      "Epoch 114/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.9058\n",
      "Epoch 115/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.8920\n",
      "Epoch 116/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2085 - accuracy: 0.8989\n",
      "Epoch 117/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9086\n",
      "Epoch 118/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9030\n",
      "Epoch 119/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2410 - accuracy: 0.8878\n",
      "Epoch 120/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2110 - accuracy: 0.9003\n",
      "Epoch 121/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2090 - accuracy: 0.9127\n",
      "Epoch 122/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.9072\n",
      "Epoch 123/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.8961\n",
      "Epoch 124/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9114\n",
      "Epoch 125/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.9086\n",
      "Epoch 126/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.9127\n",
      "Epoch 127/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.9155\n",
      "Epoch 128/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9183\n",
      "Epoch 129/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.9169\n",
      "Epoch 130/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.9072\n",
      "Epoch 131/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.9183\n",
      "Epoch 132/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2096 - accuracy: 0.9155\n",
      "Epoch 133/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2328 - accuracy: 0.8975\n",
      "Epoch 134/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.9127\n",
      "Epoch 135/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9197\n",
      "Epoch 136/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9224\n",
      "Epoch 137/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2137 - accuracy: 0.8961\n",
      "Epoch 138/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.9058\n",
      "Epoch 139/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9086\n",
      "Epoch 140/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.9169\n",
      "Epoch 141/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.9127\n",
      "Epoch 142/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.9017\n",
      "Epoch 143/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.9100\n",
      "Epoch 144/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1733 - accuracy: 0.9224\n",
      "Epoch 145/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.9224\n",
      "Epoch 146/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1673 - accuracy: 0.9141\n",
      "Epoch 147/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1496 - accuracy: 0.9252\n",
      "Epoch 148/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9072\n",
      "Epoch 149/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1740 - accuracy: 0.9169\n",
      "Epoch 150/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9238\n",
      "Epoch 151/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1622 - accuracy: 0.9335\n",
      "Epoch 152/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.9155\n",
      "Epoch 153/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.9169\n",
      "Epoch 154/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9349\n",
      "Epoch 155/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.9252\n",
      "Epoch 156/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9183\n",
      "Epoch 157/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.9238\n",
      "Epoch 158/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9072\n",
      "Epoch 159/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.9141\n",
      "Epoch 160/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9141\n",
      "Epoch 161/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9141\n",
      "Epoch 162/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9294\n",
      "Epoch 163/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9307\n",
      "Epoch 164/1500\n",
      "23/23 [==============================] - 0s 974us/step - loss: 0.1782 - accuracy: 0.9224\n",
      "Epoch 165/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9294\n",
      "Epoch 166/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.9335\n",
      "Epoch 167/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9363\n",
      "Epoch 168/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9252\n",
      "Epoch 169/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9321\n",
      "Epoch 170/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9307\n",
      "Epoch 171/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.9224\n",
      "Epoch 172/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9349\n",
      "Epoch 173/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1536 - accuracy: 0.9211\n",
      "Epoch 174/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1699 - accuracy: 0.9335\n",
      "Epoch 175/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9335\n",
      "Epoch 176/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.9183\n",
      "Epoch 177/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9404\n",
      "Epoch 178/1500\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.1518 - accuracy: 0.9307\n",
      "Epoch 179/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.9211\n",
      "Epoch 180/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.9266\n",
      "Epoch 181/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9335\n",
      "Epoch 182/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9155\n",
      "Epoch 183/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2025 - accuracy: 0.9127\n",
      "Epoch 184/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1690 - accuracy: 0.9238\n",
      "Epoch 185/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.9474\n",
      "Epoch 186/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.9238\n",
      "Epoch 187/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9252\n",
      "Epoch 188/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9266\n",
      "Epoch 189/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9321\n",
      "Epoch 190/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9349\n",
      "Epoch 191/1500\n",
      "23/23 [==============================] - 0s 999us/step - loss: 0.1593 - accuracy: 0.9238\n",
      "Epoch 192/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9432\n",
      "Epoch 193/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9349\n",
      "Epoch 194/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9211\n",
      "Epoch 195/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9197\n",
      "Epoch 196/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9335\n",
      "Epoch 197/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.9446\n",
      "Epoch 198/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9252\n",
      "Epoch 199/1500\n",
      "23/23 [==============================] - 0s 980us/step - loss: 0.1308 - accuracy: 0.9294\n",
      "Epoch 200/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1243 - accuracy: 0.9446\n",
      "Epoch 201/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1331 - accuracy: 0.9404\n",
      "Epoch 202/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9460\n",
      "Epoch 203/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9460\n",
      "Epoch 204/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9349\n",
      "Epoch 205/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9335\n",
      "Epoch 206/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.9349\n",
      "Epoch 207/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9335\n",
      "Epoch 208/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9404\n",
      "Epoch 209/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1501 - accuracy: 0.9321\n",
      "Epoch 210/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9391\n",
      "Epoch 211/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.9294\n",
      "Epoch 212/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9557\n",
      "Epoch 213/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9474\n",
      "Epoch 214/1500\n",
      "23/23 [==============================] - 0s 992us/step - loss: 0.1252 - accuracy: 0.9460\n",
      "Epoch 215/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9460\n",
      "Epoch 216/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9474\n",
      "Epoch 217/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9460\n",
      "Epoch 218/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.9474\n",
      "Epoch 219/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9252\n",
      "Epoch 220/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9307\n",
      "Epoch 221/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9418\n",
      "Epoch 222/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9571\n",
      "Epoch 223/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9418\n",
      "Epoch 224/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9501\n",
      "Epoch 225/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9391\n",
      "Epoch 226/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.9404\n",
      "Epoch 227/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9446\n",
      "Epoch 228/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9418\n",
      "Epoch 229/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9418\n",
      "Epoch 230/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 0.9501\n",
      "Epoch 231/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9515\n",
      "Epoch 232/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9349\n",
      "Epoch 233/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9460\n",
      "Epoch 234/1500\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.1103 - accuracy: 0.9557\n",
      "Epoch 235/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.9557\n",
      "Epoch 236/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9488\n",
      "Epoch 237/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9501\n",
      "Epoch 238/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.9418\n",
      "Epoch 239/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1229 - accuracy: 0.9515\n",
      "Epoch 240/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.9349\n",
      "Epoch 241/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9391\n",
      "Epoch 242/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.9460\n",
      "Epoch 243/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9529\n",
      "Epoch 244/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9446\n",
      "Epoch 245/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9418\n",
      "Epoch 246/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.9543\n",
      "Epoch 247/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9695\n",
      "Epoch 248/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9501\n",
      "Epoch 249/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9404\n",
      "Epoch 250/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9571\n",
      "Epoch 251/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9557\n",
      "Epoch 252/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9515\n",
      "Epoch 253/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9640\n",
      "Epoch 254/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9432\n",
      "Epoch 255/1500\n",
      "23/23 [==============================] - 0s 992us/step - loss: 0.1172 - accuracy: 0.9557\n",
      "Epoch 256/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.9571\n",
      "Epoch 257/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9501\n",
      "Epoch 258/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.9501\n",
      "Epoch 259/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9543\n",
      "Epoch 260/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.9529\n",
      "Epoch 261/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9488\n",
      "Epoch 262/1500\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.1096 - accuracy: 0.9543\n",
      "Epoch 263/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.9446\n",
      "Epoch 264/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9391\n",
      "Epoch 265/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9543\n",
      "Epoch 266/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9543\n",
      "Epoch 267/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9488\n",
      "Epoch 268/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9598\n",
      "Epoch 269/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.9612\n",
      "Epoch 270/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9626\n",
      "Epoch 271/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.9488\n",
      "Epoch 272/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9557\n",
      "Epoch 273/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9557\n",
      "Epoch 274/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9529\n",
      "Epoch 275/1500\n",
      "23/23 [==============================] - 0s 991us/step - loss: 0.1122 - accuracy: 0.9571\n",
      "Epoch 276/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9543\n",
      "Epoch 277/1500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.1604 - accuracy: 0.8750Restoring model weights from the end of the best epoch: 247.\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1035 - accuracy: 0.9515\n",
      "Epoch 277: early stopping\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.8703 - accuracy: 0.7442\n",
      "7/7 [==============================] - 0s 687us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.77 (23/30)\n",
      "Before appending - Cat IDs: 464, Predictions: 464, Actuals: 464, Gender: 464\n",
      "After appending - Cat IDs: 679, Predictions: 679, Actuals: 679, Gender: 679\n",
      "Final Test Results - Loss: 0.8703449368476868, Accuracy: 0.7441860437393188, Precision: 0.7156853155972874, Recall: 0.7948568994229502, F1 Score: 0.7497567201647252\n",
      "Confusion Matrix:\n",
      " [[119   2  30]\n",
      " [  0   7   0]\n",
      " [ 23   0  34]]\n",
      "outer_fold 4\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "103A    33\n",
      "002B    32\n",
      "047A    28\n",
      "074A    25\n",
      "020A    23\n",
      "000B    19\n",
      "067A    19\n",
      "029A    17\n",
      "019A    17\n",
      "097A    16\n",
      "101A    15\n",
      "106A    14\n",
      "001A    14\n",
      "042A    14\n",
      "059A    14\n",
      "028A    13\n",
      "111A    13\n",
      "002A    13\n",
      "051A    12\n",
      "116A    12\n",
      "025A    11\n",
      "068A    11\n",
      "036A    11\n",
      "063A    11\n",
      "005A    10\n",
      "016A    10\n",
      "014B    10\n",
      "071A    10\n",
      "072A     9\n",
      "051B     9\n",
      "033A     9\n",
      "015A     9\n",
      "045A     9\n",
      "022A     9\n",
      "065A     9\n",
      "010A     8\n",
      "013B     8\n",
      "095A     8\n",
      "050A     7\n",
      "099A     7\n",
      "109A     6\n",
      "008A     6\n",
      "007A     6\n",
      "037A     6\n",
      "044A     5\n",
      "025C     5\n",
      "034A     5\n",
      "070A     5\n",
      "021A     5\n",
      "075A     5\n",
      "009A     4\n",
      "104A     4\n",
      "105A     4\n",
      "003A     4\n",
      "113A     3\n",
      "056A     3\n",
      "064A     3\n",
      "060A     3\n",
      "014A     3\n",
      "006A     3\n",
      "025B     2\n",
      "102A     2\n",
      "011A     2\n",
      "061A     2\n",
      "087A     2\n",
      "038A     2\n",
      "093A     2\n",
      "054A     2\n",
      "032A     2\n",
      "018A     2\n",
      "091A     1\n",
      "024A     1\n",
      "090A     1\n",
      "100A     1\n",
      "110A     1\n",
      "043A     1\n",
      "115A     1\n",
      "076A     1\n",
      "066A     1\n",
      "026C     1\n",
      "096A     1\n",
      "049A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "000A    39\n",
      "057A    27\n",
      "055A    20\n",
      "097B    14\n",
      "039A    12\n",
      "040A    10\n",
      "094A     8\n",
      "117A     7\n",
      "031A     7\n",
      "027A     7\n",
      "023A     6\n",
      "053A     6\n",
      "108A     6\n",
      "023B     5\n",
      "026A     4\n",
      "062A     4\n",
      "052A     4\n",
      "035A     4\n",
      "058A     3\n",
      "012A     3\n",
      "069A     2\n",
      "048A     1\n",
      "088A     1\n",
      "004A     1\n",
      "073A     1\n",
      "041A     1\n",
      "092A     1\n",
      "019B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "M    306\n",
      "X    268\n",
      "F    158\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "F    94\n",
      "X    80\n",
      "M    31\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 033A, 015A, 001A, 103A, 071A, 028A, 019...\n",
      "kitten    [044A, 014B, 111A, 046A, 047A, 042A, 109A, 050...\n",
      "senior    [093A, 097A, 106A, 104A, 059A, 113A, 116A, 051...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [000A, 097B, 062A, 039A, 023A, 027A, 069A, 026...\n",
      "kitten                                   [040A, 041A, 048A]\n",
      "senior                 [057A, 055A, 117A, 058A, 094A, 108A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 55, 'kitten': 13, 'senior': 16}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 19, 'kitten': 3, 'senior': 6}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000B' '001A' '002A' '002B' '003A' '005A' '006A' '007A' '008A' '009A'\n",
      " '010A' '011A' '013B' '014A' '014B' '015A' '016A' '018A' '019A' '020A'\n",
      " '021A' '022A' '024A' '025A' '025B' '025C' '026B' '026C' '028A' '029A'\n",
      " '032A' '033A' '034A' '036A' '037A' '038A' '042A' '043A' '044A' '045A'\n",
      " '046A' '047A' '049A' '050A' '051A' '051B' '054A' '056A' '059A' '060A'\n",
      " '061A' '063A' '064A' '065A' '066A' '067A' '068A' '070A' '071A' '072A'\n",
      " '074A' '075A' '076A' '087A' '090A' '091A' '093A' '095A' '096A' '097A'\n",
      " '099A' '100A' '101A' '102A' '103A' '104A' '105A' '106A' '109A' '110A'\n",
      " '111A' '113A' '115A' '116A']\n",
      "Unique Test Group IDs:\n",
      "['000A' '004A' '012A' '019B' '023A' '023B' '026A' '027A' '031A' '035A'\n",
      " '039A' '040A' '041A' '048A' '052A' '053A' '055A' '057A' '058A' '062A'\n",
      " '069A' '073A' '088A' '092A' '094A' '097B' '108A' '117A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "{'000A'}\n",
      "Removed from Training/Validation Set:\n",
      "{'026C'}\n",
      "Moved to Test Set:\n",
      "{'026C'}\n",
      "Removed from Test Set\n",
      "{'000A'}\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '002B' '003A' '005A' '006A' '007A' '008A'\n",
      " '009A' '010A' '011A' '013B' '014A' '014B' '015A' '016A' '018A' '019A'\n",
      " '020A' '021A' '022A' '024A' '025A' '025B' '025C' '026B' '028A' '029A'\n",
      " '032A' '033A' '034A' '036A' '037A' '038A' '042A' '043A' '044A' '045A'\n",
      " '046A' '047A' '049A' '050A' '051A' '051B' '054A' '056A' '059A' '060A'\n",
      " '061A' '063A' '064A' '065A' '066A' '067A' '068A' '070A' '071A' '072A'\n",
      " '074A' '075A' '076A' '087A' '090A' '091A' '093A' '095A' '096A' '097A'\n",
      " '099A' '100A' '101A' '102A' '103A' '104A' '105A' '106A' '109A' '110A'\n",
      " '111A' '113A' '115A' '116A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['004A' '012A' '019B' '023A' '023B' '026A' '026C' '027A' '031A' '035A'\n",
      " '039A' '040A' '041A' '048A' '052A' '053A' '055A' '057A' '058A' '062A'\n",
      " '069A' '073A' '088A' '092A' '094A' '097B' '108A' '117A']\n",
      "Length of X_train_val:\n",
      "770\n",
      "Length of y_train_val:\n",
      "770\n",
      "Length of groups_train_val:\n",
      "770\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     466\n",
      "kitten    159\n",
      "senior    107\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     122\n",
      "senior     71\n",
      "kitten     12\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     504\n",
      "kitten    159\n",
      "senior    107\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     84\n",
      "senior    71\n",
      "kitten    12\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 504, 1: 159, 2: 107})\n",
      "Epoch 1/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.2878 - accuracy: 0.4442\n",
      "Epoch 2/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.9637 - accuracy: 0.5026\n",
      "Epoch 3/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.8660 - accuracy: 0.5182\n",
      "Epoch 4/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.8304 - accuracy: 0.5727\n",
      "Epoch 5/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7861 - accuracy: 0.5974\n",
      "Epoch 6/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7396 - accuracy: 0.5818\n",
      "Epoch 7/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.6182\n",
      "Epoch 8/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.6286\n",
      "Epoch 9/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7046 - accuracy: 0.6195\n",
      "Epoch 10/1500\n",
      "25/25 [==============================] - 0s 986us/step - loss: 0.6573 - accuracy: 0.6286\n",
      "Epoch 11/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6204 - accuracy: 0.6338\n",
      "Epoch 12/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.6481\n",
      "Epoch 13/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6069 - accuracy: 0.6584\n",
      "Epoch 14/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.6584\n",
      "Epoch 15/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6110 - accuracy: 0.6649\n",
      "Epoch 16/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.6571\n",
      "Epoch 17/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.6909\n",
      "Epoch 18/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.6727\n",
      "Epoch 19/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7000\n",
      "Epoch 20/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7078\n",
      "Epoch 21/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7000\n",
      "Epoch 22/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.7091\n",
      "Epoch 23/1500\n",
      "25/25 [==============================] - 0s 978us/step - loss: 0.5487 - accuracy: 0.7039\n",
      "Epoch 24/1500\n",
      "25/25 [==============================] - 0s 994us/step - loss: 0.5131 - accuracy: 0.7117\n",
      "Epoch 25/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7026\n",
      "Epoch 26/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7377\n",
      "Epoch 27/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7208\n",
      "Epoch 28/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.7182\n",
      "Epoch 29/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7312\n",
      "Epoch 30/1500\n",
      "25/25 [==============================] - 0s 999us/step - loss: 0.4570 - accuracy: 0.7468\n",
      "Epoch 31/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7312\n",
      "Epoch 32/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7403\n",
      "Epoch 33/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7351\n",
      "Epoch 34/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7286\n",
      "Epoch 35/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7429\n",
      "Epoch 36/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7649\n",
      "Epoch 37/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7416\n",
      "Epoch 38/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7688\n",
      "Epoch 39/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7571\n",
      "Epoch 40/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4245 - accuracy: 0.7623\n",
      "Epoch 41/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7519\n",
      "Epoch 42/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7545\n",
      "Epoch 43/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.7766\n",
      "Epoch 44/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7740\n",
      "Epoch 45/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.7636\n",
      "Epoch 46/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7714\n",
      "Epoch 47/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7571\n",
      "Epoch 48/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7558\n",
      "Epoch 49/1500\n",
      "25/25 [==============================] - 0s 984us/step - loss: 0.4355 - accuracy: 0.7519\n",
      "Epoch 50/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.7727\n",
      "Epoch 51/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4109 - accuracy: 0.7727\n",
      "Epoch 52/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4103 - accuracy: 0.7766\n",
      "Epoch 53/1500\n",
      "25/25 [==============================] - 0s 999us/step - loss: 0.4217 - accuracy: 0.7818\n",
      "Epoch 54/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4056 - accuracy: 0.7844\n",
      "Epoch 55/1500\n",
      "25/25 [==============================] - 0s 993us/step - loss: 0.3910 - accuracy: 0.7753\n",
      "Epoch 56/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.7779\n",
      "Epoch 57/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4037 - accuracy: 0.7727\n",
      "Epoch 58/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4072 - accuracy: 0.7701\n",
      "Epoch 59/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.7831\n",
      "Epoch 60/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4107 - accuracy: 0.7727\n",
      "Epoch 61/1500\n",
      "25/25 [==============================] - 0s 983us/step - loss: 0.3919 - accuracy: 0.7805\n",
      "Epoch 62/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.7831\n",
      "Epoch 63/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3825 - accuracy: 0.7974\n",
      "Epoch 64/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3952 - accuracy: 0.8000\n",
      "Epoch 65/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.7909\n",
      "Epoch 66/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.7857\n",
      "Epoch 67/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.7987\n",
      "Epoch 68/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3939 - accuracy: 0.8000\n",
      "Epoch 69/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4000 - accuracy: 0.7766\n",
      "Epoch 70/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4047 - accuracy: 0.7844\n",
      "Epoch 71/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4127 - accuracy: 0.7766\n",
      "Epoch 72/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.7896\n",
      "Epoch 73/1500\n",
      "25/25 [==============================] - 0s 955us/step - loss: 0.3989 - accuracy: 0.7909\n",
      "Epoch 74/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3465 - accuracy: 0.8026\n",
      "Epoch 75/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8026\n",
      "Epoch 76/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8091\n",
      "Epoch 77/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3838 - accuracy: 0.7974\n",
      "Epoch 78/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8234\n",
      "Epoch 79/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.7974\n",
      "Epoch 80/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8247\n",
      "Epoch 81/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.8104\n",
      "Epoch 82/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.8000\n",
      "Epoch 83/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8351\n",
      "Epoch 84/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8000\n",
      "Epoch 85/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3563 - accuracy: 0.8208\n",
      "Epoch 86/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.8182\n",
      "Epoch 87/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8078\n",
      "Epoch 88/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8143\n",
      "Epoch 89/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8169\n",
      "Epoch 90/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.7922\n",
      "Epoch 91/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8208\n",
      "Epoch 92/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8169\n",
      "Epoch 93/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8247\n",
      "Epoch 94/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8208\n",
      "Epoch 95/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8195\n",
      "Epoch 96/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8325\n",
      "Epoch 97/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3158 - accuracy: 0.8429\n",
      "Epoch 98/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8143\n",
      "Epoch 99/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3257 - accuracy: 0.8208\n",
      "Epoch 100/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8208\n",
      "Epoch 101/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8221\n",
      "Epoch 102/1500\n",
      "25/25 [==============================] - 0s 985us/step - loss: 0.3586 - accuracy: 0.8208\n",
      "Epoch 103/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8312\n",
      "Epoch 104/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2951 - accuracy: 0.8312\n",
      "Epoch 105/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8416\n",
      "Epoch 106/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3179 - accuracy: 0.8377\n",
      "Epoch 107/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8260\n",
      "Epoch 108/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8234\n",
      "Epoch 109/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8221\n",
      "Epoch 110/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8247\n",
      "Epoch 111/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3035 - accuracy: 0.8273\n",
      "Epoch 112/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.8312\n",
      "Epoch 113/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3257 - accuracy: 0.8221\n",
      "Epoch 114/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8416\n",
      "Epoch 115/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2933 - accuracy: 0.8442\n",
      "Epoch 116/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3179 - accuracy: 0.8429\n",
      "Epoch 117/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8117\n",
      "Epoch 118/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8312\n",
      "Epoch 119/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2913 - accuracy: 0.8429\n",
      "Epoch 120/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8390\n",
      "Epoch 121/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.8338\n",
      "Epoch 122/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2976 - accuracy: 0.8429\n",
      "Epoch 123/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8286\n",
      "Epoch 124/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8494\n",
      "Epoch 125/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3202 - accuracy: 0.8156\n",
      "Epoch 126/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8273\n",
      "Epoch 127/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2933 - accuracy: 0.8468\n",
      "Epoch 128/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2999 - accuracy: 0.8494\n",
      "Epoch 129/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2926 - accuracy: 0.8286\n",
      "Epoch 130/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3167 - accuracy: 0.8312\n",
      "Epoch 131/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8325\n",
      "Epoch 132/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2900 - accuracy: 0.8455\n",
      "Epoch 133/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3056 - accuracy: 0.8558\n",
      "Epoch 134/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3014 - accuracy: 0.8532\n",
      "Epoch 135/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2960 - accuracy: 0.8455\n",
      "Epoch 136/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3054 - accuracy: 0.8416\n",
      "Epoch 137/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2607 - accuracy: 0.8714\n",
      "Epoch 138/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3060 - accuracy: 0.8338\n",
      "Epoch 139/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2861 - accuracy: 0.8545\n",
      "Epoch 140/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2739 - accuracy: 0.8468\n",
      "Epoch 141/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2891 - accuracy: 0.8571\n",
      "Epoch 142/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.8571\n",
      "Epoch 143/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2425 - accuracy: 0.8662\n",
      "Epoch 144/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2739 - accuracy: 0.8584\n",
      "Epoch 145/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2771 - accuracy: 0.8519\n",
      "Epoch 146/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2835 - accuracy: 0.8519\n",
      "Epoch 147/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2930 - accuracy: 0.8494\n",
      "Epoch 148/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2336 - accuracy: 0.8792\n",
      "Epoch 149/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.8481\n",
      "Epoch 150/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3059 - accuracy: 0.8442\n",
      "Epoch 151/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2615 - accuracy: 0.8623\n",
      "Epoch 152/1500\n",
      "25/25 [==============================] - 0s 999us/step - loss: 0.2775 - accuracy: 0.8571\n",
      "Epoch 153/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2917 - accuracy: 0.8416\n",
      "Epoch 154/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.8623\n",
      "Epoch 155/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2936 - accuracy: 0.8338\n",
      "Epoch 156/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2816 - accuracy: 0.8545\n",
      "Epoch 157/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.8481\n",
      "Epoch 158/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2704 - accuracy: 0.8727\n",
      "Epoch 159/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2796 - accuracy: 0.8545\n",
      "Epoch 160/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2883 - accuracy: 0.8675\n",
      "Epoch 161/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2610 - accuracy: 0.8688\n",
      "Epoch 162/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2383 - accuracy: 0.8662\n",
      "Epoch 163/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2538 - accuracy: 0.8714\n",
      "Epoch 164/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.8636\n",
      "Epoch 165/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2760 - accuracy: 0.8727\n",
      "Epoch 166/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2732 - accuracy: 0.8636\n",
      "Epoch 167/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.8571\n",
      "Epoch 168/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2385 - accuracy: 0.8818\n",
      "Epoch 169/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.8597\n",
      "Epoch 170/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9013\n",
      "Epoch 171/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2531 - accuracy: 0.8584\n",
      "Epoch 172/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2532 - accuracy: 0.8688\n",
      "Epoch 173/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2607 - accuracy: 0.8545\n",
      "Epoch 174/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2680 - accuracy: 0.8610\n",
      "Epoch 175/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.8675\n",
      "Epoch 176/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.8792\n",
      "Epoch 177/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2588 - accuracy: 0.8610\n",
      "Epoch 178/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.8597\n",
      "Epoch 179/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2815 - accuracy: 0.8468\n",
      "Epoch 180/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2846 - accuracy: 0.8519\n",
      "Epoch 181/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2626 - accuracy: 0.8753\n",
      "Epoch 182/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.8610\n",
      "Epoch 183/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.8779\n",
      "Epoch 184/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.8857\n",
      "Epoch 185/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2411 - accuracy: 0.8740\n",
      "Epoch 186/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.8727\n",
      "Epoch 187/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.8792\n",
      "Epoch 188/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2538 - accuracy: 0.8662\n",
      "Epoch 189/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.8792\n",
      "Epoch 190/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.8792\n",
      "Epoch 191/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2385 - accuracy: 0.8818\n",
      "Epoch 192/1500\n",
      "25/25 [==============================] - 0s 998us/step - loss: 0.2448 - accuracy: 0.8792\n",
      "Epoch 193/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.8727\n",
      "Epoch 194/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.8805\n",
      "Epoch 195/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.8857\n",
      "Epoch 196/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.8844\n",
      "Epoch 197/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2228 - accuracy: 0.8857\n",
      "Epoch 198/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2113 - accuracy: 0.8896\n",
      "Epoch 199/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2555 - accuracy: 0.8662\n",
      "Epoch 200/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.8792\n",
      "Epoch 201/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.8818\n",
      "Epoch 202/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.8662\n",
      "Epoch 203/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.8714\n",
      "Epoch 204/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.8844\n",
      "Epoch 205/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2609 - accuracy: 0.8623\n",
      "Epoch 206/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.8792\n",
      "Epoch 207/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.8753\n",
      "Epoch 208/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.8818\n",
      "Epoch 209/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.8766\n",
      "Epoch 210/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.8727\n",
      "Epoch 211/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.8597\n",
      "Epoch 212/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.8831\n",
      "Epoch 213/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2294 - accuracy: 0.8935\n",
      "Epoch 214/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2520 - accuracy: 0.8662\n",
      "Epoch 215/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.8896\n",
      "Epoch 216/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.8922\n",
      "Epoch 217/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.8714\n",
      "Epoch 218/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.8974\n",
      "Epoch 219/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.8779\n",
      "Epoch 220/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2086 - accuracy: 0.8883\n",
      "Epoch 221/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2162 - accuracy: 0.8922\n",
      "Epoch 222/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.9052\n",
      "Epoch 223/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2110 - accuracy: 0.9013\n",
      "Epoch 224/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.8727\n",
      "Epoch 225/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2133 - accuracy: 0.8844\n",
      "Epoch 226/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2101 - accuracy: 0.8909\n",
      "Epoch 227/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2271 - accuracy: 0.8831\n",
      "Epoch 228/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2119 - accuracy: 0.8870\n",
      "Epoch 229/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.8909\n",
      "Epoch 230/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.8818\n",
      "Epoch 231/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2090 - accuracy: 0.8857\n",
      "Epoch 232/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2154 - accuracy: 0.8870\n",
      "Epoch 233/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.8870\n",
      "Epoch 234/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2336 - accuracy: 0.8792\n",
      "Epoch 235/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.8727\n",
      "Epoch 236/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.8857\n",
      "Epoch 237/1500\n",
      "25/25 [==============================] - 0s 995us/step - loss: 0.2096 - accuracy: 0.8909\n",
      "Epoch 238/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.8909\n",
      "Epoch 239/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.8857\n",
      "Epoch 240/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.8870\n",
      "Epoch 241/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.8922\n",
      "Epoch 242/1500\n",
      "25/25 [==============================] - 0s 988us/step - loss: 0.2202 - accuracy: 0.8909\n",
      "Epoch 243/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.9065\n",
      "Epoch 244/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9156\n",
      "Epoch 245/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2141 - accuracy: 0.8909\n",
      "Epoch 246/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.8961\n",
      "Epoch 247/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.9039\n",
      "Epoch 248/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9091\n",
      "Epoch 249/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.9000\n",
      "Epoch 250/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9013\n",
      "Epoch 251/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.8961\n",
      "Epoch 252/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9091\n",
      "Epoch 253/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.8857\n",
      "Epoch 254/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.8922\n",
      "Epoch 255/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.8948\n",
      "Epoch 256/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.9000\n",
      "Epoch 257/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.8935\n",
      "Epoch 258/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.8922\n",
      "Epoch 259/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.8987\n",
      "Epoch 260/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.9052\n",
      "Epoch 261/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.8896\n",
      "Epoch 262/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.9026\n",
      "Epoch 263/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1907 - accuracy: 0.9013\n",
      "Epoch 264/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1737 - accuracy: 0.9104\n",
      "Epoch 265/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1953 - accuracy: 0.9117\n",
      "Epoch 266/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.9078\n",
      "Epoch 267/1500\n",
      "25/25 [==============================] - 0s 989us/step - loss: 0.1897 - accuracy: 0.9039\n",
      "Epoch 268/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.9000\n",
      "Epoch 269/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.9000\n",
      "Epoch 270/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.9013\n",
      "Epoch 271/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.9000\n",
      "Epoch 272/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.9000\n",
      "Epoch 273/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2097 - accuracy: 0.8987\n",
      "Epoch 274/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.9078\n",
      "Epoch 275/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.9013\n",
      "Epoch 276/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9091\n",
      "Epoch 277/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.8948\n",
      "Epoch 278/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9026\n",
      "Epoch 279/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.9091\n",
      "Epoch 280/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2006 - accuracy: 0.9052\n",
      "Epoch 281/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.9078\n",
      "Epoch 282/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1971 - accuracy: 0.9039\n",
      "Epoch 283/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.9065\n",
      "Epoch 284/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.9039\n",
      "Epoch 285/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9013\n",
      "Epoch 286/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9026\n",
      "Epoch 287/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.9052\n",
      "Epoch 288/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.9013\n",
      "Epoch 289/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.9026\n",
      "Epoch 290/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.8961\n",
      "Epoch 291/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.9130\n",
      "Epoch 292/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9156\n",
      "Epoch 293/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9156\n",
      "Epoch 294/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.8935\n",
      "Epoch 295/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.9117\n",
      "Epoch 296/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1903 - accuracy: 0.9013\n",
      "Epoch 297/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9156\n",
      "Epoch 298/1500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.1935 - accuracy: 0.8974\n",
      "Epoch 299/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.9052\n",
      "Epoch 300/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.9195\n",
      "Epoch 301/1500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9260\n",
      "Epoch 302/1500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9130\n",
      "Epoch 303/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.9143\n",
      "Epoch 304/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.9013\n",
      "Epoch 305/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.9078\n",
      "Epoch 306/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.9013\n",
      "Epoch 307/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.8935\n",
      "Epoch 308/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9039\n",
      "Epoch 309/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.9026\n",
      "Epoch 310/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.9182\n",
      "Epoch 311/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.9052\n",
      "Epoch 312/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.8935\n",
      "Epoch 313/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.9052\n",
      "Epoch 314/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.8987\n",
      "Epoch 315/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.9117\n",
      "Epoch 316/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.8948\n",
      "Epoch 317/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9130\n",
      "Epoch 318/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1903 - accuracy: 0.9039\n",
      "Epoch 319/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1690 - accuracy: 0.9117\n",
      "Epoch 320/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9143\n",
      "Epoch 321/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1726 - accuracy: 0.9169\n",
      "Epoch 322/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9143\n",
      "Epoch 323/1500\n",
      "25/25 [==============================] - 0s 984us/step - loss: 0.1922 - accuracy: 0.8948\n",
      "Epoch 324/1500\n",
      "25/25 [==============================] - 0s 961us/step - loss: 0.1816 - accuracy: 0.9156\n",
      "Epoch 325/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9247\n",
      "Epoch 326/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1731 - accuracy: 0.9234\n",
      "Epoch 327/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.9091\n",
      "Epoch 328/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.9052\n",
      "Epoch 329/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.9104\n",
      "Epoch 330/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.9039\n",
      "Epoch 331/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.9039\n",
      "Epoch 332/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1707 - accuracy: 0.9208\n",
      "Epoch 333/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9078\n",
      "Epoch 334/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9156\n",
      "Epoch 335/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.9208\n",
      "Epoch 336/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.9156\n",
      "Epoch 337/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9208\n",
      "Epoch 338/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1705 - accuracy: 0.9182\n",
      "Epoch 339/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1738 - accuracy: 0.9104\n",
      "Epoch 340/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.9117\n",
      "Epoch 341/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9208\n",
      "Epoch 342/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9221\n",
      "Epoch 343/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9143\n",
      "Epoch 344/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.9169\n",
      "Epoch 345/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1660 - accuracy: 0.9169\n",
      "Epoch 346/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.9078\n",
      "Epoch 347/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9260\n",
      "Epoch 348/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9169\n",
      "Epoch 349/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1664 - accuracy: 0.9208\n",
      "Epoch 350/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1739 - accuracy: 0.9078\n",
      "Epoch 351/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.9117\n",
      "Epoch 352/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.9182\n",
      "Epoch 353/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9234\n",
      "Epoch 354/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.9156\n",
      "Epoch 355/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2154 - accuracy: 0.8961\n",
      "Epoch 356/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1736 - accuracy: 0.9104\n",
      "Epoch 357/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.9065\n",
      "Epoch 358/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.9195\n",
      "Epoch 359/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1695 - accuracy: 0.9117\n",
      "Epoch 360/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.9091\n",
      "Epoch 361/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1699 - accuracy: 0.9026\n",
      "Epoch 362/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1721 - accuracy: 0.9143\n",
      "Epoch 363/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9286\n",
      "Epoch 364/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9182\n",
      "Epoch 365/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9234\n",
      "Epoch 366/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9195\n",
      "Epoch 367/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9312\n",
      "Epoch 368/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.9169\n",
      "Epoch 369/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9143\n",
      "Epoch 370/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9130\n",
      "Epoch 371/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9247\n",
      "Epoch 372/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1737 - accuracy: 0.9091\n",
      "Epoch 373/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.9156\n",
      "Epoch 374/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9299\n",
      "Epoch 375/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9143\n",
      "Epoch 376/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9312\n",
      "Epoch 377/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9078\n",
      "Epoch 378/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9286\n",
      "Epoch 379/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.9247\n",
      "Epoch 380/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1675 - accuracy: 0.9169\n",
      "Epoch 381/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9143\n",
      "Epoch 382/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9351\n",
      "Epoch 383/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.9117\n",
      "Epoch 384/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9273\n",
      "Epoch 385/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9312\n",
      "Epoch 386/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9273\n",
      "Epoch 387/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1496 - accuracy: 0.9273\n",
      "Epoch 388/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9247\n",
      "Epoch 389/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9325\n",
      "Epoch 390/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.9260\n",
      "Epoch 391/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9260\n",
      "Epoch 392/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9260\n",
      "Epoch 393/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9273\n",
      "Epoch 394/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9247\n",
      "Epoch 395/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9143\n",
      "Epoch 396/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9221\n",
      "Epoch 397/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9117\n",
      "Epoch 398/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9390\n",
      "Epoch 399/1500\n",
      "25/25 [==============================] - 0s 999us/step - loss: 0.1529 - accuracy: 0.9247\n",
      "Epoch 400/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9104\n",
      "Epoch 401/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1705 - accuracy: 0.9091\n",
      "Epoch 402/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9286\n",
      "Epoch 403/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9273\n",
      "Epoch 404/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.9117\n",
      "Epoch 405/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9247\n",
      "Epoch 406/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.9208\n",
      "Epoch 407/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.9234\n",
      "Epoch 408/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9182\n",
      "Epoch 409/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9143\n",
      "Epoch 410/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9208\n",
      "Epoch 411/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9273\n",
      "Epoch 412/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9221\n",
      "Epoch 413/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9299\n",
      "Epoch 414/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9312\n",
      "Epoch 415/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.9234\n",
      "Epoch 416/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.9247\n",
      "Epoch 417/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9247\n",
      "Epoch 418/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9312\n",
      "Epoch 419/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9247\n",
      "Epoch 420/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.9169\n",
      "Epoch 421/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9208\n",
      "Epoch 422/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9338\n",
      "Epoch 423/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9182\n",
      "Epoch 424/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.9182\n",
      "Epoch 425/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.9208\n",
      "Epoch 426/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 0.9377\n",
      "Epoch 427/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.9312\n",
      "Epoch 428/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9221\n",
      "Epoch 429/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.9286\n",
      "Epoch 430/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9286\n",
      "Epoch 431/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9403\n",
      "Epoch 432/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9221\n",
      "Epoch 433/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9221\n",
      "Epoch 434/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9286\n",
      "Epoch 435/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9325\n",
      "Epoch 436/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.9338\n",
      "Epoch 437/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9273\n",
      "Epoch 438/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9338\n",
      "Epoch 439/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9351\n",
      "Epoch 440/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.9325\n",
      "Epoch 441/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9195\n",
      "Epoch 442/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1423 - accuracy: 0.9351\n",
      "Epoch 443/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9221\n",
      "Epoch 444/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1675 - accuracy: 0.9234\n",
      "Epoch 445/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9247\n",
      "Epoch 446/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1707 - accuracy: 0.9247\n",
      "Epoch 447/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9299\n",
      "Epoch 448/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9351\n",
      "Epoch 449/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9312\n",
      "Epoch 450/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9156\n",
      "Epoch 451/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9390\n",
      "Epoch 452/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9338\n",
      "Epoch 453/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.9338\n",
      "Epoch 454/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9416\n",
      "Epoch 455/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9325\n",
      "Epoch 456/1500\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.0976 - accuracy: 0.9688Restoring model weights from the end of the best epoch: 426.\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.9273\n",
      "Epoch 456: early stopping\n",
      "6/6 [==============================] - 0s 871us/step - loss: 0.9114 - accuracy: 0.7006\n",
      "6/6 [==============================] - 0s 622us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.75 (21/28)\n",
      "Before appending - Cat IDs: 679, Predictions: 679, Actuals: 679, Gender: 679\n",
      "After appending - Cat IDs: 846, Predictions: 846, Actuals: 846, Gender: 846\n",
      "Final Test Results - Loss: 0.911436915397644, Accuracy: 0.7005987763404846, Precision: 0.7433782267115601, Recall: 0.774703778224905, F1 Score: 0.7399255233494365\n",
      "Confusion Matrix:\n",
      " [[71  3 10]\n",
      " [ 0 12  0]\n",
      " [37  0 34]]\n",
      "\n",
      "Final Average F1-Score across all UNSEEN TEST sets: 0.6774828080875268\n",
      "\n",
      "Final Average Loss across all UNSEEN TEST sets: 0.8544330894947052\n",
      "\n",
      "Final Average Accuracy across all UNSEEN TEST sets: 0.6983116418123245\n",
      "\n",
      "Final Average Precision across all UNSEEN TEST sets: 0.676532484354322\n",
      "\n",
      "Final Average Recall across all UNSEEN TEST sets: 0.739102367844086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "all_cat_ids = []\n",
    "all_predicted_age_groups = []\n",
    "all_actual_age_groups = []\n",
    "all_gender = []\n",
    "\n",
    "# Define the StratifiedGroupKFold splitter for 4 fold CV with random shuffling\n",
    "outer_cv = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=int(random_seeds[1]))\n",
    "\n",
    "# unseen test set metrics\n",
    "unseen_losses, unseen_accuracies, unseen_precisions, unseen_recalls, unseen_f1 = [], [], [], [], []\n",
    "\n",
    "outer_fold = 0\n",
    "\n",
    "# Use the splitter to generate indices for training and testing sets\n",
    "# Note: GroupShuffleSplit.split returns indices, so we use it to index the arrays\n",
    "for train_val_idx, test_idx in outer_cv.split(X, y, groups):\n",
    "    outer_fold += 1\n",
    "    logger(f\"outer_fold {outer_fold}\", file=log_file_path)\n",
    "\n",
    "    # Convert indices back to DataFrame for easy manipulation\n",
    "    df_train_val = dataframe.iloc[train_val_idx]\n",
    "    df_test = dataframe.iloc[test_idx]\n",
    "\n",
    "    ##############################\n",
    "    # ASSESSING SPLITS BY CAT_ID #\n",
    "    ##############################\n",
    "    \n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test['cat_id'].value_counts()  \n",
    "    \n",
    "    # Log or print the distribution\n",
    "    logger(f\"Train Set Group Distribution:\\n{training_validation_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Group Distribution:\\n{testing_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test['gender'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Training Set Gender Distribution BEFORE SWAP:\\n{training_gender_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Gender Distribution BEFORE SWAP:\\n{testing_gender_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Group by 'age_group' and then list unique 'cat_id' within each age group\n",
    "    unique_cat_ids_per_age_group_train_val = df_train_val.groupby('age_group')['cat_id'].unique()\n",
    "    unique_cat_ids_per_age_group_test = df_test.groupby('age_group')['cat_id'].unique()\n",
    "    \n",
    "    # Log results\n",
    "    logger(f\"Unique Cat IDs per Age Group in Training/Validation Set:\\n{unique_cat_ids_per_age_group_train_val}\", file=log_file_path)\n",
    "    logger(f\"Unique Cat IDs per Age Group in Testing Set:\\n{unique_cat_ids_per_age_group_test}\", file=log_file_path)\n",
    "\n",
    "    # Calculate the count of unique identifiers per age group for training and testing set\n",
    "    counts_train_val = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_train_val.items()}\n",
    "    counts_test = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_test.items()}\n",
    "\n",
    "    # Log the counts of unique identifiers per age group\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Training/Validation Set:\\n{counts_train_val}\", file=log_file_path)\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Testing Set:\\n{counts_test}\", file=log_file_path)\n",
    "\n",
    "    #######################################################\n",
    "    # CONTINUE WITH ENSURING VALID AND APPROPRIATE SPLITS #\n",
    "    #######################################################\n",
    "    \n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    groups_train_val, groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # logging identifier splits \n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "\n",
    "    # check group splits\n",
    "    check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Specify the cat_ids that must be in the training/validation set\n",
    "    specific_cat_ids = ['000A', '046A']\n",
    "    \n",
    "    # Perform the swapping operation\n",
    "    train_val_idx, test_idx = swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids)\n",
    "    \n",
    "    # Re-assign the sets based on the updated indices\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    new_groups_train_val, new_groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # Find differences for training and test sets\n",
    "    moved_to_train_val, removed_from_train_val = find_group_differences(groups_train_val, new_groups_train_val)\n",
    "    moved_to_test, removed_from_test = find_group_differences(groups_test, new_groups_test)\n",
    "    \n",
    "    # Display the results\n",
    "    logger(f\"Moved to Training/Validation Set:\\n{moved_to_train_val}\", file=log_file_path)\n",
    "    logger(f\"Removed from Training/Validation Set:\\n{removed_from_train_val}\", file=log_file_path)\n",
    "    logger(f\"Moved to Test Set:\\n{moved_to_test}\", file=log_file_path)\n",
    "    logger(f\"Removed from Test Set\\n{removed_from_test}\", file=log_file_path)\n",
    "\n",
    "    # Update X_train_val, X_test, y_train_val, y_test, groups_train_val, groups_test based on updated indices\n",
    "    X_train_val = X[train_val_idx]\n",
    "    y_train_val = y[train_val_idx]\n",
    "    groups_train_val = groups[train_val_idx]\n",
    "    \n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    groups_test = groups[test_idx]\n",
    "\n",
    "    # logging identifier splits again after potential swaps\n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"AFTER SWAP - Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"AFTER SWAP - Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "    \n",
    "    # Verify the lengths are consistent\n",
    "    logger(f\"Length of X_train_val:\\n{len(X_train_val)}\", file=log_file_path)\n",
    "    logger(f\"Length of y_train_val:\\n{len(y_train_val)}\", file=log_file_path)\n",
    "    logger(f\"Length of groups_train_val:\\n{len(groups_train_val)}\", file=log_file_path)\n",
    "\n",
    "    # Check group splits once more\n",
    "    check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Convert the modified indices back to a DataFrame representing the updated df_train_val\n",
    "    df_train_val_updated = dataframe.iloc[train_val_idx].copy()\n",
    "    df_test_updated = dataframe.iloc[test_idx].copy()\n",
    "\n",
    "    ############################\n",
    "    # LOGGING AGE GROUP SPLITS #\n",
    "    ############################\n",
    "\n",
    "    # Get the distribution of age groups of age groups before the update\n",
    "    training_validation_age_group_distribution = df_train_val['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test['age_group'].value_counts()\n",
    "    \n",
    "    # Logthe distribution\n",
    "    logger(f\"Train Age Group Distribution BEFORE SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution BEFORE SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Get the distribution of age groups after the update\n",
    "    training_validation_age_group_distribution = df_train_val_updated['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test_updated['age_group'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Train Age Group Distribution AFTER SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution AFTER SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "    \n",
    "    ########################################################\n",
    "    # TRACKING FINAL CAT_IDs & GENDER AFTER REDISTRIBUTION #\n",
    "    ########################################################\n",
    "\n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val_updated['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test_updated['cat_id'].value_counts()  \n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val_updated['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test_updated['gender'].value_counts()\n",
    "    \n",
    "    logger(f\"\\n Starting training on unseen test set\\n\", file=log_file_path)\n",
    "\n",
    "    ###################\n",
    "    # PREPARING MODEL #\n",
    "    ###################\n",
    "\n",
    "    # Calculate the distribution of age groups in y_train_val\n",
    "    age_group_distribution = Counter(y_train_val)\n",
    "    print(\"Age group distribution:\", age_group_distribution)\n",
    "\n",
    "    # EarlyStopping callback: monitor 'loss' instead of 'val_loss' for the test set\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='loss',  \n",
    "        min_delta=0.001, \n",
    "        patience=30,  \n",
    "        verbose=1,  \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "\n",
    "    # One final shuffle to ensure randomness\n",
    "    outer_shuffle_idx = np.random.permutation(len(X_train_val))\n",
    "    X_train_val = X_train_val[outer_shuffle_idx]\n",
    "    y_train_val = y_train_val[outer_shuffle_idx]\n",
    "    \n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train_val),\n",
    "        y=y_train_val\n",
    "    )\n",
    "    weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "    # Scale the features\n",
    "    scaler_full = StandardScaler().fit(X_train_val)\n",
    "    X_train_full_scaled = scaler_full.transform(X_train_val)\n",
    "    X_test_scaled = scaler_full.transform(X_test)\n",
    "    \n",
    "    # Encode the labels\n",
    "    y_train_full_encoded = to_categorical(y_train_val)\n",
    "    y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "    #######################\n",
    "    # BUILD & TRAIN MODEL #\n",
    "    #######################\n",
    "\n",
    "    optimizers = {\n",
    "        'Adamax': Adamax(learning_rate=0.00038188800331973483)\n",
    "    }\n",
    "    \n",
    "    # Full model definition with dynamic number of layers\n",
    "    model_full = Sequential()\n",
    "    model_full.add(Dense(480, activation='relu', input_shape=(X_train_full_scaled.shape[1],)))  # units_l0 and activation from parameters\n",
    "    model_full.add(BatchNormalization())\n",
    "    model_full.add(Dropout(0.27188281261238406))  \n",
    "    model_full.add(Dense(3, activation='softmax'))  \n",
    "    \n",
    "    optimizer = optimizers['Adamax']  # optimizer_key from parameters\n",
    "    \n",
    "    # Compile the model\n",
    "    model_full.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model on the full training set\n",
    "    history_full = model_full.fit(X_train_full_scaled, y_train_full_encoded, epochs=1500, batch_size=32,\n",
    "                                  verbose=1, callbacks=[early_stopping], class_weight=weight_dict)\n",
    "    \n",
    "    # Evaluate the model on the held-out test set\n",
    "    test_loss, test_accuracy = model_full.evaluate(X_test_scaled, y_test_encoded)\n",
    "\n",
    "    y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    y_test_pred = np.argmax(y_test_pred_prob, axis=1)  \n",
    "    y_test_true = np.argmax(y_test_encoded, axis=1)    \n",
    "\n",
    "    ################################\n",
    "    # LOG MAJORITY VOTE PER CAT_ID #\n",
    "    ################################\n",
    "\n",
    "    # Convert numeric predictions back to age group labels\n",
    "    predicted_age_groups = label_encoder.inverse_transform(y_test_pred)\n",
    "    actual_labels = label_encoder.inverse_transform(y_test_true)\n",
    "    \n",
    "    # Map predictions and actual labels back to cat_ids\n",
    "    test_results = pd.DataFrame({\n",
    "        'cat_id': df_test_updated['cat_id'],\n",
    "        'predicted_age_group': predicted_age_groups,\n",
    "        'actual_age_group': actual_labels\n",
    "    })\n",
    "    \n",
    "    # Group by cat_id and aggregate predicted age groups\n",
    "    majority_votes = test_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "    actual_groups = test_results.groupby('cat_id')['actual_age_group'].first()\n",
    "    \n",
    "    # Calculate the accuracy of majority voting\n",
    "    correct_predictions = (majority_votes == actual_groups).sum()\n",
    "    total_cats = len(actual_groups)\n",
    "    majority_vote_accuracy = correct_predictions / total_cats\n",
    "    \n",
    "    # Log the accuracy of the majority voting\n",
    "    logger(f\"Majority Vote Accuracy for cat_id for this fold: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)\n",
    "\n",
    "    ####################################################\n",
    "    # COLLECT PREDICTIONS FOR GENDER & CAT_ID ANALYSIS #\n",
    "    ####################################################\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'Before appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Extend lists with current fold results\n",
    "    all_cat_ids.extend(df_test_updated['cat_id'].tolist())\n",
    "    all_predicted_age_groups.extend(predicted_age_groups)\n",
    "    all_actual_age_groups.extend(actual_labels)\n",
    "    all_gender.extend(df_test_updated['gender'].tolist())\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'After appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    test_precision = precision_score(y_test_true, y_test_pred, average='macro')  # Use 'macro' for imbalanced datasets\n",
    "    test_recall = recall_score(y_test_true, y_test_pred, average='macro')\n",
    "    test_f1 = f1_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "    # prepare averages of outer metrics\n",
    "    unseen_f1.append(test_f1)\n",
    "    unseen_losses.append(test_loss)\n",
    "    unseen_accuracies.append(test_accuracy)\n",
    "    unseen_precisions.append(test_precision)\n",
    "    unseen_recalls.append(test_recall)\n",
    "\n",
    "    # Print final test results\n",
    "    logger(f\"Final Test Results - Loss: {test_loss}, Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}\", file=log_file_path)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    logger(f\"Confusion Matrix:\\n {cm}\", file=log_file_path)\n",
    "\n",
    "# Calculate the overall average metrics\n",
    "unseen_set_avg_f1 = np.mean(unseen_f1)\n",
    "unseen_set_avg_loss = np.mean(unseen_losses)\n",
    "unseen_set_avg_acc = np.mean(unseen_accuracies)\n",
    "unseen_set_avg_precision = np.mean(unseen_precisions)\n",
    "unseen_set_avg_recall = np.mean(unseen_recalls)\n",
    "\n",
    "logger(f\"\\nFinal Average F1-Score across all UNSEEN TEST sets: {unseen_set_avg_f1}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Loss across all UNSEEN TEST sets: {unseen_set_avg_loss}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Accuracy across all UNSEEN TEST sets: {unseen_set_avg_acc}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Precision across all UNSEEN TEST sets: {unseen_set_avg_precision}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Recall across all UNSEEN TEST sets: {unseen_set_avg_recall}\\n\", file=log_file_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2845ad-17c1-494a-8bd0-971aefca9f01",
   "metadata": {},
   "source": [
    "## Majority Voting on Total Entries per cat_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3910db95-6772-4098-bef1-fb5857901e5c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking - Cat IDs: 846, Predictions: 846, Actuals: 846, Gender: 846\n"
     ]
    }
   ],
   "source": [
    "# Debugging print statements\n",
    "print(f'Checking - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d543c7c2-c11b-4511-ba5a-c52969a61a62",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create results df\n",
    "full_results = pd.DataFrame({\n",
    "    'cat_id': all_cat_ids,\n",
    "    'predicted_age_group': all_predicted_age_groups,\n",
    "    'actual_age_group': all_actual_age_groups,\n",
    "    'all_gender': all_gender\n",
    "})\n",
    "\n",
    "# create a correct majority prediction column\n",
    "full_results['correct'] = full_results['predicted_age_group'] == full_results['actual_age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6b6f2173-89a8-40ba-afa6-410005c2dcb1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Majority Vote Accuracy for cat_id: 0.72 (79/110)\n"
     ]
    }
   ],
   "source": [
    "# Group by cat_id and aggregate predicted age groups\n",
    "majority_votes = full_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first()\n",
    "\n",
    "# Calculate the accuracy of majority voting\n",
    "correct_predictions = (majority_votes == actual_groups).sum()\n",
    "total_cats = len(actual_groups)\n",
    "majority_vote_accuracy = correct_predictions / total_cats\n",
    "\n",
    "logger(f\"Overall Majority Vote Accuracy for cat_id: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aa8d9ba5-9d96-4aee-b3e2-ba87553d1899",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Detailed df with predictions, actual labels, and comparison including majority vote\n",
    "detailed_results = full_results.groupby('cat_id').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Predictions': list(x['predicted_age_group']),\n",
    "        'Majority Vote': x['predicted_age_group'].mode()[0],\n",
    "        'Actual Age Group': x['actual_age_group'].iloc[0],\n",
    "        'Correct Majority Vote': x['predicted_age_group'].mode()[0] == x['actual_age_group'].iloc[0]\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Convert to DataFrame for better formatting and display\n",
    "detailed_results = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0b4ff1f7-d22d-4409-98d4-49e9a82bcb58",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Majority Vote</th>\n",
       "      <th>Actual Age Group</th>\n",
       "      <th>Correct Majority Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000B</td>\n",
       "      <td>[adult, senior, adult, senior, senior, adult, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>039A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>070A</td>\n",
       "      <td>[adult, adult, senior, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>069A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>068A</td>\n",
       "      <td>[adult, adult, adult, senior, adult, adult, se...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>067A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>066A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>064A</td>\n",
       "      <td>[kitten, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>062A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>056A</td>\n",
       "      <td>[senior, senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>053A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>052A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>051B</td>\n",
       "      <td>[senior, adult, senior, adult, senior, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>051A</td>\n",
       "      <td>[senior, senior, adult, adult, senior, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001A</td>\n",
       "      <td>[adult, adult, senior, adult, adult, senior, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>049A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>048A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>045A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>044A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>043A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>041A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>071A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>072A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>073A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>100A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>116A</td>\n",
       "      <td>[senior, senior, senior, senior, adult, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>115A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>113A</td>\n",
       "      <td>[senior, senior, adult]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>111A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>106A</td>\n",
       "      <td>[adult, senior, senior, senior, senior, adult,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>105A</td>\n",
       "      <td>[adult, adult, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>102A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>101A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>099A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>074A</td>\n",
       "      <td>[adult, senior, adult, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>096A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>094A</td>\n",
       "      <td>[senior, senior, senior, senior, senior, senio...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>092A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>091A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>090A</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>088A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>087A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>075A</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>040A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>050A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>021A</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>007A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>009A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>010A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>011A</td>\n",
       "      <td>[senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>025A</td>\n",
       "      <td>[senior, adult, adult, senior, adult, adult, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>024A</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>023B</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>023A</td>\n",
       "      <td>[adult, kitten, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>022A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, kit...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>037A</td>\n",
       "      <td>[adult, senior, adult, adult, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>020A</td>\n",
       "      <td>[adult, adult, senior, adult, senior, adult, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>019B</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>019A</td>\n",
       "      <td>[adult, adult, adult, adult, kitten, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>018A</td>\n",
       "      <td>[adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>016A</td>\n",
       "      <td>[senior, adult, adult, senior, senior, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>015A</td>\n",
       "      <td>[adult, senior, senior, adult, adult, adult, s...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>014B</td>\n",
       "      <td>[kitten, kitten, kitten, adult, kitten, kitten...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>014A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>012A</td>\n",
       "      <td>[senior, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>008A</td>\n",
       "      <td>[adult, adult, adult, kitten, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>013B</td>\n",
       "      <td>[adult, adult, senior, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>004A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>026A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002B</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>006A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>035A</td>\n",
       "      <td>[senior, adult, senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>034A</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>027A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>028A</td>\n",
       "      <td>[adult, senior, adult, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>031A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>032A</td>\n",
       "      <td>[kitten, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>095A</td>\n",
       "      <td>[senior, adult, adult, senior, senior, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>103A</td>\n",
       "      <td>[adult, adult, adult, adult, senior, senior, s...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>104A</td>\n",
       "      <td>[adult, senior, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>109A</td>\n",
       "      <td>[adult, adult, kitten, kitten, kitten, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>108A</td>\n",
       "      <td>[adult, adult, adult, senior, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>005A</td>\n",
       "      <td>[senior, senior, senior, senior, senior, senio...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>097A</td>\n",
       "      <td>[adult, senior, senior, adult, adult, senior, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>097B</td>\n",
       "      <td>[senior, adult, kitten, senior, adult, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>110A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>038A</td>\n",
       "      <td>[kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>093A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>055A</td>\n",
       "      <td>[senior, adult, senior, adult, senior, adult, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>036A</td>\n",
       "      <td>[adult, senior, senior, senior, adult, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>042A</td>\n",
       "      <td>[kitten, adult, kitten, adult, adult, adult, k...</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>033A</td>\n",
       "      <td>[kitten, adult, kitten, kitten, kitten, adult,...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>047A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, kitten, ki...</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>029A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, senior, se...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>026C</td>\n",
       "      <td>[kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>026B</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>054A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>057A</td>\n",
       "      <td>[senior, adult, adult, senior, senior, senior,...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>076A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>058A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>059A</td>\n",
       "      <td>[adult, adult, senior, senior, senior, senior,...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>060A</td>\n",
       "      <td>[kitten, kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>061A</td>\n",
       "      <td>[senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>025C</td>\n",
       "      <td>[senior, senior, senior, adult, adult]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>063A</td>\n",
       "      <td>[senior, senior, senior, kitten, senior, senio...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>025B</td>\n",
       "      <td>[senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>065A</td>\n",
       "      <td>[senior, adult, adult, adult, senior, senior, ...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>117A</td>\n",
       "      <td>[adult, senior, senior, adult, senior, adult, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat_id                                        Predictions Majority Vote Actual Age Group  Correct Majority Vote\n",
       "0     000B  [adult, senior, adult, senior, senior, adult, ...         adult            adult                   True\n",
       "45    039A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "76    070A              [adult, adult, senior, adult, senior]         adult            adult                   True\n",
       "75    069A                                     [adult, adult]         adult            adult                   True\n",
       "74    068A  [adult, adult, adult, senior, adult, adult, se...         adult            adult                   True\n",
       "73    067A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "72    066A                                            [adult]         adult            adult                   True\n",
       "70    064A                             [kitten, adult, adult]         adult            adult                   True\n",
       "68    062A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "62    056A                           [senior, senior, senior]        senior           senior                   True\n",
       "59    053A         [adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "58    052A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "57    051B  [senior, adult, senior, adult, senior, senior,...        senior           senior                   True\n",
       "56    051A  [senior, senior, adult, adult, senior, senior,...        senior           senior                   True\n",
       "1     001A  [adult, adult, senior, adult, adult, senior, a...         adult            adult                   True\n",
       "54    049A                                           [kitten]        kitten           kitten                   True\n",
       "53    048A                                           [kitten]        kitten           kitten                   True\n",
       "51    045A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "50    044A           [kitten, kitten, kitten, kitten, kitten]        kitten           kitten                   True\n",
       "49    043A                                           [kitten]        kitten           kitten                   True\n",
       "47    041A                                           [kitten]        kitten           kitten                   True\n",
       "77    071A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "78    072A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "79    073A                                            [adult]         adult            adult                   True\n",
       "95    100A                                            [adult]         adult            adult                   True\n",
       "108   116A  [senior, senior, senior, senior, adult, senior...        senior           senior                   True\n",
       "107   115A                                           [kitten]        kitten           kitten                   True\n",
       "106   113A                            [senior, senior, adult]        senior           senior                   True\n",
       "105   111A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "101   106A  [adult, senior, senior, senior, senior, adult,...        senior           senior                   True\n",
       "100   105A                      [adult, adult, adult, senior]         adult            adult                   True\n",
       "97    102A                                     [adult, adult]         adult            adult                   True\n",
       "96    101A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "94    099A  [adult, adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "80    074A  [adult, senior, adult, adult, adult, adult, ad...         adult            adult                   True\n",
       "91    096A                                            [adult]         adult            adult                   True\n",
       "89    094A  [senior, senior, senior, senior, senior, senio...        senior           senior                   True\n",
       "87    092A                                            [adult]         adult            adult                   True\n",
       "86    091A                                            [adult]         adult            adult                   True\n",
       "85    090A                                           [senior]        senior           senior                   True\n",
       "84    088A                                            [adult]         adult            adult                   True\n",
       "83    087A                                     [adult, adult]         adult            adult                   True\n",
       "81    075A                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "46    040A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "55    050A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "23    021A                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "8     007A         [adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "10    009A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "11    010A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "12    011A                                   [senior, senior]        senior           senior                   True\n",
       "28    025A  [senior, adult, adult, senior, adult, adult, a...         adult            adult                   True\n",
       "27    024A                                           [senior]        senior           senior                   True\n",
       "26    023B                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "25    023A        [adult, kitten, adult, adult, adult, adult]         adult            adult                   True\n",
       "24    022A  [adult, adult, adult, adult, adult, adult, kit...         adult            adult                   True\n",
       "43    037A       [adult, senior, adult, adult, adult, senior]         adult            adult                   True\n",
       "22    020A  [adult, adult, senior, adult, senior, adult, a...         adult            adult                   True\n",
       "21    019B                                            [adult]         adult            adult                   True\n",
       "20    019A  [adult, adult, adult, adult, kitten, adult, ad...         adult            adult                   True\n",
       "19    018A                                    [adult, senior]         adult            adult                   True\n",
       "18    016A  [senior, adult, adult, senior, senior, senior,...        senior           senior                   True\n",
       "17    015A  [adult, senior, senior, adult, adult, adult, s...         adult            adult                   True\n",
       "16    014B  [kitten, kitten, kitten, adult, kitten, kitten...        kitten           kitten                   True\n",
       "15    014A                              [adult, adult, adult]         adult            adult                   True\n",
       "13    012A                             [senior, adult, adult]         adult            adult                   True\n",
       "9     008A        [adult, adult, adult, kitten, adult, adult]         adult            adult                   True\n",
       "14    013B  [adult, adult, senior, adult, adult, adult, ad...         adult            adult                   True\n",
       "5     004A                                            [adult]         adult            adult                   True\n",
       "31    026A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "2     002A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "3     002B  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "7     006A                              [adult, adult, adult]         adult            adult                   True\n",
       "41    035A                     [senior, adult, senior, adult]         adult            adult                   True\n",
       "40    034A                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "34    027A  [adult, adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "35    028A  [adult, senior, adult, adult, adult, adult, ad...         adult            adult                   True\n",
       "4     003A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "37    031A  [adult, adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "38    032A                                    [kitten, adult]         adult            adult                   True\n",
       "90    095A  [senior, adult, adult, senior, senior, senior,...        senior            adult                  False\n",
       "98    103A  [adult, adult, adult, adult, senior, senior, s...        senior            adult                  False\n",
       "99    104A                     [adult, senior, adult, senior]         adult           senior                  False\n",
       "103   109A      [adult, adult, kitten, kitten, kitten, adult]         adult           kitten                  False\n",
       "102   108A        [adult, adult, adult, senior, adult, adult]         adult           senior                  False\n",
       "6     005A  [senior, senior, senior, senior, senior, senio...        senior            adult                  False\n",
       "92    097A  [adult, senior, senior, adult, adult, senior, ...         adult           senior                  False\n",
       "93    097B  [senior, adult, kitten, senior, adult, senior,...        senior            adult                  False\n",
       "104   110A                                            [adult]         adult           kitten                  False\n",
       "44    038A                                   [kitten, kitten]        kitten            adult                  False\n",
       "88    093A                                     [adult, adult]         adult           senior                  False\n",
       "61    055A  [senior, adult, senior, adult, senior, adult, ...         adult           senior                  False\n",
       "42    036A  [adult, senior, senior, senior, adult, senior,...        senior            adult                  False\n",
       "48    042A  [kitten, adult, kitten, adult, adult, adult, k...         adult           kitten                  False\n",
       "39    033A  [kitten, adult, kitten, kitten, kitten, adult,...        kitten            adult                  False\n",
       "52    047A  [adult, adult, adult, adult, adult, kitten, ki...         adult           kitten                  False\n",
       "36    029A  [adult, adult, adult, adult, adult, senior, se...        senior            adult                  False\n",
       "33    026C                                   [kitten, kitten]        kitten            adult                  False\n",
       "32    026B                                           [senior]        senior            adult                  False\n",
       "60    054A                                     [adult, adult]         adult           senior                  False\n",
       "63    057A  [senior, adult, adult, senior, senior, senior,...         adult           senior                  False\n",
       "82    076A                                           [kitten]        kitten            adult                  False\n",
       "64    058A                              [adult, adult, adult]         adult           senior                  False\n",
       "65    059A  [adult, adult, senior, senior, senior, senior,...         adult           senior                  False\n",
       "66    060A                           [kitten, kitten, kitten]        kitten            adult                  False\n",
       "67    061A                                    [senior, adult]         adult           senior                  False\n",
       "30    025C             [senior, senior, senior, adult, adult]        senior            adult                  False\n",
       "69    063A  [senior, senior, senior, kitten, senior, senio...        senior            adult                  False\n",
       "29    025B                                   [senior, senior]        senior            adult                  False\n",
       "71    065A  [senior, adult, adult, adult, senior, senior, ...        senior            adult                  False\n",
       "109   117A  [adult, senior, senior, adult, senior, adult, ...         adult           senior                  False"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "sorted_detailed_results = detailed_results.sort_values(by='Correct Majority Vote', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5ec47984-bc63-4f3f-a7a4-d3979dbd4c52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Majority Votes per Class:\n",
      "actual_age_group\n",
      "adult     57\n",
      "kitten    11\n",
      "senior    11\n",
      "Name: Majority_Correct, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create df for majority votes\n",
    "majority_df = majority_votes.reset_index()\n",
    "majority_df.columns = ['cat_id', 'Majority_Vote']\n",
    "\n",
    "# Get actual groups for each cat_id\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first().reset_index()\n",
    "\n",
    "# Merge majority votes with actual groups\n",
    "majority_with_actual = pd.merge(majority_df, actual_groups, on='cat_id')\n",
    "\n",
    "# Add a column to check if the majority vote was correct\n",
    "majority_with_actual['Majority_Correct'] = majority_with_actual['Majority_Vote'] == majority_with_actual['actual_age_group']\n",
    "\n",
    "# Count correct majority votes per class\n",
    "correct_majority_votes_per_class = majority_with_actual.groupby('actual_age_group')['Majority_Correct'].sum()\n",
    "\n",
    "print(\"Correct Majority Votes per Class:\")\n",
    "print(correct_majority_votes_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "952d49d2-180d-4f36-85b0-6e2b96610559",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics for Majority Votes:\n",
      "  actual_age_group  total_count  correct_count   accuracy\n",
      "0            adult           73             57  78.082192\n",
      "1           kitten           15             11  73.333333\n",
      "2           senior           22             11  50.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = majority_with_actual.groupby('actual_age_group').agg(\n",
    "    total_count=('Majority_Correct', 'size'),  # Total number of cases per class\n",
    "    correct_count=('Majority_Correct', 'sum')  # Sum of correct predictions per class\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log detailed stats\n",
    "print(\"Detailed Class Statistics for Majority Votes:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6a94de06-f9df-49f6-99e7-abc9024f3dc0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics for Majority Votes\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Accuracy of Majority Votes by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885dd133-e156-4b01-8e84-4d94546e0eca",
   "metadata": {},
   "source": [
    "## Detailed Class Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dd0127df-e0fb-4862-9ac4-2113bd346e78",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics:\n",
      "  actual_age_group  total_count  correct_count   accuracy\n",
      "0            adult          550            407  74.000000\n",
      "1           kitten          118             82  69.491525\n",
      "2           senior          178            102  57.303371\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = full_results.groupby('actual_age_group').agg(\n",
    "    total_count=('correct', 'size'),\n",
    "    correct_count=('correct', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log the detailed stats\n",
    "print(\"Detailed Class Statistics:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4a0df220-5e5c-4c46-8474-ac4ecf291071",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics (Overall)\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Overall Accuracy by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a7528-860f-45b0-8c00-d0ddf10a0d8f",
   "metadata": {},
   "source": [
    "## Gender Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2924eee7-fd8b-4cee-9e43-bb0352e4c43b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Gender:\n",
      "  all_gender  count  correct  accuracy\n",
      "0          F    214      161     75.23\n",
      "1          M    337      241     71.51\n",
      "2          X    295      189     64.07\n"
     ]
    }
   ],
   "source": [
    "# Group by gender and calculate the total count, correct predictions, and accuracy\n",
    "gender_stats = full_results.groupby('all_gender').agg(\n",
    "    count=('cat_id', 'size'),  # Total number of cases per gender\n",
    "    correct=('correct', 'sum')  # Sum of correct predictions per gender\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each gender\n",
    "gender_stats['accuracy'] = (gender_stats['correct'] / gender_stats['count'] * 100).round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy by Gender:\")\n",
    "print(gender_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b7b2139e-f100-44e6-aff4-807f96753499",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Accuracy by Gender\n",
    "styled_barplot(gender_stats, 'all_gender', 'accuracy', \n",
    "               'Accuracy by Gender', \n",
    "               'Gender', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df58f49-cac6-40b1-8422-e3d95576c453",
   "metadata": {},
   "source": [
    "# RANDOM SEED 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bf9d1b64-575e-47ca-bf37-e8916438d506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult     588\n",
      "senior    178\n",
      "kitten    171\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(int(random_seeds[2]))\n",
    "np.random.seed(int(random_seeds[2]))\n",
    "tf.random.set_seed(int(random_seeds[2]))\n",
    "\n",
    "# Load datasets\n",
    "dataframe = pd.read_csv('/Users/astrid/PycharmProjects/audioset-thesis-work/audioset/vggish/embeddings/8april_looped_embeddings.csv')\n",
    "dataframe.drop('mean_freq', axis=1, inplace=True)\n",
    "\n",
    "def assign_age_group(age, age_groups):\n",
    "    for group_name, age_range in age_groups.items():\n",
    "        if age_range[0] <= age < age_range[1]:\n",
    "            return group_name\n",
    "    return 'Unknown'  # For any age that doesn't fit the defined groups\n",
    "\n",
    "# Define age groups\n",
    "age_groups = {\n",
    "    'kitten': (0, 0.5),\n",
    "    'adult': (0.5, 12),\n",
    "    'senior': (12, 20)\n",
    "}\n",
    "\n",
    "# Create a new column for the age group\n",
    "dataframe['age_group'] = dataframe['target'].apply(assign_age_group, age_groups=age_groups)\n",
    "\n",
    "print(dataframe['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "91d5db1d-6c9f-4047-97b9-5a0eef4fbaaa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = dataframe.iloc[:, :-4].values  # all columns except the last four\n",
    "\n",
    "# Encode the 'age_group' column as integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y = label_encoder.fit_transform(dataframe['age_group'].values)\n",
    "\n",
    "# Use the encoded labels for splitting and one-hot encoding\n",
    "y = encoded_y  \n",
    "\n",
    "# Convert 'cat_id' column to numpy array to be used as groups array for GroupKFold\n",
    "groups = dataframe['cat_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e435598c-cabc-4129-8504-68aac9cc06bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e29b526-5098-4ce6-bc77-a93d1e6e1397",
   "metadata": {},
   "source": [
    "## Run Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "79a922e6-198c-4c43-a6f2-90dc580ae875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_fold 1\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "000A    39\n",
      "103A    33\n",
      "002B    32\n",
      "047A    28\n",
      "057A    27\n",
      "020A    23\n",
      "055A    20\n",
      "067A    19\n",
      "097A    16\n",
      "101A    15\n",
      "042A    14\n",
      "106A    14\n",
      "059A    14\n",
      "028A    13\n",
      "002A    13\n",
      "039A    12\n",
      "116A    12\n",
      "063A    11\n",
      "025A    11\n",
      "071A    10\n",
      "016A    10\n",
      "040A    10\n",
      "014B    10\n",
      "033A     9\n",
      "072A     9\n",
      "015A     9\n",
      "022A     9\n",
      "051B     9\n",
      "065A     9\n",
      "095A     8\n",
      "013B     8\n",
      "010A     8\n",
      "094A     8\n",
      "027A     7\n",
      "099A     7\n",
      "031A     7\n",
      "050A     7\n",
      "108A     6\n",
      "109A     6\n",
      "037A     6\n",
      "007A     6\n",
      "008A     6\n",
      "025C     5\n",
      "070A     5\n",
      "021A     5\n",
      "034A     5\n",
      "075A     5\n",
      "023B     5\n",
      "035A     4\n",
      "009A     4\n",
      "026A     4\n",
      "062A     4\n",
      "003A     4\n",
      "012A     3\n",
      "060A     3\n",
      "064A     3\n",
      "006A     3\n",
      "113A     3\n",
      "056A     3\n",
      "058A     3\n",
      "014A     3\n",
      "011A     2\n",
      "061A     2\n",
      "032A     2\n",
      "093A     2\n",
      "025B     2\n",
      "087A     2\n",
      "069A     2\n",
      "073A     1\n",
      "115A     1\n",
      "088A     1\n",
      "100A     1\n",
      "090A     1\n",
      "024A     1\n",
      "019B     1\n",
      "066A     1\n",
      "004A     1\n",
      "048A     1\n",
      "026C     1\n",
      "041A     1\n",
      "092A     1\n",
      "049A     1\n",
      "076A     1\n",
      "096A     1\n",
      "043A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "074A    25\n",
      "000B    19\n",
      "019A    17\n",
      "029A    17\n",
      "001A    14\n",
      "097B    14\n",
      "111A    13\n",
      "051A    12\n",
      "068A    11\n",
      "036A    11\n",
      "005A    10\n",
      "045A     9\n",
      "117A     7\n",
      "053A     6\n",
      "023A     6\n",
      "044A     5\n",
      "105A     4\n",
      "052A     4\n",
      "104A     4\n",
      "018A     2\n",
      "054A     2\n",
      "038A     2\n",
      "102A     2\n",
      "091A     1\n",
      "110A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    265\n",
      "M    256\n",
      "F    198\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    83\n",
      "M    81\n",
      "F    54\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 000A, 033A, 015A, 103A, 071A, 028A, 067...\n",
      "kitten    [014B, 040A, 046A, 047A, 042A, 109A, 050A, 043...\n",
      "senior    [093A, 097A, 057A, 106A, 055A, 059A, 113A, 116...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [001A, 097B, 019A, 074A, 029A, 005A, 091A, 023...\n",
      "kitten                             [044A, 111A, 045A, 110A]\n",
      "senior                             [104A, 054A, 117A, 051A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 57, 'kitten': 12, 'senior': 18}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 17, 'kitten': 4, 'senior': 4}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '002A' '002B' '003A' '004A' '006A' '007A' '008A' '009A' '010A'\n",
      " '011A' '012A' '013B' '014A' '014B' '015A' '016A' '019B' '020A' '021A'\n",
      " '022A' '023B' '024A' '025A' '025B' '025C' '026A' '026B' '026C' '027A'\n",
      " '028A' '031A' '032A' '033A' '034A' '035A' '037A' '039A' '040A' '041A'\n",
      " '042A' '043A' '046A' '047A' '048A' '049A' '050A' '051B' '055A' '056A'\n",
      " '057A' '058A' '059A' '060A' '061A' '062A' '063A' '064A' '065A' '066A'\n",
      " '067A' '069A' '070A' '071A' '072A' '073A' '075A' '076A' '087A' '088A'\n",
      " '090A' '092A' '093A' '094A' '095A' '096A' '097A' '099A' '100A' '101A'\n",
      " '103A' '106A' '108A' '109A' '113A' '115A' '116A']\n",
      "Unique Test Group IDs:\n",
      "['000B' '001A' '005A' '018A' '019A' '023A' '029A' '036A' '038A' '044A'\n",
      " '045A' '051A' '052A' '053A' '054A' '068A' '074A' '091A' '097B' '102A'\n",
      " '104A' '105A' '110A' '111A' '117A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "set()\n",
      "Removed from Training/Validation Set:\n",
      "set()\n",
      "Moved to Test Set:\n",
      "set()\n",
      "Removed from Test Set\n",
      "set()\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '002A' '002B' '003A' '004A' '006A' '007A' '008A' '009A' '010A'\n",
      " '011A' '012A' '013B' '014A' '014B' '015A' '016A' '019B' '020A' '021A'\n",
      " '022A' '023B' '024A' '025A' '025B' '025C' '026A' '026B' '026C' '027A'\n",
      " '028A' '031A' '032A' '033A' '034A' '035A' '037A' '039A' '040A' '041A'\n",
      " '042A' '043A' '046A' '047A' '048A' '049A' '050A' '051B' '055A' '056A'\n",
      " '057A' '058A' '059A' '060A' '061A' '062A' '063A' '064A' '065A' '066A'\n",
      " '067A' '069A' '070A' '071A' '072A' '073A' '075A' '076A' '087A' '088A'\n",
      " '090A' '092A' '093A' '094A' '095A' '096A' '097A' '099A' '100A' '101A'\n",
      " '103A' '106A' '108A' '109A' '113A' '115A' '116A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['000B' '001A' '005A' '018A' '019A' '023A' '029A' '036A' '038A' '044A'\n",
      " '045A' '051A' '052A' '053A' '054A' '068A' '074A' '091A' '097B' '102A'\n",
      " '104A' '105A' '110A' '111A' '117A']\n",
      "Length of X_train_val:\n",
      "719\n",
      "Length of y_train_val:\n",
      "719\n",
      "Length of groups_train_val:\n",
      "719\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     423\n",
      "senior    153\n",
      "kitten    143\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     165\n",
      "kitten     28\n",
      "senior     25\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     423\n",
      "senior    153\n",
      "kitten    143\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     165\n",
      "kitten     28\n",
      "senior     25\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 423, 2: 153, 1: 143})\n",
      "Epoch 1/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.0716 - accuracy: 0.4798\n",
      "Epoch 2/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8186 - accuracy: 0.5772\n",
      "Epoch 3/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7694 - accuracy: 0.6412\n",
      "Epoch 4/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.6537\n",
      "Epoch 5/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6676\n",
      "Epoch 6/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6358 - accuracy: 0.6954\n",
      "Epoch 7/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.6940\n",
      "Epoch 8/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5778 - accuracy: 0.7177\n",
      "Epoch 9/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7135\n",
      "Epoch 10/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5393 - accuracy: 0.7191\n",
      "Epoch 11/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.7413\n",
      "Epoch 12/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.7469\n",
      "Epoch 13/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7413\n",
      "Epoch 14/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7399\n",
      "Epoch 15/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.7427\n",
      "Epoch 16/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7761\n",
      "Epoch 17/1500\n",
      "23/23 [==============================] - 0s 999us/step - loss: 0.4795 - accuracy: 0.7650\n",
      "Epoch 18/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7594\n",
      "Epoch 19/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7691\n",
      "Epoch 20/1500\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.4757 - accuracy: 0.7705\n",
      "Epoch 21/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7914\n",
      "Epoch 22/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7955\n",
      "Epoch 23/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.7955\n",
      "Epoch 24/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3974 - accuracy: 0.7983\n",
      "Epoch 25/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8095\n",
      "Epoch 26/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.7844\n",
      "Epoch 27/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.7983\n",
      "Epoch 28/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.8164\n",
      "Epoch 29/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.8248\n",
      "Epoch 30/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.8150\n",
      "Epoch 31/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.7928\n",
      "Epoch 32/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.8136\n",
      "Epoch 33/1500\n",
      "23/23 [==============================] - 0s 989us/step - loss: 0.3776 - accuracy: 0.8261\n",
      "Epoch 34/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.8081\n",
      "Epoch 35/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8428\n",
      "Epoch 36/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8331\n",
      "Epoch 37/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8289\n",
      "Epoch 38/1500\n",
      "23/23 [==============================] - 0s 999us/step - loss: 0.3519 - accuracy: 0.8331\n",
      "Epoch 39/1500\n",
      "23/23 [==============================] - 0s 968us/step - loss: 0.3373 - accuracy: 0.8401\n",
      "Epoch 40/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8526\n",
      "Epoch 41/1500\n",
      "23/23 [==============================] - 0s 983us/step - loss: 0.3302 - accuracy: 0.8470\n",
      "Epoch 42/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3194 - accuracy: 0.8498\n",
      "Epoch 43/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8401\n",
      "Epoch 44/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3181 - accuracy: 0.8526\n",
      "Epoch 45/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2886 - accuracy: 0.8720\n",
      "Epoch 46/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.8484\n",
      "Epoch 47/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3095 - accuracy: 0.8554\n",
      "Epoch 48/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8526\n",
      "Epoch 49/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2795 - accuracy: 0.8637\n",
      "Epoch 50/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2615 - accuracy: 0.8707\n",
      "Epoch 51/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2929 - accuracy: 0.8595\n",
      "Epoch 52/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2801 - accuracy: 0.8776\n",
      "Epoch 53/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2758 - accuracy: 0.8623\n",
      "Epoch 54/1500\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.2972 - accuracy: 0.8526\n",
      "Epoch 55/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2971 - accuracy: 0.8623\n",
      "Epoch 56/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2768 - accuracy: 0.8734\n",
      "Epoch 57/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.8609\n",
      "Epoch 58/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2603 - accuracy: 0.8776\n",
      "Epoch 59/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.8790\n",
      "Epoch 60/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.8776\n",
      "Epoch 61/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2735 - accuracy: 0.8720\n",
      "Epoch 62/1500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2890 - accuracy: 0.8512\n",
      "Epoch 63/1500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3053 - accuracy: 0.8623\n",
      "Epoch 64/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.8762\n",
      "Epoch 65/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.8790\n",
      "Epoch 66/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2838 - accuracy: 0.8846\n",
      "Epoch 67/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2748 - accuracy: 0.8651\n",
      "Epoch 68/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2563 - accuracy: 0.8748\n",
      "Epoch 69/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2835 - accuracy: 0.8748\n",
      "Epoch 70/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.8734\n",
      "Epoch 71/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2680 - accuracy: 0.8623\n",
      "Epoch 72/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2895 - accuracy: 0.8651\n",
      "Epoch 73/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2328 - accuracy: 0.8818\n",
      "Epoch 74/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.8957\n",
      "Epoch 75/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2547 - accuracy: 0.8720\n",
      "Epoch 76/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.8971\n",
      "Epoch 77/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.8832\n",
      "Epoch 78/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.8860\n",
      "Epoch 79/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2301 - accuracy: 0.8776\n",
      "Epoch 80/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9082\n",
      "Epoch 81/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.8887\n",
      "Epoch 82/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2372 - accuracy: 0.8943\n",
      "Epoch 83/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.8943\n",
      "Epoch 84/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.8873\n",
      "Epoch 85/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.9068\n",
      "Epoch 86/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.8929\n",
      "Epoch 87/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.9054\n",
      "Epoch 88/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9179\n",
      "Epoch 89/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.9040\n",
      "Epoch 90/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.8929\n",
      "Epoch 91/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.8887\n",
      "Epoch 92/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.8999\n",
      "Epoch 93/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.9110\n",
      "Epoch 94/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2137 - accuracy: 0.9026\n",
      "Epoch 95/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2096 - accuracy: 0.8929\n",
      "Epoch 96/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.9082\n",
      "Epoch 97/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2169 - accuracy: 0.8915\n",
      "Epoch 98/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.9013\n",
      "Epoch 99/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.8929\n",
      "Epoch 100/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2033 - accuracy: 0.9040\n",
      "Epoch 101/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.8957\n",
      "Epoch 102/1500\n",
      "23/23 [==============================] - 0s 1000us/step - loss: 0.2012 - accuracy: 0.9082\n",
      "Epoch 103/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.9013\n",
      "Epoch 104/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.9054\n",
      "Epoch 105/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9124\n",
      "Epoch 106/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.9110\n",
      "Epoch 107/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.9124\n",
      "Epoch 108/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.9096\n",
      "Epoch 109/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9124\n",
      "Epoch 110/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.8999\n",
      "Epoch 111/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1704 - accuracy: 0.9179\n",
      "Epoch 112/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9207\n",
      "Epoch 113/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.9166\n",
      "Epoch 114/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.9152\n",
      "Epoch 115/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9166\n",
      "Epoch 116/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.9179\n",
      "Epoch 117/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9082\n",
      "Epoch 118/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.9096\n",
      "Epoch 119/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.9054\n",
      "Epoch 120/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9235\n",
      "Epoch 121/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.9207\n",
      "Epoch 122/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9318\n",
      "Epoch 123/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9166\n",
      "Epoch 124/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.9166\n",
      "Epoch 125/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.9263\n",
      "Epoch 126/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9221\n",
      "Epoch 127/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1590 - accuracy: 0.9388\n",
      "Epoch 128/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9374\n",
      "Epoch 129/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9458\n",
      "Epoch 130/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1667 - accuracy: 0.9235\n",
      "Epoch 131/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1659 - accuracy: 0.9138\n",
      "Epoch 132/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9152\n",
      "Epoch 133/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9318\n",
      "Epoch 134/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9291\n",
      "Epoch 135/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1651 - accuracy: 0.9207\n",
      "Epoch 136/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1727 - accuracy: 0.9291\n",
      "Epoch 137/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1699 - accuracy: 0.9166\n",
      "Epoch 138/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1735 - accuracy: 0.9166\n",
      "Epoch 139/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9235\n",
      "Epoch 140/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9291\n",
      "Epoch 141/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1711 - accuracy: 0.9318\n",
      "Epoch 142/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9249\n",
      "Epoch 143/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9374\n",
      "Epoch 144/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1640 - accuracy: 0.9263\n",
      "Epoch 145/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9305\n",
      "Epoch 146/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9360\n",
      "Epoch 147/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9374\n",
      "Epoch 148/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9444\n",
      "Epoch 149/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1546 - accuracy: 0.9346\n",
      "Epoch 150/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9305\n",
      "Epoch 151/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9305\n",
      "Epoch 152/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9458\n",
      "Epoch 153/1500\n",
      "23/23 [==============================] - 0s 988us/step - loss: 0.1481 - accuracy: 0.9360\n",
      "Epoch 154/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9360\n",
      "Epoch 155/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.9221\n",
      "Epoch 156/1500\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1450 - accuracy: 0.9402\n",
      "Epoch 157/1500\n",
      "23/23 [==============================] - 0s 1000us/step - loss: 0.1399 - accuracy: 0.9402\n",
      "Epoch 158/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9430\n",
      "Epoch 159/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9360\n",
      "Epoch 160/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9305\n",
      "Epoch 161/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9374\n",
      "Epoch 162/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1449 - accuracy: 0.9360\n",
      "Epoch 163/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9346\n",
      "Epoch 164/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9346\n",
      "Epoch 165/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9249\n",
      "Epoch 166/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9513\n",
      "Epoch 167/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9305\n",
      "Epoch 168/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.9388\n",
      "Epoch 169/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9430\n",
      "Epoch 170/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9416\n",
      "Epoch 171/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9291\n",
      "Epoch 172/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9291\n",
      "Epoch 173/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9458\n",
      "Epoch 174/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1257 - accuracy: 0.9541\n",
      "Epoch 175/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9416\n",
      "Epoch 176/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9471\n",
      "Epoch 177/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9360\n",
      "Epoch 178/1500\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.1109 - accuracy: 0.9499\n",
      "Epoch 179/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9402\n",
      "Epoch 180/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9485\n",
      "Epoch 181/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9221\n",
      "Epoch 182/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9291\n",
      "Epoch 183/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9541\n",
      "Epoch 184/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9541\n",
      "Epoch 185/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9332\n",
      "Epoch 186/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1467 - accuracy: 0.9388\n",
      "Epoch 187/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9346\n",
      "Epoch 188/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9430\n",
      "Epoch 189/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.9416\n",
      "Epoch 190/1500\n",
      "23/23 [==============================] - 0s 998us/step - loss: 0.1364 - accuracy: 0.9360\n",
      "Epoch 191/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9458\n",
      "Epoch 192/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.9555\n",
      "Epoch 193/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9360\n",
      "Epoch 194/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9527\n",
      "Epoch 195/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9624\n",
      "Epoch 196/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9597\n",
      "Epoch 197/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9430\n",
      "Epoch 198/1500\n",
      "23/23 [==============================] - 0s 995us/step - loss: 0.1103 - accuracy: 0.9485\n",
      "Epoch 199/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9611\n",
      "Epoch 200/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.9485\n",
      "Epoch 201/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9346\n",
      "Epoch 202/1500\n",
      "23/23 [==============================] - 0s 992us/step - loss: 0.1087 - accuracy: 0.9569\n",
      "Epoch 203/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9555\n",
      "Epoch 204/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.9458\n",
      "Epoch 205/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9499\n",
      "Epoch 206/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1160 - accuracy: 0.9624\n",
      "Epoch 207/1500\n",
      "23/23 [==============================] - 0s 991us/step - loss: 0.1359 - accuracy: 0.9430\n",
      "Epoch 208/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.9402\n",
      "Epoch 209/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.9541\n",
      "Epoch 210/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9402\n",
      "Epoch 211/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1194 - accuracy: 0.9555\n",
      "Epoch 212/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9485\n",
      "Epoch 213/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9416\n",
      "Epoch 214/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.9485\n",
      "Epoch 215/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9569\n",
      "Epoch 216/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.9499\n",
      "Epoch 217/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9611\n",
      "Epoch 218/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9611\n",
      "Epoch 219/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9527\n",
      "Epoch 220/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9346\n",
      "Epoch 221/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1037 - accuracy: 0.9527\n",
      "Epoch 222/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9638\n",
      "Epoch 223/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0976 - accuracy: 0.9569\n",
      "Epoch 224/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.9527\n",
      "Epoch 225/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9555\n",
      "Epoch 226/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9569\n",
      "Epoch 227/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0984 - accuracy: 0.9569\n",
      "Epoch 228/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0817 - accuracy: 0.9750\n",
      "Epoch 229/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.9527\n",
      "Epoch 230/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.9485\n",
      "Epoch 231/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9541\n",
      "Epoch 232/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.9430\n",
      "Epoch 233/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9458\n",
      "Epoch 234/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.9430\n",
      "Epoch 235/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9638\n",
      "Epoch 236/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0937 - accuracy: 0.9569\n",
      "Epoch 237/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9485\n",
      "Epoch 238/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.9416\n",
      "Epoch 239/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9638\n",
      "Epoch 240/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9541\n",
      "Epoch 241/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.9597\n",
      "Epoch 242/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9569\n",
      "Epoch 243/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1035 - accuracy: 0.9569\n",
      "Epoch 244/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9555\n",
      "Epoch 245/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9624\n",
      "Epoch 246/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9471\n",
      "Epoch 247/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9541\n",
      "Epoch 248/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9541\n",
      "Epoch 249/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9569\n",
      "Epoch 250/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9736\n",
      "Epoch 251/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0820 - accuracy: 0.9624\n",
      "Epoch 252/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9555\n",
      "Epoch 253/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1243 - accuracy: 0.9471\n",
      "Epoch 254/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.9541\n",
      "Epoch 255/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9611\n",
      "Epoch 256/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9569\n",
      "Epoch 257/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9513\n",
      "Epoch 258/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9499\n",
      "Epoch 259/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9513\n",
      "Epoch 260/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9541\n",
      "Epoch 261/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9485\n",
      "Epoch 262/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9680\n",
      "Epoch 263/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9485\n",
      "Epoch 264/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0982 - accuracy: 0.9597\n",
      "Epoch 265/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.9652\n",
      "Epoch 266/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0830 - accuracy: 0.9624\n",
      "Epoch 267/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9555\n",
      "Epoch 268/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9611\n",
      "Epoch 269/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9555\n",
      "Epoch 270/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9764\n",
      "Epoch 271/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9541\n",
      "Epoch 272/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.9555\n",
      "Epoch 273/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9555\n",
      "Epoch 274/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9708\n",
      "Epoch 275/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9611\n",
      "Epoch 276/1500\n",
      "23/23 [==============================] - 0s 977us/step - loss: 0.0990 - accuracy: 0.9444\n",
      "Epoch 277/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9694\n",
      "Epoch 278/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9652\n",
      "Epoch 279/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9638\n",
      "Epoch 280/1500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.0822 - accuracy: 0.9375Restoring model weights from the end of the best epoch: 250.\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0896 - accuracy: 0.9611\n",
      "Epoch 280: early stopping\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0242 - accuracy: 0.6697\n",
      "7/7 [==============================] - 0s 773us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.64 (16/25)\n",
      "Before appending - Cat IDs: 0, Predictions: 0, Actuals: 0, Gender: 0\n",
      "After appending - Cat IDs: 218, Predictions: 218, Actuals: 218, Gender: 218\n",
      "Final Test Results - Loss: 1.0241814851760864, Accuracy: 0.6697247624397278, Precision: 0.6386189258312021, Recall: 0.7315295815295815, F1 Score: 0.6443246069876132\n",
      "Confusion Matrix:\n",
      " [[104   7  54]\n",
      " [  1  27   0]\n",
      " [ 10   0  15]]\n",
      "outer_fold 2\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "103A    33\n",
      "047A    28\n",
      "057A    27\n",
      "074A    25\n",
      "020A    23\n",
      "055A    20\n",
      "067A    19\n",
      "000B    19\n",
      "019A    17\n",
      "029A    17\n",
      "097A    16\n",
      "101A    15\n",
      "001A    14\n",
      "097B    14\n",
      "059A    14\n",
      "028A    13\n",
      "002A    13\n",
      "111A    13\n",
      "051A    12\n",
      "025A    11\n",
      "036A    11\n",
      "068A    11\n",
      "005A    10\n",
      "072A     9\n",
      "033A     9\n",
      "045A     9\n",
      "022A     9\n",
      "094A     8\n",
      "013B     8\n",
      "010A     8\n",
      "031A     7\n",
      "050A     7\n",
      "117A     7\n",
      "099A     7\n",
      "027A     7\n",
      "108A     6\n",
      "109A     6\n",
      "008A     6\n",
      "023A     6\n",
      "007A     6\n",
      "037A     6\n",
      "053A     6\n",
      "044A     5\n",
      "025C     5\n",
      "034A     5\n",
      "021A     5\n",
      "035A     4\n",
      "003A     4\n",
      "052A     4\n",
      "026A     4\n",
      "104A     4\n",
      "009A     4\n",
      "105A     4\n",
      "058A     3\n",
      "064A     3\n",
      "012A     3\n",
      "006A     3\n",
      "113A     3\n",
      "056A     3\n",
      "014A     3\n",
      "093A     2\n",
      "025B     2\n",
      "038A     2\n",
      "087A     2\n",
      "102A     2\n",
      "032A     2\n",
      "054A     2\n",
      "018A     2\n",
      "115A     1\n",
      "100A     1\n",
      "090A     1\n",
      "024A     1\n",
      "110A     1\n",
      "073A     1\n",
      "066A     1\n",
      "091A     1\n",
      "088A     1\n",
      "048A     1\n",
      "026C     1\n",
      "041A     1\n",
      "049A     1\n",
      "096A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "000A    39\n",
      "002B    32\n",
      "042A    14\n",
      "106A    14\n",
      "116A    12\n",
      "039A    12\n",
      "063A    11\n",
      "040A    10\n",
      "016A    10\n",
      "071A    10\n",
      "014B    10\n",
      "065A     9\n",
      "015A     9\n",
      "051B     9\n",
      "095A     8\n",
      "070A     5\n",
      "075A     5\n",
      "023B     5\n",
      "062A     4\n",
      "060A     3\n",
      "011A     2\n",
      "069A     2\n",
      "061A     2\n",
      "043A     1\n",
      "092A     1\n",
      "076A     1\n",
      "004A     1\n",
      "019B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    273\n",
      "M    241\n",
      "F    181\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "M    96\n",
      "X    75\n",
      "F    71\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 033A, 001A, 103A, 097B, 028A, 019A, 074...\n",
      "kitten    [044A, 111A, 046A, 047A, 109A, 050A, 049A, 041...\n",
      "senior    [093A, 097A, 057A, 104A, 055A, 059A, 113A, 054...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [000A, 015A, 071A, 062A, 002B, 095A, 065A, 039...\n",
      "kitten                             [014B, 040A, 042A, 043A]\n",
      "senior                 [106A, 116A, 051B, 016A, 011A, 061A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 56, 'kitten': 12, 'senior': 16}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 18, 'kitten': 4, 'senior': 6}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000B' '001A' '002A' '003A' '005A' '006A' '007A' '008A' '009A' '010A'\n",
      " '012A' '013B' '014A' '018A' '019A' '020A' '021A' '022A' '023A' '024A'\n",
      " '025A' '025B' '025C' '026A' '026B' '026C' '027A' '028A' '029A' '031A'\n",
      " '032A' '033A' '034A' '035A' '036A' '037A' '038A' '041A' '044A' '045A'\n",
      " '046A' '047A' '048A' '049A' '050A' '051A' '052A' '053A' '054A' '055A'\n",
      " '056A' '057A' '058A' '059A' '064A' '066A' '067A' '068A' '072A' '073A'\n",
      " '074A' '087A' '088A' '090A' '091A' '093A' '094A' '096A' '097A' '097B'\n",
      " '099A' '100A' '101A' '102A' '103A' '104A' '105A' '108A' '109A' '110A'\n",
      " '111A' '113A' '115A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['000A' '002B' '004A' '011A' '014B' '015A' '016A' '019B' '023B' '039A'\n",
      " '040A' '042A' '043A' '051B' '060A' '061A' '062A' '063A' '065A' '069A'\n",
      " '070A' '071A' '075A' '076A' '092A' '095A' '106A' '116A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "{'000A'}\n",
      "Removed from Training/Validation Set:\n",
      "{'026B'}\n",
      "Moved to Test Set:\n",
      "{'026B'}\n",
      "Removed from Test Set\n",
      "{'000A'}\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '003A' '005A' '006A' '007A' '008A' '009A'\n",
      " '010A' '012A' '013B' '014A' '018A' '019A' '020A' '021A' '022A' '023A'\n",
      " '024A' '025A' '025B' '025C' '026A' '026C' '027A' '028A' '029A' '031A'\n",
      " '032A' '033A' '034A' '035A' '036A' '037A' '038A' '041A' '044A' '045A'\n",
      " '046A' '047A' '048A' '049A' '050A' '051A' '052A' '053A' '054A' '055A'\n",
      " '056A' '057A' '058A' '059A' '064A' '066A' '067A' '068A' '072A' '073A'\n",
      " '074A' '087A' '088A' '090A' '091A' '093A' '094A' '096A' '097A' '097B'\n",
      " '099A' '100A' '101A' '102A' '103A' '104A' '105A' '108A' '109A' '110A'\n",
      " '111A' '113A' '115A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['002B' '004A' '011A' '014B' '015A' '016A' '019B' '023B' '026B' '039A'\n",
      " '040A' '042A' '043A' '051B' '060A' '061A' '062A' '063A' '065A' '069A'\n",
      " '070A' '071A' '075A' '076A' '092A' '095A' '106A' '116A']\n",
      "Length of X_train_val:\n",
      "733\n",
      "Length of y_train_val:\n",
      "733\n",
      "Length of groups_train_val:\n",
      "733\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     430\n",
      "kitten    136\n",
      "senior    129\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     158\n",
      "senior     49\n",
      "kitten     35\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     468\n",
      "kitten    136\n",
      "senior    129\n",
      "Name: age_group, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     120\n",
      "senior     49\n",
      "kitten     35\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 468, 1: 136, 2: 129})\n",
      "Epoch 1/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.1275 - accuracy: 0.4843\n",
      "Epoch 2/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8452 - accuracy: 0.5539\n",
      "Epoch 3/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7914 - accuracy: 0.5634\n",
      "Epoch 4/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.6003\n",
      "Epoch 5/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7028 - accuracy: 0.6248\n",
      "Epoch 6/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.6426\n",
      "Epoch 7/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6136 - accuracy: 0.6617\n",
      "Epoch 8/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6419 - accuracy: 0.6603\n",
      "Epoch 9/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6075 - accuracy: 0.6617\n",
      "Epoch 10/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.6767\n",
      "Epoch 11/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5497 - accuracy: 0.7121\n",
      "Epoch 12/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.7121\n",
      "Epoch 13/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7340\n",
      "Epoch 14/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5370 - accuracy: 0.7190\n",
      "Epoch 15/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7231\n",
      "Epoch 16/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7381\n",
      "Epoch 17/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7217\n",
      "Epoch 18/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7490\n",
      "Epoch 19/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4137 - accuracy: 0.7735\n",
      "Epoch 20/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.7503\n",
      "Epoch 21/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7599\n",
      "Epoch 22/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4236 - accuracy: 0.7667\n",
      "Epoch 23/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.7722\n",
      "Epoch 24/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7490\n",
      "Epoch 25/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.7844\n",
      "Epoch 26/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.7954\n",
      "Epoch 27/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.7885\n",
      "Epoch 28/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3830 - accuracy: 0.7954\n",
      "Epoch 29/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4022 - accuracy: 0.7995\n",
      "Epoch 30/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3716 - accuracy: 0.7967\n",
      "Epoch 31/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8158\n",
      "Epoch 32/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3746 - accuracy: 0.8090\n",
      "Epoch 33/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3813 - accuracy: 0.7899\n",
      "Epoch 34/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3538 - accuracy: 0.8063\n",
      "Epoch 35/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3884 - accuracy: 0.8131\n",
      "Epoch 36/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8295\n",
      "Epoch 37/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8213\n",
      "Epoch 38/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8322\n",
      "Epoch 39/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8213\n",
      "Epoch 40/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8390\n",
      "Epoch 41/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8308\n",
      "Epoch 42/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8390\n",
      "Epoch 43/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8295\n",
      "Epoch 44/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8281\n",
      "Epoch 45/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8145\n",
      "Epoch 46/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8295\n",
      "Epoch 47/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.8458\n",
      "Epoch 48/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8568\n",
      "Epoch 49/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3134 - accuracy: 0.8458\n",
      "Epoch 50/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3168 - accuracy: 0.8417\n",
      "Epoch 51/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3190 - accuracy: 0.8336\n",
      "Epoch 52/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2954 - accuracy: 0.8254\n",
      "Epoch 53/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3221 - accuracy: 0.8445\n",
      "Epoch 54/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3038 - accuracy: 0.8417\n",
      "Epoch 55/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.8254\n",
      "Epoch 56/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2967 - accuracy: 0.8458\n",
      "Epoch 57/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2522 - accuracy: 0.8704\n",
      "Epoch 58/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2844 - accuracy: 0.8690\n",
      "Epoch 59/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2876 - accuracy: 0.8377\n",
      "Epoch 60/1500\n",
      "23/23 [==============================] - 0s 991us/step - loss: 0.2784 - accuracy: 0.8527\n",
      "Epoch 61/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.8649\n",
      "Epoch 62/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2641 - accuracy: 0.8636\n",
      "Epoch 63/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2431 - accuracy: 0.8840\n",
      "Epoch 64/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2514 - accuracy: 0.8718\n",
      "Epoch 65/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 0.8581\n",
      "Epoch 66/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2740 - accuracy: 0.8568\n",
      "Epoch 67/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2674 - accuracy: 0.8595\n",
      "Epoch 68/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.8799\n",
      "Epoch 69/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2617 - accuracy: 0.8690\n",
      "Epoch 70/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.8636\n",
      "Epoch 71/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.8745\n",
      "Epoch 72/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.8827\n",
      "Epoch 73/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.8704\n",
      "Epoch 74/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.8649\n",
      "Epoch 75/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8690\n",
      "Epoch 76/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2629 - accuracy: 0.8690\n",
      "Epoch 77/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.8704\n",
      "Epoch 78/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.8854\n",
      "Epoch 79/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.8840\n",
      "Epoch 80/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 0.8868\n",
      "Epoch 81/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2365 - accuracy: 0.8759\n",
      "Epoch 82/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.8827\n",
      "Epoch 83/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.8922\n",
      "Epoch 84/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2358 - accuracy: 0.8827\n",
      "Epoch 85/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.8718\n",
      "Epoch 86/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.8950\n",
      "Epoch 87/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2294 - accuracy: 0.8895\n",
      "Epoch 88/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2109 - accuracy: 0.8936\n",
      "Epoch 89/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.8922\n",
      "Epoch 90/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.8936\n",
      "Epoch 91/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.8881\n",
      "Epoch 92/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.8950\n",
      "Epoch 93/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2149 - accuracy: 0.8868\n",
      "Epoch 94/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2594 - accuracy: 0.8840\n",
      "Epoch 95/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.8745\n",
      "Epoch 96/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2162 - accuracy: 0.8950\n",
      "Epoch 97/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.8840\n",
      "Epoch 98/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.8909\n",
      "Epoch 99/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.8936\n",
      "Epoch 100/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.8950\n",
      "Epoch 101/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1713 - accuracy: 0.8950\n",
      "Epoch 102/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1959 - accuracy: 0.9018\n",
      "Epoch 103/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.9045\n",
      "Epoch 104/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.8990\n",
      "Epoch 105/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.9059\n",
      "Epoch 106/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1990 - accuracy: 0.9031\n",
      "Epoch 107/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.8977\n",
      "Epoch 108/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.9059\n",
      "Epoch 109/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9072\n",
      "Epoch 110/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.9072\n",
      "Epoch 111/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.9141\n",
      "Epoch 112/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.9127\n",
      "Epoch 113/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.9031\n",
      "Epoch 114/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9059\n",
      "Epoch 115/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.9072\n",
      "Epoch 116/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9181\n",
      "Epoch 117/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1667 - accuracy: 0.9236\n",
      "Epoch 118/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1649 - accuracy: 0.9209\n",
      "Epoch 119/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.9004\n",
      "Epoch 120/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.9168\n",
      "Epoch 121/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9304\n",
      "Epoch 122/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1737 - accuracy: 0.8990\n",
      "Epoch 123/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.9141\n",
      "Epoch 124/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9209\n",
      "Epoch 125/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9304\n",
      "Epoch 126/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9250\n",
      "Epoch 127/1500\n",
      "23/23 [==============================] - 0s 999us/step - loss: 0.1793 - accuracy: 0.9154\n",
      "Epoch 128/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9127\n",
      "Epoch 129/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9168\n",
      "Epoch 130/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.9195\n",
      "Epoch 131/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9127\n",
      "Epoch 132/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9277\n",
      "Epoch 133/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9018\n",
      "Epoch 134/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.9086\n",
      "Epoch 135/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9154\n",
      "Epoch 136/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9209\n",
      "Epoch 137/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1737 - accuracy: 0.9277\n",
      "Epoch 138/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9222\n",
      "Epoch 139/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9236\n",
      "Epoch 140/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1558 - accuracy: 0.9195\n",
      "Epoch 141/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1662 - accuracy: 0.9332\n",
      "Epoch 142/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.9236\n",
      "Epoch 143/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9277\n",
      "Epoch 144/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9359\n",
      "Epoch 145/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9291\n",
      "Epoch 146/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9318\n",
      "Epoch 147/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9413\n",
      "Epoch 148/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1631 - accuracy: 0.9222\n",
      "Epoch 149/1500\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.1507 - accuracy: 0.9372\n",
      "Epoch 150/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9318\n",
      "Epoch 151/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9332\n",
      "Epoch 152/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9372\n",
      "Epoch 153/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9332\n",
      "Epoch 154/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9304\n",
      "Epoch 155/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9250\n",
      "Epoch 156/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9591\n",
      "Epoch 157/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1658 - accuracy: 0.9263\n",
      "Epoch 158/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.9345\n",
      "Epoch 159/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9345\n",
      "Epoch 160/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9372\n",
      "Epoch 161/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9386\n",
      "Epoch 162/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9209\n",
      "Epoch 163/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9250\n",
      "Epoch 164/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9304\n",
      "Epoch 165/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9400\n",
      "Epoch 166/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9413\n",
      "Epoch 167/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9386\n",
      "Epoch 168/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1301 - accuracy: 0.9441\n",
      "Epoch 169/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1380 - accuracy: 0.9482\n",
      "Epoch 170/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9427\n",
      "Epoch 171/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9304\n",
      "Epoch 172/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9386\n",
      "Epoch 173/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.9400\n",
      "Epoch 174/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9523\n",
      "Epoch 175/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.9468\n",
      "Epoch 176/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9332\n",
      "Epoch 177/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9413\n",
      "Epoch 178/1500\n",
      "23/23 [==============================] - 0s 991us/step - loss: 0.1273 - accuracy: 0.9468\n",
      "Epoch 179/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.9413\n",
      "Epoch 180/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9332\n",
      "Epoch 181/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9427\n",
      "Epoch 182/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9454\n",
      "Epoch 183/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9372\n",
      "Epoch 184/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.9400\n",
      "Epoch 185/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9427\n",
      "Epoch 186/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9482\n",
      "Epoch 187/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9427\n",
      "Epoch 188/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.9372\n",
      "Epoch 189/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9359\n",
      "Epoch 190/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9454\n",
      "Epoch 191/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.9386\n",
      "Epoch 192/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9468\n",
      "Epoch 193/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9400\n",
      "Epoch 194/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9454\n",
      "Epoch 195/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1257 - accuracy: 0.9413\n",
      "Epoch 196/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9291\n",
      "Epoch 197/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9332\n",
      "Epoch 198/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9468\n",
      "Epoch 199/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9536\n",
      "Epoch 200/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9400\n",
      "Epoch 201/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.9441\n",
      "Epoch 202/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9345\n",
      "Epoch 203/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9441\n",
      "Epoch 204/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1042 - accuracy: 0.9482\n",
      "Epoch 205/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.9427\n",
      "Epoch 206/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9454\n",
      "Epoch 207/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.9441\n",
      "Epoch 208/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9509\n",
      "Epoch 209/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0975 - accuracy: 0.9536\n",
      "Epoch 210/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.9454\n",
      "Epoch 211/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9359\n",
      "Epoch 212/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9359\n",
      "Epoch 213/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9482\n",
      "Epoch 214/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9495\n",
      "Epoch 215/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9591\n",
      "Epoch 216/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1042 - accuracy: 0.9577\n",
      "Epoch 217/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9563\n",
      "Epoch 218/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9536\n",
      "Epoch 219/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9550\n",
      "Epoch 220/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9536\n",
      "Epoch 221/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9454\n",
      "Epoch 222/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9482\n",
      "Epoch 223/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.9563\n",
      "Epoch 224/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0887 - accuracy: 0.9591\n",
      "Epoch 225/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9563\n",
      "Epoch 226/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0976 - accuracy: 0.9563\n",
      "Epoch 227/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9577\n",
      "Epoch 228/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9604\n",
      "Epoch 229/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9523\n",
      "Epoch 230/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9577\n",
      "Epoch 231/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.9563\n",
      "Epoch 232/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9536\n",
      "Epoch 233/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9577\n",
      "Epoch 234/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9618\n",
      "Epoch 235/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9618\n",
      "Epoch 236/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9632\n",
      "Epoch 237/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9686\n",
      "Epoch 238/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9523\n",
      "Epoch 239/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9618\n",
      "Epoch 240/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.9550\n",
      "Epoch 241/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9509\n",
      "Epoch 242/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0880 - accuracy: 0.9550\n",
      "Epoch 243/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0807 - accuracy: 0.9632\n",
      "Epoch 244/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1037 - accuracy: 0.9509\n",
      "Epoch 245/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9673\n",
      "Epoch 246/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0866 - accuracy: 0.9563\n",
      "Epoch 247/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9550\n",
      "Epoch 248/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9618\n",
      "Epoch 249/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.9700\n",
      "Epoch 250/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0990 - accuracy: 0.9523\n",
      "Epoch 251/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9604\n",
      "Epoch 252/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9495\n",
      "Epoch 253/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9441\n",
      "Epoch 254/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9632\n",
      "Epoch 255/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9563\n",
      "Epoch 256/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9454\n",
      "Epoch 257/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9536\n",
      "Epoch 258/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9686\n",
      "Epoch 259/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9523\n",
      "Epoch 260/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 0.9618\n",
      "Epoch 261/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9550\n",
      "Epoch 262/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9482\n",
      "Epoch 263/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0776 - accuracy: 0.9700\n",
      "Epoch 264/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9714\n",
      "Epoch 265/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9591\n",
      "Epoch 266/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9632\n",
      "Epoch 267/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9604\n",
      "Epoch 268/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0973 - accuracy: 0.9618\n",
      "Epoch 269/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9604\n",
      "Epoch 270/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9563\n",
      "Epoch 271/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9577\n",
      "Epoch 272/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9591\n",
      "Epoch 273/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0830 - accuracy: 0.9618\n",
      "Epoch 274/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9754\n",
      "Epoch 275/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9714\n",
      "Epoch 276/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0777 - accuracy: 0.9632\n",
      "Epoch 277/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9659\n",
      "Epoch 278/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9673\n",
      "Epoch 279/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9700\n",
      "Epoch 280/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9714\n",
      "Epoch 281/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9686\n",
      "Epoch 282/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.9604\n",
      "Epoch 283/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.9454\n",
      "Epoch 284/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9632\n",
      "Epoch 285/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9632\n",
      "Epoch 286/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0826 - accuracy: 0.9714\n",
      "Epoch 287/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 0.9673\n",
      "Epoch 288/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9632\n",
      "Epoch 289/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9686\n",
      "Epoch 290/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9604\n",
      "Epoch 291/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0748 - accuracy: 0.9714\n",
      "Epoch 292/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9563\n",
      "Epoch 293/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9741\n",
      "Epoch 294/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9714\n",
      "Epoch 295/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0876 - accuracy: 0.9563\n",
      "Epoch 296/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9536\n",
      "Epoch 297/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0751 - accuracy: 0.9741\n",
      "Epoch 298/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0734 - accuracy: 0.9700\n",
      "Epoch 299/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0793 - accuracy: 0.9591\n",
      "Epoch 300/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9714\n",
      "Epoch 301/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9754\n",
      "Epoch 302/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0556 - accuracy: 0.9700\n",
      "Epoch 303/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9645\n",
      "Epoch 304/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9550\n",
      "Epoch 305/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9659\n",
      "Epoch 306/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9686\n",
      "Epoch 307/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0731 - accuracy: 0.9618\n",
      "Epoch 308/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9700\n",
      "Epoch 309/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9632\n",
      "Epoch 310/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9536\n",
      "Epoch 311/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9741\n",
      "Epoch 312/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.9686\n",
      "Epoch 313/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0628 - accuracy: 0.9754\n",
      "Epoch 314/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9563\n",
      "Epoch 315/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0889 - accuracy: 0.9509\n",
      "Epoch 316/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0623 - accuracy: 0.9727\n",
      "Epoch 317/1500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0543 - accuracy: 0.9727\n",
      "Epoch 318/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9741\n",
      "Epoch 319/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9700\n",
      "Epoch 320/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9645\n",
      "Epoch 321/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9645\n",
      "Epoch 322/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9659\n",
      "Epoch 323/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9741\n",
      "Epoch 324/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9727\n",
      "Epoch 325/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9673\n",
      "Epoch 326/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0635 - accuracy: 0.9727\n",
      "Epoch 327/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0820 - accuracy: 0.9577\n",
      "Epoch 328/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.9604\n",
      "Epoch 329/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9700\n",
      "Epoch 330/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0645 - accuracy: 0.9686\n",
      "Epoch 331/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9768\n",
      "Epoch 332/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9714\n",
      "Epoch 333/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9714\n",
      "Epoch 334/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9659\n",
      "Epoch 335/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9673\n",
      "Epoch 336/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9700\n",
      "Epoch 337/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9741\n",
      "Epoch 338/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9754\n",
      "Epoch 339/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 0.9754\n",
      "Epoch 340/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9714\n",
      "Epoch 341/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9754\n",
      "Epoch 342/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9754\n",
      "Epoch 343/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9618\n",
      "Epoch 344/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9632\n",
      "Epoch 345/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0623 - accuracy: 0.9700\n",
      "Epoch 346/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 0.9632\n",
      "Epoch 347/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9700\n",
      "Epoch 348/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9714\n",
      "Epoch 349/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9714\n",
      "Epoch 350/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9727\n",
      "Epoch 351/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0559 - accuracy: 0.9768\n",
      "Epoch 352/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9700\n",
      "Epoch 353/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9809\n",
      "Epoch 354/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9768\n",
      "Epoch 355/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9659\n",
      "Epoch 356/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9823\n",
      "Epoch 357/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 0.9782\n",
      "Epoch 358/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9673\n",
      "Epoch 359/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9673\n",
      "Epoch 360/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9782\n",
      "Epoch 361/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9754\n",
      "Epoch 362/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9768\n",
      "Epoch 363/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 0.9782\n",
      "Epoch 364/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9645\n",
      "Epoch 365/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9727\n",
      "Epoch 366/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9782\n",
      "Epoch 367/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9754\n",
      "Epoch 368/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9782\n",
      "Epoch 369/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9782\n",
      "Epoch 370/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9782\n",
      "Epoch 371/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9741\n",
      "Epoch 372/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9782\n",
      "Epoch 373/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0663 - accuracy: 0.9700\n",
      "Epoch 374/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9768\n",
      "Epoch 375/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0538 - accuracy: 0.9768\n",
      "Epoch 376/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9618\n",
      "Epoch 377/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9714\n",
      "Epoch 378/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9795\n",
      "Epoch 379/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 0.9795\n",
      "Epoch 380/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0538 - accuracy: 0.9823\n",
      "Epoch 381/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 0.9686\n",
      "Epoch 382/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9836\n",
      "Epoch 383/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0645 - accuracy: 0.9768\n",
      "Epoch 384/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9782\n",
      "Epoch 385/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9754\n",
      "Epoch 386/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0571 - accuracy: 0.9741\n",
      "Epoch 387/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9659\n",
      "Epoch 388/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0670 - accuracy: 0.9741\n",
      "Epoch 389/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9686\n",
      "Epoch 390/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9754\n",
      "Epoch 391/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9795\n",
      "Epoch 392/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.9809\n",
      "Epoch 393/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9754\n",
      "Epoch 394/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9782\n",
      "Epoch 395/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9768\n",
      "Epoch 396/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.9850\n",
      "Epoch 397/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9741\n",
      "Epoch 398/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9836\n",
      "Epoch 399/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9768\n",
      "Epoch 400/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9700\n",
      "Epoch 401/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9850\n",
      "Epoch 402/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9768\n",
      "Epoch 403/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9823\n",
      "Epoch 404/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 0.9795\n",
      "Epoch 405/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 0.9795\n",
      "Epoch 406/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9809\n",
      "Epoch 407/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9809\n",
      "Epoch 408/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0513 - accuracy: 0.9850\n",
      "Epoch 409/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0528 - accuracy: 0.9714\n",
      "Epoch 410/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0596 - accuracy: 0.9727\n",
      "Epoch 411/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9823\n",
      "Epoch 412/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9782\n",
      "Epoch 413/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9809\n",
      "Epoch 414/1500\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0556 - accuracy: 0.9659\n",
      "Epoch 415/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9714\n",
      "Epoch 416/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9645\n",
      "Epoch 417/1500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9823\n",
      "Epoch 418/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 0.9864\n",
      "Epoch 419/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9809\n",
      "Epoch 420/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9823\n",
      "Epoch 421/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9673\n",
      "Epoch 422/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9714\n",
      "Epoch 423/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0485 - accuracy: 0.9809\n",
      "Epoch 424/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0518 - accuracy: 0.9823\n",
      "Epoch 425/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9809\n",
      "Epoch 426/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9823\n",
      "Epoch 427/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0472 - accuracy: 0.9809\n",
      "Epoch 428/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9673\n",
      "Epoch 429/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9782\n",
      "Epoch 430/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9836\n",
      "Epoch 431/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9836\n",
      "Epoch 432/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9864\n",
      "Epoch 433/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0569 - accuracy: 0.9727\n",
      "Epoch 434/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0455 - accuracy: 0.9809\n",
      "Epoch 435/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9850\n",
      "Epoch 436/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9850\n",
      "Epoch 437/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0534 - accuracy: 0.9727\n",
      "Epoch 438/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 0.9864\n",
      "Epoch 439/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 0.9877\n",
      "Epoch 440/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9768\n",
      "Epoch 441/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9795\n",
      "Epoch 442/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9809\n",
      "Epoch 443/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0470 - accuracy: 0.9809\n",
      "Epoch 444/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9727\n",
      "Epoch 445/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9754\n",
      "Epoch 446/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9823\n",
      "Epoch 447/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 0.9850\n",
      "Epoch 448/1500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.0261 - accuracy: 0.9688Restoring model weights from the end of the best epoch: 418.\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0426 - accuracy: 0.9795\n",
      "Epoch 448: early stopping\n",
      "7/7 [==============================] - 0s 859us/step - loss: 1.0226 - accuracy: 0.6912\n",
      "7/7 [==============================] - 0s 679us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy for cat_id for this fold: 0.64 (18/28)\n",
      "Before appending - Cat IDs: 218, Predictions: 218, Actuals: 218, Gender: 218\n",
      "After appending - Cat IDs: 422, Predictions: 422, Actuals: 422, Gender: 422\n",
      "Final Test Results - Loss: 1.0226013660430908, Accuracy: 0.6911764740943909, Precision: 0.6654040404040404, Recall: 0.6880385487528344, F1 Score: 0.6750358422939068\n",
      "Confusion Matrix:\n",
      " [[89  8 23]\n",
      " [ 2 32  1]\n",
      " [29  0 20]]\n",
      "outer_fold 3\n",
      "Train Set Group Distribution:\n",
      "000A    39\n",
      "103A    33\n",
      "002B    32\n",
      "047A    28\n",
      "057A    27\n",
      "074A    25\n",
      "055A    20\n",
      "000B    19\n",
      "019A    17\n",
      "029A    17\n",
      "101A    15\n",
      "001A    14\n",
      "097B    14\n",
      "042A    14\n",
      "106A    14\n",
      "111A    13\n",
      "028A    13\n",
      "002A    13\n",
      "051A    12\n",
      "116A    12\n",
      "039A    12\n",
      "068A    11\n",
      "025A    11\n",
      "036A    11\n",
      "063A    11\n",
      "014B    10\n",
      "040A    10\n",
      "071A    10\n",
      "005A    10\n",
      "016A    10\n",
      "051B     9\n",
      "033A     9\n",
      "065A     9\n",
      "015A     9\n",
      "045A     9\n",
      "095A     8\n",
      "117A     7\n",
      "099A     7\n",
      "031A     7\n",
      "023A     6\n",
      "007A     6\n",
      "108A     6\n",
      "053A     6\n",
      "021A     5\n",
      "023B     5\n",
      "025C     5\n",
      "070A     5\n",
      "034A     5\n",
      "044A     5\n",
      "075A     5\n",
      "035A     4\n",
      "052A     4\n",
      "026A     4\n",
      "104A     4\n",
      "105A     4\n",
      "062A     4\n",
      "012A     3\n",
      "006A     3\n",
      "056A     3\n",
      "113A     3\n",
      "060A     3\n",
      "011A     2\n",
      "061A     2\n",
      "102A     2\n",
      "069A     2\n",
      "038A     2\n",
      "093A     2\n",
      "018A     2\n",
      "054A     2\n",
      "088A     1\n",
      "090A     1\n",
      "110A     1\n",
      "091A     1\n",
      "019B     1\n",
      "092A     1\n",
      "004A     1\n",
      "049A     1\n",
      "076A     1\n",
      "043A     1\n",
      "026C     1\n",
      "073A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "046A    63\n",
      "020A    23\n",
      "067A    19\n",
      "097A    16\n",
      "059A    14\n",
      "022A     9\n",
      "072A     9\n",
      "010A     8\n",
      "094A     8\n",
      "013B     8\n",
      "050A     7\n",
      "027A     7\n",
      "037A     6\n",
      "109A     6\n",
      "008A     6\n",
      "009A     4\n",
      "003A     4\n",
      "014A     3\n",
      "058A     3\n",
      "064A     3\n",
      "025B     2\n",
      "087A     2\n",
      "032A     2\n",
      "066A     1\n",
      "048A     1\n",
      "041A     1\n",
      "115A     1\n",
      "096A     1\n",
      "100A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "M    243\n",
      "X    229\n",
      "F    226\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    119\n",
      "M     94\n",
      "F     26\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 000A, 033A, 015A, 001A, 103A, 071A, 097...\n",
      "kitten    [044A, 014B, 111A, 040A, 047A, 042A, 043A, 049...\n",
      "senior    [093A, 057A, 106A, 104A, 055A, 113A, 116A, 051...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [067A, 020A, 022A, 072A, 009A, 027A, 013B, 014...\n",
      "kitten                 [046A, 109A, 050A, 041A, 048A, 115A]\n",
      "senior                       [097A, 059A, 058A, 094A, 024A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 55, 'kitten': 10, 'senior': 17}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 19, 'kitten': 6, 'senior': 5}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '002B' '004A' '005A' '006A' '007A' '011A'\n",
      " '012A' '014B' '015A' '016A' '018A' '019A' '019B' '021A' '023A' '023B'\n",
      " '025A' '025C' '026A' '026B' '026C' '028A' '029A' '031A' '033A' '034A'\n",
      " '035A' '036A' '038A' '039A' '040A' '042A' '043A' '044A' '045A' '047A'\n",
      " '049A' '051A' '051B' '052A' '053A' '054A' '055A' '056A' '057A' '060A'\n",
      " '061A' '062A' '063A' '065A' '068A' '069A' '070A' '071A' '073A' '074A'\n",
      " '075A' '076A' '088A' '090A' '091A' '092A' '093A' '095A' '097B' '099A'\n",
      " '101A' '102A' '103A' '104A' '105A' '106A' '108A' '110A' '111A' '113A'\n",
      " '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['003A' '008A' '009A' '010A' '013B' '014A' '020A' '022A' '024A' '025B'\n",
      " '027A' '032A' '037A' '041A' '046A' '048A' '050A' '058A' '059A' '064A'\n",
      " '066A' '067A' '072A' '087A' '094A' '096A' '097A' '100A' '109A' '115A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "{'046A'}\n",
      "Removed from Training/Validation Set:\n",
      "{'042A'}\n",
      "Moved to Test Set:\n",
      "{'042A'}\n",
      "Removed from Test Set\n",
      "{'046A'}\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '002B' '004A' '005A' '006A' '007A' '011A'\n",
      " '012A' '014B' '015A' '016A' '018A' '019A' '019B' '021A' '023A' '023B'\n",
      " '025A' '025C' '026A' '026B' '026C' '028A' '029A' '031A' '033A' '034A'\n",
      " '035A' '036A' '038A' '039A' '040A' '043A' '044A' '045A' '046A' '047A'\n",
      " '049A' '051A' '051B' '052A' '053A' '054A' '055A' '056A' '057A' '060A'\n",
      " '061A' '062A' '063A' '065A' '068A' '069A' '070A' '071A' '073A' '074A'\n",
      " '075A' '076A' '088A' '090A' '091A' '092A' '093A' '095A' '097B' '099A'\n",
      " '101A' '102A' '103A' '104A' '105A' '106A' '108A' '110A' '111A' '113A'\n",
      " '116A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['003A' '008A' '009A' '010A' '013B' '014A' '020A' '022A' '024A' '025B'\n",
      " '027A' '032A' '037A' '041A' '042A' '048A' '050A' '058A' '059A' '064A'\n",
      " '066A' '067A' '072A' '087A' '094A' '096A' '097A' '100A' '109A' '115A']\n",
      "Length of X_train_val:\n",
      "747\n",
      "Length of y_train_val:\n",
      "747\n",
      "Length of groups_train_val:\n",
      "747\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     470\n",
      "senior    136\n",
      "kitten     92\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     118\n",
      "kitten     79\n",
      "senior     42\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     470\n",
      "kitten    141\n",
      "senior    136\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     118\n",
      "senior     42\n",
      "kitten     30\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 470, 1: 141, 2: 136})\n",
      "Epoch 1/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 1.1689 - accuracy: 0.4618\n",
      "Epoch 2/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.8372 - accuracy: 0.5489\n",
      "Epoch 3/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.7467 - accuracy: 0.5904\n",
      "Epoch 4/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.6037\n",
      "Epoch 5/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6703 - accuracy: 0.6372\n",
      "Epoch 6/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.6104\n",
      "Epoch 7/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6519\n",
      "Epoch 8/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6021 - accuracy: 0.6466\n",
      "Epoch 9/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6243 - accuracy: 0.6640\n",
      "Epoch 10/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.6975\n",
      "Epoch 11/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.6734\n",
      "Epoch 12/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5577 - accuracy: 0.6975\n",
      "Epoch 13/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.6894\n",
      "Epoch 14/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5733 - accuracy: 0.6787\n",
      "Epoch 15/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7122\n",
      "Epoch 16/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.7229\n",
      "Epoch 17/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7323\n",
      "Epoch 18/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7443\n",
      "Epoch 19/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7363\n",
      "Epoch 20/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7349\n",
      "Epoch 21/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7577\n",
      "Epoch 22/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7416\n",
      "Epoch 23/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7483\n",
      "Epoch 24/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7497\n",
      "Epoch 25/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7537\n",
      "Epoch 26/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7590\n",
      "Epoch 27/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7738\n",
      "Epoch 28/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.7711\n",
      "Epoch 29/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7751\n",
      "Epoch 30/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4109 - accuracy: 0.7791\n",
      "Epoch 31/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4233 - accuracy: 0.7778\n",
      "Epoch 32/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7657\n",
      "Epoch 33/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.7751\n",
      "Epoch 34/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.7898\n",
      "Epoch 35/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.7965\n",
      "Epoch 36/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8046\n",
      "Epoch 37/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.7885\n",
      "Epoch 38/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3861 - accuracy: 0.7925\n",
      "Epoch 39/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8153\n",
      "Epoch 40/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.7898\n",
      "Epoch 41/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4079 - accuracy: 0.7845\n",
      "Epoch 42/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8179\n",
      "Epoch 43/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8166\n",
      "Epoch 44/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.8032\n",
      "Epoch 45/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8126\n",
      "Epoch 46/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.7831\n",
      "Epoch 47/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3834 - accuracy: 0.8019\n",
      "Epoch 48/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3713 - accuracy: 0.8099\n",
      "Epoch 49/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8032\n",
      "Epoch 50/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.8005\n",
      "Epoch 51/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8139\n",
      "Epoch 52/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8139\n",
      "Epoch 53/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8032\n",
      "Epoch 54/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3761 - accuracy: 0.8046\n",
      "Epoch 55/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.7912\n",
      "Epoch 56/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8300\n",
      "Epoch 57/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.8153\n",
      "Epoch 58/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8153\n",
      "Epoch 59/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3147 - accuracy: 0.8300\n",
      "Epoch 60/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3192 - accuracy: 0.8193\n",
      "Epoch 61/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8353\n",
      "Epoch 62/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8206\n",
      "Epoch 63/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8313\n",
      "Epoch 64/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2905 - accuracy: 0.8501\n",
      "Epoch 65/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8380\n",
      "Epoch 66/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8220\n",
      "Epoch 67/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3400 - accuracy: 0.8246\n",
      "Epoch 68/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8353\n",
      "Epoch 69/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8300\n",
      "Epoch 70/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3103 - accuracy: 0.8340\n",
      "Epoch 71/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3051 - accuracy: 0.8260\n",
      "Epoch 72/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3063 - accuracy: 0.8394\n",
      "Epoch 73/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2943 - accuracy: 0.8527\n",
      "Epoch 74/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 0.8420\n",
      "Epoch 75/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3026 - accuracy: 0.8541\n",
      "Epoch 76/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2836 - accuracy: 0.8474\n",
      "Epoch 77/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2934 - accuracy: 0.8434\n",
      "Epoch 78/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8447\n",
      "Epoch 79/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8380\n",
      "Epoch 80/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3167 - accuracy: 0.8233\n",
      "Epoch 81/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.8394\n",
      "Epoch 82/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2918 - accuracy: 0.8420\n",
      "Epoch 83/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2819 - accuracy: 0.8380\n",
      "Epoch 84/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.8568\n",
      "Epoch 85/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2758 - accuracy: 0.8554\n",
      "Epoch 86/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3040 - accuracy: 0.8501\n",
      "Epoch 87/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2625 - accuracy: 0.8768\n",
      "Epoch 88/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.8608\n",
      "Epoch 89/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.8675\n",
      "Epoch 90/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2606 - accuracy: 0.8461\n",
      "Epoch 91/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2613 - accuracy: 0.8688\n",
      "Epoch 92/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2551 - accuracy: 0.8795\n",
      "Epoch 93/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2640 - accuracy: 0.8594\n",
      "Epoch 94/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2546 - accuracy: 0.8675\n",
      "Epoch 95/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.8621\n",
      "Epoch 96/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2530 - accuracy: 0.8715\n",
      "Epoch 97/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2600 - accuracy: 0.8568\n",
      "Epoch 98/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2581 - accuracy: 0.8581\n",
      "Epoch 99/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2559 - accuracy: 0.8581\n",
      "Epoch 100/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2721 - accuracy: 0.8487\n",
      "Epoch 101/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2872 - accuracy: 0.8675\n",
      "Epoch 102/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2552 - accuracy: 0.8581\n",
      "Epoch 103/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.8715\n",
      "Epoch 104/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2803 - accuracy: 0.8407\n",
      "Epoch 105/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.8514\n",
      "Epoch 106/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.8795\n",
      "Epoch 107/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.8835\n",
      "Epoch 108/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.8768\n",
      "Epoch 109/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2262 - accuracy: 0.8862\n",
      "Epoch 110/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.8822\n",
      "Epoch 111/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.8715\n",
      "Epoch 112/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.8742\n",
      "Epoch 113/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2439 - accuracy: 0.8755\n",
      "Epoch 114/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.8942\n",
      "Epoch 115/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2682 - accuracy: 0.8715\n",
      "Epoch 116/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.8849\n",
      "Epoch 117/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.8648\n",
      "Epoch 118/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.8755\n",
      "Epoch 119/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2141 - accuracy: 0.8956\n",
      "Epoch 120/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.8755\n",
      "Epoch 121/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.8635\n",
      "Epoch 122/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2811 - accuracy: 0.8742\n",
      "Epoch 123/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.8795\n",
      "Epoch 124/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.8835\n",
      "Epoch 125/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.8876\n",
      "Epoch 126/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2121 - accuracy: 0.8876\n",
      "Epoch 127/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.8916\n",
      "Epoch 128/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.8862\n",
      "Epoch 129/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.8862\n",
      "Epoch 130/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.8755\n",
      "Epoch 131/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.8996\n",
      "Epoch 132/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2162 - accuracy: 0.8809\n",
      "Epoch 133/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.8996\n",
      "Epoch 134/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.8902\n",
      "Epoch 135/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2090 - accuracy: 0.8889\n",
      "Epoch 136/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.9063\n",
      "Epoch 137/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.8849\n",
      "Epoch 138/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.8983\n",
      "Epoch 139/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9076\n",
      "Epoch 140/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2030 - accuracy: 0.8929\n",
      "Epoch 141/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.9090\n",
      "Epoch 142/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.8795\n",
      "Epoch 143/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.8916\n",
      "Epoch 144/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.8809\n",
      "Epoch 145/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.8942\n",
      "Epoch 146/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.8969\n",
      "Epoch 147/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.9143\n",
      "Epoch 148/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.8983\n",
      "Epoch 149/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.9063\n",
      "Epoch 150/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.8969\n",
      "Epoch 151/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.8902\n",
      "Epoch 152/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.8876\n",
      "Epoch 153/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2096 - accuracy: 0.8969\n",
      "Epoch 154/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.8996\n",
      "Epoch 155/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.9090\n",
      "Epoch 156/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.8929\n",
      "Epoch 157/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9197\n",
      "Epoch 158/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.8969\n",
      "Epoch 159/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.9023\n",
      "Epoch 160/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9063\n",
      "Epoch 161/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.8969\n",
      "Epoch 162/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1913 - accuracy: 0.9130\n",
      "Epoch 163/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9063\n",
      "Epoch 164/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.9076\n",
      "Epoch 165/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.8956\n",
      "Epoch 166/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.9116\n",
      "Epoch 167/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.9023\n",
      "Epoch 168/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9170\n",
      "Epoch 169/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.9036\n",
      "Epoch 170/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.9063\n",
      "Epoch 171/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9210\n",
      "Epoch 172/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1738 - accuracy: 0.9183\n",
      "Epoch 173/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.8889\n",
      "Epoch 174/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.8835\n",
      "Epoch 175/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.9050\n",
      "Epoch 176/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1724 - accuracy: 0.9116\n",
      "Epoch 177/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9183\n",
      "Epoch 178/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9277\n",
      "Epoch 179/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9210\n",
      "Epoch 180/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9304\n",
      "Epoch 181/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1692 - accuracy: 0.9009\n",
      "Epoch 182/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 0.9009\n",
      "Epoch 183/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9116\n",
      "Epoch 184/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9197\n",
      "Epoch 185/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.9009\n",
      "Epoch 186/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9183\n",
      "Epoch 187/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.9143\n",
      "Epoch 188/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1725 - accuracy: 0.9103\n",
      "Epoch 189/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.9036\n",
      "Epoch 190/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.9090\n",
      "Epoch 191/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1658 - accuracy: 0.9090\n",
      "Epoch 192/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1713 - accuracy: 0.9157\n",
      "Epoch 193/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9237\n",
      "Epoch 194/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9290\n",
      "Epoch 195/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9210\n",
      "Epoch 196/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9277\n",
      "Epoch 197/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9076\n",
      "Epoch 198/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.9224\n",
      "Epoch 199/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9264\n",
      "Epoch 200/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9250\n",
      "Epoch 201/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9250\n",
      "Epoch 202/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9250\n",
      "Epoch 203/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9103\n",
      "Epoch 204/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9170\n",
      "Epoch 205/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9250\n",
      "Epoch 206/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.9264\n",
      "Epoch 207/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9224\n",
      "Epoch 208/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9237\n",
      "Epoch 209/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9357\n",
      "Epoch 210/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.9250\n",
      "Epoch 211/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9277\n",
      "Epoch 212/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9290\n",
      "Epoch 213/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.9344\n",
      "Epoch 214/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9277\n",
      "Epoch 215/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9210\n",
      "Epoch 216/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9398\n",
      "Epoch 217/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9277\n",
      "Epoch 218/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9157\n",
      "Epoch 219/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.9317\n",
      "Epoch 220/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9277\n",
      "Epoch 221/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9317\n",
      "Epoch 222/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9116\n",
      "Epoch 223/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9317\n",
      "Epoch 224/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.9384\n",
      "Epoch 225/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1718 - accuracy: 0.9183\n",
      "Epoch 226/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.9384\n",
      "Epoch 227/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9478\n",
      "Epoch 228/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9331\n",
      "Epoch 229/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9384\n",
      "Epoch 230/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9357\n",
      "Epoch 231/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9290\n",
      "Epoch 232/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9344\n",
      "Epoch 233/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9384\n",
      "Epoch 234/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9304\n",
      "Epoch 235/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.9357\n",
      "Epoch 236/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.9250\n",
      "Epoch 237/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9424\n",
      "Epoch 238/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.9317\n",
      "Epoch 239/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9424\n",
      "Epoch 240/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9143\n",
      "Epoch 241/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9331\n",
      "Epoch 242/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1449 - accuracy: 0.9250\n",
      "Epoch 243/1500\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.1501 - accuracy: 0.9183\n",
      "Epoch 244/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9344\n",
      "Epoch 245/1500\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.9411\n",
      "Epoch 246/1500\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.9531\n",
      "Epoch 247/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9438\n",
      "Epoch 248/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9224\n",
      "Epoch 249/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9264\n",
      "Epoch 250/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1664 - accuracy: 0.9183\n",
      "Epoch 251/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9411\n",
      "Epoch 252/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9170\n",
      "Epoch 253/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9371\n",
      "Epoch 254/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9398\n",
      "Epoch 255/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9424\n",
      "Epoch 256/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9371\n",
      "Epoch 257/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9264\n",
      "Epoch 258/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9317\n",
      "Epoch 259/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9438\n",
      "Epoch 260/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9424\n",
      "Epoch 261/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9398\n",
      "Epoch 262/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1144 - accuracy: 0.9478\n",
      "Epoch 263/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9384\n",
      "Epoch 264/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9465\n",
      "Epoch 265/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9465\n",
      "Epoch 266/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9398\n",
      "Epoch 267/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.9478\n",
      "Epoch 268/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9465\n",
      "Epoch 269/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9491\n",
      "Epoch 270/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.9384\n",
      "Epoch 271/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9304\n",
      "Epoch 272/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9371\n",
      "Epoch 273/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9371\n",
      "Epoch 274/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9465\n",
      "Epoch 275/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9451\n",
      "Epoch 276/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9277\n",
      "Epoch 277/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9438\n",
      "Epoch 278/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9398\n",
      "Epoch 279/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9491\n",
      "Epoch 280/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9331\n",
      "Epoch 281/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9424\n",
      "Epoch 282/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9465\n",
      "Epoch 283/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9465\n",
      "Epoch 284/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9478\n",
      "Epoch 285/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9478\n",
      "Epoch 286/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9505\n",
      "Epoch 287/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.9465\n",
      "Epoch 288/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9598\n",
      "Epoch 289/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9371\n",
      "Epoch 290/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9344\n",
      "Epoch 291/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.9317\n",
      "Epoch 292/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9438\n",
      "Epoch 293/1500\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9398\n",
      "Epoch 294/1500\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.0849 - accuracy: 0.9375Restoring model weights from the end of the best epoch: 264.\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9545\n",
      "Epoch 294: early stopping\n",
      "6/6 [==============================] - 0s 935us/step - loss: 0.4737 - accuracy: 0.8316\n",
      "6/6 [==============================] - 0s 692us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy for cat_id for this fold: 0.83 (25/30)\n",
      "Before appending - Cat IDs: 422, Predictions: 422, Actuals: 422, Gender: 422\n",
      "After appending - Cat IDs: 612, Predictions: 612, Actuals: 612, Gender: 612\n",
      "Final Test Results - Loss: 0.47370749711990356, Accuracy: 0.8315789699554443, Precision: 0.834906856261023, Recall: 0.7863868711326338, F1 Score: 0.8074787856559359\n",
      "Confusion Matrix:\n",
      " [[107   2   9]\n",
      " [  5  25   0]\n",
      " [ 16   0  26]]\n",
      "outer_fold 4\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "000A    39\n",
      "002B    32\n",
      "074A    25\n",
      "020A    23\n",
      "000B    19\n",
      "067A    19\n",
      "029A    17\n",
      "019A    17\n",
      "097A    16\n",
      "001A    14\n",
      "097B    14\n",
      "106A    14\n",
      "059A    14\n",
      "042A    14\n",
      "111A    13\n",
      "039A    12\n",
      "051A    12\n",
      "116A    12\n",
      "068A    11\n",
      "036A    11\n",
      "063A    11\n",
      "016A    10\n",
      "005A    10\n",
      "040A    10\n",
      "014B    10\n",
      "071A    10\n",
      "022A     9\n",
      "015A     9\n",
      "065A     9\n",
      "045A     9\n",
      "072A     9\n",
      "051B     9\n",
      "095A     8\n",
      "013B     8\n",
      "010A     8\n",
      "094A     8\n",
      "027A     7\n",
      "050A     7\n",
      "117A     7\n",
      "037A     6\n",
      "053A     6\n",
      "008A     6\n",
      "109A     6\n",
      "023A     6\n",
      "044A     5\n",
      "023B     5\n",
      "070A     5\n",
      "075A     5\n",
      "009A     4\n",
      "052A     4\n",
      "003A     4\n",
      "104A     4\n",
      "105A     4\n",
      "062A     4\n",
      "014A     3\n",
      "058A     3\n",
      "064A     3\n",
      "060A     3\n",
      "061A     2\n",
      "102A     2\n",
      "011A     2\n",
      "025B     2\n",
      "054A     2\n",
      "087A     2\n",
      "038A     2\n",
      "032A     2\n",
      "018A     2\n",
      "069A     2\n",
      "092A     1\n",
      "100A     1\n",
      "096A     1\n",
      "110A     1\n",
      "115A     1\n",
      "019B     1\n",
      "041A     1\n",
      "004A     1\n",
      "043A     1\n",
      "048A     1\n",
      "066A     1\n",
      "091A     1\n",
      "076A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "103A    33\n",
      "047A    28\n",
      "057A    27\n",
      "055A    20\n",
      "101A    15\n",
      "028A    13\n",
      "002A    13\n",
      "025A    11\n",
      "033A     9\n",
      "031A     7\n",
      "099A     7\n",
      "007A     6\n",
      "108A     6\n",
      "034A     5\n",
      "025C     5\n",
      "021A     5\n",
      "026A     4\n",
      "035A     4\n",
      "012A     3\n",
      "006A     3\n",
      "113A     3\n",
      "056A     3\n",
      "093A     2\n",
      "049A     1\n",
      "026C     1\n",
      "073A     1\n",
      "088A     1\n",
      "090A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    277\n",
      "M    271\n",
      "F    151\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "F    101\n",
      "X     71\n",
      "M     66\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [000A, 015A, 001A, 071A, 097B, 019A, 074A, 067...\n",
      "kitten    [044A, 014B, 111A, 040A, 046A, 042A, 109A, 050...\n",
      "senior    [097A, 106A, 104A, 059A, 116A, 051B, 054A, 117...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [006A, 033A, 103A, 028A, 101A, 034A, 002A, 099...\n",
      "kitten                                         [047A, 049A]\n",
      "senior           [093A, 057A, 055A, 113A, 056A, 108A, 090A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 54, 'kitten': 14, 'senior': 15}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 20, 'kitten': 2, 'senior': 7}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002B' '003A' '004A' '005A' '008A' '009A' '010A'\n",
      " '011A' '013B' '014A' '014B' '015A' '016A' '018A' '019A' '019B' '020A'\n",
      " '022A' '023A' '023B' '024A' '025B' '027A' '029A' '032A' '036A' '037A'\n",
      " '038A' '039A' '040A' '041A' '042A' '043A' '044A' '045A' '046A' '048A'\n",
      " '050A' '051A' '051B' '052A' '053A' '054A' '058A' '059A' '060A' '061A'\n",
      " '062A' '063A' '064A' '065A' '066A' '067A' '068A' '069A' '070A' '071A'\n",
      " '072A' '074A' '075A' '076A' '087A' '091A' '092A' '094A' '095A' '096A'\n",
      " '097A' '097B' '100A' '102A' '104A' '105A' '106A' '109A' '110A' '111A'\n",
      " '115A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['002A' '006A' '007A' '012A' '021A' '025A' '025C' '026A' '026B' '026C'\n",
      " '028A' '031A' '033A' '034A' '035A' '047A' '049A' '055A' '056A' '057A'\n",
      " '073A' '088A' '090A' '093A' '099A' '101A' '103A' '108A' '113A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "set()\n",
      "Removed from Training/Validation Set:\n",
      "set()\n",
      "Moved to Test Set:\n",
      "set()\n",
      "Removed from Test Set\n",
      "set()\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002B' '003A' '004A' '005A' '008A' '009A' '010A'\n",
      " '011A' '013B' '014A' '014B' '015A' '016A' '018A' '019A' '019B' '020A'\n",
      " '022A' '023A' '023B' '024A' '025B' '027A' '029A' '032A' '036A' '037A'\n",
      " '038A' '039A' '040A' '041A' '042A' '043A' '044A' '045A' '046A' '048A'\n",
      " '050A' '051A' '051B' '052A' '053A' '054A' '058A' '059A' '060A' '061A'\n",
      " '062A' '063A' '064A' '065A' '066A' '067A' '068A' '069A' '070A' '071A'\n",
      " '072A' '074A' '075A' '076A' '087A' '091A' '092A' '094A' '095A' '096A'\n",
      " '097A' '097B' '100A' '102A' '104A' '105A' '106A' '109A' '110A' '111A'\n",
      " '115A' '116A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['002A' '006A' '007A' '012A' '021A' '025A' '025C' '026A' '026B' '026C'\n",
      " '028A' '031A' '033A' '034A' '035A' '047A' '049A' '055A' '056A' '057A'\n",
      " '073A' '088A' '090A' '093A' '099A' '101A' '103A' '108A' '113A']\n",
      "Length of X_train_val:\n",
      "699\n",
      "Length of y_train_val:\n",
      "699\n",
      "Length of groups_train_val:\n",
      "699\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     441\n",
      "kitten    142\n",
      "senior    116\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     147\n",
      "senior     62\n",
      "kitten     29\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     441\n",
      "kitten    142\n",
      "senior    116\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     147\n",
      "senior     62\n",
      "kitten     29\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 441, 1: 142, 2: 116})\n",
      "Epoch 1/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 1.1582 - accuracy: 0.4177\n",
      "Epoch 2/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8895 - accuracy: 0.5336\n",
      "Epoch 3/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8147 - accuracy: 0.5751\n",
      "Epoch 4/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7418 - accuracy: 0.5837\n",
      "Epoch 5/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7125 - accuracy: 0.6023\n",
      "Epoch 6/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.6195\n",
      "Epoch 7/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.6423\n",
      "Epoch 8/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.6681\n",
      "Epoch 9/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6160 - accuracy: 0.6652\n",
      "Epoch 10/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.6810\n",
      "Epoch 11/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5790 - accuracy: 0.7182\n",
      "Epoch 12/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5622 - accuracy: 0.6967\n",
      "Epoch 13/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.6996\n",
      "Epoch 14/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5410 - accuracy: 0.7253\n",
      "Epoch 15/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.7124\n",
      "Epoch 16/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5288 - accuracy: 0.7124\n",
      "Epoch 17/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7554\n",
      "Epoch 18/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7325\n",
      "Epoch 19/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7568\n",
      "Epoch 20/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7711\n",
      "Epoch 21/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7425\n",
      "Epoch 22/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.7554\n",
      "Epoch 23/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.7611\n",
      "Epoch 24/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7883\n",
      "Epoch 25/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.7825\n",
      "Epoch 26/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.7797\n",
      "Epoch 27/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.7783\n",
      "Epoch 28/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.7868\n",
      "Epoch 29/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4263 - accuracy: 0.7811\n",
      "Epoch 30/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4051 - accuracy: 0.7926\n",
      "Epoch 31/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8011\n",
      "Epoch 32/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.7940\n",
      "Epoch 33/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.7811\n",
      "Epoch 34/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3807 - accuracy: 0.7926\n",
      "Epoch 35/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8340\n",
      "Epoch 36/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.7969\n",
      "Epoch 37/1500\n",
      "22/22 [==============================] - 0s 996us/step - loss: 0.3881 - accuracy: 0.8183\n",
      "Epoch 38/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8155\n",
      "Epoch 39/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3816 - accuracy: 0.8140\n",
      "Epoch 40/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8169\n",
      "Epoch 41/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8226\n",
      "Epoch 42/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8312\n",
      "Epoch 43/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8069\n",
      "Epoch 44/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8155\n",
      "Epoch 45/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8340\n",
      "Epoch 46/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8212\n",
      "Epoch 47/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8312\n",
      "Epoch 48/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3228 - accuracy: 0.8398\n",
      "Epoch 49/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3585 - accuracy: 0.8326\n",
      "Epoch 50/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8097\n",
      "Epoch 51/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3095 - accuracy: 0.8484\n",
      "Epoch 52/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3052 - accuracy: 0.8469\n",
      "Epoch 53/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3483 - accuracy: 0.8426\n",
      "Epoch 54/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3449 - accuracy: 0.8484\n",
      "Epoch 55/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.8312\n",
      "Epoch 56/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3119 - accuracy: 0.8455\n",
      "Epoch 57/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2965 - accuracy: 0.8398\n",
      "Epoch 58/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8226\n",
      "Epoch 59/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2946 - accuracy: 0.8426\n",
      "Epoch 60/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.8484\n",
      "Epoch 61/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8312\n",
      "Epoch 62/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8498\n",
      "Epoch 63/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3062 - accuracy: 0.8355\n",
      "Epoch 64/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8484\n",
      "Epoch 65/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8412\n",
      "Epoch 66/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2839 - accuracy: 0.8455\n",
      "Epoch 67/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2780 - accuracy: 0.8512\n",
      "Epoch 68/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.8412\n",
      "Epoch 69/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2881 - accuracy: 0.8612\n",
      "Epoch 70/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 0.8612\n",
      "Epoch 71/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2763 - accuracy: 0.8641\n",
      "Epoch 72/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2781 - accuracy: 0.8541\n",
      "Epoch 73/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2564 - accuracy: 0.8755\n",
      "Epoch 74/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2782 - accuracy: 0.8627\n",
      "Epoch 75/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3019 - accuracy: 0.8441\n",
      "Epoch 76/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.8712\n",
      "Epoch 77/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2765 - accuracy: 0.8584\n",
      "Epoch 78/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.8755\n",
      "Epoch 79/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2785 - accuracy: 0.8755\n",
      "Epoch 80/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.8856\n",
      "Epoch 81/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.8970\n",
      "Epoch 82/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.8798\n",
      "Epoch 83/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2627 - accuracy: 0.8712\n",
      "Epoch 84/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2718 - accuracy: 0.8670\n",
      "Epoch 85/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2721 - accuracy: 0.8598\n",
      "Epoch 86/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2393 - accuracy: 0.8755\n",
      "Epoch 87/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.8870\n",
      "Epoch 88/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2560 - accuracy: 0.8741\n",
      "Epoch 89/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2622 - accuracy: 0.8684\n",
      "Epoch 90/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.8956\n",
      "Epoch 91/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.8970\n",
      "Epoch 92/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2406 - accuracy: 0.8727\n",
      "Epoch 93/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.8970\n",
      "Epoch 94/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.8870\n",
      "Epoch 95/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2154 - accuracy: 0.8870\n",
      "Epoch 96/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.8984\n",
      "Epoch 97/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.8813\n",
      "Epoch 98/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2424 - accuracy: 0.8927\n",
      "Epoch 99/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.8870\n",
      "Epoch 100/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.9056\n",
      "Epoch 101/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.8841\n",
      "Epoch 102/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.8984\n",
      "Epoch 103/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.8913\n",
      "Epoch 104/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.8798\n",
      "Epoch 105/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.8870\n",
      "Epoch 106/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.8984\n",
      "Epoch 107/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.8684\n",
      "Epoch 108/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.8927\n",
      "Epoch 109/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.9041\n",
      "Epoch 110/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.8770\n",
      "Epoch 111/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2027 - accuracy: 0.9056\n",
      "Epoch 112/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.8884\n",
      "Epoch 113/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.9127\n",
      "Epoch 114/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.9084\n",
      "Epoch 115/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.8999\n",
      "Epoch 116/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.8870\n",
      "Epoch 117/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.9070\n",
      "Epoch 118/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2087 - accuracy: 0.9013\n",
      "Epoch 119/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.8999\n",
      "Epoch 120/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.9099\n",
      "Epoch 121/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9185\n",
      "Epoch 122/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9156\n",
      "Epoch 123/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.9084\n",
      "Epoch 124/1500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.9113\n",
      "Epoch 125/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.9070\n",
      "Epoch 126/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9070\n",
      "Epoch 127/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.9041\n",
      "Epoch 128/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.9142\n",
      "Epoch 129/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.8999\n",
      "Epoch 130/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2098 - accuracy: 0.9142\n",
      "Epoch 131/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.9084\n",
      "Epoch 132/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.9070\n",
      "Epoch 133/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9070\n",
      "Epoch 134/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.9070\n",
      "Epoch 135/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.9070\n",
      "Epoch 136/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.9084\n",
      "Epoch 137/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.9185\n",
      "Epoch 138/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.9156\n",
      "Epoch 139/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.9227\n",
      "Epoch 140/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.9170\n",
      "Epoch 141/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9041\n",
      "Epoch 142/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.9070\n",
      "Epoch 143/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9099\n",
      "Epoch 144/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9142\n",
      "Epoch 145/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.9127\n",
      "Epoch 146/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.8956\n",
      "Epoch 147/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.9156\n",
      "Epoch 148/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.8999\n",
      "Epoch 149/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1680 - accuracy: 0.9127\n",
      "Epoch 150/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9185\n",
      "Epoch 151/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9227\n",
      "Epoch 152/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1728 - accuracy: 0.9227\n",
      "Epoch 153/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.9127\n",
      "Epoch 154/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.8984\n",
      "Epoch 155/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.9156\n",
      "Epoch 156/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9299\n",
      "Epoch 157/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.8941\n",
      "Epoch 158/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9199\n",
      "Epoch 159/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9256\n",
      "Epoch 160/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.9213\n",
      "Epoch 161/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9328\n",
      "Epoch 162/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9256\n",
      "Epoch 163/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9442\n",
      "Epoch 164/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9285\n",
      "Epoch 165/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9428\n",
      "Epoch 166/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9328\n",
      "Epoch 167/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1741 - accuracy: 0.9185\n",
      "Epoch 168/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9113\n",
      "Epoch 169/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.9142\n",
      "Epoch 170/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9299\n",
      "Epoch 171/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9070\n",
      "Epoch 172/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9242\n",
      "Epoch 173/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9342\n",
      "Epoch 174/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9385\n",
      "Epoch 175/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9199\n",
      "Epoch 176/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.9127\n",
      "Epoch 177/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9399\n",
      "Epoch 178/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1622 - accuracy: 0.9213\n",
      "Epoch 179/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9256\n",
      "Epoch 180/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9285\n",
      "Epoch 181/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9442\n",
      "Epoch 182/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1297 - accuracy: 0.9356\n",
      "Epoch 183/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1556 - accuracy: 0.9199\n",
      "Epoch 184/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9242\n",
      "Epoch 185/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9499\n",
      "Epoch 186/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9313\n",
      "Epoch 187/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9442\n",
      "Epoch 188/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.9227\n",
      "Epoch 189/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1546 - accuracy: 0.9385\n",
      "Epoch 190/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.9170\n",
      "Epoch 191/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9285\n",
      "Epoch 192/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9485\n",
      "Epoch 193/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1495 - accuracy: 0.9256\n",
      "Epoch 194/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9328\n",
      "Epoch 195/1500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9471\n",
      "Epoch 196/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1496 - accuracy: 0.9242\n",
      "Epoch 197/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9256\n",
      "Epoch 198/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.9299\n",
      "Epoch 199/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9428\n",
      "Epoch 200/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.9399\n",
      "Epoch 201/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9356\n",
      "Epoch 202/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9399\n",
      "Epoch 203/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.9413\n",
      "Epoch 204/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9385\n",
      "Epoch 205/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9499\n",
      "Epoch 206/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9499\n",
      "Epoch 207/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.9385\n",
      "Epoch 208/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9456\n",
      "Epoch 209/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9385\n",
      "Epoch 210/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9442\n",
      "Epoch 211/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.9413\n",
      "Epoch 212/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9642\n",
      "Epoch 213/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9442\n",
      "Epoch 214/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9499\n",
      "Epoch 215/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.9385\n",
      "Epoch 216/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9185\n",
      "Epoch 217/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.9342\n",
      "Epoch 218/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9399\n",
      "Epoch 219/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9371\n",
      "Epoch 220/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9299\n",
      "Epoch 221/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9213\n",
      "Epoch 222/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9371\n",
      "Epoch 223/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9413\n",
      "Epoch 224/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9528\n",
      "Epoch 225/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9442\n",
      "Epoch 226/1500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9371\n",
      "Epoch 227/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1345 - accuracy: 0.9428\n",
      "Epoch 228/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9356\n",
      "Epoch 229/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9371\n",
      "Epoch 230/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9456\n",
      "Epoch 231/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9514\n",
      "Epoch 232/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9528\n",
      "Epoch 233/1500\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.1471 - accuracy: 0.9342\n",
      "Epoch 234/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9657\n",
      "Epoch 235/1500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1160 - accuracy: 0.9485\n",
      "Epoch 236/1500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.9442\n",
      "Epoch 237/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.9528\n",
      "Epoch 238/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9471\n",
      "Epoch 239/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9599\n",
      "Epoch 240/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.9499\n",
      "Epoch 241/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9585\n",
      "Epoch 242/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9571\n",
      "Epoch 243/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.9628\n",
      "Epoch 244/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9428\n",
      "Epoch 245/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9485\n",
      "Epoch 246/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9442\n",
      "Epoch 247/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9542\n",
      "Epoch 248/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9442\n",
      "Epoch 249/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9514\n",
      "Epoch 250/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9342\n",
      "Epoch 251/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9456\n",
      "Epoch 252/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.9442\n",
      "Epoch 253/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.9442\n",
      "Epoch 254/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9413\n",
      "Epoch 255/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9628\n",
      "Epoch 256/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1144 - accuracy: 0.9442\n",
      "Epoch 257/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9542\n",
      "Epoch 258/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9542\n",
      "Epoch 259/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0969 - accuracy: 0.9599\n",
      "Epoch 260/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9628\n",
      "Epoch 261/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9614\n",
      "Epoch 262/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9456\n",
      "Epoch 263/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9528\n",
      "Epoch 264/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9471\n",
      "Epoch 265/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9485\n",
      "Epoch 266/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9499\n",
      "Epoch 267/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.9485\n",
      "Epoch 268/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9685\n",
      "Epoch 269/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9471\n",
      "Epoch 270/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9542\n",
      "Epoch 271/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9585\n",
      "Epoch 272/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9499\n",
      "Epoch 273/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9442\n",
      "Epoch 274/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9485\n",
      "Epoch 275/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9557\n",
      "Epoch 276/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9571\n",
      "Epoch 277/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9642\n",
      "Epoch 278/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9528\n",
      "Epoch 279/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.9700\n",
      "Epoch 280/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9485\n",
      "Epoch 281/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9413\n",
      "Epoch 282/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1014 - accuracy: 0.9571\n",
      "Epoch 283/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.9585\n",
      "Epoch 284/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9528\n",
      "Epoch 285/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9528\n",
      "Epoch 286/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9657\n",
      "Epoch 287/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9528\n",
      "Epoch 288/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9571\n",
      "Epoch 289/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0789 - accuracy: 0.9671\n",
      "Epoch 290/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9428\n",
      "Epoch 291/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9514\n",
      "Epoch 292/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9571\n",
      "Epoch 293/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9585\n",
      "Epoch 294/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9485\n",
      "Epoch 295/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9571\n",
      "Epoch 296/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9614\n",
      "Epoch 297/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9642\n",
      "Epoch 298/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9657\n",
      "Epoch 299/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9542\n",
      "Epoch 300/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9628\n",
      "Epoch 301/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0748 - accuracy: 0.9714\n",
      "Epoch 302/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9499\n",
      "Epoch 303/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9542\n",
      "Epoch 304/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.9599\n",
      "Epoch 305/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.9585\n",
      "Epoch 306/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9614\n",
      "Epoch 307/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9628\n",
      "Epoch 308/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9514\n",
      "Epoch 309/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9585\n",
      "Epoch 310/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9585\n",
      "Epoch 311/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9614\n",
      "Epoch 312/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9528\n",
      "Epoch 313/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9628\n",
      "Epoch 314/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0816 - accuracy: 0.9628\n",
      "Epoch 315/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9614\n",
      "Epoch 316/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9571\n",
      "Epoch 317/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9599\n",
      "Epoch 318/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1015 - accuracy: 0.9571\n",
      "Epoch 319/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9742\n",
      "Epoch 320/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.9571\n",
      "Epoch 321/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9571\n",
      "Epoch 322/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9685\n",
      "Epoch 323/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9671\n",
      "Epoch 324/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.9585\n",
      "Epoch 325/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9585\n",
      "Epoch 326/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0844 - accuracy: 0.9685\n",
      "Epoch 327/1500\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.0256 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 297.\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9628\n",
      "Epoch 327: early stopping\n",
      "8/8 [==============================] - 0s 773us/step - loss: 0.9627 - accuracy: 0.6513\n",
      "8/8 [==============================] - 0s 587us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.72 (21/29)\n",
      "Before appending - Cat IDs: 612, Predictions: 612, Actuals: 612, Gender: 612\n",
      "After appending - Cat IDs: 850, Predictions: 850, Actuals: 850, Gender: 850\n",
      "Final Test Results - Loss: 0.9627315402030945, Accuracy: 0.651260495185852, Precision: 0.6768707482993198, Recall: 0.5950741438585074, F1 Score: 0.6262834262834263\n",
      "Confusion Matrix:\n",
      " [[116   1  30]\n",
      " [  9  20   0]\n",
      " [ 43   0  19]]\n",
      "\n",
      "Final Average F1-Score across all UNSEEN TEST sets: 0.6882806653052206\n",
      "\n",
      "Final Average Loss across all UNSEEN TEST sets: 0.8708054721355438\n",
      "\n",
      "Final Average Accuracy across all UNSEEN TEST sets: 0.7109351754188538\n",
      "\n",
      "Final Average Precision across all UNSEEN TEST sets: 0.7039501426988963\n",
      "\n",
      "Final Average Recall across all UNSEEN TEST sets: 0.7002572863183893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "all_cat_ids = []\n",
    "all_predicted_age_groups = []\n",
    "all_actual_age_groups = []\n",
    "all_gender = []\n",
    "\n",
    "# Define the StratifiedGroupKFold splitter for 4 fold CV with random shuffling\n",
    "outer_cv = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=int(random_seeds[2]))\n",
    "\n",
    "# unseen test set metrics\n",
    "unseen_losses, unseen_accuracies, unseen_precisions, unseen_recalls, unseen_f1 = [], [], [], [], []\n",
    "\n",
    "outer_fold = 0\n",
    "\n",
    "# Use the splitter to generate indices for training and testing sets\n",
    "# Note: GroupShuffleSplit.split returns indices, so we use it to index the arrays\n",
    "for train_val_idx, test_idx in outer_cv.split(X, y, groups):\n",
    "    outer_fold += 1\n",
    "    logger(f\"outer_fold {outer_fold}\", file=log_file_path)\n",
    "\n",
    "    # Convert indices back to DataFrame for easy manipulation\n",
    "    df_train_val = dataframe.iloc[train_val_idx]\n",
    "    df_test = dataframe.iloc[test_idx]\n",
    "\n",
    "    ##############################\n",
    "    # ASSESSING SPLITS BY CAT_ID #\n",
    "    ##############################\n",
    "    \n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test['cat_id'].value_counts()  \n",
    "    \n",
    "    # Log or print the distribution\n",
    "    logger(f\"Train Set Group Distribution:\\n{training_validation_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Group Distribution:\\n{testing_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test['gender'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Training Set Gender Distribution BEFORE SWAP:\\n{training_gender_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Gender Distribution BEFORE SWAP:\\n{testing_gender_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Group by 'age_group' and then list unique 'cat_id' within each age group\n",
    "    unique_cat_ids_per_age_group_train_val = df_train_val.groupby('age_group')['cat_id'].unique()\n",
    "    unique_cat_ids_per_age_group_test = df_test.groupby('age_group')['cat_id'].unique()\n",
    "    \n",
    "    # Log results\n",
    "    logger(f\"Unique Cat IDs per Age Group in Training/Validation Set:\\n{unique_cat_ids_per_age_group_train_val}\", file=log_file_path)\n",
    "    logger(f\"Unique Cat IDs per Age Group in Testing Set:\\n{unique_cat_ids_per_age_group_test}\", file=log_file_path)\n",
    "\n",
    "    # Calculate the count of unique identifiers per age group for training and testing set\n",
    "    counts_train_val = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_train_val.items()}\n",
    "    counts_test = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_test.items()}\n",
    "\n",
    "    # Log the counts of unique identifiers per age group\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Training/Validation Set:\\n{counts_train_val}\", file=log_file_path)\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Testing Set:\\n{counts_test}\", file=log_file_path)\n",
    "\n",
    "    #######################################################\n",
    "    # CONTINUE WITH ENSURING VALID AND APPROPRIATE SPLITS #\n",
    "    #######################################################\n",
    "    \n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    groups_train_val, groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # logging identifier splits \n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "\n",
    "    # check group splits\n",
    "    check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Specify the cat_ids that must be in the training/validation set\n",
    "    specific_cat_ids = ['000A', '046A']\n",
    "    \n",
    "    # Perform the swapping operation\n",
    "    train_val_idx, test_idx = swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids)\n",
    "    \n",
    "    # Re-assign the sets based on the updated indices\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    new_groups_train_val, new_groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # Find differences for training and test sets\n",
    "    moved_to_train_val, removed_from_train_val = find_group_differences(groups_train_val, new_groups_train_val)\n",
    "    moved_to_test, removed_from_test = find_group_differences(groups_test, new_groups_test)\n",
    "    \n",
    "    # Display the results\n",
    "    logger(f\"Moved to Training/Validation Set:\\n{moved_to_train_val}\", file=log_file_path)\n",
    "    logger(f\"Removed from Training/Validation Set:\\n{removed_from_train_val}\", file=log_file_path)\n",
    "    logger(f\"Moved to Test Set:\\n{moved_to_test}\", file=log_file_path)\n",
    "    logger(f\"Removed from Test Set\\n{removed_from_test}\", file=log_file_path)\n",
    "\n",
    "    # Update X_train_val, X_test, y_train_val, y_test, groups_train_val, groups_test based on updated indices\n",
    "    X_train_val = X[train_val_idx]\n",
    "    y_train_val = y[train_val_idx]\n",
    "    groups_train_val = groups[train_val_idx]\n",
    "    \n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    groups_test = groups[test_idx]\n",
    "\n",
    "    # logging identifier splits again after potential swaps\n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"AFTER SWAP - Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"AFTER SWAP - Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "    \n",
    "    # Verify the lengths are consistent\n",
    "    logger(f\"Length of X_train_val:\\n{len(X_train_val)}\", file=log_file_path)\n",
    "    logger(f\"Length of y_train_val:\\n{len(y_train_val)}\", file=log_file_path)\n",
    "    logger(f\"Length of groups_train_val:\\n{len(groups_train_val)}\", file=log_file_path)\n",
    "\n",
    "    # Check group splits once more\n",
    "    check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Convert the modified indices back to a DataFrame representing the updated df_train_val\n",
    "    df_train_val_updated = dataframe.iloc[train_val_idx].copy()\n",
    "    df_test_updated = dataframe.iloc[test_idx].copy()\n",
    "\n",
    "    ############################\n",
    "    # LOGGING AGE GROUP SPLITS #\n",
    "    ############################\n",
    "\n",
    "    # Get the distribution of age groups of age groups before the update\n",
    "    training_validation_age_group_distribution = df_train_val['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test['age_group'].value_counts()\n",
    "    \n",
    "    # Logthe distribution\n",
    "    logger(f\"Train Age Group Distribution BEFORE SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution BEFORE SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Get the distribution of age groups after the update\n",
    "    training_validation_age_group_distribution = df_train_val_updated['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test_updated['age_group'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Train Age Group Distribution AFTER SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution AFTER SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "    \n",
    "    ########################################################\n",
    "    # TRACKING FINAL CAT_IDs & GENDER AFTER REDISTRIBUTION #\n",
    "    ########################################################\n",
    "\n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val_updated['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test_updated['cat_id'].value_counts()  \n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val_updated['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test_updated['gender'].value_counts()\n",
    "    \n",
    "    logger(f\"\\n Starting training on unseen test set\\n\", file=log_file_path)\n",
    "\n",
    "    ###################\n",
    "    # PREPARING MODEL #\n",
    "    ###################\n",
    "\n",
    "    # Calculate the distribution of age groups in y_train_val\n",
    "    age_group_distribution = Counter(y_train_val)\n",
    "    print(\"Age group distribution:\", age_group_distribution)\n",
    "\n",
    "    # EarlyStopping callback: monitor 'loss' instead of 'val_loss' for the test set\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='loss',  \n",
    "        min_delta=0.001, \n",
    "        patience=30,  \n",
    "        verbose=1,  \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "\n",
    "    # One final shuffle to ensure randomness\n",
    "    outer_shuffle_idx = np.random.permutation(len(X_train_val))\n",
    "    X_train_val = X_train_val[outer_shuffle_idx]\n",
    "    y_train_val = y_train_val[outer_shuffle_idx]\n",
    "    \n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train_val),\n",
    "        y=y_train_val\n",
    "    )\n",
    "    weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "    # Scale the features\n",
    "    scaler_full = StandardScaler().fit(X_train_val)\n",
    "    X_train_full_scaled = scaler_full.transform(X_train_val)\n",
    "    X_test_scaled = scaler_full.transform(X_test)\n",
    "    \n",
    "    # Encode the labels\n",
    "    y_train_full_encoded = to_categorical(y_train_val)\n",
    "    y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "    #######################\n",
    "    # BUILD & TRAIN MODEL #\n",
    "    #######################\n",
    "\n",
    "    optimizers = {\n",
    "        'Adamax': Adamax(learning_rate=0.00038188800331973483)\n",
    "    }\n",
    "    \n",
    "    # Full model definition with dynamic number of layers\n",
    "    model_full = Sequential()\n",
    "    model_full.add(Dense(480, activation='relu', input_shape=(X_train_full_scaled.shape[1],)))  # units_l0 and activation from parameters\n",
    "    model_full.add(BatchNormalization())\n",
    "    model_full.add(Dropout(0.27188281261238406))  \n",
    "    model_full.add(Dense(3, activation='softmax'))  \n",
    "    \n",
    "    optimizer = optimizers['Adamax']  # optimizer_key from parameters\n",
    "    \n",
    "    # Compile the model\n",
    "    model_full.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model on the full training set\n",
    "    history_full = model_full.fit(X_train_full_scaled, y_train_full_encoded, epochs=1500, batch_size=32,\n",
    "                                  verbose=1, callbacks=[early_stopping], class_weight=weight_dict)\n",
    "    \n",
    "    # Evaluate the model on the held-out test set\n",
    "    test_loss, test_accuracy = model_full.evaluate(X_test_scaled, y_test_encoded)\n",
    "\n",
    "    y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    y_test_pred = np.argmax(y_test_pred_prob, axis=1)  \n",
    "    y_test_true = np.argmax(y_test_encoded, axis=1)    \n",
    "\n",
    "    ################################\n",
    "    # LOG MAJORITY VOTE PER CAT_ID #\n",
    "    ################################\n",
    "\n",
    "    # Convert numeric predictions back to age group labels\n",
    "    predicted_age_groups = label_encoder.inverse_transform(y_test_pred)\n",
    "    actual_labels = label_encoder.inverse_transform(y_test_true)\n",
    "    \n",
    "    # Map predictions and actual labels back to cat_ids\n",
    "    test_results = pd.DataFrame({\n",
    "        'cat_id': df_test_updated['cat_id'],\n",
    "        'predicted_age_group': predicted_age_groups,\n",
    "        'actual_age_group': actual_labels\n",
    "    })\n",
    "    \n",
    "    # Group by cat_id and aggregate predicted age groups\n",
    "    majority_votes = test_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "    actual_groups = test_results.groupby('cat_id')['actual_age_group'].first()\n",
    "    \n",
    "    # Calculate the accuracy of majority voting\n",
    "    correct_predictions = (majority_votes == actual_groups).sum()\n",
    "    total_cats = len(actual_groups)\n",
    "    majority_vote_accuracy = correct_predictions / total_cats\n",
    "    \n",
    "    # Log the accuracy of the majority voting\n",
    "    logger(f\"Majority Vote Accuracy for cat_id for this fold: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)\n",
    "\n",
    "    ####################################################\n",
    "    # COLLECT PREDICTIONS FOR GENDER & CAT_ID ANALYSIS #\n",
    "    ####################################################\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'Before appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Extend lists with current fold results\n",
    "    all_cat_ids.extend(df_test_updated['cat_id'].tolist())\n",
    "    all_predicted_age_groups.extend(predicted_age_groups)\n",
    "    all_actual_age_groups.extend(actual_labels)\n",
    "    all_gender.extend(df_test_updated['gender'].tolist())\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'After appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    test_precision = precision_score(y_test_true, y_test_pred, average='macro')  # Use 'macro' for imbalanced datasets\n",
    "    test_recall = recall_score(y_test_true, y_test_pred, average='macro')\n",
    "    test_f1 = f1_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "    # prepare averages of outer metrics\n",
    "    unseen_f1.append(test_f1)\n",
    "    unseen_losses.append(test_loss)\n",
    "    unseen_accuracies.append(test_accuracy)\n",
    "    unseen_precisions.append(test_precision)\n",
    "    unseen_recalls.append(test_recall)\n",
    "\n",
    "    # Print final test results\n",
    "    logger(f\"Final Test Results - Loss: {test_loss}, Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}\", file=log_file_path)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    logger(f\"Confusion Matrix:\\n {cm}\", file=log_file_path)\n",
    "\n",
    "# Calculate the overall average metrics\n",
    "unseen_set_avg_f1 = np.mean(unseen_f1)\n",
    "unseen_set_avg_loss = np.mean(unseen_losses)\n",
    "unseen_set_avg_acc = np.mean(unseen_accuracies)\n",
    "unseen_set_avg_precision = np.mean(unseen_precisions)\n",
    "unseen_set_avg_recall = np.mean(unseen_recalls)\n",
    "\n",
    "logger(f\"\\nFinal Average F1-Score across all UNSEEN TEST sets: {unseen_set_avg_f1}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Loss across all UNSEEN TEST sets: {unseen_set_avg_loss}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Accuracy across all UNSEEN TEST sets: {unseen_set_avg_acc}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Precision across all UNSEEN TEST sets: {unseen_set_avg_precision}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Recall across all UNSEEN TEST sets: {unseen_set_avg_recall}\\n\", file=log_file_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be692ae4-6d3f-4353-b5bf-554d20da4df3",
   "metadata": {},
   "source": [
    "## Majority Voting on Total Entries per cat_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8da9a092-ed2e-4397-a6c8-2c4888735265",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking - Cat IDs: 850, Predictions: 850, Actuals: 850, Gender: 850\n"
     ]
    }
   ],
   "source": [
    "# Debugging print statements\n",
    "print(f'Checking - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "51cf386a-c49e-4716-ba15-aa3b7930419a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create results df\n",
    "full_results = pd.DataFrame({\n",
    "    'cat_id': all_cat_ids,\n",
    "    'predicted_age_group': all_predicted_age_groups,\n",
    "    'actual_age_group': all_actual_age_groups,\n",
    "    'all_gender': all_gender\n",
    "})\n",
    "\n",
    "# create a correct majority prediction column\n",
    "full_results['correct'] = full_results['predicted_age_group'] == full_results['actual_age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a8d43ac5-d50e-430d-98a1-ff4f45006bae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Majority Vote Accuracy for cat_id: 0.72 (79/110)\n"
     ]
    }
   ],
   "source": [
    "# Group by cat_id and aggregate predicted age groups\n",
    "majority_votes = full_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first()\n",
    "\n",
    "# Calculate the accuracy of majority voting\n",
    "correct_predictions = (majority_votes == actual_groups).sum()\n",
    "total_cats = len(actual_groups)\n",
    "majority_vote_accuracy = correct_predictions / total_cats\n",
    "\n",
    "logger(f\"Overall Majority Vote Accuracy for cat_id: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ccc9acb7-bb1b-42a6-bb25-cdf5a3356315",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Detailed df with predictions, actual labels, and comparison including majority vote\n",
    "detailed_results = full_results.groupby('cat_id').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Predictions': list(x['predicted_age_group']),\n",
    "        'Majority Vote': x['predicted_age_group'].mode()[0],\n",
    "        'Actual Age Group': x['actual_age_group'].iloc[0],\n",
    "        'Correct Majority Vote': x['predicted_age_group'].mode()[0] == x['actual_age_group'].iloc[0]\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Convert to DataFrame for better formatting and display\n",
    "detailed_results = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "95e69b27-cae1-4a3a-ba70-5244a11aadf1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Majority Vote</th>\n",
       "      <th>Actual Age Group</th>\n",
       "      <th>Correct Majority Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000B</td>\n",
       "      <td>[adult, adult, kitten, senior, adult, adult, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>039A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>072A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>071A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>070A</td>\n",
       "      <td>[adult, adult, senior, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>069A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>067A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>066A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>064A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>062A</td>\n",
       "      <td>[kitten, kitten, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>053A</td>\n",
       "      <td>[adult, adult, senior, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>051B</td>\n",
       "      <td>[senior, adult, senior, adult, senior, adult, ...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>051A</td>\n",
       "      <td>[senior, adult, senior, adult, senior, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001A</td>\n",
       "      <td>[adult, adult, senior, adult, adult, senior, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>049A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>047A</td>\n",
       "      <td>[adult, kitten, adult, kitten, kitten, kitten,...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>045A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>044A</td>\n",
       "      <td>[kitten, adult, kitten, kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>043A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>042A</td>\n",
       "      <td>[adult, kitten, kitten, kitten, kitten, kitten...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>041A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>073A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>074A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, kit...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>075A</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>103A</td>\n",
       "      <td>[adult, adult, adult, adult, senior, senior, s...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>116A</td>\n",
       "      <td>[senior, senior, senior, senior, adult, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>115A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>113A</td>\n",
       "      <td>[senior, senior, adult]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>111A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>110A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>108A</td>\n",
       "      <td>[senior, senior, senior, senior, adult, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>105A</td>\n",
       "      <td>[senior, adult, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>104A</td>\n",
       "      <td>[senior, senior, senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>102A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>076A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>100A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>099A</td>\n",
       "      <td>[adult, senior, adult, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>097B</td>\n",
       "      <td>[adult, adult, kitten, senior, adult, adult, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>097A</td>\n",
       "      <td>[senior, senior, senior, adult, senior, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>096A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>094A</td>\n",
       "      <td>[senior, senior, adult, senior, senior, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>088A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>087A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>040A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>050A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>023A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>008A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>026A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>025C</td>\n",
       "      <td>[adult, adult, adult, senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>025B</td>\n",
       "      <td>[adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>025A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>013B</td>\n",
       "      <td>[adult, adult, senior, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>014A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>023B</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>037A</td>\n",
       "      <td>[adult, adult, senior, adult, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>022A</td>\n",
       "      <td>[adult, kitten, adult, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>021A</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>020A</td>\n",
       "      <td>[adult, adult, senior, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>019B</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>019A</td>\n",
       "      <td>[adult, adult, adult, adult, kitten, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>018A</td>\n",
       "      <td>[adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>014B</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>009A</td>\n",
       "      <td>[adult, adult, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>010A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>007A</td>\n",
       "      <td>[adult, senior, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>028A</td>\n",
       "      <td>[adult, senior, adult, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>035A</td>\n",
       "      <td>[senior, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>034A</td>\n",
       "      <td>[adult, senior, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>033A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>032A</td>\n",
       "      <td>[kitten, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>031A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002B</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>027A</td>\n",
       "      <td>[adult, senior, adult, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>004A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>026B</td>\n",
       "      <td>[senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>006A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>015A</td>\n",
       "      <td>[adult, senior, adult, adult, senior, adult, s...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>106A</td>\n",
       "      <td>[adult, senior, senior, senior, adult, adult, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>005A</td>\n",
       "      <td>[senior, senior, senior, senior, senior, senio...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>012A</td>\n",
       "      <td>[senior, adult, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>109A</td>\n",
       "      <td>[adult, adult, kitten, kitten, kitten, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>011A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>101A</td>\n",
       "      <td>[adult, adult, senior, senior, adult, adult, a...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>093A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>095A</td>\n",
       "      <td>[senior, senior, adult, senior, senior, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>038A</td>\n",
       "      <td>[kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>092A</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>091A</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>036A</td>\n",
       "      <td>[senior, senior, senior, senior, adult, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>048A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>029A</td>\n",
       "      <td>[senior, adult, senior, senior, adult, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>026C</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>052A</td>\n",
       "      <td>[senior, senior, senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>054A</td>\n",
       "      <td>[adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>055A</td>\n",
       "      <td>[adult, adult, senior, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>056A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>057A</td>\n",
       "      <td>[adult, adult, adult, senior, adult, adult, se...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>058A</td>\n",
       "      <td>[senior, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>059A</td>\n",
       "      <td>[adult, adult, adult, senior, senior, adult, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>060A</td>\n",
       "      <td>[senior, kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>061A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>063A</td>\n",
       "      <td>[senior, senior, senior, kitten, senior, senio...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>065A</td>\n",
       "      <td>[senior, adult, kitten, adult, senior, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>068A</td>\n",
       "      <td>[adult, adult, adult, senior, senior, adult, s...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>024A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>016A</td>\n",
       "      <td>[adult, adult, adult, adult, senior, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>090A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>117A</td>\n",
       "      <td>[senior, senior, adult, adult, senior, adult, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat_id                                        Predictions Majority Vote Actual Age Group  Correct Majority Vote\n",
       "0     000B  [adult, adult, kitten, senior, adult, adult, a...         adult            adult                   True\n",
       "45    039A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "78    072A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "77    071A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "76    070A              [adult, adult, senior, adult, senior]         adult            adult                   True\n",
       "75    069A                                     [adult, adult]         adult            adult                   True\n",
       "73    067A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "72    066A                                            [adult]         adult            adult                   True\n",
       "70    064A                              [adult, adult, adult]         adult            adult                   True\n",
       "68    062A                     [kitten, kitten, adult, adult]         adult            adult                   True\n",
       "59    053A        [adult, adult, senior, adult, adult, adult]         adult            adult                   True\n",
       "57    051B  [senior, adult, senior, adult, senior, adult, ...        senior           senior                   True\n",
       "56    051A  [senior, adult, senior, adult, senior, senior,...        senior           senior                   True\n",
       "1     001A  [adult, adult, senior, adult, adult, senior, a...         adult            adult                   True\n",
       "54    049A                                           [kitten]        kitten           kitten                   True\n",
       "52    047A  [adult, kitten, adult, kitten, kitten, kitten,...        kitten           kitten                   True\n",
       "51    045A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "50    044A            [kitten, adult, kitten, kitten, kitten]        kitten           kitten                   True\n",
       "49    043A                                           [kitten]        kitten           kitten                   True\n",
       "48    042A  [adult, kitten, kitten, kitten, kitten, kitten...        kitten           kitten                   True\n",
       "47    041A                                           [kitten]        kitten           kitten                   True\n",
       "79    073A                                            [adult]         adult            adult                   True\n",
       "80    074A  [adult, adult, adult, adult, adult, adult, kit...         adult            adult                   True\n",
       "81    075A                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "98    103A  [adult, adult, adult, adult, senior, senior, s...         adult            adult                   True\n",
       "108   116A  [senior, senior, senior, senior, adult, senior...        senior           senior                   True\n",
       "107   115A                                           [kitten]        kitten           kitten                   True\n",
       "106   113A                            [senior, senior, adult]        senior           senior                   True\n",
       "105   111A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "104   110A                                           [kitten]        kitten           kitten                   True\n",
       "102   108A    [senior, senior, senior, senior, adult, senior]        senior           senior                   True\n",
       "100   105A                     [senior, adult, adult, senior]         adult            adult                   True\n",
       "99    104A                   [senior, senior, senior, senior]        senior           senior                   True\n",
       "97    102A                                     [adult, adult]         adult            adult                   True\n",
       "82    076A                                            [adult]         adult            adult                   True\n",
       "95    100A                                            [adult]         adult            adult                   True\n",
       "94    099A  [adult, senior, adult, adult, adult, adult, ad...         adult            adult                   True\n",
       "93    097B  [adult, adult, kitten, senior, adult, adult, a...         adult            adult                   True\n",
       "92    097A  [senior, senior, senior, adult, senior, senior...        senior           senior                   True\n",
       "91    096A                                            [adult]         adult            adult                   True\n",
       "89    094A  [senior, senior, adult, senior, senior, senior...        senior           senior                   True\n",
       "84    088A                                            [adult]         adult            adult                   True\n",
       "83    087A                                     [adult, adult]         adult            adult                   True\n",
       "46    040A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "55    050A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "25    023A         [adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "9     008A         [adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "31    026A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "30    025C               [adult, adult, adult, senior, adult]         adult            adult                   True\n",
       "29    025B                                    [adult, senior]         adult            adult                   True\n",
       "28    025A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "14    013B  [adult, adult, senior, adult, adult, adult, ad...         adult            adult                   True\n",
       "15    014A                              [adult, adult, adult]         adult            adult                   True\n",
       "26    023B                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "43    037A       [adult, adult, senior, adult, adult, senior]         adult            adult                   True\n",
       "24    022A  [adult, kitten, adult, adult, adult, adult, ad...         adult            adult                   True\n",
       "23    021A                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "22    020A  [adult, adult, senior, adult, adult, adult, ad...         adult            adult                   True\n",
       "21    019B                                            [adult]         adult            adult                   True\n",
       "20    019A  [adult, adult, adult, adult, kitten, adult, ad...         adult            adult                   True\n",
       "19    018A                                    [adult, senior]         adult            adult                   True\n",
       "16    014B  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "10    009A                      [adult, adult, adult, senior]         adult            adult                   True\n",
       "11    010A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "8     007A        [adult, senior, adult, adult, adult, adult]         adult            adult                   True\n",
       "35    028A  [adult, senior, adult, adult, adult, adult, ad...         adult            adult                   True\n",
       "2     002A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "41    035A                      [senior, adult, adult, adult]         adult            adult                   True\n",
       "40    034A               [adult, senior, adult, adult, adult]         adult            adult                   True\n",
       "39    033A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "38    032A                                    [kitten, adult]         adult            adult                   True\n",
       "37    031A  [adult, adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "3     002B  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "4     003A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "34    027A  [adult, senior, adult, adult, adult, adult, ad...         adult            adult                   True\n",
       "5     004A                                            [adult]         adult            adult                   True\n",
       "32    026B                                    [senior, adult]         adult            adult                   True\n",
       "7     006A                              [adult, adult, adult]         adult            adult                   True\n",
       "17    015A  [adult, senior, adult, adult, senior, adult, s...         adult            adult                   True\n",
       "101   106A  [adult, senior, senior, senior, adult, adult, ...         adult           senior                  False\n",
       "6     005A  [senior, senior, senior, senior, senior, senio...        senior            adult                  False\n",
       "13    012A                            [senior, adult, senior]        senior            adult                  False\n",
       "103   109A      [adult, adult, kitten, kitten, kitten, adult]         adult           kitten                  False\n",
       "12    011A                                     [adult, adult]         adult           senior                  False\n",
       "96    101A  [adult, adult, senior, senior, adult, adult, a...        senior            adult                  False\n",
       "88    093A                                     [adult, adult]         adult           senior                  False\n",
       "90    095A  [senior, senior, adult, senior, senior, senior...        senior            adult                  False\n",
       "44    038A                                   [kitten, kitten]        kitten            adult                  False\n",
       "87    092A                                           [senior]        senior            adult                  False\n",
       "86    091A                                           [senior]        senior            adult                  False\n",
       "42    036A  [senior, senior, senior, senior, adult, senior...        senior            adult                  False\n",
       "53    048A                                            [adult]         adult           kitten                  False\n",
       "36    029A  [senior, adult, senior, senior, adult, senior,...        senior            adult                  False\n",
       "33    026C                                           [kitten]        kitten            adult                  False\n",
       "58    052A                   [senior, senior, senior, senior]        senior            adult                  False\n",
       "60    054A                                    [adult, senior]         adult           senior                  False\n",
       "61    055A  [adult, adult, senior, adult, adult, adult, ad...         adult           senior                  False\n",
       "62    056A                              [adult, adult, adult]         adult           senior                  False\n",
       "63    057A  [adult, adult, adult, senior, adult, adult, se...         adult           senior                  False\n",
       "64    058A                             [senior, adult, adult]         adult           senior                  False\n",
       "65    059A  [adult, adult, adult, senior, senior, adult, a...         adult           senior                  False\n",
       "66    060A                           [senior, kitten, kitten]        kitten            adult                  False\n",
       "67    061A                                     [adult, adult]         adult           senior                  False\n",
       "69    063A  [senior, senior, senior, kitten, senior, senio...        senior            adult                  False\n",
       "71    065A  [senior, adult, kitten, adult, senior, senior,...        senior            adult                  False\n",
       "74    068A  [adult, adult, adult, senior, senior, adult, s...        senior            adult                  False\n",
       "27    024A                                            [adult]         adult           senior                  False\n",
       "18    016A  [adult, adult, adult, adult, senior, adult, ad...         adult           senior                  False\n",
       "85    090A                                            [adult]         adult           senior                  False\n",
       "109   117A  [senior, senior, adult, adult, senior, adult, ...         adult           senior                  False"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "sorted_detailed_results = detailed_results.sort_values(by='Correct Majority Vote', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d36b3c54-3377-4249-a774-6d31557e36da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Majority Votes per Class:\n",
      "actual_age_group\n",
      "adult     58\n",
      "kitten    13\n",
      "senior     8\n",
      "Name: Majority_Correct, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create df for majority votes\n",
    "majority_df = majority_votes.reset_index()\n",
    "majority_df.columns = ['cat_id', 'Majority_Vote']\n",
    "\n",
    "# Get actual groups for each cat_id\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first().reset_index()\n",
    "\n",
    "# Merge majority votes with actual groups\n",
    "majority_with_actual = pd.merge(majority_df, actual_groups, on='cat_id')\n",
    "\n",
    "# Add a column to check if the majority vote was correct\n",
    "majority_with_actual['Majority_Correct'] = majority_with_actual['Majority_Vote'] == majority_with_actual['actual_age_group']\n",
    "\n",
    "# Count correct majority votes per class\n",
    "correct_majority_votes_per_class = majority_with_actual.groupby('actual_age_group')['Majority_Correct'].sum()\n",
    "\n",
    "print(\"Correct Majority Votes per Class:\")\n",
    "print(correct_majority_votes_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b36eb8a4-57f3-48c0-b92c-4a8e5a52c59e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics for Majority Votes:\n",
      "  actual_age_group  total_count  correct_count   accuracy\n",
      "0            adult           73             58  79.452055\n",
      "1           kitten           15             13  86.666667\n",
      "2           senior           22              8  36.363636\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = majority_with_actual.groupby('actual_age_group').agg(\n",
    "    total_count=('Majority_Correct', 'size'),  # Total number of cases per class\n",
    "    correct_count=('Majority_Correct', 'sum')  # Sum of correct predictions per class\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log detailed stats\n",
    "print(\"Detailed Class Statistics for Majority Votes:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1750e2da-df8c-4f00-b860-539dd822864f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics for Majority Votes\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Accuracy of Majority Votes by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6b34e-2368-4956-8241-8e6ab6e8cf81",
   "metadata": {},
   "source": [
    "## Detailed Class Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fdefd9be-6e6d-4903-a0ec-7824da4313d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics:\n",
      "  actual_age_group  total_count  correct_count   accuracy\n",
      "0            adult          550            416  75.636364\n",
      "1           kitten          122            104  85.245902\n",
      "2           senior          178             80  44.943820\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = full_results.groupby('actual_age_group').agg(\n",
    "    total_count=('correct', 'size'),\n",
    "    correct_count=('correct', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log the detailed stats\n",
    "print(\"Detailed Class Statistics:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "57576e25-349c-46e0-b57b-8bf3cee3b5de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics (Overall)\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Overall Accuracy by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b69785-d4c1-49ab-ba75-4a733326cdc1",
   "metadata": {},
   "source": [
    "## Gender Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "15c5b6e5-d7b0-4089-ae78-3dafe1cead3e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Gender:\n",
      "  all_gender  count  correct  accuracy\n",
      "0          F    213      144     67.61\n",
      "1          M    338      241     71.30\n",
      "2          X    299      215     71.91\n"
     ]
    }
   ],
   "source": [
    "# Group by gender and calculate the total count, correct predictions, and accuracy\n",
    "gender_stats = full_results.groupby('all_gender').agg(\n",
    "    count=('cat_id', 'size'),  # Total number of cases per gender\n",
    "    correct=('correct', 'sum')  # Sum of correct predictions per gender\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each gender\n",
    "gender_stats['accuracy'] = (gender_stats['correct'] / gender_stats['count'] * 100).round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy by Gender:\")\n",
    "print(gender_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b6001f1b-3f01-42e9-8761-4253acbed5e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Gender:\n",
      "  all_gender  count  correct  accuracy\n",
      "0          F    213      144     67.61\n",
      "1          M    338      241     71.30\n",
      "2          X    299      215     71.91\n"
     ]
    }
   ],
   "source": [
    "# Group by gender and calculate the total count, correct predictions, and accuracy\n",
    "gender_stats = full_results.groupby('all_gender').agg(\n",
    "    count=('cat_id', 'size'),  # Total number of cases per gender\n",
    "    correct=('correct', 'sum')  # Sum of correct predictions per gender\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each gender\n",
    "gender_stats['accuracy'] = (gender_stats['correct'] / gender_stats['count'] * 100).round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy by Gender:\")\n",
    "print(gender_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71b5d44-f489-4de0-8785-4bfa52d09797",
   "metadata": {},
   "source": [
    "# RANDOM SEED 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c4439fc4-670c-4009-8ca9-23c419ee99ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult     588\n",
      "senior    178\n",
      "kitten    171\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(int(random_seeds[3])) \n",
    "np.random.seed(int(random_seeds[3]))\n",
    "tf.random.set_seed(int(random_seeds[3]))\n",
    "\n",
    "# Load datasets\n",
    "dataframe = pd.read_csv('/Users/astrid/PycharmProjects/audioset-thesis-work/audioset/vggish/embeddings/8april_looped_embeddings.csv')\n",
    "dataframe.drop('mean_freq', axis=1, inplace=True)\n",
    "\n",
    "def assign_age_group(age, age_groups):\n",
    "    for group_name, age_range in age_groups.items():\n",
    "        if age_range[0] <= age < age_range[1]:\n",
    "            return group_name\n",
    "    return 'Unknown'  # For any age that doesn't fit the defined groups\n",
    "\n",
    "# Define age groups\n",
    "age_groups = {\n",
    "    'kitten': (0, 0.5),\n",
    "    'adult': (0.5, 12),\n",
    "    'senior': (12, 20)\n",
    "}\n",
    "\n",
    "# Create a new column for the age group\n",
    "dataframe['age_group'] = dataframe['target'].apply(assign_age_group, age_groups=age_groups)\n",
    "\n",
    "print(dataframe['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5fe04e3d-fd90-43c1-97af-5eac75e35f85",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = dataframe.iloc[:, :-4].values  # all columns except the last four\n",
    "\n",
    "# Encode the 'age_group' column as integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y = label_encoder.fit_transform(dataframe['age_group'].values)\n",
    "\n",
    "# Use the encoded labels for splitting and one-hot encoding\n",
    "y = encoded_y  \n",
    "\n",
    "# Convert 'cat_id' column to numpy array to be used as groups array for GroupKFold\n",
    "groups = dataframe['cat_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2ed5261d-2aeb-412e-a017-65b461a2cf5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f70aa6-1716-400a-be48-cccb3511542e",
   "metadata": {},
   "source": [
    "## Run Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fb9d0248-481e-4807-85dd-407fa88963f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_fold 1\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "000A    39\n",
      "103A    33\n",
      "002B    32\n",
      "047A    28\n",
      "057A    27\n",
      "074A    25\n",
      "020A    23\n",
      "055A    20\n",
      "067A    19\n",
      "000B    19\n",
      "029A    17\n",
      "097A    16\n",
      "059A    14\n",
      "042A    14\n",
      "001A    14\n",
      "097B    14\n",
      "106A    14\n",
      "111A    13\n",
      "028A    13\n",
      "002A    13\n",
      "051A    12\n",
      "116A    12\n",
      "036A    11\n",
      "068A    11\n",
      "025A    11\n",
      "014B    10\n",
      "016A    10\n",
      "040A    10\n",
      "072A     9\n",
      "015A     9\n",
      "051B     9\n",
      "022A     9\n",
      "033A     9\n",
      "045A     9\n",
      "095A     8\n",
      "013B     8\n",
      "117A     7\n",
      "031A     7\n",
      "027A     7\n",
      "007A     6\n",
      "108A     6\n",
      "053A     6\n",
      "109A     6\n",
      "023A     6\n",
      "037A     6\n",
      "075A     5\n",
      "070A     5\n",
      "025C     5\n",
      "021A     5\n",
      "034A     5\n",
      "044A     5\n",
      "023B     5\n",
      "003A     4\n",
      "105A     4\n",
      "035A     4\n",
      "026A     4\n",
      "052A     4\n",
      "062A     4\n",
      "012A     3\n",
      "113A     3\n",
      "058A     3\n",
      "060A     3\n",
      "064A     3\n",
      "006A     3\n",
      "025B     2\n",
      "032A     2\n",
      "093A     2\n",
      "054A     2\n",
      "069A     2\n",
      "087A     2\n",
      "038A     2\n",
      "073A     1\n",
      "004A     1\n",
      "090A     1\n",
      "110A     1\n",
      "115A     1\n",
      "091A     1\n",
      "019B     1\n",
      "066A     1\n",
      "048A     1\n",
      "092A     1\n",
      "026C     1\n",
      "076A     1\n",
      "043A     1\n",
      "041A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "019A    17\n",
      "101A    15\n",
      "039A    12\n",
      "063A    11\n",
      "071A    10\n",
      "005A    10\n",
      "065A     9\n",
      "010A     8\n",
      "094A     8\n",
      "050A     7\n",
      "099A     7\n",
      "008A     6\n",
      "009A     4\n",
      "104A     4\n",
      "014A     3\n",
      "056A     3\n",
      "018A     2\n",
      "011A     2\n",
      "061A     2\n",
      "102A     2\n",
      "096A     1\n",
      "049A     1\n",
      "088A     1\n",
      "100A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "M    296\n",
      "X    286\n",
      "F    208\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    62\n",
      "F    44\n",
      "M    41\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 000A, 033A, 015A, 001A, 103A, 097B, 028...\n",
      "kitten    [044A, 014B, 111A, 040A, 046A, 047A, 042A, 109...\n",
      "senior    [093A, 097A, 057A, 106A, 055A, 059A, 113A, 116...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [071A, 019A, 101A, 005A, 065A, 039A, 009A, 063...\n",
      "kitten                                         [050A, 049A]\n",
      "senior                       [104A, 056A, 094A, 011A, 061A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 56, 'kitten': 14, 'senior': 17}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 18, 'kitten': 2, 'senior': 5}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '002B' '003A' '004A' '006A' '007A' '012A'\n",
      " '013B' '014B' '015A' '016A' '019B' '020A' '021A' '022A' '023A' '023B'\n",
      " '024A' '025A' '025B' '025C' '026A' '026C' '027A' '028A' '029A' '031A'\n",
      " '032A' '033A' '034A' '035A' '036A' '037A' '038A' '040A' '041A' '042A'\n",
      " '043A' '044A' '045A' '046A' '047A' '048A' '051A' '051B' '052A' '053A'\n",
      " '054A' '055A' '057A' '058A' '059A' '060A' '062A' '064A' '066A' '067A'\n",
      " '068A' '069A' '070A' '072A' '073A' '074A' '075A' '076A' '087A' '090A'\n",
      " '091A' '092A' '093A' '095A' '097A' '097B' '103A' '105A' '106A' '108A'\n",
      " '109A' '110A' '111A' '113A' '115A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['005A' '008A' '009A' '010A' '011A' '014A' '018A' '019A' '026B' '039A'\n",
      " '049A' '050A' '056A' '061A' '063A' '065A' '071A' '088A' '094A' '096A'\n",
      " '099A' '100A' '101A' '102A' '104A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "set()\n",
      "Removed from Training/Validation Set:\n",
      "set()\n",
      "Moved to Test Set:\n",
      "set()\n",
      "Removed from Test Set\n",
      "set()\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '002B' '003A' '004A' '006A' '007A' '012A'\n",
      " '013B' '014B' '015A' '016A' '019B' '020A' '021A' '022A' '023A' '023B'\n",
      " '024A' '025A' '025B' '025C' '026A' '026C' '027A' '028A' '029A' '031A'\n",
      " '032A' '033A' '034A' '035A' '036A' '037A' '038A' '040A' '041A' '042A'\n",
      " '043A' '044A' '045A' '046A' '047A' '048A' '051A' '051B' '052A' '053A'\n",
      " '054A' '055A' '057A' '058A' '059A' '060A' '062A' '064A' '066A' '067A'\n",
      " '068A' '069A' '070A' '072A' '073A' '074A' '075A' '076A' '087A' '090A'\n",
      " '091A' '092A' '093A' '095A' '097A' '097B' '103A' '105A' '106A' '108A'\n",
      " '109A' '110A' '111A' '113A' '115A' '116A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['005A' '008A' '009A' '010A' '011A' '014A' '018A' '019A' '026B' '039A'\n",
      " '049A' '050A' '056A' '061A' '063A' '065A' '071A' '088A' '094A' '096A'\n",
      " '099A' '100A' '101A' '102A' '104A']\n",
      "Length of X_train_val:\n",
      "790\n",
      "Length of y_train_val:\n",
      "790\n",
      "Length of groups_train_val:\n",
      "790\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     468\n",
      "kitten    163\n",
      "senior    159\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     120\n",
      "senior     19\n",
      "kitten      8\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     468\n",
      "kitten    163\n",
      "senior    159\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     120\n",
      "senior     19\n",
      "kitten      8\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 468, 1: 163, 2: 159})\n",
      "Epoch 1/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.0868 - accuracy: 0.4810\n",
      "Epoch 2/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.8280 - accuracy: 0.5848\n",
      "Epoch 3/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.6152\n",
      "Epoch 4/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.6291\n",
      "Epoch 5/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6660 - accuracy: 0.6468\n",
      "Epoch 6/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6557\n",
      "Epoch 7/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.6886\n",
      "Epoch 8/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6163 - accuracy: 0.6759\n",
      "Epoch 9/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.7241\n",
      "Epoch 10/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5920 - accuracy: 0.7076\n",
      "Epoch 11/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.7063\n",
      "Epoch 12/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7241\n",
      "Epoch 13/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5333 - accuracy: 0.7316\n",
      "Epoch 14/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.7405\n",
      "Epoch 15/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7228\n",
      "Epoch 16/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5260 - accuracy: 0.7278\n",
      "Epoch 17/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.7481\n",
      "Epoch 18/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7633\n",
      "Epoch 19/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7519\n",
      "Epoch 20/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7430\n",
      "Epoch 21/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7671\n",
      "Epoch 22/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7709\n",
      "Epoch 23/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7772\n",
      "Epoch 24/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.7759\n",
      "Epoch 25/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7772\n",
      "Epoch 26/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7785\n",
      "Epoch 27/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4184 - accuracy: 0.7772\n",
      "Epoch 28/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.7975\n",
      "Epoch 29/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7911\n",
      "Epoch 30/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3739 - accuracy: 0.8025\n",
      "Epoch 31/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 0.7975\n",
      "Epoch 32/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.8025\n",
      "Epoch 33/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8139\n",
      "Epoch 34/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8025\n",
      "Epoch 35/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8190\n",
      "Epoch 36/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8051\n",
      "Epoch 37/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8203\n",
      "Epoch 38/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3896 - accuracy: 0.8165\n",
      "Epoch 39/1500\n",
      "25/25 [==============================] - 0s 977us/step - loss: 0.4197 - accuracy: 0.7873\n",
      "Epoch 40/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3617 - accuracy: 0.8000\n",
      "Epoch 41/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3659 - accuracy: 0.8304\n",
      "Epoch 42/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8316\n",
      "Epoch 43/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8101\n",
      "Epoch 44/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8291\n",
      "Epoch 45/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8165\n",
      "Epoch 46/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3608 - accuracy: 0.8253\n",
      "Epoch 47/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3142 - accuracy: 0.8468\n",
      "Epoch 48/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8367\n",
      "Epoch 49/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3040 - accuracy: 0.8544\n",
      "Epoch 50/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.8241\n",
      "Epoch 51/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8329\n",
      "Epoch 52/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8329\n",
      "Epoch 53/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8354\n",
      "Epoch 54/1500\n",
      "25/25 [==============================] - 0s 983us/step - loss: 0.3124 - accuracy: 0.8443\n",
      "Epoch 55/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3121 - accuracy: 0.8443\n",
      "Epoch 56/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2840 - accuracy: 0.8443\n",
      "Epoch 57/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3070 - accuracy: 0.8405\n",
      "Epoch 58/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3020 - accuracy: 0.8595\n",
      "Epoch 59/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2909 - accuracy: 0.8519\n",
      "Epoch 60/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3060 - accuracy: 0.8354\n",
      "Epoch 61/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3154 - accuracy: 0.8494\n",
      "Epoch 62/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2800 - accuracy: 0.8608\n",
      "Epoch 63/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3107 - accuracy: 0.8367\n",
      "Epoch 64/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8532\n",
      "Epoch 65/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2938 - accuracy: 0.8494\n",
      "Epoch 66/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.8468\n",
      "Epoch 67/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2716 - accuracy: 0.8747\n",
      "Epoch 68/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2890 - accuracy: 0.8646\n",
      "Epoch 69/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2933 - accuracy: 0.8544\n",
      "Epoch 70/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2760 - accuracy: 0.8620\n",
      "Epoch 71/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2717 - accuracy: 0.8797\n",
      "Epoch 72/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2743 - accuracy: 0.8671\n",
      "Epoch 73/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2887 - accuracy: 0.8506\n",
      "Epoch 74/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2732 - accuracy: 0.8608\n",
      "Epoch 75/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3051 - accuracy: 0.8506\n",
      "Epoch 76/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2537 - accuracy: 0.8709\n",
      "Epoch 77/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2676 - accuracy: 0.8759\n",
      "Epoch 78/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2919 - accuracy: 0.8570\n",
      "Epoch 79/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2943 - accuracy: 0.8722\n",
      "Epoch 80/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2682 - accuracy: 0.8709\n",
      "Epoch 81/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.8519\n",
      "Epoch 82/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2757 - accuracy: 0.8532\n",
      "Epoch 83/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2702 - accuracy: 0.8696\n",
      "Epoch 84/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.8785\n",
      "Epoch 85/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.8734\n",
      "Epoch 86/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2421 - accuracy: 0.8734\n",
      "Epoch 87/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.8861\n",
      "Epoch 88/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.8734\n",
      "Epoch 89/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.8899\n",
      "Epoch 90/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.8911\n",
      "Epoch 91/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.8747\n",
      "Epoch 92/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9038\n",
      "Epoch 93/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2557 - accuracy: 0.8785\n",
      "Epoch 94/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.8759\n",
      "Epoch 95/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2596 - accuracy: 0.8671\n",
      "Epoch 96/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2375 - accuracy: 0.8797\n",
      "Epoch 97/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2425 - accuracy: 0.8899\n",
      "Epoch 98/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.8873\n",
      "Epoch 99/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2272 - accuracy: 0.8949\n",
      "Epoch 100/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2107 - accuracy: 0.9076\n",
      "Epoch 101/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2027 - accuracy: 0.9152\n",
      "Epoch 102/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2090 - accuracy: 0.8924\n",
      "Epoch 103/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.8911\n",
      "Epoch 104/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2332 - accuracy: 0.8962\n",
      "Epoch 105/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.8886\n",
      "Epoch 106/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.8848\n",
      "Epoch 107/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2410 - accuracy: 0.8835\n",
      "Epoch 108/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2089 - accuracy: 0.8873\n",
      "Epoch 109/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.8962\n",
      "Epoch 110/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.8848\n",
      "Epoch 111/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 0.8975\n",
      "Epoch 112/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.8848\n",
      "Epoch 113/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.8987\n",
      "Epoch 114/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.8848\n",
      "Epoch 115/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.8987\n",
      "Epoch 116/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2054 - accuracy: 0.9051\n",
      "Epoch 117/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9013\n",
      "Epoch 118/1500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9013\n",
      "Epoch 119/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9101\n",
      "Epoch 120/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.8949\n",
      "Epoch 121/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2139 - accuracy: 0.8899\n",
      "Epoch 122/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.8987\n",
      "Epoch 123/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2087 - accuracy: 0.9076\n",
      "Epoch 124/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2317 - accuracy: 0.8937\n",
      "Epoch 125/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.9127\n",
      "Epoch 126/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.9089\n",
      "Epoch 127/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.9165\n",
      "Epoch 128/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9076\n",
      "Epoch 129/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.9127\n",
      "Epoch 130/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.9051\n",
      "Epoch 131/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.9165\n",
      "Epoch 132/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.9089\n",
      "Epoch 133/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9089\n",
      "Epoch 134/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.9114\n",
      "Epoch 135/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1737 - accuracy: 0.9152\n",
      "Epoch 136/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.9127\n",
      "Epoch 137/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.9076\n",
      "Epoch 138/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9190\n",
      "Epoch 139/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.9228\n",
      "Epoch 140/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.9215\n",
      "Epoch 141/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.9215\n",
      "Epoch 142/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.9152\n",
      "Epoch 143/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.9152\n",
      "Epoch 144/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9114\n",
      "Epoch 145/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.9152\n",
      "Epoch 146/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.9241\n",
      "Epoch 147/1500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9165\n",
      "Epoch 148/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.9127\n",
      "Epoch 149/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.9127\n",
      "Epoch 150/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9177\n",
      "Epoch 151/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9152\n",
      "Epoch 152/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9089\n",
      "Epoch 153/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9392\n",
      "Epoch 154/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.9051\n",
      "Epoch 155/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1713 - accuracy: 0.9203\n",
      "Epoch 156/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9228\n",
      "Epoch 157/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9152\n",
      "Epoch 158/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9152\n",
      "Epoch 159/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9190\n",
      "Epoch 160/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9114\n",
      "Epoch 161/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.9177\n",
      "Epoch 162/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.9253\n",
      "Epoch 163/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9278\n",
      "Epoch 164/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1629 - accuracy: 0.9228\n",
      "Epoch 165/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9354\n",
      "Epoch 166/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.9253\n",
      "Epoch 167/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9316\n",
      "Epoch 168/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9342\n",
      "Epoch 169/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.9367\n",
      "Epoch 170/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9253\n",
      "Epoch 171/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9316\n",
      "Epoch 172/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1720 - accuracy: 0.9266\n",
      "Epoch 173/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9278\n",
      "Epoch 174/1500\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.1604 - accuracy: 0.9215\n",
      "Epoch 175/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9241\n",
      "Epoch 176/1500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1525 - accuracy: 0.9291\n",
      "Epoch 177/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9266\n",
      "Epoch 178/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9215\n",
      "Epoch 179/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1693 - accuracy: 0.9215\n",
      "Epoch 180/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9266\n",
      "Epoch 181/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9405\n",
      "Epoch 182/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1690 - accuracy: 0.9203\n",
      "Epoch 183/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9329\n",
      "Epoch 184/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9139\n",
      "Epoch 185/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9342\n",
      "Epoch 186/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1395 - accuracy: 0.9266\n",
      "Epoch 187/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9278\n",
      "Epoch 188/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9443\n",
      "Epoch 189/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9177\n",
      "Epoch 190/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1713 - accuracy: 0.9177\n",
      "Epoch 191/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9392\n",
      "Epoch 192/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9354\n",
      "Epoch 193/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9316\n",
      "Epoch 194/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9329\n",
      "Epoch 195/1500\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.1031 - accuracy: 0.9688Restoring model weights from the end of the best epoch: 165.\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9316\n",
      "Epoch 195: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.7755\n",
      "5/5 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy for cat_id for this fold: 0.80 (20/25)\n",
      "Before appending - Cat IDs: 0, Predictions: 0, Actuals: 0, Gender: 0\n",
      "After appending - Cat IDs: 147, Predictions: 147, Actuals: 147, Gender: 147\n",
      "Final Test Results - Loss: 0.6756552457809448, Accuracy: 0.7755101919174194, Precision: 0.6943574943574943, Recall: 0.8788011695906434, F1 Score: 0.7389857196308306\n",
      "Confusion Matrix:\n",
      " [[89  3 28]\n",
      " [ 0  8  0]\n",
      " [ 2  0 17]]\n",
      "outer_fold 2\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "000A    39\n",
      "103A    33\n",
      "047A    28\n",
      "057A    27\n",
      "074A    25\n",
      "000B    19\n",
      "019A    17\n",
      "097A    16\n",
      "101A    15\n",
      "106A    14\n",
      "042A    14\n",
      "059A    14\n",
      "001A    14\n",
      "028A    13\n",
      "002A    13\n",
      "111A    13\n",
      "116A    12\n",
      "039A    12\n",
      "051A    12\n",
      "063A    11\n",
      "025A    11\n",
      "036A    11\n",
      "040A    10\n",
      "016A    10\n",
      "005A    10\n",
      "071A    10\n",
      "014B    10\n",
      "022A     9\n",
      "065A     9\n",
      "051B     9\n",
      "072A     9\n",
      "010A     8\n",
      "013B     8\n",
      "095A     8\n",
      "094A     8\n",
      "031A     7\n",
      "050A     7\n",
      "117A     7\n",
      "027A     7\n",
      "099A     7\n",
      "008A     6\n",
      "108A     6\n",
      "007A     6\n",
      "023A     6\n",
      "037A     6\n",
      "023B     5\n",
      "070A     5\n",
      "044A     5\n",
      "021A     5\n",
      "034A     5\n",
      "052A     4\n",
      "026A     4\n",
      "009A     4\n",
      "105A     4\n",
      "035A     4\n",
      "003A     4\n",
      "104A     4\n",
      "064A     3\n",
      "058A     3\n",
      "006A     3\n",
      "056A     3\n",
      "113A     3\n",
      "014A     3\n",
      "012A     3\n",
      "011A     2\n",
      "061A     2\n",
      "102A     2\n",
      "069A     2\n",
      "018A     2\n",
      "032A     2\n",
      "093A     2\n",
      "092A     1\n",
      "049A     1\n",
      "073A     1\n",
      "048A     1\n",
      "096A     1\n",
      "088A     1\n",
      "076A     1\n",
      "091A     1\n",
      "115A     1\n",
      "110A     1\n",
      "100A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "002B    32\n",
      "020A    23\n",
      "055A    20\n",
      "067A    19\n",
      "029A    17\n",
      "097B    14\n",
      "068A    11\n",
      "015A     9\n",
      "045A     9\n",
      "033A     9\n",
      "109A     6\n",
      "053A     6\n",
      "075A     5\n",
      "025C     5\n",
      "062A     4\n",
      "060A     3\n",
      "025B     2\n",
      "087A     2\n",
      "038A     2\n",
      "054A     2\n",
      "041A     1\n",
      "043A     1\n",
      "026C     1\n",
      "066A     1\n",
      "004A     1\n",
      "019B     1\n",
      "090A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    299\n",
      "F    216\n",
      "M    214\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "M    123\n",
      "X     49\n",
      "F     36\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 000A, 001A, 103A, 071A, 028A, 019A, 074...\n",
      "kitten    [044A, 014B, 111A, 040A, 046A, 047A, 042A, 050...\n",
      "senior    [093A, 097A, 057A, 106A, 104A, 059A, 113A, 116...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [033A, 015A, 097B, 067A, 020A, 062A, 002B, 029...\n",
      "kitten                             [109A, 043A, 041A, 045A]\n",
      "senior                             [055A, 054A, 090A, 024A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 54, 'kitten': 12, 'senior': 18}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 20, 'kitten': 4, 'senior': 4}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '003A' '005A' '006A' '007A' '008A' '009A'\n",
      " '010A' '011A' '012A' '013B' '014A' '014B' '016A' '018A' '019A' '021A'\n",
      " '022A' '023A' '023B' '025A' '026A' '026B' '027A' '028A' '031A' '032A'\n",
      " '034A' '035A' '036A' '037A' '039A' '040A' '042A' '044A' '046A' '047A'\n",
      " '048A' '049A' '050A' '051A' '051B' '052A' '056A' '057A' '058A' '059A'\n",
      " '061A' '063A' '064A' '065A' '069A' '070A' '071A' '072A' '073A' '074A'\n",
      " '076A' '088A' '091A' '092A' '093A' '094A' '095A' '096A' '097A' '099A'\n",
      " '100A' '101A' '102A' '103A' '104A' '105A' '106A' '108A' '110A' '111A'\n",
      " '113A' '115A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['002B' '004A' '015A' '019B' '020A' '024A' '025B' '025C' '026C' '029A'\n",
      " '033A' '038A' '041A' '043A' '045A' '053A' '054A' '055A' '060A' '062A'\n",
      " '066A' '067A' '068A' '075A' '087A' '090A' '097B' '109A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "set()\n",
      "Removed from Training/Validation Set:\n",
      "set()\n",
      "Moved to Test Set:\n",
      "set()\n",
      "Removed from Test Set\n",
      "set()\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '003A' '005A' '006A' '007A' '008A' '009A'\n",
      " '010A' '011A' '012A' '013B' '014A' '014B' '016A' '018A' '019A' '021A'\n",
      " '022A' '023A' '023B' '025A' '026A' '026B' '027A' '028A' '031A' '032A'\n",
      " '034A' '035A' '036A' '037A' '039A' '040A' '042A' '044A' '046A' '047A'\n",
      " '048A' '049A' '050A' '051A' '051B' '052A' '056A' '057A' '058A' '059A'\n",
      " '061A' '063A' '064A' '065A' '069A' '070A' '071A' '072A' '073A' '074A'\n",
      " '076A' '088A' '091A' '092A' '093A' '094A' '095A' '096A' '097A' '099A'\n",
      " '100A' '101A' '102A' '103A' '104A' '105A' '106A' '108A' '110A' '111A'\n",
      " '113A' '115A' '116A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['002B' '004A' '015A' '019B' '020A' '024A' '025B' '025C' '026C' '029A'\n",
      " '033A' '038A' '041A' '043A' '045A' '053A' '054A' '055A' '060A' '062A'\n",
      " '066A' '067A' '068A' '075A' '087A' '090A' '097B' '109A']\n",
      "Length of X_train_val:\n",
      "729\n",
      "Length of y_train_val:\n",
      "729\n",
      "Length of groups_train_val:\n",
      "729\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     421\n",
      "kitten    154\n",
      "senior    154\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     167\n",
      "senior     24\n",
      "kitten     17\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     421\n",
      "kitten    154\n",
      "senior    154\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     167\n",
      "senior     24\n",
      "kitten     17\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 421, 1: 154, 2: 154})\n",
      "Epoch 1/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.0482 - accuracy: 0.4527\n",
      "Epoch 2/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.9129 - accuracy: 0.5624\n",
      "Epoch 3/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.6132\n",
      "Epoch 4/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.6214\n",
      "Epoch 5/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.6461\n",
      "Epoch 6/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6735\n",
      "Epoch 7/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.6968\n",
      "Epoch 8/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6292 - accuracy: 0.6872\n",
      "Epoch 9/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6149 - accuracy: 0.6927\n",
      "Epoch 10/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.7078\n",
      "Epoch 11/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.7202\n",
      "Epoch 12/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7106\n",
      "Epoch 13/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7270\n",
      "Epoch 14/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7037\n",
      "Epoch 15/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.7407\n",
      "Epoch 16/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7215\n",
      "Epoch 17/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7572\n",
      "Epoch 18/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7380\n",
      "Epoch 19/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7531\n",
      "Epoch 20/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7654\n",
      "Epoch 21/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7586\n",
      "Epoch 22/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7682\n",
      "Epoch 23/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7682\n",
      "Epoch 24/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.7819\n",
      "Epoch 25/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7833\n",
      "Epoch 26/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.8025\n",
      "Epoch 27/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4156 - accuracy: 0.7833\n",
      "Epoch 28/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.7819\n",
      "Epoch 29/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.7915\n",
      "Epoch 30/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.7874\n",
      "Epoch 31/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.7984\n",
      "Epoch 32/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4164 - accuracy: 0.7901\n",
      "Epoch 33/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.7888\n",
      "Epoch 34/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4012 - accuracy: 0.7956\n",
      "Epoch 35/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8121\n",
      "Epoch 36/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3905 - accuracy: 0.8176\n",
      "Epoch 37/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8134\n",
      "Epoch 38/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4012 - accuracy: 0.7984\n",
      "Epoch 39/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8326\n",
      "Epoch 40/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8038\n",
      "Epoch 41/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.7970\n",
      "Epoch 42/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8217\n",
      "Epoch 43/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8368\n",
      "Epoch 44/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.8052\n",
      "Epoch 45/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8326\n",
      "Epoch 46/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3724 - accuracy: 0.8299\n",
      "Epoch 47/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 0.8189\n",
      "Epoch 48/1500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8272\n",
      "Epoch 49/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3240 - accuracy: 0.8436\n",
      "Epoch 50/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8340\n",
      "Epoch 51/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8162\n",
      "Epoch 52/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8244\n",
      "Epoch 53/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3227 - accuracy: 0.8368\n",
      "Epoch 54/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8244\n",
      "Epoch 55/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8436\n",
      "Epoch 56/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.8505\n",
      "Epoch 57/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8395\n",
      "Epoch 58/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.8326\n",
      "Epoch 59/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.8505\n",
      "Epoch 60/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2941 - accuracy: 0.8505\n",
      "Epoch 61/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8422\n",
      "Epoch 62/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.8519\n",
      "Epoch 63/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.8519\n",
      "Epoch 64/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8560\n",
      "Epoch 65/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2843 - accuracy: 0.8532\n",
      "Epoch 66/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3056 - accuracy: 0.8546\n",
      "Epoch 67/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.8656\n",
      "Epoch 68/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2939 - accuracy: 0.8464\n",
      "Epoch 69/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2892 - accuracy: 0.8642\n",
      "Epoch 70/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8464\n",
      "Epoch 71/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2929 - accuracy: 0.8601\n",
      "Epoch 72/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2715 - accuracy: 0.8628\n",
      "Epoch 73/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2807 - accuracy: 0.8491\n",
      "Epoch 74/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2953 - accuracy: 0.8615\n",
      "Epoch 75/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.8560\n",
      "Epoch 76/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2596 - accuracy: 0.8779\n",
      "Epoch 77/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2927 - accuracy: 0.8669\n",
      "Epoch 78/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2767 - accuracy: 0.8752\n",
      "Epoch 79/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2711 - accuracy: 0.8711\n",
      "Epoch 80/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2667 - accuracy: 0.8738\n",
      "Epoch 81/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8615\n",
      "Epoch 82/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.8848\n",
      "Epoch 83/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2497 - accuracy: 0.8711\n",
      "Epoch 84/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2552 - accuracy: 0.8848\n",
      "Epoch 85/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.8848\n",
      "Epoch 86/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.8807\n",
      "Epoch 87/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2519 - accuracy: 0.8875\n",
      "Epoch 88/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.8793\n",
      "Epoch 89/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.8834\n",
      "Epoch 90/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2625 - accuracy: 0.8779\n",
      "Epoch 91/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2380 - accuracy: 0.8848\n",
      "Epoch 92/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.8834\n",
      "Epoch 93/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.8875\n",
      "Epoch 94/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2287 - accuracy: 0.8848\n",
      "Epoch 95/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.8848\n",
      "Epoch 96/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2635 - accuracy: 0.8724\n",
      "Epoch 97/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.8807\n",
      "Epoch 98/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2517 - accuracy: 0.8875\n",
      "Epoch 99/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2786 - accuracy: 0.8532\n",
      "Epoch 100/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.8916\n",
      "Epoch 101/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.8889\n",
      "Epoch 102/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2113 - accuracy: 0.8944\n",
      "Epoch 103/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9040\n",
      "Epoch 104/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2154 - accuracy: 0.9095\n",
      "Epoch 105/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.8971\n",
      "Epoch 106/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.8903\n",
      "Epoch 107/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.9026\n",
      "Epoch 108/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.9163\n",
      "Epoch 109/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.8889\n",
      "Epoch 110/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9026\n",
      "Epoch 111/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.8807\n",
      "Epoch 112/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.8793\n",
      "Epoch 113/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.9067\n",
      "Epoch 114/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2406 - accuracy: 0.8957\n",
      "Epoch 115/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.8820\n",
      "Epoch 116/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.9040\n",
      "Epoch 117/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.8971\n",
      "Epoch 118/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.9081\n",
      "Epoch 119/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.8999\n",
      "Epoch 120/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2132 - accuracy: 0.8889\n",
      "Epoch 121/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.9053\n",
      "Epoch 122/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.9067\n",
      "Epoch 123/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9040\n",
      "Epoch 124/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9026\n",
      "Epoch 125/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9136\n",
      "Epoch 126/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.9040\n",
      "Epoch 127/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.9191\n",
      "Epoch 128/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.9108\n",
      "Epoch 129/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1953 - accuracy: 0.9026\n",
      "Epoch 130/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.8971\n",
      "Epoch 131/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2014 - accuracy: 0.9081\n",
      "Epoch 132/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.8999\n",
      "Epoch 133/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1720 - accuracy: 0.9191\n",
      "Epoch 134/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.9191\n",
      "Epoch 135/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2007 - accuracy: 0.9122\n",
      "Epoch 136/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.9246\n",
      "Epoch 137/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.9081\n",
      "Epoch 138/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.9012\n",
      "Epoch 139/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9095\n",
      "Epoch 140/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.8985\n",
      "Epoch 141/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.9108\n",
      "Epoch 142/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1709 - accuracy: 0.9246\n",
      "Epoch 143/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.9136\n",
      "Epoch 144/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.9273\n",
      "Epoch 145/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.9246\n",
      "Epoch 146/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9218\n",
      "Epoch 147/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1713 - accuracy: 0.9232\n",
      "Epoch 148/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 0.9191\n",
      "Epoch 149/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9259\n",
      "Epoch 150/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9191\n",
      "Epoch 151/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9150\n",
      "Epoch 152/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.9081\n",
      "Epoch 153/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.9012\n",
      "Epoch 154/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1635 - accuracy: 0.9218\n",
      "Epoch 155/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9287\n",
      "Epoch 156/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.9218\n",
      "Epoch 157/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.9369\n",
      "Epoch 158/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.9053\n",
      "Epoch 159/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9314\n",
      "Epoch 160/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.9040\n",
      "Epoch 161/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.9136\n",
      "Epoch 162/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9451\n",
      "Epoch 163/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9259\n",
      "Epoch 164/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9342\n",
      "Epoch 165/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1643 - accuracy: 0.9273\n",
      "Epoch 166/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9342\n",
      "Epoch 167/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9300\n",
      "Epoch 168/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9355\n",
      "Epoch 169/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.9204\n",
      "Epoch 170/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1736 - accuracy: 0.9246\n",
      "Epoch 171/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.9314\n",
      "Epoch 172/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1467 - accuracy: 0.9369\n",
      "Epoch 173/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.9122\n",
      "Epoch 174/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9328\n",
      "Epoch 175/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9259\n",
      "Epoch 176/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1658 - accuracy: 0.9204\n",
      "Epoch 177/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9369\n",
      "Epoch 178/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.9438\n",
      "Epoch 179/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9273\n",
      "Epoch 180/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9328\n",
      "Epoch 181/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1718 - accuracy: 0.9300\n",
      "Epoch 182/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9369\n",
      "Epoch 183/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9355\n",
      "Epoch 184/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.9369\n",
      "Epoch 185/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9150\n",
      "Epoch 186/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9273\n",
      "Epoch 187/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9314\n",
      "Epoch 188/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1699 - accuracy: 0.9259\n",
      "Epoch 189/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9369\n",
      "Epoch 190/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9232\n",
      "Epoch 191/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9273\n",
      "Epoch 192/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9259\n",
      "Epoch 193/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9204\n",
      "Epoch 194/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.9273\n",
      "Epoch 195/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1558 - accuracy: 0.9314\n",
      "Epoch 196/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9465\n",
      "Epoch 197/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9410\n",
      "Epoch 198/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9328\n",
      "Epoch 199/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9410\n",
      "Epoch 200/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9424\n",
      "Epoch 201/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9273\n",
      "Epoch 202/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.9218\n",
      "Epoch 203/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9287\n",
      "Epoch 204/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9410\n",
      "Epoch 205/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9300\n",
      "Epoch 206/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9369\n",
      "Epoch 207/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9410\n",
      "Epoch 208/1500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.1337 - accuracy: 0.9375Restoring model weights from the end of the best epoch: 178.\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9328\n",
      "Epoch 208: early stopping\n",
      "7/7 [==============================] - 0s 786us/step - loss: 0.6587 - accuracy: 0.7500\n",
      "7/7 [==============================] - 0s 622us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.79 (22/28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before appending - Cat IDs: 147, Predictions: 147, Actuals: 147, Gender: 147\n",
      "After appending - Cat IDs: 355, Predictions: 355, Actuals: 355, Gender: 355\n",
      "Final Test Results - Loss: 0.6587229371070862, Accuracy: 0.75, Precision: 0.6262272771459122, Recall: 0.8134123909044656, F1 Score: 0.6725893154464583\n",
      "Confusion Matrix:\n",
      " [[121  12  34]\n",
      " [  2  15   0]\n",
      " [  4   0  20]]\n",
      "outer_fold 3\n",
      "Train Set Group Distribution:\n",
      "002B    32\n",
      "047A    28\n",
      "074A    25\n",
      "020A    23\n",
      "055A    20\n",
      "000B    19\n",
      "067A    19\n",
      "019A    17\n",
      "029A    17\n",
      "097A    16\n",
      "101A    15\n",
      "097B    14\n",
      "059A    14\n",
      "028A    13\n",
      "002A    13\n",
      "039A    12\n",
      "051A    12\n",
      "063A    11\n",
      "036A    11\n",
      "068A    11\n",
      "005A    10\n",
      "016A    10\n",
      "071A    10\n",
      "065A     9\n",
      "045A     9\n",
      "022A     9\n",
      "015A     9\n",
      "033A     9\n",
      "010A     8\n",
      "094A     8\n",
      "050A     7\n",
      "031A     7\n",
      "117A     7\n",
      "099A     7\n",
      "007A     6\n",
      "108A     6\n",
      "109A     6\n",
      "008A     6\n",
      "053A     6\n",
      "075A     5\n",
      "044A     5\n",
      "021A     5\n",
      "025C     5\n",
      "034A     5\n",
      "023B     5\n",
      "009A     4\n",
      "003A     4\n",
      "104A     4\n",
      "062A     4\n",
      "113A     3\n",
      "014A     3\n",
      "056A     3\n",
      "060A     3\n",
      "064A     3\n",
      "025B     2\n",
      "102A     2\n",
      "061A     2\n",
      "069A     2\n",
      "018A     2\n",
      "054A     2\n",
      "087A     2\n",
      "038A     2\n",
      "093A     2\n",
      "011A     2\n",
      "100A     1\n",
      "090A     1\n",
      "115A     1\n",
      "088A     1\n",
      "024A     1\n",
      "019B     1\n",
      "096A     1\n",
      "004A     1\n",
      "048A     1\n",
      "066A     1\n",
      "026C     1\n",
      "041A     1\n",
      "092A     1\n",
      "049A     1\n",
      "073A     1\n",
      "043A     1\n",
      "091A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "046A    63\n",
      "000A    39\n",
      "103A    33\n",
      "057A    27\n",
      "042A    14\n",
      "001A    14\n",
      "106A    14\n",
      "111A    13\n",
      "116A    12\n",
      "025A    11\n",
      "040A    10\n",
      "014B    10\n",
      "072A     9\n",
      "051B     9\n",
      "095A     8\n",
      "013B     8\n",
      "027A     7\n",
      "037A     6\n",
      "023A     6\n",
      "070A     5\n",
      "052A     4\n",
      "035A     4\n",
      "026A     4\n",
      "105A     4\n",
      "012A     3\n",
      "006A     3\n",
      "058A     3\n",
      "032A     2\n",
      "076A     1\n",
      "110A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "M    235\n",
      "X    186\n",
      "F    169\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    162\n",
      "M    102\n",
      "F     83\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [033A, 015A, 071A, 097B, 028A, 019A, 074A, 067...\n",
      "kitten    [044A, 047A, 109A, 050A, 043A, 049A, 041A, 045...\n",
      "senior    [093A, 097A, 104A, 055A, 059A, 113A, 054A, 117...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [006A, 000A, 001A, 103A, 095A, 072A, 023A, 027...\n",
      "kitten                 [014B, 111A, 040A, 046A, 042A, 110A]\n",
      "senior                       [057A, 106A, 116A, 051B, 058A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 55, 'kitten': 10, 'senior': 17}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 19, 'kitten': 6, 'senior': 5}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000B' '002A' '002B' '003A' '004A' '005A' '007A' '008A' '009A' '010A'\n",
      " '011A' '014A' '015A' '016A' '018A' '019A' '019B' '020A' '021A' '022A'\n",
      " '023B' '024A' '025B' '025C' '026B' '026C' '028A' '029A' '031A' '033A'\n",
      " '034A' '036A' '038A' '039A' '041A' '043A' '044A' '045A' '047A' '048A'\n",
      " '049A' '050A' '051A' '053A' '054A' '055A' '056A' '059A' '060A' '061A'\n",
      " '062A' '063A' '064A' '065A' '066A' '067A' '068A' '069A' '071A' '073A'\n",
      " '074A' '075A' '087A' '088A' '090A' '091A' '092A' '093A' '094A' '096A'\n",
      " '097A' '097B' '099A' '100A' '101A' '102A' '104A' '108A' '109A' '113A'\n",
      " '115A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['000A' '001A' '006A' '012A' '013B' '014B' '023A' '025A' '026A' '027A'\n",
      " '032A' '035A' '037A' '040A' '042A' '046A' '051B' '052A' '057A' '058A'\n",
      " '070A' '072A' '076A' '095A' '103A' '105A' '106A' '110A' '111A' '116A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "{'046A', '000A'}\n",
      "Removed from Training/Validation Set:\n",
      "{'109A', '038A'}\n",
      "Moved to Test Set:\n",
      "{'109A', '038A'}\n",
      "Removed from Test Set\n",
      "{'046A', '000A'}\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '002A' '002B' '003A' '004A' '005A' '007A' '008A' '009A'\n",
      " '010A' '011A' '014A' '015A' '016A' '018A' '019A' '019B' '020A' '021A'\n",
      " '022A' '023B' '024A' '025B' '025C' '026B' '026C' '028A' '029A' '031A'\n",
      " '033A' '034A' '036A' '039A' '041A' '043A' '044A' '045A' '046A' '047A'\n",
      " '048A' '049A' '050A' '051A' '053A' '054A' '055A' '056A' '059A' '060A'\n",
      " '061A' '062A' '063A' '064A' '065A' '066A' '067A' '068A' '069A' '071A'\n",
      " '073A' '074A' '075A' '087A' '088A' '090A' '091A' '092A' '093A' '094A'\n",
      " '096A' '097A' '097B' '099A' '100A' '101A' '102A' '104A' '108A' '113A'\n",
      " '115A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['001A' '006A' '012A' '013B' '014B' '023A' '025A' '026A' '027A' '032A'\n",
      " '035A' '037A' '038A' '040A' '042A' '051B' '052A' '057A' '058A' '070A'\n",
      " '072A' '076A' '095A' '103A' '105A' '106A' '109A' '110A' '111A' '116A']\n",
      "Length of X_train_val:\n",
      "684\n",
      "Length of y_train_val:\n",
      "684\n",
      "Length of groups_train_val:\n",
      "684\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     417\n",
      "senior    113\n",
      "kitten     60\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     171\n",
      "kitten    111\n",
      "senior     65\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     454\n",
      "kitten    117\n",
      "senior    113\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     134\n",
      "senior     65\n",
      "kitten     54\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 454, 1: 117, 2: 113})\n",
      "Epoch 1/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 1.2911 - accuracy: 0.3889\n",
      "Epoch 2/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.9096 - accuracy: 0.5088\n",
      "Epoch 3/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7982 - accuracy: 0.5687\n",
      "Epoch 4/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.6038\n",
      "Epoch 5/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.5877\n",
      "Epoch 6/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6667 - accuracy: 0.6170\n",
      "Epoch 7/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6082\n",
      "Epoch 8/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5874 - accuracy: 0.6725\n",
      "Epoch 9/1500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6579\n",
      "Epoch 10/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 0.6506\n",
      "Epoch 11/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6176 - accuracy: 0.6754\n",
      "Epoch 12/1500\n",
      "22/22 [==============================] - 0s 996us/step - loss: 0.5432 - accuracy: 0.6871\n",
      "Epoch 13/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5247 - accuracy: 0.7105\n",
      "Epoch 14/1500\n",
      "22/22 [==============================] - 0s 984us/step - loss: 0.5267 - accuracy: 0.6988\n",
      "Epoch 15/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7222\n",
      "Epoch 16/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7295\n",
      "Epoch 17/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7354\n",
      "Epoch 18/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7339\n",
      "Epoch 19/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7442\n",
      "Epoch 20/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.7529\n",
      "Epoch 21/1500\n",
      "22/22 [==============================] - 0s 986us/step - loss: 0.4539 - accuracy: 0.7675\n",
      "Epoch 22/1500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 0.4847 - accuracy: 0.7544\n",
      "Epoch 23/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.7442\n",
      "Epoch 24/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.7632\n",
      "Epoch 25/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4022 - accuracy: 0.7749\n",
      "Epoch 26/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.7865\n",
      "Epoch 27/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3972 - accuracy: 0.7675\n",
      "Epoch 28/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.7719\n",
      "Epoch 29/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3812 - accuracy: 0.7939\n",
      "Epoch 30/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.7982\n",
      "Epoch 31/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.8041\n",
      "Epoch 32/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.7909\n",
      "Epoch 33/1500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 0.4305 - accuracy: 0.7895\n",
      "Epoch 34/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.7895\n",
      "Epoch 35/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.7909\n",
      "Epoch 36/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8114\n",
      "Epoch 37/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.7953\n",
      "Epoch 38/1500\n",
      "22/22 [==============================] - 0s 999us/step - loss: 0.3638 - accuracy: 0.7968\n",
      "Epoch 39/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3492 - accuracy: 0.8129\n",
      "Epoch 40/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.7968\n",
      "Epoch 41/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8026\n",
      "Epoch 42/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8026\n",
      "Epoch 43/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8129\n",
      "Epoch 44/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8289\n",
      "Epoch 45/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8289\n",
      "Epoch 46/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3249 - accuracy: 0.8406\n",
      "Epoch 47/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3434 - accuracy: 0.8187\n",
      "Epoch 48/1500\n",
      "22/22 [==============================] - 0s 992us/step - loss: 0.3177 - accuracy: 0.8436\n",
      "Epoch 49/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3049 - accuracy: 0.8275\n",
      "Epoch 50/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.8260\n",
      "Epoch 51/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3034 - accuracy: 0.8333\n",
      "Epoch 52/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3184 - accuracy: 0.8216\n",
      "Epoch 53/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3037 - accuracy: 0.8304\n",
      "Epoch 54/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2921 - accuracy: 0.8480\n",
      "Epoch 55/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3114 - accuracy: 0.8377\n",
      "Epoch 56/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8333\n",
      "Epoch 57/1500\n",
      "22/22 [==============================] - 0s 958us/step - loss: 0.3087 - accuracy: 0.8275\n",
      "Epoch 58/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2985 - accuracy: 0.8392\n",
      "Epoch 59/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2942 - accuracy: 0.8304\n",
      "Epoch 60/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2847 - accuracy: 0.8509\n",
      "Epoch 61/1500\n",
      "22/22 [==============================] - 0s 971us/step - loss: 0.2872 - accuracy: 0.8611\n",
      "Epoch 62/1500\n",
      "22/22 [==============================] - 0s 997us/step - loss: 0.3248 - accuracy: 0.8275\n",
      "Epoch 63/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8450\n",
      "Epoch 64/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2981 - accuracy: 0.8275\n",
      "Epoch 65/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8216\n",
      "Epoch 66/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2650 - accuracy: 0.8523\n",
      "Epoch 67/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2865 - accuracy: 0.8509\n",
      "Epoch 68/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3121 - accuracy: 0.8377\n",
      "Epoch 69/1500\n",
      "22/22 [==============================] - 0s 984us/step - loss: 0.3241 - accuracy: 0.8070\n",
      "Epoch 70/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2554 - accuracy: 0.8523\n",
      "Epoch 71/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2751 - accuracy: 0.8596\n",
      "Epoch 72/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8582\n",
      "Epoch 73/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2620 - accuracy: 0.8553\n",
      "Epoch 74/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2727 - accuracy: 0.8582\n",
      "Epoch 75/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.8670\n",
      "Epoch 76/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3015 - accuracy: 0.8450\n",
      "Epoch 77/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8450\n",
      "Epoch 78/1500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 0.2615 - accuracy: 0.8596\n",
      "Epoch 79/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.8801\n",
      "Epoch 80/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.8860\n",
      "Epoch 81/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2525 - accuracy: 0.8713\n",
      "Epoch 82/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2691 - accuracy: 0.8713\n",
      "Epoch 83/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2420 - accuracy: 0.8743\n",
      "Epoch 84/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.8640\n",
      "Epoch 85/1500\n",
      "22/22 [==============================] - 0s 993us/step - loss: 0.2559 - accuracy: 0.8699\n",
      "Epoch 86/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2340 - accuracy: 0.8670\n",
      "Epoch 87/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.8757\n",
      "Epoch 88/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.8684\n",
      "Epoch 89/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2642 - accuracy: 0.8480\n",
      "Epoch 90/1500\n",
      "22/22 [==============================] - 0s 983us/step - loss: 0.2381 - accuracy: 0.8713\n",
      "Epoch 91/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.8860\n",
      "Epoch 92/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.8596\n",
      "Epoch 93/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2647 - accuracy: 0.8626\n",
      "Epoch 94/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.8684\n",
      "Epoch 95/1500\n",
      "22/22 [==============================] - 0s 996us/step - loss: 0.2426 - accuracy: 0.8816\n",
      "Epoch 96/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.8816\n",
      "Epoch 97/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.8626\n",
      "Epoch 98/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.8830\n",
      "Epoch 99/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.8860\n",
      "Epoch 100/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.8918\n",
      "Epoch 101/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.8933\n",
      "Epoch 102/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.8874\n",
      "Epoch 103/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.8830\n",
      "Epoch 104/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.8889\n",
      "Epoch 105/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.8889\n",
      "Epoch 106/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.8860\n",
      "Epoch 107/1500\n",
      "22/22 [==============================] - 0s 993us/step - loss: 0.2134 - accuracy: 0.8874\n",
      "Epoch 108/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2358 - accuracy: 0.8845\n",
      "Epoch 109/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.8874\n",
      "Epoch 110/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2033 - accuracy: 0.9020\n",
      "Epoch 111/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.8933\n",
      "Epoch 112/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.8977\n",
      "Epoch 113/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.8889\n",
      "Epoch 114/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.8904\n",
      "Epoch 115/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2014 - accuracy: 0.8860\n",
      "Epoch 116/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.8977\n",
      "Epoch 117/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2087 - accuracy: 0.8830\n",
      "Epoch 118/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.9050\n",
      "Epoch 119/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.8918\n",
      "Epoch 120/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.8962\n",
      "Epoch 121/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2025 - accuracy: 0.8991\n",
      "Epoch 122/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9094\n",
      "Epoch 123/1500\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.1696 - accuracy: 0.9167\n",
      "Epoch 124/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2011 - accuracy: 0.9094\n",
      "Epoch 125/1500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9108\n",
      "Epoch 126/1500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9108\n",
      "Epoch 127/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9094\n",
      "Epoch 128/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9035\n",
      "Epoch 129/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.8904\n",
      "Epoch 130/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.9167\n",
      "Epoch 131/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8991\n",
      "Epoch 132/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.9094\n",
      "Epoch 133/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.8904\n",
      "Epoch 134/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.9050\n",
      "Epoch 135/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2030 - accuracy: 0.9006\n",
      "Epoch 136/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.9094\n",
      "Epoch 137/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.9020\n",
      "Epoch 138/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9108\n",
      "Epoch 139/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1732 - accuracy: 0.9167\n",
      "Epoch 140/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.9006\n",
      "Epoch 141/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9006\n",
      "Epoch 142/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.8991\n",
      "Epoch 143/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9050\n",
      "Epoch 144/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9284\n",
      "Epoch 145/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1971 - accuracy: 0.9079\n",
      "Epoch 146/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.8962\n",
      "Epoch 147/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9050\n",
      "Epoch 148/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1619 - accuracy: 0.9240\n",
      "Epoch 149/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.9050\n",
      "Epoch 150/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.9123\n",
      "Epoch 151/1500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 0.1795 - accuracy: 0.9079\n",
      "Epoch 152/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9211\n",
      "Epoch 153/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9050\n",
      "Epoch 154/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9225\n",
      "Epoch 155/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1662 - accuracy: 0.9298\n",
      "Epoch 156/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9254\n",
      "Epoch 157/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9167\n",
      "Epoch 158/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9225\n",
      "Epoch 159/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.9196\n",
      "Epoch 160/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9006\n",
      "Epoch 161/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.9269\n",
      "Epoch 162/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9225\n",
      "Epoch 163/1500\n",
      "22/22 [==============================] - 0s 991us/step - loss: 0.1445 - accuracy: 0.9313\n",
      "Epoch 164/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9284\n",
      "Epoch 165/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9269\n",
      "Epoch 166/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9342\n",
      "Epoch 167/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9357\n",
      "Epoch 168/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9327\n",
      "Epoch 169/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9225\n",
      "Epoch 170/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9167\n",
      "Epoch 171/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.9167\n",
      "Epoch 172/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9225\n",
      "Epoch 173/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9167\n",
      "Epoch 174/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9137\n",
      "Epoch 175/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1629 - accuracy: 0.9094\n",
      "Epoch 176/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9181\n",
      "Epoch 177/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1705 - accuracy: 0.9064\n",
      "Epoch 178/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9225\n",
      "Epoch 179/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9196\n",
      "Epoch 180/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9298\n",
      "Epoch 181/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1642 - accuracy: 0.9225\n",
      "Epoch 182/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9357\n",
      "Epoch 183/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9284\n",
      "Epoch 184/1500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 0.1465 - accuracy: 0.9152\n",
      "Epoch 185/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9254\n",
      "Epoch 186/1500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 0.1322 - accuracy: 0.9357\n",
      "Epoch 187/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.9386\n",
      "Epoch 188/1500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 0.1537 - accuracy: 0.9225\n",
      "Epoch 189/1500\n",
      "22/22 [==============================] - 0s 1000us/step - loss: 0.1436 - accuracy: 0.9254\n",
      "Epoch 190/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9313\n",
      "Epoch 191/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9430\n",
      "Epoch 192/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9488\n",
      "Epoch 193/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9240\n",
      "Epoch 194/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9357\n",
      "Epoch 195/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1423 - accuracy: 0.9298\n",
      "Epoch 196/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9298\n",
      "Epoch 197/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9357\n",
      "Epoch 198/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9298\n",
      "Epoch 199/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9386\n",
      "Epoch 200/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9474\n",
      "Epoch 201/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9284\n",
      "Epoch 202/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9313\n",
      "Epoch 203/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9357\n",
      "Epoch 204/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9181\n",
      "Epoch 205/1500\n",
      "22/22 [==============================] - 0s 980us/step - loss: 0.1452 - accuracy: 0.9342\n",
      "Epoch 206/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9371\n",
      "Epoch 207/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9342\n",
      "Epoch 208/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1380 - accuracy: 0.9415\n",
      "Epoch 209/1500\n",
      "22/22 [==============================] - 0s 993us/step - loss: 0.1265 - accuracy: 0.9269\n",
      "Epoch 210/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9371\n",
      "Epoch 211/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9474\n",
      "Epoch 212/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9444\n",
      "Epoch 213/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9386\n",
      "Epoch 214/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1412 - accuracy: 0.9386\n",
      "Epoch 215/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9474\n",
      "Epoch 216/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9532\n",
      "Epoch 217/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9474\n",
      "Epoch 218/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9401\n",
      "Epoch 219/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9386\n",
      "Epoch 220/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1187 - accuracy: 0.9386\n",
      "Epoch 221/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9430\n",
      "Epoch 222/1500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 0.1244 - accuracy: 0.9444\n",
      "Epoch 223/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9284\n",
      "Epoch 224/1500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 0.1062 - accuracy: 0.9444\n",
      "Epoch 225/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9503\n",
      "Epoch 226/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9459\n",
      "Epoch 227/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9459\n",
      "Epoch 228/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9371\n",
      "Epoch 229/1500\n",
      "22/22 [==============================] - 0s 953us/step - loss: 0.1160 - accuracy: 0.9444\n",
      "Epoch 230/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9561\n",
      "Epoch 231/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9547\n",
      "Epoch 232/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9561\n",
      "Epoch 233/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9635\n",
      "Epoch 234/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9415\n",
      "Epoch 235/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9503\n",
      "Epoch 236/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1442 - accuracy: 0.9284\n",
      "Epoch 237/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.9474\n",
      "Epoch 238/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0949 - accuracy: 0.9635\n",
      "Epoch 239/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9459\n",
      "Epoch 240/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9386\n",
      "Epoch 241/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9357\n",
      "Epoch 242/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9386\n",
      "Epoch 243/1500\n",
      "22/22 [==============================] - 0s 989us/step - loss: 0.0986 - accuracy: 0.9488\n",
      "Epoch 244/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.9401\n",
      "Epoch 245/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9547\n",
      "Epoch 246/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9415\n",
      "Epoch 247/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9488\n",
      "Epoch 248/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9430\n",
      "Epoch 249/1500\n",
      "22/22 [==============================] - 0s 989us/step - loss: 0.1179 - accuracy: 0.9430\n",
      "Epoch 250/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9488\n",
      "Epoch 251/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9488\n",
      "Epoch 252/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9561\n",
      "Epoch 253/1500\n",
      "22/22 [==============================] - 0s 991us/step - loss: 0.1019 - accuracy: 0.9547\n",
      "Epoch 254/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9576\n",
      "Epoch 255/1500\n",
      "22/22 [==============================] - 0s 987us/step - loss: 0.1202 - accuracy: 0.9459\n",
      "Epoch 256/1500\n",
      "22/22 [==============================] - 0s 969us/step - loss: 0.1057 - accuracy: 0.9503\n",
      "Epoch 257/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9459\n",
      "Epoch 258/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9561\n",
      "Epoch 259/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.9459\n",
      "Epoch 260/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9561\n",
      "Epoch 261/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9547\n",
      "Epoch 262/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.9547\n",
      "Epoch 263/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9532\n",
      "Epoch 264/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9503\n",
      "Epoch 265/1500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.9474\n",
      "Epoch 266/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9401\n",
      "Epoch 267/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9518\n",
      "Epoch 268/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9561\n",
      "Epoch 269/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1027 - accuracy: 0.9591\n",
      "Epoch 270/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9605\n",
      "Epoch 271/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9444\n",
      "Epoch 272/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9547\n",
      "Epoch 273/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9415\n",
      "Epoch 274/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9401\n",
      "Epoch 275/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9386\n",
      "Epoch 276/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9459\n",
      "Epoch 277/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9430\n",
      "Epoch 278/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9620\n",
      "Epoch 279/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0943 - accuracy: 0.9678\n",
      "Epoch 280/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9518\n",
      "Epoch 281/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9430\n",
      "Epoch 282/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9488\n",
      "Epoch 283/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9547\n",
      "Epoch 284/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9576\n",
      "Epoch 285/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9459\n",
      "Epoch 286/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9591\n",
      "Epoch 287/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9605\n",
      "Epoch 288/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9415\n",
      "Epoch 289/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9605\n",
      "Epoch 290/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9561\n",
      "Epoch 291/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9532\n",
      "Epoch 292/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9357\n",
      "Epoch 293/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.9430\n",
      "Epoch 294/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0943 - accuracy: 0.9532\n",
      "Epoch 295/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0937 - accuracy: 0.9503\n",
      "Epoch 296/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9547\n",
      "Epoch 297/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0987 - accuracy: 0.9430\n",
      "Epoch 298/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9459\n",
      "Epoch 299/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9547\n",
      "Epoch 300/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.9518\n",
      "Epoch 301/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9605\n",
      "Epoch 302/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0871 - accuracy: 0.9547\n",
      "Epoch 303/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9532\n",
      "Epoch 304/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9605\n",
      "Epoch 305/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.9459\n",
      "Epoch 306/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.9561\n",
      "Epoch 307/1500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.9649\n",
      "Epoch 308/1500\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.1073 - accuracy: 0.9062Restoring model weights from the end of the best epoch: 278.\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9605\n",
      "Epoch 308: early stopping\n",
      "8/8 [==============================] - 0s 924us/step - loss: 0.7928 - accuracy: 0.7312\n",
      "8/8 [==============================] - 0s 724us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy for cat_id for this fold: 0.80 (24/30)\n",
      "Before appending - Cat IDs: 355, Predictions: 355, Actuals: 355, Gender: 355\n",
      "After appending - Cat IDs: 608, Predictions: 608, Actuals: 608, Gender: 608\n",
      "Final Test Results - Loss: 0.792750895023346, Accuracy: 0.731225311756134, Precision: 0.7420235777633571, Recall: 0.7232470127992516, F1 Score: 0.7315805109922757\n",
      "Confusion Matrix:\n",
      " [[102   6  26]\n",
      " [ 12  42   0]\n",
      " [ 24   0  41]]\n",
      "outer_fold 4\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "000A    39\n",
      "103A    33\n",
      "002B    32\n",
      "057A    27\n",
      "020A    23\n",
      "055A    20\n",
      "067A    19\n",
      "019A    17\n",
      "029A    17\n",
      "101A    15\n",
      "097B    14\n",
      "042A    14\n",
      "001A    14\n",
      "106A    14\n",
      "111A    13\n",
      "039A    12\n",
      "116A    12\n",
      "068A    11\n",
      "025A    11\n",
      "063A    11\n",
      "040A    10\n",
      "071A    10\n",
      "014B    10\n",
      "005A    10\n",
      "072A     9\n",
      "065A     9\n",
      "015A     9\n",
      "033A     9\n",
      "051B     9\n",
      "045A     9\n",
      "094A     8\n",
      "010A     8\n",
      "095A     8\n",
      "013B     8\n",
      "050A     7\n",
      "027A     7\n",
      "099A     7\n",
      "053A     6\n",
      "109A     6\n",
      "008A     6\n",
      "037A     6\n",
      "023A     6\n",
      "025C     5\n",
      "070A     5\n",
      "075A     5\n",
      "035A     4\n",
      "052A     4\n",
      "026A     4\n",
      "105A     4\n",
      "104A     4\n",
      "062A     4\n",
      "009A     4\n",
      "012A     3\n",
      "058A     3\n",
      "060A     3\n",
      "006A     3\n",
      "056A     3\n",
      "014A     3\n",
      "061A     2\n",
      "018A     2\n",
      "038A     2\n",
      "054A     2\n",
      "032A     2\n",
      "087A     2\n",
      "025B     2\n",
      "011A     2\n",
      "102A     2\n",
      "043A     1\n",
      "024A     1\n",
      "090A     1\n",
      "100A     1\n",
      "110A     1\n",
      "004A     1\n",
      "019B     1\n",
      "088A     1\n",
      "066A     1\n",
      "026C     1\n",
      "076A     1\n",
      "096A     1\n",
      "041A     1\n",
      "049A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "047A    28\n",
      "074A    25\n",
      "000B    19\n",
      "097A    16\n",
      "059A    14\n",
      "028A    13\n",
      "002A    13\n",
      "051A    12\n",
      "036A    11\n",
      "016A    10\n",
      "022A     9\n",
      "117A     7\n",
      "031A     7\n",
      "108A     6\n",
      "007A     6\n",
      "023B     5\n",
      "044A     5\n",
      "021A     5\n",
      "034A     5\n",
      "003A     4\n",
      "064A     3\n",
      "113A     3\n",
      "093A     2\n",
      "069A     2\n",
      "073A     1\n",
      "091A     1\n",
      "092A     1\n",
      "048A     1\n",
      "115A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    273\n",
      "M    266\n",
      "F    163\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "F    89\n",
      "X    75\n",
      "M    71\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 000A, 033A, 015A, 001A, 103A, 071A, 097...\n",
      "kitten    [014B, 111A, 040A, 046A, 042A, 109A, 050A, 043...\n",
      "senior    [057A, 106A, 104A, 055A, 116A, 051B, 054A, 056...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [028A, 074A, 022A, 034A, 091A, 002A, 007A, 069...\n",
      "kitten                             [044A, 047A, 048A, 115A]\n",
      "senior     [093A, 097A, 059A, 113A, 117A, 051A, 016A, 108A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 57, 'kitten': 12, 'senior': 14}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 17, 'kitten': 4, 'senior': 8}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '001A' '002B' '004A' '005A' '006A' '008A' '009A' '010A' '011A'\n",
      " '012A' '013B' '014A' '014B' '015A' '018A' '019A' '019B' '020A' '023A'\n",
      " '024A' '025A' '025B' '025C' '026A' '026B' '026C' '027A' '029A' '032A'\n",
      " '033A' '035A' '037A' '038A' '039A' '040A' '041A' '042A' '043A' '045A'\n",
      " '046A' '049A' '050A' '051B' '052A' '053A' '054A' '055A' '056A' '057A'\n",
      " '058A' '060A' '061A' '062A' '063A' '065A' '066A' '067A' '068A' '070A'\n",
      " '071A' '072A' '075A' '076A' '087A' '088A' '090A' '094A' '095A' '096A'\n",
      " '097B' '099A' '100A' '101A' '102A' '103A' '104A' '105A' '106A' '109A'\n",
      " '110A' '111A' '116A']\n",
      "Unique Test Group IDs:\n",
      "['000B' '002A' '003A' '007A' '016A' '021A' '022A' '023B' '028A' '031A'\n",
      " '034A' '036A' '044A' '047A' '048A' '051A' '059A' '064A' '069A' '073A'\n",
      " '074A' '091A' '092A' '093A' '097A' '108A' '113A' '115A' '117A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "set()\n",
      "Removed from Training/Validation Set:\n",
      "set()\n",
      "Moved to Test Set:\n",
      "set()\n",
      "Removed from Test Set\n",
      "set()\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '001A' '002B' '004A' '005A' '006A' '008A' '009A' '010A' '011A'\n",
      " '012A' '013B' '014A' '014B' '015A' '018A' '019A' '019B' '020A' '023A'\n",
      " '024A' '025A' '025B' '025C' '026A' '026B' '026C' '027A' '029A' '032A'\n",
      " '033A' '035A' '037A' '038A' '039A' '040A' '041A' '042A' '043A' '045A'\n",
      " '046A' '049A' '050A' '051B' '052A' '053A' '054A' '055A' '056A' '057A'\n",
      " '058A' '060A' '061A' '062A' '063A' '065A' '066A' '067A' '068A' '070A'\n",
      " '071A' '072A' '075A' '076A' '087A' '088A' '090A' '094A' '095A' '096A'\n",
      " '097B' '099A' '100A' '101A' '102A' '103A' '104A' '105A' '106A' '109A'\n",
      " '110A' '111A' '116A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['000B' '002A' '003A' '007A' '016A' '021A' '022A' '023B' '028A' '031A'\n",
      " '034A' '036A' '044A' '047A' '048A' '051A' '059A' '064A' '069A' '073A'\n",
      " '074A' '091A' '092A' '093A' '097A' '108A' '113A' '115A' '117A']\n",
      "Length of X_train_val:\n",
      "702\n",
      "Length of y_train_val:\n",
      "702\n",
      "Length of groups_train_val:\n",
      "702\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     458\n",
      "kitten    136\n",
      "senior    108\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     130\n",
      "senior     70\n",
      "kitten     35\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     458\n",
      "kitten    136\n",
      "senior    108\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     130\n",
      "senior     70\n",
      "kitten     35\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 458, 1: 136, 2: 108})\n",
      "Epoch 1/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 1.1388 - accuracy: 0.4359\n",
      "Epoch 2/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8509 - accuracy: 0.5185\n",
      "Epoch 3/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7673 - accuracy: 0.5641\n",
      "Epoch 4/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7308 - accuracy: 0.5684\n",
      "Epoch 5/1500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7332 - accuracy: 0.5570\n",
      "Epoch 6/1500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.5969\n",
      "Epoch 7/1500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.5969\n",
      "Epoch 8/1500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6239\n",
      "Epoch 9/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6176 - accuracy: 0.6410\n",
      "Epoch 10/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.6425\n",
      "Epoch 11/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6114 - accuracy: 0.6553\n",
      "Epoch 12/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.6952\n",
      "Epoch 13/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.6595\n",
      "Epoch 14/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5321 - accuracy: 0.6738\n",
      "Epoch 15/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.6752\n",
      "Epoch 16/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.7066\n",
      "Epoch 17/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7179\n",
      "Epoch 18/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7293\n",
      "Epoch 19/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.6895\n",
      "Epoch 20/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7336\n",
      "Epoch 21/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7236\n",
      "Epoch 22/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7678\n",
      "Epoch 23/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7450\n",
      "Epoch 24/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7365\n",
      "Epoch 25/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.7707\n",
      "Epoch 26/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7493\n",
      "Epoch 27/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7422\n",
      "Epoch 28/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.7721\n",
      "Epoch 29/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.7650\n",
      "Epoch 30/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.7778\n",
      "Epoch 31/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.7806\n",
      "Epoch 32/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 0.7849\n",
      "Epoch 33/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.7963\n",
      "Epoch 34/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4127 - accuracy: 0.7877\n",
      "Epoch 35/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3791 - accuracy: 0.7863\n",
      "Epoch 36/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.8020\n",
      "Epoch 37/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8148\n",
      "Epoch 38/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.7949\n",
      "Epoch 39/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4112 - accuracy: 0.7892\n",
      "Epoch 40/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3412 - accuracy: 0.8063\n",
      "Epoch 41/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.8105\n",
      "Epoch 42/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8191\n",
      "Epoch 43/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8148\n",
      "Epoch 44/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.7735\n",
      "Epoch 45/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.7934\n",
      "Epoch 46/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3903 - accuracy: 0.7892\n",
      "Epoch 47/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.8162\n",
      "Epoch 48/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3189 - accuracy: 0.8219\n",
      "Epoch 49/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8205\n",
      "Epoch 50/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8191\n",
      "Epoch 51/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3227 - accuracy: 0.8319\n",
      "Epoch 52/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3130 - accuracy: 0.8376\n",
      "Epoch 53/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3021 - accuracy: 0.8305\n",
      "Epoch 54/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3142 - accuracy: 0.8405\n",
      "Epoch 55/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3115 - accuracy: 0.8362\n",
      "Epoch 56/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3036 - accuracy: 0.8305\n",
      "Epoch 57/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3134 - accuracy: 0.8319\n",
      "Epoch 58/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3145 - accuracy: 0.8476\n",
      "Epoch 59/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3156 - accuracy: 0.8305\n",
      "Epoch 60/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8490\n",
      "Epoch 61/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2722 - accuracy: 0.8433\n",
      "Epoch 62/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2929 - accuracy: 0.8462\n",
      "Epoch 63/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2803 - accuracy: 0.8561\n",
      "Epoch 64/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.8533\n",
      "Epoch 65/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2617 - accuracy: 0.8661\n",
      "Epoch 66/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3064 - accuracy: 0.8462\n",
      "Epoch 67/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2789 - accuracy: 0.8519\n",
      "Epoch 68/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2976 - accuracy: 0.8319\n",
      "Epoch 69/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.8661\n",
      "Epoch 70/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.8632\n",
      "Epoch 71/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2581 - accuracy: 0.8590\n",
      "Epoch 72/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8504\n",
      "Epoch 73/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2764 - accuracy: 0.8504\n",
      "Epoch 74/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2693 - accuracy: 0.8533\n",
      "Epoch 75/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2542 - accuracy: 0.8604\n",
      "Epoch 76/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2512 - accuracy: 0.8604\n",
      "Epoch 77/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2635 - accuracy: 0.8775\n",
      "Epoch 78/1500\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.2598 - accuracy: 0.8618\n",
      "Epoch 79/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2814 - accuracy: 0.8547\n",
      "Epoch 80/1500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.8647\n",
      "Epoch 81/1500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.8789\n",
      "Epoch 82/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2591 - accuracy: 0.8732\n",
      "Epoch 83/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2513 - accuracy: 0.8689\n",
      "Epoch 84/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.8875\n",
      "Epoch 85/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.8575\n",
      "Epoch 86/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2562 - accuracy: 0.8718\n",
      "Epoch 87/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.8789\n",
      "Epoch 88/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.8818\n",
      "Epoch 89/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2560 - accuracy: 0.8618\n",
      "Epoch 90/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.8718\n",
      "Epoch 91/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.8832\n",
      "Epoch 92/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.8590\n",
      "Epoch 93/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2377 - accuracy: 0.8689\n",
      "Epoch 94/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2559 - accuracy: 0.8661\n",
      "Epoch 95/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2339 - accuracy: 0.8661\n",
      "Epoch 96/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.8775\n",
      "Epoch 97/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.8860\n",
      "Epoch 98/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2439 - accuracy: 0.8846\n",
      "Epoch 99/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2160 - accuracy: 0.9003\n",
      "Epoch 100/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.8903\n",
      "Epoch 101/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2284 - accuracy: 0.8846\n",
      "Epoch 102/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.8818\n",
      "Epoch 103/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2263 - accuracy: 0.8789\n",
      "Epoch 104/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.8932\n",
      "Epoch 105/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.8946\n",
      "Epoch 106/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.9003\n",
      "Epoch 107/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.9031\n",
      "Epoch 108/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.9017\n",
      "Epoch 109/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.8989\n",
      "Epoch 110/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.8903\n",
      "Epoch 111/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.9017\n",
      "Epoch 112/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9103\n",
      "Epoch 113/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.9017\n",
      "Epoch 114/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2091 - accuracy: 0.8946\n",
      "Epoch 115/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.9046\n",
      "Epoch 116/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.9088\n",
      "Epoch 117/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.8989\n",
      "Epoch 118/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.9046\n",
      "Epoch 119/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.9003\n",
      "Epoch 120/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.8960\n",
      "Epoch 121/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.8889\n",
      "Epoch 122/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.8974\n",
      "Epoch 123/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.8932\n",
      "Epoch 124/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.8932\n",
      "Epoch 125/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2124 - accuracy: 0.9017\n",
      "Epoch 126/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1675 - accuracy: 0.9145\n",
      "Epoch 127/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9031\n",
      "Epoch 128/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9174\n",
      "Epoch 129/1500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 0.1828 - accuracy: 0.9117\n",
      "Epoch 130/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.9017\n",
      "Epoch 131/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.9160\n",
      "Epoch 132/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.8946\n",
      "Epoch 133/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.8917\n",
      "Epoch 134/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.9117\n",
      "Epoch 135/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.8989\n",
      "Epoch 136/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.9202\n",
      "Epoch 137/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.9131\n",
      "Epoch 138/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.9031\n",
      "Epoch 139/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9188\n",
      "Epoch 140/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9217\n",
      "Epoch 141/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1721 - accuracy: 0.8932\n",
      "Epoch 142/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9188\n",
      "Epoch 143/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1653 - accuracy: 0.9202\n",
      "Epoch 144/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9231\n",
      "Epoch 145/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9217\n",
      "Epoch 146/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9188\n",
      "Epoch 147/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9444\n",
      "Epoch 148/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.9031\n",
      "Epoch 149/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9145\n",
      "Epoch 150/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1592 - accuracy: 0.9145\n",
      "Epoch 151/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9302\n",
      "Epoch 152/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.9160\n",
      "Epoch 153/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9288\n",
      "Epoch 154/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9259\n",
      "Epoch 155/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9202\n",
      "Epoch 156/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1741 - accuracy: 0.9188\n",
      "Epoch 157/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.9145\n",
      "Epoch 158/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9274\n",
      "Epoch 159/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.9217\n",
      "Epoch 160/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9245\n",
      "Epoch 161/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9217\n",
      "Epoch 162/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9202\n",
      "Epoch 163/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9188\n",
      "Epoch 164/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.9088\n",
      "Epoch 165/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9259\n",
      "Epoch 166/1500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 0.1592 - accuracy: 0.9188\n",
      "Epoch 167/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.9174\n",
      "Epoch 168/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9217\n",
      "Epoch 169/1500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 0.1523 - accuracy: 0.9316\n",
      "Epoch 170/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1635 - accuracy: 0.9231\n",
      "Epoch 171/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9160\n",
      "Epoch 172/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 0.9288\n",
      "Epoch 173/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9202\n",
      "Epoch 174/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9202\n",
      "Epoch 175/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1395 - accuracy: 0.9288\n",
      "Epoch 176/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9416\n",
      "Epoch 177/1500\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.0918 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 147.\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9373\n",
      "Epoch 177: early stopping\n",
      "8/8 [==============================] - 0s 869us/step - loss: 0.5728 - accuracy: 0.7915\n",
      "8/8 [==============================] - 0s 674us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.76 (22/29)\n",
      "Before appending - Cat IDs: 608, Predictions: 608, Actuals: 608, Gender: 608\n",
      "After appending - Cat IDs: 843, Predictions: 843, Actuals: 843, Gender: 843\n",
      "Final Test Results - Loss: 0.5727673172950745, Accuracy: 0.7914893627166748, Precision: 0.8142088533916406, Recall: 0.7758241758241758, F1 Score: 0.7886897082629729\n",
      "Confusion Matrix:\n",
      " [[115   4  11]\n",
      " [  5  30   0]\n",
      " [ 29   0  41]]\n",
      "\n",
      "Final Average F1-Score across all UNSEEN TEST sets: 0.7329613135831344\n",
      "\n",
      "Final Average Loss across all UNSEEN TEST sets: 0.6749740988016129\n",
      "\n",
      "Final Average Accuracy across all UNSEEN TEST sets: 0.7620562165975571\n",
      "\n",
      "Final Average Precision across all UNSEEN TEST sets: 0.7192043006646011\n",
      "\n",
      "Final Average Recall across all UNSEEN TEST sets: 0.7978211872796341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "all_cat_ids = []\n",
    "all_predicted_age_groups = []\n",
    "all_actual_age_groups = []\n",
    "all_gender = []\n",
    "\n",
    "# Define the StratifiedGroupKFold splitter for 4 fold CV with random shuffling\n",
    "outer_cv = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=int(random_seeds[3]))\n",
    "\n",
    "# unseen test set metrics\n",
    "unseen_losses, unseen_accuracies, unseen_precisions, unseen_recalls, unseen_f1 = [], [], [], [], []\n",
    "\n",
    "outer_fold = 0\n",
    "\n",
    "# Use the splitter to generate indices for training and testing sets\n",
    "# Note: GroupShuffleSplit.split returns indices, so we use it to index the arrays\n",
    "for train_val_idx, test_idx in outer_cv.split(X, y, groups):\n",
    "    outer_fold += 1\n",
    "    logger(f\"outer_fold {outer_fold}\", file=log_file_path)\n",
    "\n",
    "    # Convert indices back to DataFrame for easy manipulation\n",
    "    df_train_val = dataframe.iloc[train_val_idx]\n",
    "    df_test = dataframe.iloc[test_idx]\n",
    "\n",
    "    ##############################\n",
    "    # ASSESSING SPLITS BY CAT_ID #\n",
    "    ##############################\n",
    "    \n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test['cat_id'].value_counts()  \n",
    "    \n",
    "    # Log or print the distribution\n",
    "    logger(f\"Train Set Group Distribution:\\n{training_validation_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Group Distribution:\\n{testing_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test['gender'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Training Set Gender Distribution BEFORE SWAP:\\n{training_gender_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Gender Distribution BEFORE SWAP:\\n{testing_gender_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Group by 'age_group' and then list unique 'cat_id' within each age group\n",
    "    unique_cat_ids_per_age_group_train_val = df_train_val.groupby('age_group')['cat_id'].unique()\n",
    "    unique_cat_ids_per_age_group_test = df_test.groupby('age_group')['cat_id'].unique()\n",
    "    \n",
    "    # Log results\n",
    "    logger(f\"Unique Cat IDs per Age Group in Training/Validation Set:\\n{unique_cat_ids_per_age_group_train_val}\", file=log_file_path)\n",
    "    logger(f\"Unique Cat IDs per Age Group in Testing Set:\\n{unique_cat_ids_per_age_group_test}\", file=log_file_path)\n",
    "\n",
    "    # Calculate the count of unique identifiers per age group for training and testing set\n",
    "    counts_train_val = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_train_val.items()}\n",
    "    counts_test = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_test.items()}\n",
    "\n",
    "    # Log the counts of unique identifiers per age group\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Training/Validation Set:\\n{counts_train_val}\", file=log_file_path)\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Testing Set:\\n{counts_test}\", file=log_file_path)\n",
    "\n",
    "    #######################################################\n",
    "    # CONTINUE WITH ENSURING VALID AND APPROPRIATE SPLITS #\n",
    "    #######################################################\n",
    "    \n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    groups_train_val, groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # logging identifier splits \n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "\n",
    "    # check group splits\n",
    "    check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Specify the cat_ids that must be in the training/validation set\n",
    "    specific_cat_ids = ['000A', '046A']\n",
    "    \n",
    "    # Perform the swapping operation\n",
    "    train_val_idx, test_idx = swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids)\n",
    "    \n",
    "    # Re-assign the sets based on the updated indices\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    new_groups_train_val, new_groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # Find differences for training and test sets\n",
    "    moved_to_train_val, removed_from_train_val = find_group_differences(groups_train_val, new_groups_train_val)\n",
    "    moved_to_test, removed_from_test = find_group_differences(groups_test, new_groups_test)\n",
    "    \n",
    "    # Display the results\n",
    "    logger(f\"Moved to Training/Validation Set:\\n{moved_to_train_val}\", file=log_file_path)\n",
    "    logger(f\"Removed from Training/Validation Set:\\n{removed_from_train_val}\", file=log_file_path)\n",
    "    logger(f\"Moved to Test Set:\\n{moved_to_test}\", file=log_file_path)\n",
    "    logger(f\"Removed from Test Set\\n{removed_from_test}\", file=log_file_path)\n",
    "\n",
    "    # Update X_train_val, X_test, y_train_val, y_test, groups_train_val, groups_test based on updated indices\n",
    "    X_train_val = X[train_val_idx]\n",
    "    y_train_val = y[train_val_idx]\n",
    "    groups_train_val = groups[train_val_idx]\n",
    "    \n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    groups_test = groups[test_idx]\n",
    "\n",
    "    # logging identifier splits again after potential swaps\n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"AFTER SWAP - Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"AFTER SWAP - Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "    \n",
    "    # Verify the lengths are consistent\n",
    "    logger(f\"Length of X_train_val:\\n{len(X_train_val)}\", file=log_file_path)\n",
    "    logger(f\"Length of y_train_val:\\n{len(y_train_val)}\", file=log_file_path)\n",
    "    logger(f\"Length of groups_train_val:\\n{len(groups_train_val)}\", file=log_file_path)\n",
    "\n",
    "    # Check group splits once more\n",
    "    check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Convert the modified indices back to a DataFrame representing the updated df_train_val\n",
    "    df_train_val_updated = dataframe.iloc[train_val_idx].copy()\n",
    "    df_test_updated = dataframe.iloc[test_idx].copy()\n",
    "\n",
    "    ############################\n",
    "    # LOGGING AGE GROUP SPLITS #\n",
    "    ############################\n",
    "\n",
    "    # Get the distribution of age groups of age groups before the update\n",
    "    training_validation_age_group_distribution = df_train_val['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test['age_group'].value_counts()\n",
    "    \n",
    "    # Logthe distribution\n",
    "    logger(f\"Train Age Group Distribution BEFORE SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution BEFORE SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Get the distribution of age groups after the update\n",
    "    training_validation_age_group_distribution = df_train_val_updated['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test_updated['age_group'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Train Age Group Distribution AFTER SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution AFTER SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "    \n",
    "    ########################################################\n",
    "    # TRACKING FINAL CAT_IDs & GENDER AFTER REDISTRIBUTION #\n",
    "    ########################################################\n",
    "\n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val_updated['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test_updated['cat_id'].value_counts()  \n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val_updated['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test_updated['gender'].value_counts()\n",
    "    \n",
    "    logger(f\"\\n Starting training on unseen test set\\n\", file=log_file_path)\n",
    "\n",
    "    ###################\n",
    "    # PREPARING MODEL #\n",
    "    ###################\n",
    "\n",
    "    # Calculate the distribution of age groups in y_train_val\n",
    "    age_group_distribution = Counter(y_train_val)\n",
    "    print(\"Age group distribution:\", age_group_distribution)\n",
    "\n",
    "    # EarlyStopping callback: monitor 'loss' instead of 'val_loss' for the test set\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='loss',  \n",
    "        min_delta=0.001, \n",
    "        patience=30,  \n",
    "        verbose=1,  \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "\n",
    "    # One final shuffle to ensure randomness\n",
    "    outer_shuffle_idx = np.random.permutation(len(X_train_val))\n",
    "    X_train_val = X_train_val[outer_shuffle_idx]\n",
    "    y_train_val = y_train_val[outer_shuffle_idx]\n",
    "    \n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train_val),\n",
    "        y=y_train_val\n",
    "    )\n",
    "    weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "    # Scale the features\n",
    "    scaler_full = StandardScaler().fit(X_train_val)\n",
    "    X_train_full_scaled = scaler_full.transform(X_train_val)\n",
    "    X_test_scaled = scaler_full.transform(X_test)\n",
    "    \n",
    "    # Encode the labels\n",
    "    y_train_full_encoded = to_categorical(y_train_val)\n",
    "    y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "    #######################\n",
    "    # BUILD & TRAIN MODEL #\n",
    "    #######################\n",
    "\n",
    "    optimizers = {\n",
    "        'Adamax': Adamax(learning_rate=0.00038188800331973483)\n",
    "    }\n",
    "    \n",
    "    # Full model definition with dynamic number of layers\n",
    "    model_full = Sequential()\n",
    "    model_full.add(Dense(480, activation='relu', input_shape=(X_train_full_scaled.shape[1],)))  # units_l0 and activation from parameters\n",
    "    model_full.add(BatchNormalization())\n",
    "    model_full.add(Dropout(0.27188281261238406))  \n",
    "    model_full.add(Dense(3, activation='softmax'))  \n",
    "    \n",
    "    optimizer = optimizers['Adamax']  # optimizer_key from parameters\n",
    "    \n",
    "    # Compile the model\n",
    "    model_full.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model on the full training set\n",
    "    history_full = model_full.fit(X_train_full_scaled, y_train_full_encoded, epochs=1500, batch_size=32,\n",
    "                                  verbose=1, callbacks=[early_stopping], class_weight=weight_dict)\n",
    "    \n",
    "    # Evaluate the model on the held-out test set\n",
    "    test_loss, test_accuracy = model_full.evaluate(X_test_scaled, y_test_encoded)\n",
    "\n",
    "    y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    y_test_pred = np.argmax(y_test_pred_prob, axis=1)  \n",
    "    y_test_true = np.argmax(y_test_encoded, axis=1)    \n",
    "\n",
    "    ################################\n",
    "    # LOG MAJORITY VOTE PER CAT_ID #\n",
    "    ################################\n",
    "\n",
    "    # Convert numeric predictions back to age group labels\n",
    "    predicted_age_groups = label_encoder.inverse_transform(y_test_pred)\n",
    "    actual_labels = label_encoder.inverse_transform(y_test_true)\n",
    "    \n",
    "    # Map predictions and actual labels back to cat_ids\n",
    "    test_results = pd.DataFrame({\n",
    "        'cat_id': df_test_updated['cat_id'],\n",
    "        'predicted_age_group': predicted_age_groups,\n",
    "        'actual_age_group': actual_labels\n",
    "    })\n",
    "    \n",
    "    # Group by cat_id and aggregate predicted age groups\n",
    "    majority_votes = test_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "    actual_groups = test_results.groupby('cat_id')['actual_age_group'].first()\n",
    "    \n",
    "    # Calculate the accuracy of majority voting\n",
    "    correct_predictions = (majority_votes == actual_groups).sum()\n",
    "    total_cats = len(actual_groups)\n",
    "    majority_vote_accuracy = correct_predictions / total_cats\n",
    "    \n",
    "    # Log the accuracy of the majority voting\n",
    "    logger(f\"Majority Vote Accuracy for cat_id for this fold: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)\n",
    "\n",
    "    ####################################################\n",
    "    # COLLECT PREDICTIONS FOR GENDER & CAT_ID ANALYSIS #\n",
    "    ####################################################\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'Before appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Extend lists with current fold results\n",
    "    all_cat_ids.extend(df_test_updated['cat_id'].tolist())\n",
    "    all_predicted_age_groups.extend(predicted_age_groups)\n",
    "    all_actual_age_groups.extend(actual_labels)\n",
    "    all_gender.extend(df_test_updated['gender'].tolist())\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'After appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    test_precision = precision_score(y_test_true, y_test_pred, average='macro')  # Use 'macro' for imbalanced datasets\n",
    "    test_recall = recall_score(y_test_true, y_test_pred, average='macro')\n",
    "    test_f1 = f1_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "    # prepare averages of outer metrics\n",
    "    unseen_f1.append(test_f1)\n",
    "    unseen_losses.append(test_loss)\n",
    "    unseen_accuracies.append(test_accuracy)\n",
    "    unseen_precisions.append(test_precision)\n",
    "    unseen_recalls.append(test_recall)\n",
    "\n",
    "    # Print final test results\n",
    "    logger(f\"Final Test Results - Loss: {test_loss}, Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}\", file=log_file_path)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    logger(f\"Confusion Matrix:\\n {cm}\", file=log_file_path)\n",
    "\n",
    "# Calculate the overall average metrics\n",
    "unseen_set_avg_f1 = np.mean(unseen_f1)\n",
    "unseen_set_avg_loss = np.mean(unseen_losses)\n",
    "unseen_set_avg_acc = np.mean(unseen_accuracies)\n",
    "unseen_set_avg_precision = np.mean(unseen_precisions)\n",
    "unseen_set_avg_recall = np.mean(unseen_recalls)\n",
    "\n",
    "logger(f\"\\nFinal Average F1-Score across all UNSEEN TEST sets: {unseen_set_avg_f1}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Loss across all UNSEEN TEST sets: {unseen_set_avg_loss}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Accuracy across all UNSEEN TEST sets: {unseen_set_avg_acc}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Precision across all UNSEEN TEST sets: {unseen_set_avg_precision}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Recall across all UNSEEN TEST sets: {unseen_set_avg_recall}\\n\", file=log_file_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0522ad-89f9-479c-b073-c5e720fc6221",
   "metadata": {},
   "source": [
    "## Majority Voting on Total Entries per cat_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ecac477e-680c-4a82-abcb-2b3a2dbfbea4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking - Cat IDs: 843, Predictions: 843, Actuals: 843, Gender: 843\n"
     ]
    }
   ],
   "source": [
    "# Debugging print statements\n",
    "print(f'Checking - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ce33a298-d7a3-40ec-8f78-00c109118230",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create results df\n",
    "full_results = pd.DataFrame({\n",
    "    'cat_id': all_cat_ids,\n",
    "    'predicted_age_group': all_predicted_age_groups,\n",
    "    'actual_age_group': all_actual_age_groups,\n",
    "    'all_gender': all_gender\n",
    "})\n",
    "\n",
    "# create a correct majority prediction column\n",
    "full_results['correct'] = full_results['predicted_age_group'] == full_results['actual_age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "23d083a1-d61a-4fce-9b56-667a9930bfe0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Majority Vote Accuracy for cat_id: 0.79 (87/110)\n"
     ]
    }
   ],
   "source": [
    "# Group by cat_id and aggregate predicted age groups\n",
    "majority_votes = full_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first()\n",
    "\n",
    "# Calculate the accuracy of majority voting\n",
    "correct_predictions = (majority_votes == actual_groups).sum()\n",
    "total_cats = len(actual_groups)\n",
    "majority_vote_accuracy = correct_predictions / total_cats\n",
    "\n",
    "logger(f\"Overall Majority Vote Accuracy for cat_id: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "431e9ecf-be90-466a-a1b7-dd98f7fb2a9a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Detailed df with predictions, actual labels, and comparison including majority vote\n",
    "detailed_results = full_results.groupby('cat_id').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Predictions': list(x['predicted_age_group']),\n",
    "        'Majority Vote': x['predicted_age_group'].mode()[0],\n",
    "        'Actual Age Group': x['actual_age_group'].iloc[0],\n",
    "        'Correct Majority Vote': x['predicted_age_group'].mode()[0] == x['actual_age_group'].iloc[0]\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Convert to DataFrame for better formatting and display\n",
    "detailed_results = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "42e4a5c0-56dd-4771-820f-bcecaf391f0c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Majority Vote</th>\n",
       "      <th>Actual Age Group</th>\n",
       "      <th>Correct Majority Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000B</td>\n",
       "      <td>[adult, kitten, kitten, senior, adult, adult, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>055A</td>\n",
       "      <td>[senior, senior, senior, senior, senior, senio...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>070A</td>\n",
       "      <td>[adult, adult, senior, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>069A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>067A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>066A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>064A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>062A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>059A</td>\n",
       "      <td>[senior, adult, senior, adult, senior, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>057A</td>\n",
       "      <td>[senior, senior, adult, senior, senior, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>056A</td>\n",
       "      <td>[senior, senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>053A</td>\n",
       "      <td>[kitten, adult, senior, adult, kitten, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>072A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>052A</td>\n",
       "      <td>[adult, senior, senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>051B</td>\n",
       "      <td>[senior, senior, senior, adult, senior, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001A</td>\n",
       "      <td>[adult, adult, senior, adult, adult, senior, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>049A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>048A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>047A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>045A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>044A</td>\n",
       "      <td>[kitten, adult, adult, kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>043A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>071A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>073A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>041A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>099A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>116A</td>\n",
       "      <td>[senior, senior, senior, senior, adult, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>115A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>111A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>105A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>104A</td>\n",
       "      <td>[senior, senior, senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>103A</td>\n",
       "      <td>[adult, adult, adult, adult, senior, senior, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>102A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>101A</td>\n",
       "      <td>[adult, adult, senior, kitten, adult, adult, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>100A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>097B</td>\n",
       "      <td>[senior, adult, kitten, senior, adult, adult, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>074A</td>\n",
       "      <td>[adult, adult, adult, kitten, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>097A</td>\n",
       "      <td>[senior, senior, senior, adult, senior, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>096A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>095A</td>\n",
       "      <td>[senior, adult, adult, adult, senior, senior, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>094A</td>\n",
       "      <td>[senior, senior, senior, senior, senior, senio...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>092A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>090A</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>088A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>087A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>075A</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>042A</td>\n",
       "      <td>[adult, kitten, kitten, kitten, adult, kitten,...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>050A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>040A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>013B</td>\n",
       "      <td>[adult, adult, senior, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>023B</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>023A</td>\n",
       "      <td>[kitten, kitten, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>022A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, kit...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>039A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>020A</td>\n",
       "      <td>[adult, adult, senior, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>019A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>018A</td>\n",
       "      <td>[adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>015A</td>\n",
       "      <td>[adult, senior, adult, adult, senior, adult, s...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>014B</td>\n",
       "      <td>[kitten, kitten, kitten, adult, kitten, kitten...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>014A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>012A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>025A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>011A</td>\n",
       "      <td>[senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>010A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>009A</td>\n",
       "      <td>[adult, adult, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>008A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>007A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>006A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>004A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002B</td>\n",
       "      <td>[adult, adult, adult, senior, adult, adult, se...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>024A</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>021A</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>117A</td>\n",
       "      <td>[senior, senior, senior, adult, senior, adult,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>035A</td>\n",
       "      <td>[adult, adult, senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>031A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>029A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, senior, se...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>025B</td>\n",
       "      <td>[adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>028A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>027A</td>\n",
       "      <td>[adult, senior, adult, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>033A</td>\n",
       "      <td>[adult, adult, adult, kitten, kitten, adult, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>034A</td>\n",
       "      <td>[adult, senior, adult, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>032A</td>\n",
       "      <td>[kitten, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>026A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>037A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>025C</td>\n",
       "      <td>[adult, adult, senior, senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>108A</td>\n",
       "      <td>[senior, adult, adult, senior, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>051A</td>\n",
       "      <td>[senior, senior, adult, adult, adult, senior, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>109A</td>\n",
       "      <td>[adult, adult, kitten, kitten, kitten, kitten,...</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>005A</td>\n",
       "      <td>[senior, senior, senior, senior, senior, senio...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>110A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>036A</td>\n",
       "      <td>[senior, senior, senior, senior, adult, adult,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>113A</td>\n",
       "      <td>[adult, senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>038A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>106A</td>\n",
       "      <td>[adult, senior, adult, senior, adult, adult, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>068A</td>\n",
       "      <td>[senior, adult, senior, senior, senior, adult,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>026C</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>093A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>058A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>091A</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>016A</td>\n",
       "      <td>[adult, adult, senior, senior, senior, senior,...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>026B</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>060A</td>\n",
       "      <td>[kitten, kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>076A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>019B</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>061A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>063A</td>\n",
       "      <td>[senior, senior, senior, adult, senior, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>065A</td>\n",
       "      <td>[senior, adult, adult, adult, senior, senior, ...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>054A</td>\n",
       "      <td>[senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat_id                                        Predictions Majority Vote Actual Age Group  Correct Majority Vote\n",
       "0     000B  [adult, kitten, kitten, senior, adult, adult, ...         adult            adult                   True\n",
       "61    055A  [senior, senior, senior, senior, senior, senio...        senior           senior                   True\n",
       "76    070A              [adult, adult, senior, adult, senior]         adult            adult                   True\n",
       "75    069A                                     [adult, adult]         adult            adult                   True\n",
       "73    067A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "72    066A                                            [adult]         adult            adult                   True\n",
       "70    064A                              [adult, adult, adult]         adult            adult                   True\n",
       "68    062A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "65    059A  [senior, adult, senior, adult, senior, senior,...        senior           senior                   True\n",
       "63    057A  [senior, senior, adult, senior, senior, senior...        senior           senior                   True\n",
       "62    056A                           [senior, senior, senior]        senior           senior                   True\n",
       "59    053A     [kitten, adult, senior, adult, kitten, senior]         adult            adult                   True\n",
       "78    072A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "58    052A                     [adult, senior, senior, adult]         adult            adult                   True\n",
       "57    051B  [senior, senior, senior, adult, senior, senior...        senior           senior                   True\n",
       "1     001A  [adult, adult, senior, adult, adult, senior, a...         adult            adult                   True\n",
       "54    049A                                           [kitten]        kitten           kitten                   True\n",
       "53    048A                                           [kitten]        kitten           kitten                   True\n",
       "52    047A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "51    045A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "50    044A             [kitten, adult, adult, kitten, kitten]        kitten           kitten                   True\n",
       "49    043A                                           [kitten]        kitten           kitten                   True\n",
       "77    071A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "79    073A                                            [adult]         adult            adult                   True\n",
       "47    041A                                           [kitten]        kitten           kitten                   True\n",
       "94    099A  [adult, adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "108   116A  [senior, senior, senior, senior, adult, senior...        senior           senior                   True\n",
       "107   115A                                           [kitten]        kitten           kitten                   True\n",
       "105   111A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "100   105A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "99    104A                   [senior, senior, senior, senior]        senior           senior                   True\n",
       "98    103A  [adult, adult, adult, adult, senior, senior, a...         adult            adult                   True\n",
       "97    102A                                     [adult, adult]         adult            adult                   True\n",
       "96    101A  [adult, adult, senior, kitten, adult, adult, a...         adult            adult                   True\n",
       "95    100A                                            [adult]         adult            adult                   True\n",
       "93    097B  [senior, adult, kitten, senior, adult, adult, ...         adult            adult                   True\n",
       "80    074A  [adult, adult, adult, kitten, adult, adult, ad...         adult            adult                   True\n",
       "92    097A  [senior, senior, senior, adult, senior, senior...        senior           senior                   True\n",
       "91    096A                                            [adult]         adult            adult                   True\n",
       "90    095A  [senior, adult, adult, adult, senior, senior, ...         adult            adult                   True\n",
       "89    094A  [senior, senior, senior, senior, senior, senio...        senior           senior                   True\n",
       "87    092A                                            [adult]         adult            adult                   True\n",
       "85    090A                                           [senior]        senior           senior                   True\n",
       "84    088A                                            [adult]         adult            adult                   True\n",
       "83    087A                                     [adult, adult]         adult            adult                   True\n",
       "81    075A                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "48    042A  [adult, kitten, kitten, kitten, adult, kitten,...        kitten           kitten                   True\n",
       "55    050A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "46    040A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "14    013B  [adult, adult, senior, adult, adult, adult, ad...         adult            adult                   True\n",
       "26    023B                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "25    023A       [kitten, kitten, adult, adult, adult, adult]         adult            adult                   True\n",
       "24    022A  [adult, adult, adult, adult, adult, adult, kit...         adult            adult                   True\n",
       "45    039A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "22    020A  [adult, adult, senior, adult, adult, adult, ad...         adult            adult                   True\n",
       "20    019A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "19    018A                                    [adult, senior]         adult            adult                   True\n",
       "17    015A  [adult, senior, adult, adult, senior, adult, s...         adult            adult                   True\n",
       "16    014B  [kitten, kitten, kitten, adult, kitten, kitten...        kitten           kitten                   True\n",
       "15    014A                              [adult, adult, adult]         adult            adult                   True\n",
       "13    012A                              [adult, adult, adult]         adult            adult                   True\n",
       "28    025A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "12    011A                                   [senior, senior]        senior           senior                   True\n",
       "11    010A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "10    009A                      [adult, adult, adult, senior]         adult            adult                   True\n",
       "9     008A         [adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "8     007A         [adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "7     006A                              [adult, adult, adult]         adult            adult                   True\n",
       "5     004A                                            [adult]         adult            adult                   True\n",
       "4     003A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "3     002B  [adult, adult, adult, senior, adult, adult, se...         adult            adult                   True\n",
       "2     002A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "27    024A                                           [senior]        senior           senior                   True\n",
       "23    021A                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "109   117A  [senior, senior, senior, adult, senior, adult,...        senior           senior                   True\n",
       "41    035A                      [adult, adult, senior, adult]         adult            adult                   True\n",
       "37    031A  [adult, adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "36    029A  [adult, adult, adult, adult, adult, senior, se...         adult            adult                   True\n",
       "29    025B                                    [adult, senior]         adult            adult                   True\n",
       "35    028A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "34    027A  [adult, senior, adult, adult, adult, adult, ad...         adult            adult                   True\n",
       "39    033A  [adult, adult, adult, kitten, kitten, adult, a...         adult            adult                   True\n",
       "40    034A              [adult, senior, adult, adult, senior]         adult            adult                   True\n",
       "38    032A                                    [kitten, adult]         adult            adult                   True\n",
       "31    026A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "43    037A         [adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "30    025C              [adult, adult, senior, senior, adult]         adult            adult                   True\n",
       "102   108A      [senior, adult, adult, senior, adult, senior]         adult           senior                  False\n",
       "56    051A  [senior, senior, adult, adult, adult, senior, ...         adult           senior                  False\n",
       "103   109A  [adult, adult, kitten, kitten, kitten, kitten,...         adult           kitten                  False\n",
       "6     005A  [senior, senior, senior, senior, senior, senio...        senior            adult                  False\n",
       "104   110A                                            [adult]         adult           kitten                  False\n",
       "42    036A  [senior, senior, senior, senior, adult, adult,...        senior            adult                  False\n",
       "106   113A                             [adult, senior, adult]         adult           senior                  False\n",
       "44    038A                   [kitten, kitten, kitten, kitten]        kitten            adult                  False\n",
       "101   106A  [adult, senior, adult, senior, adult, adult, a...         adult           senior                  False\n",
       "74    068A  [senior, adult, senior, senior, senior, adult,...        senior            adult                  False\n",
       "33    026C                                           [senior]        senior            adult                  False\n",
       "88    093A                                     [adult, adult]         adult           senior                  False\n",
       "64    058A                              [adult, adult, adult]         adult           senior                  False\n",
       "86    091A                                           [senior]        senior            adult                  False\n",
       "18    016A  [adult, adult, senior, senior, senior, senior,...         adult           senior                  False\n",
       "32    026B                                           [senior]        senior            adult                  False\n",
       "66    060A                           [kitten, kitten, kitten]        kitten            adult                  False\n",
       "82    076A                                           [kitten]        kitten            adult                  False\n",
       "21    019B                                           [senior]        senior            adult                  False\n",
       "67    061A                                     [adult, adult]         adult           senior                  False\n",
       "69    063A  [senior, senior, senior, adult, senior, senior...        senior            adult                  False\n",
       "71    065A  [senior, adult, adult, adult, senior, senior, ...        senior            adult                  False\n",
       "60    054A                                    [senior, adult]         adult           senior                  False"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "sorted_detailed_results = detailed_results.sort_values(by='Correct Majority Vote', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bc2e5ff6-b761-4b71-b7cd-9eb24aae0ebc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Majority Votes per Class:\n",
      "actual_age_group\n",
      "adult     61\n",
      "kitten    13\n",
      "senior    13\n",
      "Name: Majority_Correct, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create df for majority votes\n",
    "majority_df = majority_votes.reset_index()\n",
    "majority_df.columns = ['cat_id', 'Majority_Vote']\n",
    "\n",
    "# Get actual groups for each cat_id\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first().reset_index()\n",
    "\n",
    "# Merge majority votes with actual groups\n",
    "majority_with_actual = pd.merge(majority_df, actual_groups, on='cat_id')\n",
    "\n",
    "# Add a column to check if the majority vote was correct\n",
    "majority_with_actual['Majority_Correct'] = majority_with_actual['Majority_Vote'] == majority_with_actual['actual_age_group']\n",
    "\n",
    "# Count correct majority votes per class\n",
    "correct_majority_votes_per_class = majority_with_actual.groupby('actual_age_group')['Majority_Correct'].sum()\n",
    "\n",
    "print(\"Correct Majority Votes per Class:\")\n",
    "print(correct_majority_votes_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ff925f9d-efd5-46a0-89a0-1fb3da66a46a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics for Majority Votes:\n",
      "  actual_age_group  total_count  correct_count   accuracy\n",
      "0            adult           73             61  83.561644\n",
      "1           kitten           15             13  86.666667\n",
      "2           senior           22             13  59.090909\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = majority_with_actual.groupby('actual_age_group').agg(\n",
    "    total_count=('Majority_Correct', 'size'),  # Total number of cases per class\n",
    "    correct_count=('Majority_Correct', 'sum')  # Sum of correct predictions per class\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log detailed stats\n",
    "print(\"Detailed Class Statistics for Majority Votes:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d8f08817-c78c-4654-b195-911f2a9ccb2b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics for Majority Votes\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Accuracy of Majority Votes by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea6f284-fe35-4071-8054-5e5a086b4ed9",
   "metadata": {},
   "source": [
    "## Detailed Class Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4394c6ec-6da8-42de-aaaa-bc1b17bbf74b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics:\n",
      "  actual_age_group  total_count  correct_count   accuracy\n",
      "0            adult          551            427  77.495463\n",
      "1           kitten          114             95  83.333333\n",
      "2           senior          178            119  66.853933\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = full_results.groupby('actual_age_group').agg(\n",
    "    total_count=('correct', 'size'),\n",
    "    correct_count=('correct', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log the detailed stats\n",
    "print(\"Detailed Class Statistics:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8d541c77-590d-4b79-b526-85520ea5c4a2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics (Overall)\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Overall Accuracy by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c98d75-f483-4819-b292-975bd229cfd2",
   "metadata": {},
   "source": [
    "## Gender Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c7325b11-ab06-45bd-8e77-d498737b7552",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Gender:\n",
      "  all_gender  count  correct  accuracy\n",
      "0          F    215      163     75.81\n",
      "1          M    337      256     75.96\n",
      "2          X    291      222     76.29\n"
     ]
    }
   ],
   "source": [
    "# Group by gender and calculate the total count, correct predictions, and accuracy\n",
    "gender_stats = full_results.groupby('all_gender').agg(\n",
    "    count=('cat_id', 'size'),  # Total number of cases per gender\n",
    "    correct=('correct', 'sum')  # Sum of correct predictions per gender\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each gender\n",
    "gender_stats['accuracy'] = (gender_stats['correct'] / gender_stats['count'] * 100).round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy by Gender:\")\n",
    "print(gender_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "777ae0eb-dab5-47c0-86a7-0d3c6b01b9c5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Accuracy by Gender\n",
    "styled_barplot(gender_stats, 'all_gender', 'accuracy', \n",
    "               'Accuracy by Gender', \n",
    "               'Gender', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40270db-853d-46a1-acb4-8dab8a4f9c81",
   "metadata": {},
   "source": [
    "# RANDOM SEED 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "588e6cfb-6ee5-4b51-a9ee-79dcbfbb208c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult     588\n",
      "senior    178\n",
      "kitten    171\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(int(random_seeds[4]))\n",
    "np.random.seed(int(random_seeds[4]))\n",
    "tf.random.set_seed(int(random_seeds[4]))\n",
    "\n",
    "# Load datasets\n",
    "dataframe = pd.read_csv('/Users/astrid/PycharmProjects/audioset-thesis-work/audioset/vggish/embeddings/8april_looped_embeddings.csv')\n",
    "dataframe.drop('mean_freq', axis=1, inplace=True)\n",
    "\n",
    "def assign_age_group(age, age_groups):\n",
    "    for group_name, age_range in age_groups.items():\n",
    "        if age_range[0] <= age < age_range[1]:\n",
    "            return group_name\n",
    "    return 'Unknown'  # For any age that doesn't fit the defined groups\n",
    "\n",
    "# Define age groups\n",
    "age_groups = {\n",
    "    'kitten': (0, 0.5),\n",
    "    'adult': (0.5, 12),\n",
    "    'senior': (12, 20)\n",
    "}\n",
    "\n",
    "# Create a new column for the age group\n",
    "dataframe['age_group'] = dataframe['target'].apply(assign_age_group, age_groups=age_groups)\n",
    "\n",
    "print(dataframe['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "432a9515-e7f1-482c-bdaf-73cb07a9132e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = dataframe.iloc[:, :-4].values  # all columns except the last four\n",
    "\n",
    "# Encode the 'age_group' column as integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y = label_encoder.fit_transform(dataframe['age_group'].values)\n",
    "\n",
    "# Use the encoded labels for splitting and one-hot encoding\n",
    "y = encoded_y  \n",
    "\n",
    "# Convert 'cat_id' column to numpy array to be used as groups array for GroupKFold\n",
    "groups = dataframe['cat_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8231e441-4472-4d9b-8ddf-dc285c07923b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b9ed6b-6d2f-491e-95d8-73d33edeef6a",
   "metadata": {},
   "source": [
    "## Run Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6cd63258-8a3b-4bc0-9ac6-ae8aa4b515b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_fold 1\n",
      "Train Set Group Distribution:\n",
      "000A    39\n",
      "002B    32\n",
      "047A    28\n",
      "057A    27\n",
      "074A    25\n",
      "020A    23\n",
      "055A    20\n",
      "067A    19\n",
      "029A    17\n",
      "019A    17\n",
      "097A    16\n",
      "101A    15\n",
      "059A    14\n",
      "042A    14\n",
      "106A    14\n",
      "097B    14\n",
      "028A    13\n",
      "111A    13\n",
      "051A    12\n",
      "039A    12\n",
      "116A    12\n",
      "025A    11\n",
      "036A    11\n",
      "063A    11\n",
      "068A    11\n",
      "014B    10\n",
      "016A    10\n",
      "071A    10\n",
      "005A    10\n",
      "072A     9\n",
      "051B     9\n",
      "033A     9\n",
      "045A     9\n",
      "015A     9\n",
      "013B     8\n",
      "094A     8\n",
      "095A     8\n",
      "010A     8\n",
      "050A     7\n",
      "027A     7\n",
      "031A     7\n",
      "099A     7\n",
      "117A     7\n",
      "053A     6\n",
      "008A     6\n",
      "007A     6\n",
      "037A     6\n",
      "023A     6\n",
      "025C     5\n",
      "075A     5\n",
      "021A     5\n",
      "023B     5\n",
      "070A     5\n",
      "034A     5\n",
      "062A     4\n",
      "052A     4\n",
      "003A     4\n",
      "104A     4\n",
      "105A     4\n",
      "009A     4\n",
      "035A     4\n",
      "056A     3\n",
      "014A     3\n",
      "058A     3\n",
      "060A     3\n",
      "025B     2\n",
      "102A     2\n",
      "061A     2\n",
      "069A     2\n",
      "032A     2\n",
      "093A     2\n",
      "038A     2\n",
      "087A     2\n",
      "073A     1\n",
      "090A     1\n",
      "100A     1\n",
      "110A     1\n",
      "091A     1\n",
      "041A     1\n",
      "088A     1\n",
      "048A     1\n",
      "066A     1\n",
      "076A     1\n",
      "096A     1\n",
      "026C     1\n",
      "043A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "046A    63\n",
      "103A    33\n",
      "000B    19\n",
      "001A    14\n",
      "002A    13\n",
      "040A    10\n",
      "022A     9\n",
      "065A     9\n",
      "109A     6\n",
      "108A     6\n",
      "044A     5\n",
      "026A     4\n",
      "113A     3\n",
      "012A     3\n",
      "064A     3\n",
      "006A     3\n",
      "011A     2\n",
      "054A     2\n",
      "018A     2\n",
      "092A     1\n",
      "049A     1\n",
      "004A     1\n",
      "019B     1\n",
      "115A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "M    280\n",
      "X    256\n",
      "F    186\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    92\n",
      "F    66\n",
      "M    57\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [000A, 033A, 015A, 071A, 097B, 028A, 019A, 074...\n",
      "kitten    [014B, 111A, 047A, 042A, 050A, 043A, 041A, 045...\n",
      "senior    [093A, 097A, 057A, 106A, 104A, 055A, 059A, 116...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [006A, 001A, 103A, 022A, 065A, 002A, 000B, 026...\n",
      "kitten                 [044A, 040A, 046A, 109A, 049A, 115A]\n",
      "senior                             [113A, 054A, 108A, 011A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 59, 'kitten': 10, 'senior': 18}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 15, 'kitten': 6, 'senior': 4}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '002B' '003A' '005A' '007A' '008A' '009A' '010A' '013B' '014A'\n",
      " '014B' '015A' '016A' '019A' '020A' '021A' '023A' '023B' '024A' '025A'\n",
      " '025B' '025C' '026C' '027A' '028A' '029A' '031A' '032A' '033A' '034A'\n",
      " '035A' '036A' '037A' '038A' '039A' '041A' '042A' '043A' '045A' '047A'\n",
      " '048A' '050A' '051A' '051B' '052A' '053A' '055A' '056A' '057A' '058A'\n",
      " '059A' '060A' '061A' '062A' '063A' '066A' '067A' '068A' '069A' '070A'\n",
      " '071A' '072A' '073A' '074A' '075A' '076A' '087A' '088A' '090A' '091A'\n",
      " '093A' '094A' '095A' '096A' '097A' '097B' '099A' '100A' '101A' '102A'\n",
      " '104A' '105A' '106A' '110A' '111A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['000B' '001A' '002A' '004A' '006A' '011A' '012A' '018A' '019B' '022A'\n",
      " '026A' '026B' '040A' '044A' '046A' '049A' '054A' '064A' '065A' '092A'\n",
      " '103A' '108A' '109A' '113A' '115A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "{'046A'}\n",
      "Removed from Training/Validation Set:\n",
      "{'041A'}\n",
      "Moved to Test Set:\n",
      "{'041A'}\n",
      "Removed from Test Set\n",
      "{'046A'}\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '002B' '003A' '005A' '007A' '008A' '009A' '010A' '013B' '014A'\n",
      " '014B' '015A' '016A' '019A' '020A' '021A' '023A' '023B' '024A' '025A'\n",
      " '025B' '025C' '026C' '027A' '028A' '029A' '031A' '032A' '033A' '034A'\n",
      " '035A' '036A' '037A' '038A' '039A' '042A' '043A' '045A' '046A' '047A'\n",
      " '048A' '050A' '051A' '051B' '052A' '053A' '055A' '056A' '057A' '058A'\n",
      " '059A' '060A' '061A' '062A' '063A' '066A' '067A' '068A' '069A' '070A'\n",
      " '071A' '072A' '073A' '074A' '075A' '076A' '087A' '088A' '090A' '091A'\n",
      " '093A' '094A' '095A' '096A' '097A' '097B' '099A' '100A' '101A' '102A'\n",
      " '104A' '105A' '106A' '110A' '111A' '116A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['000B' '001A' '002A' '004A' '006A' '011A' '012A' '018A' '019B' '022A'\n",
      " '026A' '026B' '040A' '041A' '044A' '049A' '054A' '064A' '065A' '092A'\n",
      " '103A' '108A' '109A' '113A' '115A']\n",
      "Length of X_train_val:\n",
      "784\n",
      "Length of y_train_val:\n",
      "784\n",
      "Length of groups_train_val:\n",
      "784\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     472\n",
      "senior    165\n",
      "kitten     85\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     116\n",
      "kitten     86\n",
      "senior     13\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     472\n",
      "senior    165\n",
      "kitten    147\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     116\n",
      "kitten     24\n",
      "senior     13\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 472, 2: 165, 1: 147})\n",
      "Epoch 1/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.1140 - accuracy: 0.4605\n",
      "Epoch 2/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.8554 - accuracy: 0.5638\n",
      "Epoch 3/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7847 - accuracy: 0.5765\n",
      "Epoch 4/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7689 - accuracy: 0.6237\n",
      "Epoch 5/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.6569\n",
      "Epoch 6/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.6633\n",
      "Epoch 7/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6644 - accuracy: 0.6633\n",
      "Epoch 8/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.6773\n",
      "Epoch 9/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.7066\n",
      "Epoch 10/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.7168\n",
      "Epoch 11/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5378 - accuracy: 0.7232\n",
      "Epoch 12/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.7041\n",
      "Epoch 13/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.7309\n",
      "Epoch 14/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7334\n",
      "Epoch 15/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7500\n",
      "Epoch 16/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7564\n",
      "Epoch 17/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5508 - accuracy: 0.7181\n",
      "Epoch 18/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7666\n",
      "Epoch 19/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.7526\n",
      "Epoch 20/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7538\n",
      "Epoch 21/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.7793\n",
      "Epoch 22/1500\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.4612 - accuracy: 0.7589\n",
      "Epoch 23/1500\n",
      "25/25 [==============================] - 0s 968us/step - loss: 0.4399 - accuracy: 0.7781\n",
      "Epoch 24/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7602\n",
      "Epoch 25/1500\n",
      "25/25 [==============================] - 0s 998us/step - loss: 0.4387 - accuracy: 0.7895\n",
      "Epoch 26/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7717\n",
      "Epoch 27/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7832\n",
      "Epoch 28/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4240 - accuracy: 0.7883\n",
      "Epoch 29/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4088 - accuracy: 0.7946\n",
      "Epoch 30/1500\n",
      "25/25 [==============================] - 0s 982us/step - loss: 0.4271 - accuracy: 0.7921\n",
      "Epoch 31/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8010\n",
      "Epoch 32/1500\n",
      "25/25 [==============================] - 0s 994us/step - loss: 0.4282 - accuracy: 0.7806\n",
      "Epoch 33/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4018 - accuracy: 0.8163\n",
      "Epoch 34/1500\n",
      "25/25 [==============================] - 0s 984us/step - loss: 0.4042 - accuracy: 0.7934\n",
      "Epoch 35/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.8010\n",
      "Epoch 36/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3905 - accuracy: 0.7997\n",
      "Epoch 37/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8112\n",
      "Epoch 38/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.8023\n",
      "Epoch 39/1500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8151\n",
      "Epoch 40/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8214\n",
      "Epoch 41/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.8227\n",
      "Epoch 42/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8036\n",
      "Epoch 43/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8214\n",
      "Epoch 44/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8214\n",
      "Epoch 45/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3565 - accuracy: 0.8163\n",
      "Epoch 46/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8355\n",
      "Epoch 47/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.8214\n",
      "Epoch 48/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3390 - accuracy: 0.8393\n",
      "Epoch 49/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8329\n",
      "Epoch 50/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8508\n",
      "Epoch 51/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3167 - accuracy: 0.8469\n",
      "Epoch 52/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3118 - accuracy: 0.8661\n",
      "Epoch 53/1500\n",
      "25/25 [==============================] - 0s 985us/step - loss: 0.3172 - accuracy: 0.8367\n",
      "Epoch 54/1500\n",
      "25/25 [==============================] - 0s 991us/step - loss: 0.3324 - accuracy: 0.8418\n",
      "Epoch 55/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8444\n",
      "Epoch 56/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8431\n",
      "Epoch 57/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8342\n",
      "Epoch 58/1500\n",
      "25/25 [==============================] - 0s 994us/step - loss: 0.3183 - accuracy: 0.8278\n",
      "Epoch 59/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3061 - accuracy: 0.8597\n",
      "Epoch 60/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8406\n",
      "Epoch 61/1500\n",
      "25/25 [==============================] - 0s 988us/step - loss: 0.3132 - accuracy: 0.8597\n",
      "Epoch 62/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3037 - accuracy: 0.8367\n",
      "Epoch 63/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.8584\n",
      "Epoch 64/1500\n",
      "25/25 [==============================] - 0s 986us/step - loss: 0.3235 - accuracy: 0.8329\n",
      "Epoch 65/1500\n",
      "25/25 [==============================] - 0s 976us/step - loss: 0.3069 - accuracy: 0.8482\n",
      "Epoch 66/1500\n",
      "25/25 [==============================] - 0s 972us/step - loss: 0.3282 - accuracy: 0.8406\n",
      "Epoch 67/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3227 - accuracy: 0.8431\n",
      "Epoch 68/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3199 - accuracy: 0.8431\n",
      "Epoch 69/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8444\n",
      "Epoch 70/1500\n",
      "25/25 [==============================] - 0s 973us/step - loss: 0.3112 - accuracy: 0.8584\n",
      "Epoch 71/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2896 - accuracy: 0.8495\n",
      "Epoch 72/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2704 - accuracy: 0.8635\n",
      "Epoch 73/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2680 - accuracy: 0.8737\n",
      "Epoch 74/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2794 - accuracy: 0.8724\n",
      "Epoch 75/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2864 - accuracy: 0.8814\n",
      "Epoch 76/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2596 - accuracy: 0.8903\n",
      "Epoch 77/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2787 - accuracy: 0.8622\n",
      "Epoch 78/1500\n",
      "25/25 [==============================] - 0s 993us/step - loss: 0.3004 - accuracy: 0.8622\n",
      "Epoch 79/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2690 - accuracy: 0.8712\n",
      "Epoch 80/1500\n",
      "25/25 [==============================] - 0s 984us/step - loss: 0.2736 - accuracy: 0.8724\n",
      "Epoch 81/1500\n",
      "25/25 [==============================] - 0s 992us/step - loss: 0.2966 - accuracy: 0.8559\n",
      "Epoch 82/1500\n",
      "25/25 [==============================] - 0s 975us/step - loss: 0.2623 - accuracy: 0.8712\n",
      "Epoch 83/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2636 - accuracy: 0.8737\n",
      "Epoch 84/1500\n",
      "25/25 [==============================] - 0s 960us/step - loss: 0.2762 - accuracy: 0.8763\n",
      "Epoch 85/1500\n",
      "25/25 [==============================] - 0s 990us/step - loss: 0.2542 - accuracy: 0.8648\n",
      "Epoch 86/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2589 - accuracy: 0.8686\n",
      "Epoch 87/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.8724\n",
      "Epoch 88/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.8712\n",
      "Epoch 89/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.8929\n",
      "Epoch 90/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2626 - accuracy: 0.8763\n",
      "Epoch 91/1500\n",
      "25/25 [==============================] - 0s 986us/step - loss: 0.2423 - accuracy: 0.8673\n",
      "Epoch 92/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2543 - accuracy: 0.8827\n",
      "Epoch 93/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.8929\n",
      "Epoch 94/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2327 - accuracy: 0.8801\n",
      "Epoch 95/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.8865\n",
      "Epoch 96/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.8776\n",
      "Epoch 97/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2097 - accuracy: 0.8967\n",
      "Epoch 98/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2523 - accuracy: 0.8712\n",
      "Epoch 99/1500\n",
      "25/25 [==============================] - 0s 997us/step - loss: 0.3046 - accuracy: 0.8571\n",
      "Epoch 100/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2524 - accuracy: 0.8801\n",
      "Epoch 101/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.8941\n",
      "Epoch 102/1500\n",
      "25/25 [==============================] - 0s 1000us/step - loss: 0.2228 - accuracy: 0.8916\n",
      "Epoch 103/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.8967\n",
      "Epoch 104/1500\n",
      "25/25 [==============================] - 0s 990us/step - loss: 0.2394 - accuracy: 0.8839\n",
      "Epoch 105/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.8839\n",
      "Epoch 106/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.8878\n",
      "Epoch 107/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.8801\n",
      "Epoch 108/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.8903\n",
      "Epoch 109/1500\n",
      "25/25 [==============================] - 0s 980us/step - loss: 0.2179 - accuracy: 0.9056\n",
      "Epoch 110/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.8980\n",
      "Epoch 111/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2521 - accuracy: 0.8750\n",
      "Epoch 112/1500\n",
      "25/25 [==============================] - 0s 993us/step - loss: 0.2362 - accuracy: 0.8827\n",
      "Epoch 113/1500\n",
      "25/25 [==============================] - 0s 988us/step - loss: 0.2189 - accuracy: 0.8980\n",
      "Epoch 114/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.8941\n",
      "Epoch 115/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.8941\n",
      "Epoch 116/1500\n",
      "25/25 [==============================] - 0s 990us/step - loss: 0.1934 - accuracy: 0.9018\n",
      "Epoch 117/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.9069\n",
      "Epoch 118/1500\n",
      "25/25 [==============================] - 0s 995us/step - loss: 0.2028 - accuracy: 0.8916\n",
      "Epoch 119/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.8763\n",
      "Epoch 120/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2097 - accuracy: 0.8941\n",
      "Epoch 121/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.8878\n",
      "Epoch 122/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.8941\n",
      "Epoch 123/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.9056\n",
      "Epoch 124/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.9031\n",
      "Epoch 125/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2137 - accuracy: 0.8967\n",
      "Epoch 126/1500\n",
      "25/25 [==============================] - 0s 999us/step - loss: 0.2160 - accuracy: 0.8852\n",
      "Epoch 127/1500\n",
      "25/25 [==============================] - 0s 986us/step - loss: 0.1989 - accuracy: 0.8967\n",
      "Epoch 128/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9005\n",
      "Epoch 129/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.9069\n",
      "Epoch 130/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.9133\n",
      "Epoch 131/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.9018\n",
      "Epoch 132/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.8980\n",
      "Epoch 133/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1990 - accuracy: 0.9043\n",
      "Epoch 134/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.9133\n",
      "Epoch 135/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.9056\n",
      "Epoch 136/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9145\n",
      "Epoch 137/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2085 - accuracy: 0.8941\n",
      "Epoch 138/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9018\n",
      "Epoch 139/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.9260\n",
      "Epoch 140/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.8916\n",
      "Epoch 141/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.9209\n",
      "Epoch 142/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.8967\n",
      "Epoch 143/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.9031\n",
      "Epoch 144/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.9120\n",
      "Epoch 145/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.9018\n",
      "Epoch 146/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.9056\n",
      "Epoch 147/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9286\n",
      "Epoch 148/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.9196\n",
      "Epoch 149/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.9005\n",
      "Epoch 150/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9184\n",
      "Epoch 151/1500\n",
      "25/25 [==============================] - 0s 979us/step - loss: 0.1862 - accuracy: 0.9043\n",
      "Epoch 152/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.9133\n",
      "Epoch 153/1500\n",
      "25/25 [==============================] - 0s 990us/step - loss: 0.1648 - accuracy: 0.9235\n",
      "Epoch 154/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 0.9082\n",
      "Epoch 155/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9158\n",
      "Epoch 156/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.9133\n",
      "Epoch 157/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9043\n",
      "Epoch 158/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.9273\n",
      "Epoch 159/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1630 - accuracy: 0.9222\n",
      "Epoch 160/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.9247\n",
      "Epoch 161/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.9184\n",
      "Epoch 162/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9120\n",
      "Epoch 163/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9247\n",
      "Epoch 164/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.9184\n",
      "Epoch 165/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9107\n",
      "Epoch 166/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.9171\n",
      "Epoch 167/1500\n",
      "25/25 [==============================] - 0s 975us/step - loss: 0.2081 - accuracy: 0.9120\n",
      "Epoch 168/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.9171\n",
      "Epoch 169/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.9069\n",
      "Epoch 170/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.9107\n",
      "Epoch 171/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9273\n",
      "Epoch 172/1500\n",
      "25/25 [==============================] - 0s 998us/step - loss: 0.1600 - accuracy: 0.9260\n",
      "Epoch 173/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9133\n",
      "Epoch 174/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9337\n",
      "Epoch 175/1500\n",
      "25/25 [==============================] - 0s 998us/step - loss: 0.1782 - accuracy: 0.9171\n",
      "Epoch 176/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.9056\n",
      "Epoch 177/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.9133\n",
      "Epoch 178/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9286\n",
      "Epoch 179/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9247\n",
      "Epoch 180/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1653 - accuracy: 0.9209\n",
      "Epoch 181/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.9158\n",
      "Epoch 182/1500\n",
      "25/25 [==============================] - 0s 981us/step - loss: 0.1647 - accuracy: 0.9222\n",
      "Epoch 183/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.9349\n",
      "Epoch 184/1500\n",
      "25/25 [==============================] - 0s 969us/step - loss: 0.1739 - accuracy: 0.9184\n",
      "Epoch 185/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9196\n",
      "Epoch 186/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9158\n",
      "Epoch 187/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9209\n",
      "Epoch 188/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9388\n",
      "Epoch 189/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9184\n",
      "Epoch 190/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9222\n",
      "Epoch 191/1500\n",
      "25/25 [==============================] - 0s 988us/step - loss: 0.1640 - accuracy: 0.9247\n",
      "Epoch 192/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9120\n",
      "Epoch 193/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.9184\n",
      "Epoch 194/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9349\n",
      "Epoch 195/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9388\n",
      "Epoch 196/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9337\n",
      "Epoch 197/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9260\n",
      "Epoch 198/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9388\n",
      "Epoch 199/1500\n",
      "25/25 [==============================] - 0s 990us/step - loss: 0.1607 - accuracy: 0.9222\n",
      "Epoch 200/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9362\n",
      "Epoch 201/1500\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9311\n",
      "Epoch 202/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.9375\n",
      "Epoch 203/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9375\n",
      "Epoch 204/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9235\n",
      "Epoch 205/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1719 - accuracy: 0.9273\n",
      "Epoch 206/1500\n",
      "25/25 [==============================] - 0s 998us/step - loss: 0.1439 - accuracy: 0.9349\n",
      "Epoch 207/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9311\n",
      "Epoch 208/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9426\n",
      "Epoch 209/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9375\n",
      "Epoch 210/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9503\n",
      "Epoch 211/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9209\n",
      "Epoch 212/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9349\n",
      "Epoch 213/1500\n",
      "25/25 [==============================] - 0s 979us/step - loss: 0.1315 - accuracy: 0.9388\n",
      "Epoch 214/1500\n",
      "25/25 [==============================] - 0s 991us/step - loss: 0.1361 - accuracy: 0.9337\n",
      "Epoch 215/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9375\n",
      "Epoch 216/1500\n",
      "25/25 [==============================] - 0s 998us/step - loss: 0.1365 - accuracy: 0.9375\n",
      "Epoch 217/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1351 - accuracy: 0.9324\n",
      "Epoch 218/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9452\n",
      "Epoch 219/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.9158\n",
      "Epoch 220/1500\n",
      "25/25 [==============================] - 0s 999us/step - loss: 0.1627 - accuracy: 0.9222\n",
      "Epoch 221/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9247\n",
      "Epoch 222/1500\n",
      "25/25 [==============================] - 0s 987us/step - loss: 0.1108 - accuracy: 0.9439\n",
      "Epoch 223/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9286\n",
      "Epoch 224/1500\n",
      "25/25 [==============================] - 0s 960us/step - loss: 0.1291 - accuracy: 0.9426\n",
      "Epoch 225/1500\n",
      "25/25 [==============================] - 0s 983us/step - loss: 0.1336 - accuracy: 0.9439\n",
      "Epoch 226/1500\n",
      "25/25 [==============================] - 0s 965us/step - loss: 0.1447 - accuracy: 0.9413\n",
      "Epoch 227/1500\n",
      "25/25 [==============================] - 0s 956us/step - loss: 0.1220 - accuracy: 0.9362\n",
      "Epoch 228/1500\n",
      "25/25 [==============================] - 0s 988us/step - loss: 0.1312 - accuracy: 0.9452\n",
      "Epoch 229/1500\n",
      "25/25 [==============================] - 0s 980us/step - loss: 0.1544 - accuracy: 0.9286\n",
      "Epoch 230/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9452\n",
      "Epoch 231/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.9413\n",
      "Epoch 232/1500\n",
      "25/25 [==============================] - 0s 988us/step - loss: 0.1291 - accuracy: 0.9286\n",
      "Epoch 233/1500\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.1381 - accuracy: 0.9452\n",
      "Epoch 234/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9375\n",
      "Epoch 235/1500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9375\n",
      "Epoch 236/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.9286\n",
      "Epoch 237/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.9503\n",
      "Epoch 238/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1673 - accuracy: 0.9247\n",
      "Epoch 239/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9413\n",
      "Epoch 240/1500\n",
      "25/25 [==============================] - 0s 996us/step - loss: 0.1112 - accuracy: 0.9528\n",
      "Epoch 241/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.9413\n",
      "Epoch 242/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1194 - accuracy: 0.9566\n",
      "Epoch 243/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9362\n",
      "Epoch 244/1500\n",
      "25/25 [==============================] - 0s 983us/step - loss: 0.1326 - accuracy: 0.9375\n",
      "Epoch 245/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.9477\n",
      "Epoch 246/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9464\n",
      "Epoch 247/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1412 - accuracy: 0.9413\n",
      "Epoch 248/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9439\n",
      "Epoch 249/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9464\n",
      "Epoch 250/1500\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.9362\n",
      "Epoch 251/1500\n",
      "25/25 [==============================] - 0s 989us/step - loss: 0.1191 - accuracy: 0.9490\n",
      "Epoch 252/1500\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.0454 - accuracy: 0.9688Restoring model weights from the end of the best epoch: 222.\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9362\n",
      "Epoch 252: early stopping\n",
      "5/5 [==============================] - 0s 976us/step - loss: 0.7172 - accuracy: 0.7190\n",
      "5/5 [==============================] - 0s 780us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.72 (18/25)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before appending - Cat IDs: 0, Predictions: 0, Actuals: 0, Gender: 0\n",
      "After appending - Cat IDs: 153, Predictions: 153, Actuals: 153, Gender: 153\n",
      "Final Test Results - Loss: 0.7172483801841736, Accuracy: 0.7189542651176453, Precision: 0.6281033500560487, Recall: 0.6854921898025346, F1 Score: 0.6258926774750673\n",
      "Confusion Matrix:\n",
      " [[85  5 26]\n",
      " [ 7 17  0]\n",
      " [ 5  0  8]]\n",
      "outer_fold 2\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "103A    33\n",
      "057A    27\n",
      "074A    25\n",
      "020A    23\n",
      "055A    20\n",
      "000B    19\n",
      "029A    17\n",
      "019A    17\n",
      "097A    16\n",
      "101A    15\n",
      "059A    14\n",
      "001A    14\n",
      "097B    14\n",
      "106A    14\n",
      "028A    13\n",
      "002A    13\n",
      "111A    13\n",
      "051A    12\n",
      "025A    11\n",
      "036A    11\n",
      "005A    10\n",
      "040A    10\n",
      "071A    10\n",
      "014B    10\n",
      "022A     9\n",
      "015A     9\n",
      "065A     9\n",
      "045A     9\n",
      "072A     9\n",
      "095A     8\n",
      "094A     8\n",
      "031A     7\n",
      "027A     7\n",
      "008A     6\n",
      "108A     6\n",
      "109A     6\n",
      "053A     6\n",
      "023A     6\n",
      "037A     6\n",
      "023B     5\n",
      "070A     5\n",
      "044A     5\n",
      "021A     5\n",
      "034A     5\n",
      "052A     4\n",
      "003A     4\n",
      "105A     4\n",
      "009A     4\n",
      "026A     4\n",
      "035A     4\n",
      "104A     4\n",
      "062A     4\n",
      "064A     3\n",
      "058A     3\n",
      "006A     3\n",
      "056A     3\n",
      "012A     3\n",
      "113A     3\n",
      "014A     3\n",
      "060A     3\n",
      "011A     2\n",
      "102A     2\n",
      "032A     2\n",
      "069A     2\n",
      "018A     2\n",
      "093A     2\n",
      "054A     2\n",
      "038A     2\n",
      "019B     1\n",
      "090A     1\n",
      "100A     1\n",
      "110A     1\n",
      "115A     1\n",
      "092A     1\n",
      "004A     1\n",
      "041A     1\n",
      "076A     1\n",
      "096A     1\n",
      "026C     1\n",
      "073A     1\n",
      "049A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "000A    39\n",
      "002B    32\n",
      "047A    28\n",
      "067A    19\n",
      "042A    14\n",
      "116A    12\n",
      "039A    12\n",
      "068A    11\n",
      "063A    11\n",
      "016A    10\n",
      "033A     9\n",
      "051B     9\n",
      "010A     8\n",
      "013B     8\n",
      "099A     7\n",
      "117A     7\n",
      "050A     7\n",
      "007A     6\n",
      "075A     5\n",
      "025C     5\n",
      "087A     2\n",
      "061A     2\n",
      "025B     2\n",
      "043A     1\n",
      "066A     1\n",
      "048A     1\n",
      "088A     1\n",
      "091A     1\n",
      "024A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    263\n",
      "M    226\n",
      "F    177\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "M    111\n",
      "X     85\n",
      "F     75\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 015A, 001A, 103A, 071A, 097B, 028A, 019...\n",
      "kitten    [044A, 014B, 111A, 040A, 046A, 109A, 049A, 041...\n",
      "senior    [093A, 097A, 057A, 106A, 104A, 055A, 059A, 113...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [000A, 033A, 067A, 002B, 091A, 039A, 063A, 013...\n",
      "kitten                       [047A, 042A, 050A, 043A, 048A]\n",
      "senior                 [116A, 051B, 117A, 016A, 061A, 024A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 56, 'kitten': 11, 'senior': 16}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 18, 'kitten': 5, 'senior': 6}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000B' '001A' '002A' '003A' '004A' '005A' '006A' '008A' '009A' '011A'\n",
      " '012A' '014A' '014B' '015A' '018A' '019A' '019B' '020A' '021A' '022A'\n",
      " '023A' '023B' '025A' '026A' '026B' '026C' '027A' '028A' '029A' '031A'\n",
      " '032A' '034A' '035A' '036A' '037A' '038A' '040A' '041A' '044A' '045A'\n",
      " '046A' '049A' '051A' '052A' '053A' '054A' '055A' '056A' '057A' '058A'\n",
      " '059A' '060A' '062A' '064A' '065A' '069A' '070A' '071A' '072A' '073A'\n",
      " '074A' '076A' '090A' '092A' '093A' '094A' '095A' '096A' '097A' '097B'\n",
      " '100A' '101A' '102A' '103A' '104A' '105A' '106A' '108A' '109A' '110A'\n",
      " '111A' '113A' '115A']\n",
      "Unique Test Group IDs:\n",
      "['000A' '002B' '007A' '010A' '013B' '016A' '024A' '025B' '025C' '033A'\n",
      " '039A' '042A' '043A' '047A' '048A' '050A' '051B' '061A' '063A' '066A'\n",
      " '067A' '068A' '075A' '087A' '088A' '091A' '099A' '116A' '117A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "{'000A'}\n",
      "Removed from Training/Validation Set:\n",
      "{'002A'}\n",
      "Moved to Test Set:\n",
      "{'002A'}\n",
      "Removed from Test Set\n",
      "{'000A'}\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '003A' '004A' '005A' '006A' '008A' '009A' '011A'\n",
      " '012A' '014A' '014B' '015A' '018A' '019A' '019B' '020A' '021A' '022A'\n",
      " '023A' '023B' '025A' '026A' '026B' '026C' '027A' '028A' '029A' '031A'\n",
      " '032A' '034A' '035A' '036A' '037A' '038A' '040A' '041A' '044A' '045A'\n",
      " '046A' '049A' '051A' '052A' '053A' '054A' '055A' '056A' '057A' '058A'\n",
      " '059A' '060A' '062A' '064A' '065A' '069A' '070A' '071A' '072A' '073A'\n",
      " '074A' '076A' '090A' '092A' '093A' '094A' '095A' '096A' '097A' '097B'\n",
      " '100A' '101A' '102A' '103A' '104A' '105A' '106A' '108A' '109A' '110A'\n",
      " '111A' '113A' '115A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['002A' '002B' '007A' '010A' '013B' '016A' '024A' '025B' '025C' '033A'\n",
      " '039A' '042A' '043A' '047A' '048A' '050A' '051B' '061A' '063A' '066A'\n",
      " '067A' '068A' '075A' '087A' '088A' '091A' '099A' '116A' '117A']\n",
      "Length of X_train_val:\n",
      "692\n",
      "Length of y_train_val:\n",
      "692\n",
      "Length of groups_train_val:\n",
      "692\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     409\n",
      "senior    137\n",
      "kitten    120\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     179\n",
      "kitten     51\n",
      "senior     41\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     435\n",
      "senior    137\n",
      "kitten    120\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     153\n",
      "kitten     51\n",
      "senior     41\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 435, 2: 137, 1: 120})\n",
      "Epoch 1/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 1.0972 - accuracy: 0.4422\n",
      "Epoch 2/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.8270 - accuracy: 0.5564\n",
      "Epoch 3/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7730 - accuracy: 0.5737\n",
      "Epoch 4/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7122 - accuracy: 0.5896\n",
      "Epoch 5/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6378 - accuracy: 0.6214\n",
      "Epoch 6/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.6156\n",
      "Epoch 7/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5961 - accuracy: 0.6517\n",
      "Epoch 8/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6142\n",
      "Epoch 9/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.6720\n",
      "Epoch 10/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.6676\n",
      "Epoch 11/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.6980\n",
      "Epoch 12/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.7110\n",
      "Epoch 13/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5506 - accuracy: 0.6951\n",
      "Epoch 14/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.6994\n",
      "Epoch 15/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7153\n",
      "Epoch 16/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7038\n",
      "Epoch 17/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7442\n",
      "Epoch 18/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7341\n",
      "Epoch 19/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7399\n",
      "Epoch 20/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.7413\n",
      "Epoch 21/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7500\n",
      "Epoch 22/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7471\n",
      "Epoch 23/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.7616\n",
      "Epoch 24/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7919\n",
      "Epoch 25/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7645\n",
      "Epoch 26/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7630\n",
      "Epoch 27/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.7760\n",
      "Epoch 28/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.7948\n",
      "Epoch 29/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.8049\n",
      "Epoch 30/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4090 - accuracy: 0.7673\n",
      "Epoch 31/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3987 - accuracy: 0.7818\n",
      "Epoch 32/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8078\n",
      "Epoch 33/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.7731\n",
      "Epoch 34/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.7861\n",
      "Epoch 35/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.8064\n",
      "Epoch 36/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3642 - accuracy: 0.8136\n",
      "Epoch 37/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8035\n",
      "Epoch 38/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3713 - accuracy: 0.7818\n",
      "Epoch 39/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4047 - accuracy: 0.7832\n",
      "Epoch 40/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8150\n",
      "Epoch 41/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8107\n",
      "Epoch 42/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8049\n",
      "Epoch 43/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3679 - accuracy: 0.8179\n",
      "Epoch 44/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8064\n",
      "Epoch 45/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.8136\n",
      "Epoch 46/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3226 - accuracy: 0.8338\n",
      "Epoch 47/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8251\n",
      "Epoch 48/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8324\n",
      "Epoch 49/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3228 - accuracy: 0.8136\n",
      "Epoch 50/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8295\n",
      "Epoch 51/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3168 - accuracy: 0.8237\n",
      "Epoch 52/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8280\n",
      "Epoch 53/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8179\n",
      "Epoch 54/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3155 - accuracy: 0.8468\n",
      "Epoch 55/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.8194\n",
      "Epoch 56/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3030 - accuracy: 0.8324\n",
      "Epoch 57/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.8396\n",
      "Epoch 58/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3130 - accuracy: 0.8251\n",
      "Epoch 59/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3023 - accuracy: 0.8425\n",
      "Epoch 60/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.8613\n",
      "Epoch 61/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2721 - accuracy: 0.8598\n",
      "Epoch 62/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.3057 - accuracy: 0.8468\n",
      "Epoch 63/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 0.8483\n",
      "Epoch 64/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.8627\n",
      "Epoch 65/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2886 - accuracy: 0.8439\n",
      "Epoch 66/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 0.8555\n",
      "Epoch 67/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2876 - accuracy: 0.8512\n",
      "Epoch 68/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2689 - accuracy: 0.8540\n",
      "Epoch 69/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2764 - accuracy: 0.8613\n",
      "Epoch 70/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2750 - accuracy: 0.8512\n",
      "Epoch 71/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2730 - accuracy: 0.8685\n",
      "Epoch 72/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.8627\n",
      "Epoch 73/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.8699\n",
      "Epoch 74/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.8642\n",
      "Epoch 75/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 0.8454\n",
      "Epoch 76/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.8685\n",
      "Epoch 77/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2678 - accuracy: 0.8714\n",
      "Epoch 78/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2549 - accuracy: 0.8569\n",
      "Epoch 79/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2592 - accuracy: 0.8598\n",
      "Epoch 80/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2542 - accuracy: 0.8569\n",
      "Epoch 81/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.8483\n",
      "Epoch 82/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2703 - accuracy: 0.8598\n",
      "Epoch 83/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2825 - accuracy: 0.8540\n",
      "Epoch 84/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.8772\n",
      "Epoch 85/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2780 - accuracy: 0.8468\n",
      "Epoch 86/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2249 - accuracy: 0.8815\n",
      "Epoch 87/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2330 - accuracy: 0.8685\n",
      "Epoch 88/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.8786\n",
      "Epoch 89/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2132 - accuracy: 0.8757\n",
      "Epoch 90/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.8902\n",
      "Epoch 91/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.8858\n",
      "Epoch 92/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.8714\n",
      "Epoch 93/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.8786\n",
      "Epoch 94/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.8743\n",
      "Epoch 95/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.8887\n",
      "Epoch 96/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.8815\n",
      "Epoch 97/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2286 - accuracy: 0.8801\n",
      "Epoch 98/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.8815\n",
      "Epoch 99/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2082 - accuracy: 0.8960\n",
      "Epoch 100/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.8902\n",
      "Epoch 101/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.8699\n",
      "Epoch 102/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.8671\n",
      "Epoch 103/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2202 - accuracy: 0.9017\n",
      "Epoch 104/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2087 - accuracy: 0.8974\n",
      "Epoch 105/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.8757\n",
      "Epoch 106/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.9061\n",
      "Epoch 107/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 0.8974\n",
      "Epoch 108/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.8671\n",
      "Epoch 109/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.9003\n",
      "Epoch 110/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.8757\n",
      "Epoch 111/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.8902\n",
      "Epoch 112/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2101 - accuracy: 0.9046\n",
      "Epoch 113/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.9061\n",
      "Epoch 114/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2105 - accuracy: 0.9003\n",
      "Epoch 115/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2118 - accuracy: 0.9061\n",
      "Epoch 116/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.8974\n",
      "Epoch 117/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.9205\n",
      "Epoch 118/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9061\n",
      "Epoch 119/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.9046\n",
      "Epoch 120/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.9090\n",
      "Epoch 121/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9046\n",
      "Epoch 122/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.8945\n",
      "Epoch 123/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9133\n",
      "Epoch 124/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.8974\n",
      "Epoch 125/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.8988\n",
      "Epoch 126/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9104\n",
      "Epoch 127/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9046\n",
      "Epoch 128/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.9090\n",
      "Epoch 129/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.9075\n",
      "Epoch 130/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9133\n",
      "Epoch 131/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1728 - accuracy: 0.9090\n",
      "Epoch 132/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9046\n",
      "Epoch 133/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.8960\n",
      "Epoch 134/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.9061\n",
      "Epoch 135/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.9017\n",
      "Epoch 136/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9277\n",
      "Epoch 137/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1651 - accuracy: 0.9205\n",
      "Epoch 138/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9234\n",
      "Epoch 139/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9249\n",
      "Epoch 140/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.9147\n",
      "Epoch 141/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9147\n",
      "Epoch 142/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.8974\n",
      "Epoch 143/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.9176\n",
      "Epoch 144/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.9162\n",
      "Epoch 145/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1629 - accuracy: 0.9234\n",
      "Epoch 146/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.9147\n",
      "Epoch 147/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9090\n",
      "Epoch 148/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9162\n",
      "Epoch 149/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.9017\n",
      "Epoch 150/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.9176\n",
      "Epoch 151/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1733 - accuracy: 0.9104\n",
      "Epoch 152/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9176\n",
      "Epoch 153/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9162\n",
      "Epoch 154/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9306\n",
      "Epoch 155/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.9133\n",
      "Epoch 156/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9220\n",
      "Epoch 157/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.9147\n",
      "Epoch 158/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.9162\n",
      "Epoch 159/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9321\n",
      "Epoch 160/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9249\n",
      "Epoch 161/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9306\n",
      "Epoch 162/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9220\n",
      "Epoch 163/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9321\n",
      "Epoch 164/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1649 - accuracy: 0.9191\n",
      "Epoch 165/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9176\n",
      "Epoch 166/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9292\n",
      "Epoch 167/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1590 - accuracy: 0.9249\n",
      "Epoch 168/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9205\n",
      "Epoch 169/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9292\n",
      "Epoch 170/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1536 - accuracy: 0.9292\n",
      "Epoch 171/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9335\n",
      "Epoch 172/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9379\n",
      "Epoch 173/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9191\n",
      "Epoch 174/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9234\n",
      "Epoch 175/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1493 - accuracy: 0.9350\n",
      "Epoch 176/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9306\n",
      "Epoch 177/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9292\n",
      "Epoch 178/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9393\n",
      "Epoch 179/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9350\n",
      "Epoch 180/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9263\n",
      "Epoch 181/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9249\n",
      "Epoch 182/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9321\n",
      "Epoch 183/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9234\n",
      "Epoch 184/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.9277\n",
      "Epoch 185/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9393\n",
      "Epoch 186/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9408\n",
      "Epoch 187/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9581\n",
      "Epoch 188/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9306\n",
      "Epoch 189/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.9205\n",
      "Epoch 190/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9350\n",
      "Epoch 191/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1301 - accuracy: 0.9393\n",
      "Epoch 192/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9436\n",
      "Epoch 193/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9306\n",
      "Epoch 194/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9205\n",
      "Epoch 195/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9350\n",
      "Epoch 196/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9436\n",
      "Epoch 197/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.9480\n",
      "Epoch 198/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9480\n",
      "Epoch 199/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1282 - accuracy: 0.9393\n",
      "Epoch 200/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9422\n",
      "Epoch 201/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9509\n",
      "Epoch 202/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.9306\n",
      "Epoch 203/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9451\n",
      "Epoch 204/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1248 - accuracy: 0.9393\n",
      "Epoch 205/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.9509\n",
      "Epoch 206/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9422\n",
      "Epoch 207/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9436\n",
      "Epoch 208/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9277\n",
      "Epoch 209/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.9408\n",
      "Epoch 210/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9436\n",
      "Epoch 211/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.9436\n",
      "Epoch 212/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9393\n",
      "Epoch 213/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9364\n",
      "Epoch 214/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9566\n",
      "Epoch 215/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9451\n",
      "Epoch 216/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9364\n",
      "Epoch 217/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9465\n",
      "Epoch 218/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.9465\n",
      "Epoch 219/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9494\n",
      "Epoch 220/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9393\n",
      "Epoch 221/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.9364\n",
      "Epoch 222/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9393\n",
      "Epoch 223/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9306\n",
      "Epoch 224/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9379\n",
      "Epoch 225/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9379\n",
      "Epoch 226/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9408\n",
      "Epoch 227/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9465\n",
      "Epoch 228/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9350\n",
      "Epoch 229/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9509\n",
      "Epoch 230/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9523\n",
      "Epoch 231/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9523\n",
      "Epoch 232/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9610\n",
      "Epoch 233/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9552\n",
      "Epoch 234/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9422\n",
      "Epoch 235/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9523\n",
      "Epoch 236/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9422\n",
      "Epoch 237/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9494\n",
      "Epoch 238/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9480\n",
      "Epoch 239/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9465\n",
      "Epoch 240/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9494\n",
      "Epoch 241/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9653\n",
      "Epoch 242/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9566\n",
      "Epoch 243/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9711\n",
      "Epoch 244/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9509\n",
      "Epoch 245/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 0.9292\n",
      "Epoch 246/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9610\n",
      "Epoch 247/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9566\n",
      "Epoch 248/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9538\n",
      "Epoch 249/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9639\n",
      "Epoch 250/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.9480\n",
      "Epoch 251/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.9393\n",
      "Epoch 252/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.9509\n",
      "Epoch 253/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9379\n",
      "Epoch 254/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9509\n",
      "Epoch 255/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9509\n",
      "Epoch 256/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9610\n",
      "Epoch 257/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9538\n",
      "Epoch 258/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9566\n",
      "Epoch 259/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9538\n",
      "Epoch 260/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9610\n",
      "Epoch 261/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9639\n",
      "Epoch 262/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9552\n",
      "Epoch 263/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9581\n",
      "Epoch 264/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9566\n",
      "Epoch 265/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9436\n",
      "Epoch 266/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9494\n",
      "Epoch 267/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9350\n",
      "Epoch 268/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.9639\n",
      "Epoch 269/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9494\n",
      "Epoch 270/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9552\n",
      "Epoch 271/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9595\n",
      "Epoch 272/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.9509\n",
      "Epoch 273/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9509\n",
      "Epoch 274/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9566\n",
      "Epoch 275/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0943 - accuracy: 0.9581\n",
      "Epoch 276/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9595\n",
      "Epoch 277/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9465\n",
      "Epoch 278/1500\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0960 - accuracy: 0.9595\n",
      "Epoch 279/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9610\n",
      "Epoch 280/1500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0874 - accuracy: 0.9653\n",
      "Epoch 281/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9653\n",
      "Epoch 282/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9624\n",
      "Epoch 283/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0681 - accuracy: 0.9812\n",
      "Epoch 284/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9610\n",
      "Epoch 285/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9639\n",
      "Epoch 286/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.9639\n",
      "Epoch 287/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9538\n",
      "Epoch 288/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9523\n",
      "Epoch 289/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9581\n",
      "Epoch 290/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9711\n",
      "Epoch 291/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0890 - accuracy: 0.9624\n",
      "Epoch 292/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.9653\n",
      "Epoch 293/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9711\n",
      "Epoch 294/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9595\n",
      "Epoch 295/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9610\n",
      "Epoch 296/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9624\n",
      "Epoch 297/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9595\n",
      "Epoch 298/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9451\n",
      "Epoch 299/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9610\n",
      "Epoch 300/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9566\n",
      "Epoch 301/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.9494\n",
      "Epoch 302/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9581\n",
      "Epoch 303/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9494\n",
      "Epoch 304/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9552\n",
      "Epoch 305/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9538\n",
      "Epoch 306/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9624\n",
      "Epoch 307/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9653\n",
      "Epoch 308/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9509\n",
      "Epoch 309/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9711\n",
      "Epoch 310/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0915 - accuracy: 0.9639\n",
      "Epoch 311/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9610\n",
      "Epoch 312/1500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9581\n",
      "Epoch 313/1500\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.0832 - accuracy: 0.9375Restoring model weights from the end of the best epoch: 283.\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9509\n",
      "Epoch 313: early stopping\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8117 - accuracy: 0.7020\n",
      "8/8 [==============================] - 0s 682us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.69 (20/29)\n",
      "Before appending - Cat IDs: 153, Predictions: 153, Actuals: 153, Gender: 153\n",
      "After appending - Cat IDs: 398, Predictions: 398, Actuals: 398, Gender: 398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Results - Loss: 0.8116528987884521, Accuracy: 0.7020407915115356, Precision: 0.7186952348242671, Recall: 0.5733567139592964, F1 Score: 0.6071805647511794\n",
      "Confusion Matrix:\n",
      " [[133   1  19]\n",
      " [ 30  21   0]\n",
      " [ 23   0  18]]\n",
      "outer_fold 3\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "000A    39\n",
      "103A    33\n",
      "002B    32\n",
      "047A    28\n",
      "020A    23\n",
      "055A    20\n",
      "000B    19\n",
      "067A    19\n",
      "019A    17\n",
      "101A    15\n",
      "059A    14\n",
      "042A    14\n",
      "097B    14\n",
      "001A    14\n",
      "002A    13\n",
      "111A    13\n",
      "116A    12\n",
      "051A    12\n",
      "039A    12\n",
      "068A    11\n",
      "036A    11\n",
      "063A    11\n",
      "014B    10\n",
      "016A    10\n",
      "040A    10\n",
      "071A    10\n",
      "065A     9\n",
      "033A     9\n",
      "051B     9\n",
      "022A     9\n",
      "010A     8\n",
      "095A     8\n",
      "013B     8\n",
      "027A     7\n",
      "099A     7\n",
      "031A     7\n",
      "050A     7\n",
      "117A     7\n",
      "007A     6\n",
      "109A     6\n",
      "108A     6\n",
      "037A     6\n",
      "008A     6\n",
      "044A     5\n",
      "025C     5\n",
      "070A     5\n",
      "075A     5\n",
      "034A     5\n",
      "023B     5\n",
      "052A     4\n",
      "026A     4\n",
      "105A     4\n",
      "060A     3\n",
      "012A     3\n",
      "064A     3\n",
      "006A     3\n",
      "113A     3\n",
      "014A     3\n",
      "061A     2\n",
      "054A     2\n",
      "087A     2\n",
      "025B     2\n",
      "011A     2\n",
      "018A     2\n",
      "102A     2\n",
      "043A     1\n",
      "024A     1\n",
      "090A     1\n",
      "091A     1\n",
      "110A     1\n",
      "115A     1\n",
      "004A     1\n",
      "019B     1\n",
      "088A     1\n",
      "048A     1\n",
      "066A     1\n",
      "041A     1\n",
      "092A     1\n",
      "049A     1\n",
      "096A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "057A    27\n",
      "074A    25\n",
      "029A    17\n",
      "097A    16\n",
      "106A    14\n",
      "028A    13\n",
      "025A    11\n",
      "005A    10\n",
      "015A     9\n",
      "045A     9\n",
      "072A     9\n",
      "094A     8\n",
      "023A     6\n",
      "053A     6\n",
      "021A     5\n",
      "009A     4\n",
      "035A     4\n",
      "104A     4\n",
      "062A     4\n",
      "003A     4\n",
      "058A     3\n",
      "056A     3\n",
      "093A     2\n",
      "032A     2\n",
      "069A     2\n",
      "038A     2\n",
      "073A     1\n",
      "076A     1\n",
      "026C     1\n",
      "100A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "X    266\n",
      "M    237\n",
      "F    211\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "M    100\n",
      "X     82\n",
      "F     41\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 000A, 033A, 001A, 103A, 071A, 097B, 019...\n",
      "kitten    [044A, 014B, 111A, 040A, 046A, 047A, 042A, 109...\n",
      "senior    [055A, 059A, 113A, 116A, 051B, 054A, 117A, 051...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [015A, 028A, 074A, 062A, 029A, 005A, 072A, 009...\n",
      "kitten                                               [045A]\n",
      "senior     [093A, 097A, 057A, 106A, 104A, 056A, 058A, 094A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 53, 'kitten': 15, 'senior': 14}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 21, 'kitten': 1, 'senior': 8}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '002B' '004A' '006A' '007A' '008A' '010A'\n",
      " '011A' '012A' '013B' '014A' '014B' '016A' '018A' '019A' '019B' '020A'\n",
      " '022A' '023B' '024A' '025B' '025C' '026A' '026B' '027A' '031A' '033A'\n",
      " '034A' '036A' '037A' '039A' '040A' '041A' '042A' '043A' '044A' '046A'\n",
      " '047A' '048A' '049A' '050A' '051A' '051B' '052A' '054A' '055A' '059A'\n",
      " '060A' '061A' '063A' '064A' '065A' '066A' '067A' '068A' '070A' '071A'\n",
      " '075A' '087A' '088A' '090A' '091A' '092A' '095A' '096A' '097B' '099A'\n",
      " '101A' '102A' '103A' '105A' '108A' '109A' '110A' '111A' '113A' '115A'\n",
      " '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['003A' '005A' '009A' '015A' '021A' '023A' '025A' '026C' '028A' '029A'\n",
      " '032A' '035A' '038A' '045A' '053A' '056A' '057A' '058A' '062A' '069A'\n",
      " '072A' '073A' '074A' '076A' '093A' '094A' '097A' '100A' '104A' '106A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "set()\n",
      "Removed from Training/Validation Set:\n",
      "set()\n",
      "Moved to Test Set:\n",
      "set()\n",
      "Removed from Test Set\n",
      "set()\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '002B' '004A' '006A' '007A' '008A' '010A'\n",
      " '011A' '012A' '013B' '014A' '014B' '016A' '018A' '019A' '019B' '020A'\n",
      " '022A' '023B' '024A' '025B' '025C' '026A' '026B' '027A' '031A' '033A'\n",
      " '034A' '036A' '037A' '039A' '040A' '041A' '042A' '043A' '044A' '046A'\n",
      " '047A' '048A' '049A' '050A' '051A' '051B' '052A' '054A' '055A' '059A'\n",
      " '060A' '061A' '063A' '064A' '065A' '066A' '067A' '068A' '070A' '071A'\n",
      " '075A' '087A' '088A' '090A' '091A' '092A' '095A' '096A' '097B' '099A'\n",
      " '101A' '102A' '103A' '105A' '108A' '109A' '110A' '111A' '113A' '115A'\n",
      " '116A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['003A' '005A' '009A' '015A' '021A' '023A' '025A' '026C' '028A' '029A'\n",
      " '032A' '035A' '038A' '045A' '053A' '056A' '057A' '058A' '062A' '069A'\n",
      " '072A' '073A' '074A' '076A' '093A' '094A' '097A' '100A' '104A' '106A']\n",
      "Length of X_train_val:\n",
      "714\n",
      "Length of y_train_val:\n",
      "714\n",
      "Length of groups_train_val:\n",
      "714\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     451\n",
      "kitten    162\n",
      "senior    101\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     137\n",
      "senior     77\n",
      "kitten      9\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     451\n",
      "kitten    162\n",
      "senior    101\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     137\n",
      "senior     77\n",
      "kitten      9\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 451, 1: 162, 2: 101})\n",
      "Epoch 1/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.0265 - accuracy: 0.4748\n",
      "Epoch 2/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8252 - accuracy: 0.5504\n",
      "Epoch 3/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.6064\n",
      "Epoch 4/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.5994\n",
      "Epoch 5/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6569\n",
      "Epoch 6/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6230 - accuracy: 0.6681\n",
      "Epoch 7/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5886 - accuracy: 0.6975\n",
      "Epoch 8/1500\n",
      "23/23 [==============================] - 0s 979us/step - loss: 0.5881 - accuracy: 0.6975\n",
      "Epoch 9/1500\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.5449 - accuracy: 0.7045\n",
      "Epoch 10/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.7241\n",
      "Epoch 11/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.7101\n",
      "Epoch 12/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7381\n",
      "Epoch 13/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.7045\n",
      "Epoch 14/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7437\n",
      "Epoch 15/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7451\n",
      "Epoch 16/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7619\n",
      "Epoch 17/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7549\n",
      "Epoch 18/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.7647\n",
      "Epoch 19/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7759\n",
      "Epoch 20/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7829\n",
      "Epoch 21/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4162 - accuracy: 0.7801\n",
      "Epoch 22/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7773\n",
      "Epoch 23/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4022 - accuracy: 0.7717\n",
      "Epoch 24/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.7759\n",
      "Epoch 25/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3830 - accuracy: 0.7899\n",
      "Epoch 26/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.7745\n",
      "Epoch 27/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4004 - accuracy: 0.8011\n",
      "Epoch 28/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4261 - accuracy: 0.7787\n",
      "Epoch 29/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.8095\n",
      "Epoch 30/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8025\n",
      "Epoch 31/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3826 - accuracy: 0.7787\n",
      "Epoch 32/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8067\n",
      "Epoch 33/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8025\n",
      "Epoch 34/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8221\n",
      "Epoch 35/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3626 - accuracy: 0.8039\n",
      "Epoch 36/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3760 - accuracy: 0.8039\n",
      "Epoch 37/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8039\n",
      "Epoch 38/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3706 - accuracy: 0.8109\n",
      "Epoch 39/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.8137\n",
      "Epoch 40/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8277\n",
      "Epoch 41/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3133 - accuracy: 0.8235\n",
      "Epoch 42/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3176 - accuracy: 0.8221\n",
      "Epoch 43/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.8445\n",
      "Epoch 44/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8347\n",
      "Epoch 45/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3041 - accuracy: 0.8459\n",
      "Epoch 46/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8305\n",
      "Epoch 47/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8417\n",
      "Epoch 48/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3035 - accuracy: 0.8515\n",
      "Epoch 49/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8221\n",
      "Epoch 50/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8249\n",
      "Epoch 51/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3005 - accuracy: 0.8347\n",
      "Epoch 52/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3049 - accuracy: 0.8249\n",
      "Epoch 53/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2973 - accuracy: 0.8529\n",
      "Epoch 54/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2901 - accuracy: 0.8361\n",
      "Epoch 55/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2843 - accuracy: 0.8529\n",
      "Epoch 56/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2949 - accuracy: 0.8515\n",
      "Epoch 57/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8417\n",
      "Epoch 58/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2938 - accuracy: 0.8403\n",
      "Epoch 59/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2912 - accuracy: 0.8529\n",
      "Epoch 60/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2772 - accuracy: 0.8641\n",
      "Epoch 61/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8599\n",
      "Epoch 62/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.8445\n",
      "Epoch 63/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2729 - accuracy: 0.8683\n",
      "Epoch 64/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2981 - accuracy: 0.8557\n",
      "Epoch 65/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2921 - accuracy: 0.8543\n",
      "Epoch 66/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8683\n",
      "Epoch 67/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.8739\n",
      "Epoch 68/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2988 - accuracy: 0.8529\n",
      "Epoch 69/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2627 - accuracy: 0.8627\n",
      "Epoch 70/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2546 - accuracy: 0.8697\n",
      "Epoch 71/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.8683\n",
      "Epoch 72/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.8739\n",
      "Epoch 73/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2971 - accuracy: 0.8557\n",
      "Epoch 74/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2746 - accuracy: 0.8768\n",
      "Epoch 75/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2883 - accuracy: 0.8529\n",
      "Epoch 76/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.8725\n",
      "Epoch 77/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.8725\n",
      "Epoch 78/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.8922\n",
      "Epoch 79/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2607 - accuracy: 0.8739\n",
      "Epoch 80/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2927 - accuracy: 0.8641\n",
      "Epoch 81/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2577 - accuracy: 0.8641\n",
      "Epoch 82/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.8922\n",
      "Epoch 83/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.8796\n",
      "Epoch 84/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.8782\n",
      "Epoch 85/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.8768\n",
      "Epoch 86/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.8824\n",
      "Epoch 87/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.8768\n",
      "Epoch 88/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.8978\n",
      "Epoch 89/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2086 - accuracy: 0.9020\n",
      "Epoch 90/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2613 - accuracy: 0.8880\n",
      "Epoch 91/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2347 - accuracy: 0.8725\n",
      "Epoch 92/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.8866\n",
      "Epoch 93/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.8768\n",
      "Epoch 94/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2137 - accuracy: 0.8922\n",
      "Epoch 95/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.8894\n",
      "Epoch 96/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.9034\n",
      "Epoch 97/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.8866\n",
      "Epoch 98/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.9020\n",
      "Epoch 99/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2369 - accuracy: 0.8782\n",
      "Epoch 100/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2208 - accuracy: 0.8936\n",
      "Epoch 101/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.8978\n",
      "Epoch 102/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.8894\n",
      "Epoch 103/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.8964\n",
      "Epoch 104/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.8964\n",
      "Epoch 105/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2104 - accuracy: 0.8992\n",
      "Epoch 106/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.8838\n",
      "Epoch 107/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.9104\n",
      "Epoch 108/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.8978\n",
      "Epoch 109/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.9076\n",
      "Epoch 110/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.8824\n",
      "Epoch 111/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.8964\n",
      "Epoch 112/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.9048\n",
      "Epoch 113/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.9048\n",
      "Epoch 114/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1954 - accuracy: 0.9118\n",
      "Epoch 115/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.8810\n",
      "Epoch 116/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.8866\n",
      "Epoch 117/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2095 - accuracy: 0.8978\n",
      "Epoch 118/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.9146\n",
      "Epoch 119/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9006\n",
      "Epoch 120/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.9034\n",
      "Epoch 121/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.9062\n",
      "Epoch 122/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.9020\n",
      "Epoch 123/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.9090\n",
      "Epoch 124/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.8992\n",
      "Epoch 125/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.9118\n",
      "Epoch 126/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9104\n",
      "Epoch 127/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2007 - accuracy: 0.9118\n",
      "Epoch 128/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.8978\n",
      "Epoch 129/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9062\n",
      "Epoch 130/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.9048\n",
      "Epoch 131/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1677 - accuracy: 0.9202\n",
      "Epoch 132/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9146\n",
      "Epoch 133/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.9090\n",
      "Epoch 134/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.9244\n",
      "Epoch 135/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.9048\n",
      "Epoch 136/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2106 - accuracy: 0.8978\n",
      "Epoch 137/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.9020\n",
      "Epoch 138/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9188\n",
      "Epoch 139/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1734 - accuracy: 0.9328\n",
      "Epoch 140/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1705 - accuracy: 0.9188\n",
      "Epoch 141/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.9202\n",
      "Epoch 142/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9258\n",
      "Epoch 143/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.9118\n",
      "Epoch 144/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9244\n",
      "Epoch 145/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9146\n",
      "Epoch 146/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.9258\n",
      "Epoch 147/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9314\n",
      "Epoch 148/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.8992\n",
      "Epoch 149/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9216\n",
      "Epoch 150/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1736 - accuracy: 0.9258\n",
      "Epoch 151/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9258\n",
      "Epoch 152/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.9160\n",
      "Epoch 153/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9118\n",
      "Epoch 154/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.9174\n",
      "Epoch 155/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.9048\n",
      "Epoch 156/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.9146\n",
      "Epoch 157/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2042 - accuracy: 0.8978\n",
      "Epoch 158/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9300\n",
      "Epoch 159/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9146\n",
      "Epoch 160/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.9146\n",
      "Epoch 161/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9230\n",
      "Epoch 162/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.9258\n",
      "Epoch 163/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9230\n",
      "Epoch 164/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1734 - accuracy: 0.9174\n",
      "Epoch 165/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9258\n",
      "Epoch 166/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9314\n",
      "Epoch 167/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9174\n",
      "Epoch 168/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9202\n",
      "Epoch 169/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9300\n",
      "Epoch 170/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9216\n",
      "Epoch 171/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9328\n",
      "Epoch 172/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9244\n",
      "Epoch 173/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9384\n",
      "Epoch 174/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9244\n",
      "Epoch 175/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.9244\n",
      "Epoch 176/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1380 - accuracy: 0.9398\n",
      "Epoch 177/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9300\n",
      "Epoch 178/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9328\n",
      "Epoch 179/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9426\n",
      "Epoch 180/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9454\n",
      "Epoch 181/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.9300\n",
      "Epoch 182/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9510\n",
      "Epoch 183/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9258\n",
      "Epoch 184/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9244\n",
      "Epoch 185/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9426\n",
      "Epoch 186/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9370\n",
      "Epoch 187/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1434 - accuracy: 0.9454\n",
      "Epoch 188/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9328\n",
      "Epoch 189/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9328\n",
      "Epoch 190/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9272\n",
      "Epoch 191/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9370\n",
      "Epoch 192/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.9440\n",
      "Epoch 193/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9314\n",
      "Epoch 194/1500\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.1265 - accuracy: 0.9426\n",
      "Epoch 195/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9174\n",
      "Epoch 196/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9328\n",
      "Epoch 197/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9370\n",
      "Epoch 198/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9314\n",
      "Epoch 199/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9286\n",
      "Epoch 200/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9244\n",
      "Epoch 201/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9538\n",
      "Epoch 202/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9468\n",
      "Epoch 203/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.9482\n",
      "Epoch 204/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.9370\n",
      "Epoch 205/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1640 - accuracy: 0.9202\n",
      "Epoch 206/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9300\n",
      "Epoch 207/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9580\n",
      "Epoch 208/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9356\n",
      "Epoch 209/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.9356\n",
      "Epoch 210/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9370\n",
      "Epoch 211/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9482\n",
      "Epoch 212/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9328\n",
      "Epoch 213/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.9258\n",
      "Epoch 214/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9426\n",
      "Epoch 215/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9328\n",
      "Epoch 216/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.9510\n",
      "Epoch 217/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.9412\n",
      "Epoch 218/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.9468\n",
      "Epoch 219/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9580\n",
      "Epoch 220/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9342\n",
      "Epoch 221/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.9510\n",
      "Epoch 222/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9412\n",
      "Epoch 223/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9650\n",
      "Epoch 224/1500\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.1356 - accuracy: 0.9412\n",
      "Epoch 225/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.9356\n",
      "Epoch 226/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9412\n",
      "Epoch 227/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9468\n",
      "Epoch 228/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.9426\n",
      "Epoch 229/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9398\n",
      "Epoch 230/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.9482\n",
      "Epoch 231/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9440\n",
      "Epoch 232/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9538\n",
      "Epoch 233/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9524\n",
      "Epoch 234/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9468\n",
      "Epoch 235/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.9440\n",
      "Epoch 236/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9454\n",
      "Epoch 237/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9524\n",
      "Epoch 238/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9300\n",
      "Epoch 239/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9440\n",
      "Epoch 240/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9496\n",
      "Epoch 241/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9580\n",
      "Epoch 242/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1322 - accuracy: 0.9384\n",
      "Epoch 243/1500\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.1011 - accuracy: 0.9510\n",
      "Epoch 244/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9510\n",
      "Epoch 245/1500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9524\n",
      "Epoch 246/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9496\n",
      "Epoch 247/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.9468\n",
      "Epoch 248/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9538\n",
      "Epoch 249/1500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.0458 - accuracy: 0.9688Restoring model weights from the end of the best epoch: 219.\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.9440\n",
      "Epoch 249: early stopping\n",
      "7/7 [==============================] - 0s 920us/step - loss: 0.9417 - accuracy: 0.6682\n",
      "7/7 [==============================] - 0s 704us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy for cat_id for this fold: 0.73 (22/30)\n",
      "Before appending - Cat IDs: 398, Predictions: 398, Actuals: 398, Gender: 398\n",
      "After appending - Cat IDs: 621, Predictions: 621, Actuals: 621, Gender: 621\n",
      "Final Test Results - Loss: 0.9416781067848206, Accuracy: 0.6681614518165588, Precision: 0.6001009718540957, Recall: 0.7479065946219231, F1 Score: 0.6413456584920149\n",
      "Confusion Matrix:\n",
      " [[101  10  26]\n",
      " [  0   9   0]\n",
      " [ 38   0  39]]\n",
      "outer_fold 4\n",
      "Train Set Group Distribution:\n",
      "046A    63\n",
      "000A    39\n",
      "103A    33\n",
      "002B    32\n",
      "047A    28\n",
      "057A    27\n",
      "074A    25\n",
      "067A    19\n",
      "000B    19\n",
      "029A    17\n",
      "097A    16\n",
      "042A    14\n",
      "001A    14\n",
      "106A    14\n",
      "028A    13\n",
      "002A    13\n",
      "039A    12\n",
      "116A    12\n",
      "025A    11\n",
      "063A    11\n",
      "068A    11\n",
      "040A    10\n",
      "005A    10\n",
      "016A    10\n",
      "051B     9\n",
      "022A     9\n",
      "045A     9\n",
      "065A     9\n",
      "072A     9\n",
      "033A     9\n",
      "015A     9\n",
      "094A     8\n",
      "010A     8\n",
      "013B     8\n",
      "117A     7\n",
      "099A     7\n",
      "050A     7\n",
      "007A     6\n",
      "053A     6\n",
      "108A     6\n",
      "109A     6\n",
      "023A     6\n",
      "021A     5\n",
      "025C     5\n",
      "044A     5\n",
      "075A     5\n",
      "009A     4\n",
      "035A     4\n",
      "104A     4\n",
      "026A     4\n",
      "062A     4\n",
      "003A     4\n",
      "012A     3\n",
      "056A     3\n",
      "064A     3\n",
      "058A     3\n",
      "006A     3\n",
      "113A     3\n",
      "069A     2\n",
      "025B     2\n",
      "061A     2\n",
      "018A     2\n",
      "038A     2\n",
      "087A     2\n",
      "011A     2\n",
      "093A     2\n",
      "032A     2\n",
      "054A     2\n",
      "088A     1\n",
      "115A     1\n",
      "100A     1\n",
      "024A     1\n",
      "019B     1\n",
      "043A     1\n",
      "091A     1\n",
      "004A     1\n",
      "048A     1\n",
      "066A     1\n",
      "026C     1\n",
      "092A     1\n",
      "049A     1\n",
      "076A     1\n",
      "073A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "020A    23\n",
      "055A    20\n",
      "019A    17\n",
      "101A    15\n",
      "097B    14\n",
      "059A    14\n",
      "111A    13\n",
      "051A    12\n",
      "036A    11\n",
      "014B    10\n",
      "071A    10\n",
      "095A     8\n",
      "027A     7\n",
      "031A     7\n",
      "037A     6\n",
      "008A     6\n",
      "023B     5\n",
      "070A     5\n",
      "034A     5\n",
      "105A     4\n",
      "052A     4\n",
      "014A     3\n",
      "060A     3\n",
      "102A     2\n",
      "110A     1\n",
      "096A     1\n",
      "041A     1\n",
      "090A     1\n",
      "Name: cat_id, dtype: int64\n",
      "Training Set Gender Distribution BEFORE SWAP:\n",
      "M    268\n",
      "X    259\n",
      "F    182\n",
      "Name: gender, dtype: int64\n",
      "Testing Set Gender Distribution BEFORE SWAP:\n",
      "X    89\n",
      "F    70\n",
      "M    69\n",
      "Name: gender, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 000A, 033A, 015A, 001A, 103A, 028A, 074...\n",
      "kitten    [044A, 040A, 046A, 047A, 042A, 109A, 050A, 043...\n",
      "senior    [093A, 097A, 057A, 106A, 104A, 113A, 116A, 051...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [071A, 097B, 019A, 020A, 101A, 095A, 034A, 027...\n",
      "kitten                             [014B, 111A, 041A, 110A]\n",
      "senior                             [055A, 059A, 051A, 090A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 54, 'kitten': 12, 'senior': 18}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 20, 'kitten': 4, 'senior': 4}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '002B' '003A' '004A' '005A' '006A' '007A'\n",
      " '009A' '010A' '011A' '012A' '013B' '015A' '016A' '018A' '019B' '021A'\n",
      " '022A' '023A' '024A' '025A' '025B' '025C' '026A' '026B' '026C' '028A'\n",
      " '029A' '032A' '033A' '035A' '038A' '039A' '040A' '042A' '043A' '044A'\n",
      " '045A' '046A' '047A' '048A' '049A' '050A' '051B' '053A' '054A' '056A'\n",
      " '057A' '058A' '061A' '062A' '063A' '064A' '065A' '066A' '067A' '068A'\n",
      " '069A' '072A' '073A' '074A' '075A' '076A' '087A' '088A' '091A' '092A'\n",
      " '093A' '094A' '097A' '099A' '100A' '103A' '104A' '106A' '108A' '109A'\n",
      " '113A' '115A' '116A' '117A']\n",
      "Unique Test Group IDs:\n",
      "['008A' '014A' '014B' '019A' '020A' '023B' '027A' '031A' '034A' '036A'\n",
      " '037A' '041A' '051A' '052A' '055A' '059A' '060A' '070A' '071A' '090A'\n",
      " '095A' '096A' '097B' '101A' '102A' '105A' '110A' '111A']\n",
      "No common groups found between train and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "set()\n",
      "Removed from Training/Validation Set:\n",
      "set()\n",
      "Moved to Test Set:\n",
      "set()\n",
      "Removed from Test Set\n",
      "set()\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '002B' '003A' '004A' '005A' '006A' '007A'\n",
      " '009A' '010A' '011A' '012A' '013B' '015A' '016A' '018A' '019B' '021A'\n",
      " '022A' '023A' '024A' '025A' '025B' '025C' '026A' '026B' '026C' '028A'\n",
      " '029A' '032A' '033A' '035A' '038A' '039A' '040A' '042A' '043A' '044A'\n",
      " '045A' '046A' '047A' '048A' '049A' '050A' '051B' '053A' '054A' '056A'\n",
      " '057A' '058A' '061A' '062A' '063A' '064A' '065A' '066A' '067A' '068A'\n",
      " '069A' '072A' '073A' '074A' '075A' '076A' '087A' '088A' '091A' '092A'\n",
      " '093A' '094A' '097A' '099A' '100A' '103A' '104A' '106A' '108A' '109A'\n",
      " '113A' '115A' '116A' '117A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['008A' '014A' '014B' '019A' '020A' '023B' '027A' '031A' '034A' '036A'\n",
      " '037A' '041A' '051A' '052A' '055A' '059A' '060A' '070A' '071A' '090A'\n",
      " '095A' '096A' '097B' '101A' '102A' '105A' '110A' '111A']\n",
      "Length of X_train_val:\n",
      "709\n",
      "Length of y_train_val:\n",
      "709\n",
      "Length of groups_train_val:\n",
      "709\n",
      "No common groups found between train and test sets.\n",
      "Train Age Group Distribution BEFORE SWAP:\n",
      "adult     432\n",
      "kitten    146\n",
      "senior    131\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution BEFORE SWAP:\n",
      "adult     156\n",
      "senior     47\n",
      "kitten     25\n",
      "Name: age_group, dtype: int64\n",
      "Train Age Group Distribution AFTER SWAP:\n",
      "adult     432\n",
      "kitten    146\n",
      "senior    131\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution AFTER SWAP:\n",
      "adult     156\n",
      "senior     47\n",
      "kitten     25\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      " Starting training on unseen test set\n",
      "\n",
      "Age group distribution: Counter({0: 432, 1: 146, 2: 131})\n",
      "Epoch 1/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.1504 - accuracy: 0.4669\n",
      "Epoch 2/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.9057 - accuracy: 0.5275\n",
      "Epoch 3/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7984 - accuracy: 0.5599\n",
      "Epoch 4/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7487 - accuracy: 0.6023\n",
      "Epoch 5/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.6432\n",
      "Epoch 6/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.6248\n",
      "Epoch 7/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6418 - accuracy: 0.6516\n",
      "Epoch 8/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7015 - accuracy: 0.6502\n",
      "Epoch 9/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6488\n",
      "Epoch 10/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5979 - accuracy: 0.6685\n",
      "Epoch 11/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5915 - accuracy: 0.6897\n",
      "Epoch 12/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6121 - accuracy: 0.6770\n",
      "Epoch 13/1500\n",
      "23/23 [==============================] - 0s 999us/step - loss: 0.6024 - accuracy: 0.6855\n",
      "Epoch 14/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.6968\n",
      "Epoch 15/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6094 - accuracy: 0.6897\n",
      "Epoch 16/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5538 - accuracy: 0.6869\n",
      "Epoch 17/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.7137\n",
      "Epoch 18/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.6968\n",
      "Epoch 19/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5407 - accuracy: 0.7179\n",
      "Epoch 20/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7207\n",
      "Epoch 21/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5319 - accuracy: 0.7123\n",
      "Epoch 22/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7179\n",
      "Epoch 23/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7348\n",
      "Epoch 24/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.7419\n",
      "Epoch 25/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7292\n",
      "Epoch 26/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.7306\n",
      "Epoch 27/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7362\n",
      "Epoch 28/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7475\n",
      "Epoch 29/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7391\n",
      "Epoch 30/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7687\n",
      "Epoch 31/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7447\n",
      "Epoch 32/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7504\n",
      "Epoch 33/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4189 - accuracy: 0.7800\n",
      "Epoch 34/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7504\n",
      "Epoch 35/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.7616\n",
      "Epoch 36/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.7560\n",
      "Epoch 37/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7659\n",
      "Epoch 38/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7532\n",
      "Epoch 39/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7743\n",
      "Epoch 40/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7800\n",
      "Epoch 41/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8025\n",
      "Epoch 42/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.7842\n",
      "Epoch 43/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4208 - accuracy: 0.7884\n",
      "Epoch 44/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.7828\n",
      "Epoch 45/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.7870\n",
      "Epoch 46/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4078 - accuracy: 0.7941\n",
      "Epoch 47/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3930 - accuracy: 0.7870\n",
      "Epoch 48/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.8011\n",
      "Epoch 49/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.7927\n",
      "Epoch 50/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3706 - accuracy: 0.7997\n",
      "Epoch 51/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8011\n",
      "Epoch 52/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8181\n",
      "Epoch 53/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8054\n",
      "Epoch 54/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.7757\n",
      "Epoch 55/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.7927\n",
      "Epoch 56/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3865 - accuracy: 0.8096\n",
      "Epoch 57/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.7997\n",
      "Epoch 58/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3745 - accuracy: 0.8195\n",
      "Epoch 59/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3850 - accuracy: 0.8054\n",
      "Epoch 60/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.7856\n",
      "Epoch 61/1500\n",
      "23/23 [==============================] - 0s 991us/step - loss: 0.3848 - accuracy: 0.8025\n",
      "Epoch 62/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8082\n",
      "Epoch 63/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8251\n",
      "Epoch 64/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8068\n",
      "Epoch 65/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3555 - accuracy: 0.8110\n",
      "Epoch 66/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8265\n",
      "Epoch 67/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8307\n",
      "Epoch 68/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8251\n",
      "Epoch 69/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8124\n",
      "Epoch 70/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3945 - accuracy: 0.7800\n",
      "Epoch 71/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.8251\n",
      "Epoch 72/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8237\n",
      "Epoch 73/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3228 - accuracy: 0.8124\n",
      "Epoch 74/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8251\n",
      "Epoch 75/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8307\n",
      "Epoch 76/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3095 - accuracy: 0.8336\n",
      "Epoch 77/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8279\n",
      "Epoch 78/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3599 - accuracy: 0.8195\n",
      "Epoch 79/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3195 - accuracy: 0.8406\n",
      "Epoch 80/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3186 - accuracy: 0.8336\n",
      "Epoch 81/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8279\n",
      "Epoch 82/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8223\n",
      "Epoch 83/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8251\n",
      "Epoch 84/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3700 - accuracy: 0.8166\n",
      "Epoch 85/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3166 - accuracy: 0.8463\n",
      "Epoch 86/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3045 - accuracy: 0.8364\n",
      "Epoch 87/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3205 - accuracy: 0.8350\n",
      "Epoch 88/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2958 - accuracy: 0.8378\n",
      "Epoch 89/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3113 - accuracy: 0.8420\n",
      "Epoch 90/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8322\n",
      "Epoch 91/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3044 - accuracy: 0.8209\n",
      "Epoch 92/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8223\n",
      "Epoch 93/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3101 - accuracy: 0.8392\n",
      "Epoch 94/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3177 - accuracy: 0.8293\n",
      "Epoch 95/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2877 - accuracy: 0.8561\n",
      "Epoch 96/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8378\n",
      "Epoch 97/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8505\n",
      "Epoch 98/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2919 - accuracy: 0.8646\n",
      "Epoch 99/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2878 - accuracy: 0.8660\n",
      "Epoch 100/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8364\n",
      "Epoch 101/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2902 - accuracy: 0.8604\n",
      "Epoch 102/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2699 - accuracy: 0.8773\n",
      "Epoch 103/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3039 - accuracy: 0.8322\n",
      "Epoch 104/1500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2958 - accuracy: 0.8575\n",
      "Epoch 105/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2898 - accuracy: 0.8477\n",
      "Epoch 106/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2953 - accuracy: 0.8491\n",
      "Epoch 107/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3177 - accuracy: 0.8420\n",
      "Epoch 108/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2919 - accuracy: 0.8420\n",
      "Epoch 109/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2944 - accuracy: 0.8561\n",
      "Epoch 110/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.8717\n",
      "Epoch 111/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8307\n",
      "Epoch 112/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2851 - accuracy: 0.8646\n",
      "Epoch 113/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2900 - accuracy: 0.8505\n",
      "Epoch 114/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.8858\n",
      "Epoch 115/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2519 - accuracy: 0.8731\n",
      "Epoch 116/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2701 - accuracy: 0.8604\n",
      "Epoch 117/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2421 - accuracy: 0.8717\n",
      "Epoch 118/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2601 - accuracy: 0.8618\n",
      "Epoch 119/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2681 - accuracy: 0.8604\n",
      "Epoch 120/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2593 - accuracy: 0.8533\n",
      "Epoch 121/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2879 - accuracy: 0.8519\n",
      "Epoch 122/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2610 - accuracy: 0.8618\n",
      "Epoch 123/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2369 - accuracy: 0.8815\n",
      "Epoch 124/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.8745\n",
      "Epoch 125/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.8702\n",
      "Epoch 126/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.8872\n",
      "Epoch 127/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.8674\n",
      "Epoch 128/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2551 - accuracy: 0.8717\n",
      "Epoch 129/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2607 - accuracy: 0.8801\n",
      "Epoch 130/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2551 - accuracy: 0.8759\n",
      "Epoch 131/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.8731\n",
      "Epoch 132/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.8829\n",
      "Epoch 133/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.8660\n",
      "Epoch 134/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2681 - accuracy: 0.8717\n",
      "Epoch 135/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2519 - accuracy: 0.8717\n",
      "Epoch 136/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.8928\n",
      "Epoch 137/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.8843\n",
      "Epoch 138/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.8632\n",
      "Epoch 139/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2525 - accuracy: 0.8688\n",
      "Epoch 140/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2625 - accuracy: 0.8674\n",
      "Epoch 141/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2585 - accuracy: 0.8731\n",
      "Epoch 142/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.8900\n",
      "Epoch 143/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.8688\n",
      "Epoch 144/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.8858\n",
      "Epoch 145/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2338 - accuracy: 0.8801\n",
      "Epoch 146/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2517 - accuracy: 0.8702\n",
      "Epoch 147/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2390 - accuracy: 0.8801\n",
      "Epoch 148/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.8688\n",
      "Epoch 149/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2592 - accuracy: 0.8745\n",
      "Epoch 150/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2377 - accuracy: 0.8843\n",
      "Epoch 151/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2518 - accuracy: 0.8843\n",
      "Epoch 152/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.8858\n",
      "Epoch 153/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.8759\n",
      "Epoch 154/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.8745\n",
      "Epoch 155/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2356 - accuracy: 0.8773\n",
      "Epoch 156/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2357 - accuracy: 0.8900\n",
      "Epoch 157/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.8717\n",
      "Epoch 158/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2272 - accuracy: 0.8900\n",
      "Epoch 159/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.8745\n",
      "Epoch 160/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.8858\n",
      "Epoch 161/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2093 - accuracy: 0.8872\n",
      "Epoch 162/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.9140\n",
      "Epoch 163/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2188 - accuracy: 0.8872\n",
      "Epoch 164/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.8872\n",
      "Epoch 165/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.8956\n",
      "Epoch 166/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 0.8970\n",
      "Epoch 167/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.8900\n",
      "Epoch 168/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2346 - accuracy: 0.8900\n",
      "Epoch 169/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2365 - accuracy: 0.8914\n",
      "Epoch 170/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.9013\n",
      "Epoch 171/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2120 - accuracy: 0.9027\n",
      "Epoch 172/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.8956\n",
      "Epoch 173/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.9027\n",
      "Epoch 174/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.8829\n",
      "Epoch 175/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2228 - accuracy: 0.8815\n",
      "Epoch 176/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.8928\n",
      "Epoch 177/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.8801\n",
      "Epoch 178/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.8843\n",
      "Epoch 179/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2094 - accuracy: 0.8970\n",
      "Epoch 180/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.8999\n",
      "Epoch 181/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.8999\n",
      "Epoch 182/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9069\n",
      "Epoch 183/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.8956\n",
      "Epoch 184/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.9041\n",
      "Epoch 185/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.9097\n",
      "Epoch 186/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.9097\n",
      "Epoch 187/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.8999\n",
      "Epoch 188/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2091 - accuracy: 0.8858\n",
      "Epoch 189/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.8984\n",
      "Epoch 190/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.9083\n",
      "Epoch 191/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9097\n",
      "Epoch 192/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.8886\n",
      "Epoch 193/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.8900\n",
      "Epoch 194/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2116 - accuracy: 0.8872\n",
      "Epoch 195/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2045 - accuracy: 0.9041\n",
      "Epoch 196/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.8970\n",
      "Epoch 197/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.8928\n",
      "Epoch 198/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.9097\n",
      "Epoch 199/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.9097\n",
      "Epoch 200/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 0.9097\n",
      "Epoch 201/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9140\n",
      "Epoch 202/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2048 - accuracy: 0.9055\n",
      "Epoch 203/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2120 - accuracy: 0.8886\n",
      "Epoch 204/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.8970\n",
      "Epoch 205/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.9027\n",
      "Epoch 206/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.9069\n",
      "Epoch 207/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9196\n",
      "Epoch 208/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9097\n",
      "Epoch 209/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.9013\n",
      "Epoch 210/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.8970\n",
      "Epoch 211/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.9013\n",
      "Epoch 212/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.9013\n",
      "Epoch 213/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.9196\n",
      "Epoch 214/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2068 - accuracy: 0.8956\n",
      "Epoch 215/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9154\n",
      "Epoch 216/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1677 - accuracy: 0.9182\n",
      "Epoch 217/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.9182\n",
      "Epoch 218/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9168\n",
      "Epoch 219/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.9111\n",
      "Epoch 220/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9168\n",
      "Epoch 221/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.8928\n",
      "Epoch 222/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.8970\n",
      "Epoch 223/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.9097\n",
      "Epoch 224/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.9140\n",
      "Epoch 225/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9351\n",
      "Epoch 226/1500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1604 - accuracy: 0.9323\n",
      "Epoch 227/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.9238\n",
      "Epoch 228/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.9196\n",
      "Epoch 229/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9351\n",
      "Epoch 230/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9041\n",
      "Epoch 231/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1701 - accuracy: 0.9168\n",
      "Epoch 232/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.9182\n",
      "Epoch 233/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.8956\n",
      "Epoch 234/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.9182\n",
      "Epoch 235/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1688 - accuracy: 0.9309\n",
      "Epoch 236/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1640 - accuracy: 0.9210\n",
      "Epoch 237/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9238\n",
      "Epoch 238/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1697 - accuracy: 0.9196\n",
      "Epoch 239/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9337\n",
      "Epoch 240/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.9267\n",
      "Epoch 241/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9309\n",
      "Epoch 242/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.9281\n",
      "Epoch 243/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1629 - accuracy: 0.9168\n",
      "Epoch 244/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9196\n",
      "Epoch 245/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9309\n",
      "Epoch 246/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9252\n",
      "Epoch 247/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9252\n",
      "Epoch 248/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9337\n",
      "Epoch 249/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.9238\n",
      "Epoch 250/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1384 - accuracy: 0.9295\n",
      "Epoch 251/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.9281\n",
      "Epoch 252/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1713 - accuracy: 0.9210\n",
      "Epoch 253/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9492\n",
      "Epoch 254/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9224\n",
      "Epoch 255/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9351\n",
      "Epoch 256/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.9281\n",
      "Epoch 257/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.9055\n",
      "Epoch 258/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.9168\n",
      "Epoch 259/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.9295\n",
      "Epoch 260/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9083\n",
      "Epoch 261/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9210\n",
      "Epoch 262/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9351\n",
      "Epoch 263/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9210\n",
      "Epoch 264/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1659 - accuracy: 0.9182\n",
      "Epoch 265/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.9196\n",
      "Epoch 266/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9126\n",
      "Epoch 267/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 0.9097\n",
      "Epoch 268/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9394\n",
      "Epoch 269/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1449 - accuracy: 0.9182\n",
      "Epoch 270/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9281\n",
      "Epoch 271/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.9337\n",
      "Epoch 272/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1664 - accuracy: 0.9154\n",
      "Epoch 273/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9196\n",
      "Epoch 274/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9436\n",
      "Epoch 275/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.9196\n",
      "Epoch 276/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9436\n",
      "Epoch 277/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9252\n",
      "Epoch 278/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9168\n",
      "Epoch 279/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9281\n",
      "Epoch 280/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9238\n",
      "Epoch 281/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9238\n",
      "Epoch 282/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9252\n",
      "Epoch 283/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1331 - accuracy: 0.9365\n",
      "Epoch 284/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9379\n",
      "Epoch 285/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9252\n",
      "Epoch 286/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9267\n",
      "Epoch 287/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1629 - accuracy: 0.9210\n",
      "Epoch 288/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9408\n",
      "Epoch 289/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9351\n",
      "Epoch 290/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1421 - accuracy: 0.9394\n",
      "Epoch 291/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9295\n",
      "Epoch 292/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.9295\n",
      "Epoch 293/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9492\n",
      "Epoch 294/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9394\n",
      "Epoch 295/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9379\n",
      "Epoch 296/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9436\n",
      "Epoch 297/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9394\n",
      "Epoch 298/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9351\n",
      "Epoch 299/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.9379\n",
      "Epoch 300/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9535\n",
      "Epoch 301/1500\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.1473 - accuracy: 0.9267\n",
      "Epoch 302/1500\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1576 - accuracy: 0.9224\n",
      "Epoch 303/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9337\n",
      "Epoch 304/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9365\n",
      "Epoch 305/1500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9436\n",
      "Epoch 306/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9365\n",
      "Epoch 307/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.9478\n",
      "Epoch 308/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9140\n",
      "Epoch 309/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.9281\n",
      "Epoch 310/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9238\n",
      "Epoch 311/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9224\n",
      "Epoch 312/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9252\n",
      "Epoch 313/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9379\n",
      "Epoch 314/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1235 - accuracy: 0.9436\n",
      "Epoch 315/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.9436\n",
      "Epoch 316/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9422\n",
      "Epoch 317/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9351\n",
      "Epoch 318/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9309\n",
      "Epoch 319/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9408\n",
      "Epoch 320/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9422\n",
      "Epoch 321/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.9309\n",
      "Epoch 322/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9464\n",
      "Epoch 323/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9422\n",
      "Epoch 324/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.9295\n",
      "Epoch 325/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9379\n",
      "Epoch 326/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9295\n",
      "Epoch 327/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9379\n",
      "Epoch 328/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9267\n",
      "Epoch 329/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9309\n",
      "Epoch 330/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9365\n",
      "Epoch 331/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.9408\n",
      "Epoch 332/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.9549\n",
      "Epoch 333/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9450\n",
      "Epoch 334/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9323\n",
      "Epoch 335/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9520\n",
      "Epoch 336/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.9450\n",
      "Epoch 337/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1377 - accuracy: 0.9464\n",
      "Epoch 338/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9408\n",
      "Epoch 339/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9478\n",
      "Epoch 340/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9408\n",
      "Epoch 341/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9422\n",
      "Epoch 342/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9436\n",
      "Epoch 343/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9295\n",
      "Epoch 344/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.9365\n",
      "Epoch 345/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9492\n",
      "Epoch 346/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.9422\n",
      "Epoch 347/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9337\n",
      "Epoch 348/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.9464\n",
      "Epoch 349/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9422\n",
      "Epoch 350/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9379\n",
      "Epoch 351/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.9506\n",
      "Epoch 352/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9422\n",
      "Epoch 353/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9506\n",
      "Epoch 354/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9408\n",
      "Epoch 355/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9295\n",
      "Epoch 356/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9478\n",
      "Epoch 357/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9535\n",
      "Epoch 358/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9464\n",
      "Epoch 359/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9408\n",
      "Epoch 360/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9520\n",
      "Epoch 361/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1194 - accuracy: 0.9450\n",
      "Epoch 362/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9224\n",
      "Epoch 363/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9577\n",
      "Epoch 364/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9154\n",
      "Epoch 365/1500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9464\n",
      "Epoch 366/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9450\n",
      "Epoch 367/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9365\n",
      "Epoch 368/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9492\n",
      "Epoch 369/1500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.0867 - accuracy: 0.9375Restoring model weights from the end of the best epoch: 339.\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9563\n",
      "Epoch 369: early stopping\n",
      "8/8 [==============================] - 0s 917us/step - loss: 0.6384 - accuracy: 0.7719\n",
      "8/8 [==============================] - 0s 677us/step\n",
      "Majority Vote Accuracy for cat_id for this fold: 0.82 (23/28)\n",
      "Before appending - Cat IDs: 621, Predictions: 621, Actuals: 621, Gender: 621\n",
      "After appending - Cat IDs: 849, Predictions: 849, Actuals: 849, Gender: 849\n",
      "Final Test Results - Loss: 0.6383829712867737, Accuracy: 0.7719298005104065, Precision: 0.7433579492403021, Recall: 0.8070303691580287, F1 Score: 0.7653548749734148\n",
      "Confusion Matrix:\n",
      " [[118   5  33]\n",
      " [  2  23   0]\n",
      " [ 12   0  35]]\n",
      "\n",
      "Final Average F1-Score across all UNSEEN TEST sets: 0.6599434439229191\n",
      "\n",
      "Final Average Loss across all UNSEEN TEST sets: 0.777240589261055\n",
      "\n",
      "Final Average Accuracy across all UNSEEN TEST sets: 0.7152715772390366\n",
      "\n",
      "Final Average Precision across all UNSEEN TEST sets: 0.6725643764936784\n",
      "\n",
      "Final Average Recall across all UNSEEN TEST sets: 0.7034464668854458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "all_cat_ids = []\n",
    "all_predicted_age_groups = []\n",
    "all_actual_age_groups = []\n",
    "all_gender = []\n",
    "\n",
    "# Define the StratifiedGroupKFold splitter for 4 fold CV with random shuffling\n",
    "outer_cv = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=int(random_seeds[4]))\n",
    "\n",
    "# unseen test set metrics\n",
    "unseen_losses, unseen_accuracies, unseen_precisions, unseen_recalls, unseen_f1 = [], [], [], [], []\n",
    "\n",
    "outer_fold = 0\n",
    "\n",
    "# Use the splitter to generate indices for training and testing sets\n",
    "# Note: GroupShuffleSplit.split returns indices, so we use it to index the arrays\n",
    "for train_val_idx, test_idx in outer_cv.split(X, y, groups):\n",
    "    outer_fold += 1\n",
    "    logger(f\"outer_fold {outer_fold}\", file=log_file_path)\n",
    "\n",
    "    # Convert indices back to DataFrame for easy manipulation\n",
    "    df_train_val = dataframe.iloc[train_val_idx]\n",
    "    df_test = dataframe.iloc[test_idx]\n",
    "\n",
    "    ##############################\n",
    "    # ASSESSING SPLITS BY CAT_ID #\n",
    "    ##############################\n",
    "    \n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test['cat_id'].value_counts()  \n",
    "    \n",
    "    # Log or print the distribution\n",
    "    logger(f\"Train Set Group Distribution:\\n{training_validation_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Group Distribution:\\n{testing_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test['gender'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Training Set Gender Distribution BEFORE SWAP:\\n{training_gender_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Gender Distribution BEFORE SWAP:\\n{testing_gender_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Group by 'age_group' and then list unique 'cat_id' within each age group\n",
    "    unique_cat_ids_per_age_group_train_val = df_train_val.groupby('age_group')['cat_id'].unique()\n",
    "    unique_cat_ids_per_age_group_test = df_test.groupby('age_group')['cat_id'].unique()\n",
    "    \n",
    "    # Log results\n",
    "    logger(f\"Unique Cat IDs per Age Group in Training/Validation Set:\\n{unique_cat_ids_per_age_group_train_val}\", file=log_file_path)\n",
    "    logger(f\"Unique Cat IDs per Age Group in Testing Set:\\n{unique_cat_ids_per_age_group_test}\", file=log_file_path)\n",
    "\n",
    "    # Calculate the count of unique identifiers per age group for training and testing set\n",
    "    counts_train_val = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_train_val.items()}\n",
    "    counts_test = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_test.items()}\n",
    "\n",
    "    # Log the counts of unique identifiers per age group\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Training/Validation Set:\\n{counts_train_val}\", file=log_file_path)\n",
    "    logger(f\"Count of Unique Cat IDs per Age Group in Testing Set:\\n{counts_test}\", file=log_file_path)\n",
    "\n",
    "    #######################################################\n",
    "    # CONTINUE WITH ENSURING VALID AND APPROPRIATE SPLITS #\n",
    "    #######################################################\n",
    "    \n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    groups_train_val, groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # logging identifier splits \n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "\n",
    "    # check group splits\n",
    "    check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Specify the cat_ids that must be in the training/validation set\n",
    "    specific_cat_ids = ['000A', '046A']\n",
    "    \n",
    "    # Perform the swapping operation\n",
    "    train_val_idx, test_idx = swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids)\n",
    "    \n",
    "    # Re-assign the sets based on the updated indices\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    new_groups_train_val, new_groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "    # Find differences for training and test sets\n",
    "    moved_to_train_val, removed_from_train_val = find_group_differences(groups_train_val, new_groups_train_val)\n",
    "    moved_to_test, removed_from_test = find_group_differences(groups_test, new_groups_test)\n",
    "    \n",
    "    # Display the results\n",
    "    logger(f\"Moved to Training/Validation Set:\\n{moved_to_train_val}\", file=log_file_path)\n",
    "    logger(f\"Removed from Training/Validation Set:\\n{removed_from_train_val}\", file=log_file_path)\n",
    "    logger(f\"Moved to Test Set:\\n{moved_to_test}\", file=log_file_path)\n",
    "    logger(f\"Removed from Test Set\\n{removed_from_test}\", file=log_file_path)\n",
    "\n",
    "    # Update X_train_val, X_test, y_train_val, y_test, groups_train_val, groups_test based on updated indices\n",
    "    X_train_val = X[train_val_idx]\n",
    "    y_train_val = y[train_val_idx]\n",
    "    groups_train_val = groups[train_val_idx]\n",
    "    \n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    groups_test = groups[test_idx]\n",
    "\n",
    "    # logging identifier splits again after potential swaps\n",
    "    unique_train_val_groups = np.unique(groups_train_val)\n",
    "    unique_test_groups = np.unique(groups_test)\n",
    "    \n",
    "    logger(f\"AFTER SWAP - Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "    logger(f\"AFTER SWAP - Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "    \n",
    "    # Verify the lengths are consistent\n",
    "    logger(f\"Length of X_train_val:\\n{len(X_train_val)}\", file=log_file_path)\n",
    "    logger(f\"Length of y_train_val:\\n{len(y_train_val)}\", file=log_file_path)\n",
    "    logger(f\"Length of groups_train_val:\\n{len(groups_train_val)}\", file=log_file_path)\n",
    "\n",
    "    # Check group splits once more\n",
    "    check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "    # Convert the modified indices back to a DataFrame representing the updated df_train_val\n",
    "    df_train_val_updated = dataframe.iloc[train_val_idx].copy()\n",
    "    df_test_updated = dataframe.iloc[test_idx].copy()\n",
    "\n",
    "    ############################\n",
    "    # LOGGING AGE GROUP SPLITS #\n",
    "    ############################\n",
    "\n",
    "    # Get the distribution of age groups of age groups before the update\n",
    "    training_validation_age_group_distribution = df_train_val['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test['age_group'].value_counts()\n",
    "    \n",
    "    # Logthe distribution\n",
    "    logger(f\"Train Age Group Distribution BEFORE SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution BEFORE SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "\n",
    "    # Get the distribution of age groups after the update\n",
    "    training_validation_age_group_distribution = df_train_val_updated['age_group'].value_counts()\n",
    "    testing_age_group_distribution = df_test_updated['age_group'].value_counts()\n",
    "    \n",
    "    # Log the distribution\n",
    "    logger(f\"Train Age Group Distribution AFTER SWAP:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "    logger(f\"Testing Set Age Group Distribution AFTER SWAP:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "    \n",
    "    ########################################################\n",
    "    # TRACKING FINAL CAT_IDs & GENDER AFTER REDISTRIBUTION #\n",
    "    ########################################################\n",
    "\n",
    "    # Get the distribution of groups\n",
    "    training_validation_group_distribution = df_train_val_updated['cat_id'].value_counts()  \n",
    "    testing_group_distribution = df_test_updated['cat_id'].value_counts()  \n",
    "\n",
    "    # Log gender distribution in training and testing datasets\n",
    "    training_gender_distribution = df_train_val_updated['gender'].value_counts()\n",
    "    testing_gender_distribution = df_test_updated['gender'].value_counts()\n",
    "    \n",
    "    logger(f\"\\n Starting training on unseen test set\\n\", file=log_file_path)\n",
    "\n",
    "    ###################\n",
    "    # PREPARING MODEL #\n",
    "    ###################\n",
    "\n",
    "    # Calculate the distribution of age groups in y_train_val\n",
    "    age_group_distribution = Counter(y_train_val)\n",
    "    print(\"Age group distribution:\", age_group_distribution)\n",
    "\n",
    "    # EarlyStopping callback: monitor 'loss' instead of 'val_loss' for the test set\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='loss',  \n",
    "        min_delta=0.001, \n",
    "        patience=30,  \n",
    "        verbose=1,  \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "\n",
    "    # One final shuffle to ensure randomness\n",
    "    outer_shuffle_idx = np.random.permutation(len(X_train_val))\n",
    "    X_train_val = X_train_val[outer_shuffle_idx]\n",
    "    y_train_val = y_train_val[outer_shuffle_idx]\n",
    "    \n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train_val),\n",
    "        y=y_train_val\n",
    "    )\n",
    "    weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "    # Scale the features\n",
    "    scaler_full = StandardScaler().fit(X_train_val)\n",
    "    X_train_full_scaled = scaler_full.transform(X_train_val)\n",
    "    X_test_scaled = scaler_full.transform(X_test)\n",
    "    \n",
    "    # Encode the labels\n",
    "    y_train_full_encoded = to_categorical(y_train_val)\n",
    "    y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "    #######################\n",
    "    # BUILD & TRAIN MODEL #\n",
    "    #######################\n",
    "\n",
    "    optimizers = {\n",
    "        'Adamax': Adamax(learning_rate=0.00038188800331973483)\n",
    "    }\n",
    "    \n",
    "    # Full model definition with dynamic number of layers\n",
    "    model_full = Sequential()\n",
    "    model_full.add(Dense(480, activation='relu', input_shape=(X_train_full_scaled.shape[1],)))  # units_l0 and activation from parameters\n",
    "    model_full.add(BatchNormalization())\n",
    "    model_full.add(Dropout(0.27188281261238406))  \n",
    "    model_full.add(Dense(3, activation='softmax'))  \n",
    "    \n",
    "    optimizer = optimizers['Adamax']  # optimizer_key from parameters\n",
    "    \n",
    "    # Compile the model\n",
    "    model_full.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model on the full training set\n",
    "    history_full = model_full.fit(X_train_full_scaled, y_train_full_encoded, epochs=1500, batch_size=32,\n",
    "                                  verbose=1, callbacks=[early_stopping], class_weight=weight_dict)\n",
    "    \n",
    "    # Evaluate the model on the held-out test set\n",
    "    test_loss, test_accuracy = model_full.evaluate(X_test_scaled, y_test_encoded)\n",
    "\n",
    "    y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "    y_test_pred = np.argmax(y_test_pred_prob, axis=1)  \n",
    "    y_test_true = np.argmax(y_test_encoded, axis=1)    \n",
    "\n",
    "    ################################\n",
    "    # LOG MAJORITY VOTE PER CAT_ID #\n",
    "    ################################\n",
    "\n",
    "    # Convert numeric predictions back to age group labels\n",
    "    predicted_age_groups = label_encoder.inverse_transform(y_test_pred)\n",
    "    actual_labels = label_encoder.inverse_transform(y_test_true)\n",
    "    \n",
    "    # Map predictions and actual labels back to cat_ids\n",
    "    test_results = pd.DataFrame({\n",
    "        'cat_id': df_test_updated['cat_id'],\n",
    "        'predicted_age_group': predicted_age_groups,\n",
    "        'actual_age_group': actual_labels\n",
    "    })\n",
    "    \n",
    "    # Group by cat_id and aggregate predicted age groups\n",
    "    majority_votes = test_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "    actual_groups = test_results.groupby('cat_id')['actual_age_group'].first()\n",
    "    \n",
    "    # Calculate the accuracy of majority voting\n",
    "    correct_predictions = (majority_votes == actual_groups).sum()\n",
    "    total_cats = len(actual_groups)\n",
    "    majority_vote_accuracy = correct_predictions / total_cats\n",
    "    \n",
    "    # Log the accuracy of the majority voting\n",
    "    logger(f\"Majority Vote Accuracy for cat_id for this fold: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)\n",
    "\n",
    "    ####################################################\n",
    "    # COLLECT PREDICTIONS FOR GENDER & CAT_ID ANALYSIS #\n",
    "    ####################################################\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'Before appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Extend lists with current fold results\n",
    "    all_cat_ids.extend(df_test_updated['cat_id'].tolist())\n",
    "    all_predicted_age_groups.extend(predicted_age_groups)\n",
    "    all_actual_age_groups.extend(actual_labels)\n",
    "    all_gender.extend(df_test_updated['gender'].tolist())\n",
    "\n",
    "    # Debugging print statements\n",
    "    print(f'After appending - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    test_precision = precision_score(y_test_true, y_test_pred, average='macro')  # Use 'macro' for imbalanced datasets\n",
    "    test_recall = recall_score(y_test_true, y_test_pred, average='macro')\n",
    "    test_f1 = f1_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "    # prepare averages of outer metrics\n",
    "    unseen_f1.append(test_f1)\n",
    "    unseen_losses.append(test_loss)\n",
    "    unseen_accuracies.append(test_accuracy)\n",
    "    unseen_precisions.append(test_precision)\n",
    "    unseen_recalls.append(test_recall)\n",
    "\n",
    "    # Print final test results\n",
    "    logger(f\"Final Test Results - Loss: {test_loss}, Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}\", file=log_file_path)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    logger(f\"Confusion Matrix:\\n {cm}\", file=log_file_path)\n",
    "\n",
    "# Calculate the overall average metrics\n",
    "unseen_set_avg_f1 = np.mean(unseen_f1)\n",
    "unseen_set_avg_loss = np.mean(unseen_losses)\n",
    "unseen_set_avg_acc = np.mean(unseen_accuracies)\n",
    "unseen_set_avg_precision = np.mean(unseen_precisions)\n",
    "unseen_set_avg_recall = np.mean(unseen_recalls)\n",
    "\n",
    "logger(f\"\\nFinal Average F1-Score across all UNSEEN TEST sets: {unseen_set_avg_f1}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Loss across all UNSEEN TEST sets: {unseen_set_avg_loss}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Accuracy across all UNSEEN TEST sets: {unseen_set_avg_acc}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Precision across all UNSEEN TEST sets: {unseen_set_avg_precision}\", file=log_file_path)\n",
    "logger(f\"\\nFinal Average Recall across all UNSEEN TEST sets: {unseen_set_avg_recall}\\n\", file=log_file_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90d80b-198d-4293-a1a0-73a65f6588d0",
   "metadata": {},
   "source": [
    "## Majority Voting on Total Entries per cat_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e9dd5399-64d4-435b-9e73-cb31f16d042d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking - Cat IDs: 849, Predictions: 849, Actuals: 849, Gender: 849\n"
     ]
    }
   ],
   "source": [
    "# Debugging print statements\n",
    "print(f'Checking - Cat IDs: {len(all_cat_ids)}, Predictions: {len(all_predicted_age_groups)}, Actuals: {len(all_actual_age_groups)}, Gender: {len(all_gender)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9d9869f0-e23f-4453-a329-395fa44f1208",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create results df\n",
    "full_results = pd.DataFrame({\n",
    "    'cat_id': all_cat_ids,\n",
    "    'predicted_age_group': all_predicted_age_groups,\n",
    "    'actual_age_group': all_actual_age_groups,\n",
    "    'all_gender': all_gender\n",
    "})\n",
    "\n",
    "# create a correct majority prediction column\n",
    "full_results['correct'] = full_results['predicted_age_group'] == full_results['actual_age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a7f81185-7b51-497f-98cb-80c4b8f35388",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Majority Vote Accuracy for cat_id: 0.74 (81/110)\n"
     ]
    }
   ],
   "source": [
    "# Group by cat_id and aggregate predicted age groups\n",
    "majority_votes = full_results.groupby('cat_id')['predicted_age_group'].agg(lambda x: x.mode()[0])\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first()\n",
    "\n",
    "# Calculate the accuracy of majority voting\n",
    "correct_predictions = (majority_votes == actual_groups).sum()\n",
    "total_cats = len(actual_groups)\n",
    "majority_vote_accuracy = correct_predictions / total_cats\n",
    "\n",
    "logger(f\"Overall Majority Vote Accuracy for cat_id: {majority_vote_accuracy:.2f} ({correct_predictions}/{total_cats})\", file=log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "adbd2ca0-3dea-4b42-bfad-93138cb1ae30",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Detailed df with predictions, actual labels, and comparison including majority vote\n",
    "detailed_results = full_results.groupby('cat_id').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Predictions': list(x['predicted_age_group']),\n",
    "        'Majority Vote': x['predicted_age_group'].mode()[0],\n",
    "        'Actual Age Group': x['actual_age_group'].iloc[0],\n",
    "        'Correct Majority Vote': x['predicted_age_group'].mode()[0] == x['actual_age_group'].iloc[0]\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Convert to DataFrame for better formatting and display\n",
    "detailed_results = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b1ea4fe7-6ee1-4185-a009-b864d9aa6b85",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Majority Vote</th>\n",
       "      <th>Actual Age Group</th>\n",
       "      <th>Correct Majority Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000B</td>\n",
       "      <td>[adult, kitten, kitten, senior, adult, adult, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>075A</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>073A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>072A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>071A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>070A</td>\n",
       "      <td>[adult, adult, senior, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>069A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>068A</td>\n",
       "      <td>[adult, adult, adult, senior, senior, adult, s...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>067A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>066A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>065A</td>\n",
       "      <td>[senior, adult, adult, adult, adult, senior, s...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>064A</td>\n",
       "      <td>[adult, adult, kitten]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>062A</td>\n",
       "      <td>[kitten, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>059A</td>\n",
       "      <td>[senior, adult, adult, senior, senior, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>056A</td>\n",
       "      <td>[senior, senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>055A</td>\n",
       "      <td>[adult, adult, senior, senior, senior, senior,...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>053A</td>\n",
       "      <td>[kitten, adult, senior, adult, kitten, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>051A</td>\n",
       "      <td>[senior, adult, adult, adult, senior, senior, ...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001A</td>\n",
       "      <td>[adult, adult, senior, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>045A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>044A</td>\n",
       "      <td>[kitten, adult, kitten, kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>074A</td>\n",
       "      <td>[adult, adult, adult, kitten, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>087A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>040A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>088A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>116A</td>\n",
       "      <td>[senior, senior, senior, senior, adult, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>115A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>113A</td>\n",
       "      <td>[senior, senior, adult]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>111A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>110A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>105A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>104A</td>\n",
       "      <td>[senior, senior, senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>103A</td>\n",
       "      <td>[adult, adult, adult, adult, senior, senior, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>102A</td>\n",
       "      <td>[senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>101A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>100A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>099A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>097B</td>\n",
       "      <td>[senior, adult, kitten, adult, adult, adult, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>097A</td>\n",
       "      <td>[senior, senior, senior, adult, senior, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>096A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>094A</td>\n",
       "      <td>[senior, senior, senior, senior, senior, senio...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>092A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>091A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>090A</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>043A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>050A</td>\n",
       "      <td>[kitten, kitten, kitten, kitten, kitten, kitte...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>039A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>013B</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>025A</td>\n",
       "      <td>[senior, adult, senior, adult, adult, adult, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>023A</td>\n",
       "      <td>[adult, kitten, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>022A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, kit...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>021A</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>020A</td>\n",
       "      <td>[adult, adult, senior, adult, adult, adult, se...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>019A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>018A</td>\n",
       "      <td>[adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>015A</td>\n",
       "      <td>[adult, adult, senior, senior, senior, adult, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>014B</td>\n",
       "      <td>[kitten, kitten, kitten, adult, kitten, kitten...</td>\n",
       "      <td>kitten</td>\n",
       "      <td>kitten</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>014A</td>\n",
       "      <td>[adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>012A</td>\n",
       "      <td>[senior, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>026A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>011A</td>\n",
       "      <td>[senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>010A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>009A</td>\n",
       "      <td>[adult, adult, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>008A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>007A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>006A</td>\n",
       "      <td>[adult, senior, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>004A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003A</td>\n",
       "      <td>[adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002B</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>025B</td>\n",
       "      <td>[adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>023B</td>\n",
       "      <td>[adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>032A</td>\n",
       "      <td>[kitten, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>028A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>037A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>035A</td>\n",
       "      <td>[senior, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>033A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>031A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>029A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, adult, adu...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>117A</td>\n",
       "      <td>[senior, senior, adult, adult, senior, adult, ...</td>\n",
       "      <td>senior</td>\n",
       "      <td>senior</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>027A</td>\n",
       "      <td>[adult, adult, adult, senior, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>061A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>060A</td>\n",
       "      <td>[kitten, kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>042A</td>\n",
       "      <td>[kitten, adult, adult, adult, adult, adult, ad...</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>038A</td>\n",
       "      <td>[kitten, kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>025C</td>\n",
       "      <td>[senior, senior, adult, senior, adult]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>036A</td>\n",
       "      <td>[senior, senior, senior, senior, adult, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>005A</td>\n",
       "      <td>[senior, senior, senior, senior, senior, senio...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>109A</td>\n",
       "      <td>[adult, adult, kitten, kitten, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>108A</td>\n",
       "      <td>[senior, adult, adult, senior, adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>106A</td>\n",
       "      <td>[adult, senior, senior, senior, adult, adult, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>047A</td>\n",
       "      <td>[adult, adult, adult, adult, adult, kitten, ki...</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>048A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>049A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>034A</td>\n",
       "      <td>[adult, senior, adult, senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>051B</td>\n",
       "      <td>[senior, adult, adult, adult, senior, adult, a...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>052A</td>\n",
       "      <td>[adult, senior, senior, senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>063A</td>\n",
       "      <td>[senior, senior, senior, senior, adult, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>054A</td>\n",
       "      <td>[adult, senior]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>026C</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>095A</td>\n",
       "      <td>[senior, senior, adult, senior, senior, senior...</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>024A</td>\n",
       "      <td>[adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>093A</td>\n",
       "      <td>[adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>016A</td>\n",
       "      <td>[adult, adult, adult, senior, senior, senior, ...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>057A</td>\n",
       "      <td>[adult, adult, adult, senior, senior, adult, s...</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>058A</td>\n",
       "      <td>[senior, adult, adult]</td>\n",
       "      <td>adult</td>\n",
       "      <td>senior</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>019B</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>041A</td>\n",
       "      <td>[adult, kitten]</td>\n",
       "      <td>adult</td>\n",
       "      <td>kitten</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>076A</td>\n",
       "      <td>[kitten]</td>\n",
       "      <td>kitten</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>026B</td>\n",
       "      <td>[senior]</td>\n",
       "      <td>senior</td>\n",
       "      <td>adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat_id                                        Predictions Majority Vote Actual Age Group  Correct Majority Vote\n",
       "0     000B  [adult, kitten, kitten, senior, adult, adult, ...         adult            adult                   True\n",
       "81    075A                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "79    073A                                            [adult]         adult            adult                   True\n",
       "78    072A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "77    071A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "76    070A              [adult, adult, senior, adult, senior]         adult            adult                   True\n",
       "75    069A                                     [adult, adult]         adult            adult                   True\n",
       "74    068A  [adult, adult, adult, senior, senior, adult, s...         adult            adult                   True\n",
       "73    067A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "72    066A                                            [adult]         adult            adult                   True\n",
       "71    065A  [senior, adult, adult, adult, adult, senior, s...         adult            adult                   True\n",
       "70    064A                             [adult, adult, kitten]         adult            adult                   True\n",
       "68    062A                      [kitten, adult, adult, adult]         adult            adult                   True\n",
       "65    059A  [senior, adult, adult, senior, senior, senior,...        senior           senior                   True\n",
       "62    056A                           [senior, senior, senior]        senior           senior                   True\n",
       "61    055A  [adult, adult, senior, senior, senior, senior,...        senior           senior                   True\n",
       "59    053A     [kitten, adult, senior, adult, kitten, senior]         adult            adult                   True\n",
       "56    051A  [senior, adult, adult, adult, senior, senior, ...        senior           senior                   True\n",
       "1     001A  [adult, adult, senior, adult, adult, adult, ad...         adult            adult                   True\n",
       "51    045A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "50    044A            [kitten, adult, kitten, kitten, kitten]        kitten           kitten                   True\n",
       "80    074A  [adult, adult, adult, kitten, adult, adult, ad...         adult            adult                   True\n",
       "83    087A                                     [adult, adult]         adult            adult                   True\n",
       "46    040A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "84    088A                                            [adult]         adult            adult                   True\n",
       "108   116A  [senior, senior, senior, senior, adult, senior...        senior           senior                   True\n",
       "107   115A                                           [kitten]        kitten           kitten                   True\n",
       "106   113A                            [senior, senior, adult]        senior           senior                   True\n",
       "105   111A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "104   110A                                           [kitten]        kitten           kitten                   True\n",
       "100   105A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "99    104A                   [senior, senior, senior, senior]        senior           senior                   True\n",
       "98    103A  [adult, adult, adult, adult, senior, senior, a...         adult            adult                   True\n",
       "97    102A                                    [senior, adult]         adult            adult                   True\n",
       "96    101A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "95    100A                                            [adult]         adult            adult                   True\n",
       "94    099A  [adult, adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "93    097B  [senior, adult, kitten, adult, adult, adult, a...         adult            adult                   True\n",
       "92    097A  [senior, senior, senior, adult, senior, senior...        senior           senior                   True\n",
       "91    096A                                            [adult]         adult            adult                   True\n",
       "89    094A  [senior, senior, senior, senior, senior, senio...        senior           senior                   True\n",
       "87    092A                                            [adult]         adult            adult                   True\n",
       "86    091A                                            [adult]         adult            adult                   True\n",
       "85    090A                                           [senior]        senior           senior                   True\n",
       "49    043A                                           [kitten]        kitten           kitten                   True\n",
       "55    050A  [kitten, kitten, kitten, kitten, kitten, kitte...        kitten           kitten                   True\n",
       "45    039A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "14    013B  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "28    025A  [senior, adult, senior, adult, adult, adult, a...         adult            adult                   True\n",
       "25    023A        [adult, kitten, adult, adult, adult, adult]         adult            adult                   True\n",
       "24    022A  [adult, adult, adult, adult, adult, adult, kit...         adult            adult                   True\n",
       "23    021A                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "22    020A  [adult, adult, senior, adult, adult, adult, se...         adult            adult                   True\n",
       "20    019A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "19    018A                                    [adult, senior]         adult            adult                   True\n",
       "17    015A  [adult, adult, senior, senior, senior, adult, ...         adult            adult                   True\n",
       "16    014B  [kitten, kitten, kitten, adult, kitten, kitten...        kitten           kitten                   True\n",
       "15    014A                              [adult, adult, adult]         adult            adult                   True\n",
       "13    012A                             [senior, adult, adult]         adult            adult                   True\n",
       "31    026A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "12    011A                                   [senior, senior]        senior           senior                   True\n",
       "11    010A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "10    009A                      [adult, adult, adult, senior]         adult            adult                   True\n",
       "9     008A         [adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "8     007A         [adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "7     006A                             [adult, senior, adult]         adult            adult                   True\n",
       "5     004A                                            [adult]         adult            adult                   True\n",
       "4     003A                       [adult, adult, adult, adult]         adult            adult                   True\n",
       "3     002B  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "2     002A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "29    025B                                    [adult, senior]         adult            adult                   True\n",
       "26    023B                [adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "38    032A                                    [kitten, adult]         adult            adult                   True\n",
       "35    028A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "43    037A         [adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "41    035A                      [senior, adult, adult, adult]         adult            adult                   True\n",
       "39    033A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "37    031A  [adult, adult, adult, adult, adult, adult, adult]         adult            adult                   True\n",
       "36    029A  [adult, adult, adult, adult, adult, adult, adu...         adult            adult                   True\n",
       "109   117A  [senior, senior, adult, adult, senior, adult, ...        senior           senior                   True\n",
       "34    027A  [adult, adult, adult, senior, adult, adult, ad...         adult            adult                   True\n",
       "67    061A                                     [adult, adult]         adult           senior                  False\n",
       "66    060A                           [kitten, kitten, kitten]        kitten            adult                  False\n",
       "48    042A  [kitten, adult, adult, adult, adult, adult, ad...         adult           kitten                  False\n",
       "44    038A                                   [kitten, kitten]        kitten            adult                  False\n",
       "30    025C             [senior, senior, adult, senior, adult]        senior            adult                  False\n",
       "42    036A  [senior, senior, senior, senior, adult, senior...        senior            adult                  False\n",
       "6     005A  [senior, senior, senior, senior, senior, senio...        senior            adult                  False\n",
       "103   109A       [adult, adult, kitten, kitten, adult, adult]         adult           kitten                  False\n",
       "102   108A      [senior, adult, adult, senior, adult, senior]         adult           senior                  False\n",
       "101   106A  [adult, senior, senior, senior, adult, adult, ...         adult           senior                  False\n",
       "52    047A  [adult, adult, adult, adult, adult, kitten, ki...         adult           kitten                  False\n",
       "53    048A                                            [adult]         adult           kitten                  False\n",
       "54    049A                                            [adult]         adult           kitten                  False\n",
       "40    034A             [adult, senior, adult, senior, senior]        senior            adult                  False\n",
       "57    051B  [senior, adult, adult, adult, senior, adult, a...         adult           senior                  False\n",
       "58    052A                    [adult, senior, senior, senior]        senior            adult                  False\n",
       "69    063A  [senior, senior, senior, senior, adult, senior...        senior            adult                  False\n",
       "60    054A                                    [adult, senior]         adult           senior                  False\n",
       "33    026C                                           [kitten]        kitten            adult                  False\n",
       "90    095A  [senior, senior, adult, senior, senior, senior...        senior            adult                  False\n",
       "27    024A                                            [adult]         adult           senior                  False\n",
       "88    093A                                     [adult, adult]         adult           senior                  False\n",
       "18    016A  [adult, adult, adult, senior, senior, senior, ...         adult           senior                  False\n",
       "63    057A  [adult, adult, adult, senior, senior, adult, s...         adult           senior                  False\n",
       "64    058A                             [senior, adult, adult]         adult           senior                  False\n",
       "21    019B                                           [senior]        senior            adult                  False\n",
       "47    041A                                    [adult, kitten]         adult           kitten                  False\n",
       "82    076A                                           [kitten]        kitten            adult                  False\n",
       "32    026B                                           [senior]        senior            adult                  False"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "sorted_detailed_results = detailed_results.sort_values(by='Correct Majority Vote', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e03366c5-a807-4159-b0c1-8dc88c04d91e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Majority Votes per Class:\n",
      "actual_age_group\n",
      "adult     60\n",
      "kitten     9\n",
      "senior    12\n",
      "Name: Majority_Correct, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create df for majority votes\n",
    "majority_df = majority_votes.reset_index()\n",
    "majority_df.columns = ['cat_id', 'Majority_Vote']\n",
    "\n",
    "# Get actual groups for each cat_id\n",
    "actual_groups = full_results.groupby('cat_id')['actual_age_group'].first().reset_index()\n",
    "\n",
    "# Merge majority votes with actual groups\n",
    "majority_with_actual = pd.merge(majority_df, actual_groups, on='cat_id')\n",
    "\n",
    "# Add a column to check if the majority vote was correct\n",
    "majority_with_actual['Majority_Correct'] = majority_with_actual['Majority_Vote'] == majority_with_actual['actual_age_group']\n",
    "\n",
    "# Count correct majority votes per class\n",
    "correct_majority_votes_per_class = majority_with_actual.groupby('actual_age_group')['Majority_Correct'].sum()\n",
    "\n",
    "print(\"Correct Majority Votes per Class:\")\n",
    "print(correct_majority_votes_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0ae8f86b-0e19-49df-a07c-f64383bce76b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics for Majority Votes:\n",
      "  actual_age_group  total_count  correct_count   accuracy\n",
      "0            adult           73             60  82.191781\n",
      "1           kitten           15              9  60.000000\n",
      "2           senior           22             12  54.545455\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = majority_with_actual.groupby('actual_age_group').agg(\n",
    "    total_count=('Majority_Correct', 'size'),  # Total number of cases per class\n",
    "    correct_count=('Majority_Correct', 'sum')  # Sum of correct predictions per class\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log detailed stats\n",
    "print(\"Detailed Class Statistics for Majority Votes:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6350c1b2-050d-4bf3-98f1-5a80b3078d3a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics for Majority Votes\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Accuracy of Majority Votes by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ea2c7-0827-4ffa-9777-ad2891e5f49b",
   "metadata": {},
   "source": [
    "## Detailed Class Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "94fbe612-c62e-4abe-8ec3-d75940a993cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Class Statistics:\n",
      "  actual_age_group  total_count  correct_count   accuracy\n",
      "0            adult          562            437  77.758007\n",
      "1           kitten          109             70  64.220183\n",
      "2           senior          178            100  56.179775\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total count and the number of correct predictions for each class\n",
    "class_stats = full_results.groupby('actual_age_group').agg(\n",
    "    total_count=('correct', 'size'),\n",
    "    correct_count=('correct', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_stats['accuracy'] = class_stats['correct_count'] / class_stats['total_count'] * 100\n",
    "\n",
    "# Log the detailed stats\n",
    "print(\"Detailed Class Statistics:\")\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "50e84f5a-909e-47ca-93ca-2e92abf7ded1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Detailed Class Statistics for Majority Votes\n",
    "styled_barplot(class_stats, 'actual_age_group', 'accuracy', \n",
    "               'Accuracy of Majority Votes by Age Group', \n",
    "               'Age Group', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416ac46e-4cc6-4237-925c-524d47e83b46",
   "metadata": {},
   "source": [
    "## Gender Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1743599c-0d3f-4b10-a095-02c36218c679",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Gender:\n",
      "  all_gender  count  correct  accuracy\n",
      "0          F    226      176     77.88\n",
      "1          M    337      248     73.59\n",
      "2          X    286      183     63.99\n"
     ]
    }
   ],
   "source": [
    "# Group by gender and calculate the total count, correct predictions, and accuracy\n",
    "gender_stats = full_results.groupby('all_gender').agg(\n",
    "    count=('cat_id', 'size'),  # Total number of cases per gender\n",
    "    correct=('correct', 'sum')  # Sum of correct predictions per gender\n",
    ").reset_index()\n",
    "\n",
    "# Calculate accuracy for each gender\n",
    "gender_stats['accuracy'] = (gender_stats['correct'] / gender_stats['count'] * 100).round(2)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy by Gender:\")\n",
    "print(gender_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b8546267-aa7a-4e4b-b60e-810f836ebf8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for Accuracy by Gender\n",
    "styled_barplot(gender_stats, 'all_gender', 'accuracy', \n",
    "               'Accuracy by Gender', \n",
    "               'Gender', 'Accuracy (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a613636d-22ae-4629-ac86-daf482925194",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
