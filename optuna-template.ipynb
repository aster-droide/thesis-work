{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14d8383-ddcf-4522-b7be-b10ec59c91bb",
   "metadata": {},
   "source": [
    "# Optuna Hyperparameter Tuning Notebook\n",
    "\n",
    "## Contains a template for hyperparameter tuning\n",
    "## Set parameters in the `def objective(trial):` as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f269553f-ebda-4e38-9068-bbc49a7fd486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Filter deprecated feature warnings from Optuna\n",
    "warnings.filterwarnings(\"ignore\", message=\".*suggest_loguniform has been deprecated in v3.0.0.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*suggest_uniform has been deprecated in v3.0.0.*\")\n",
    "\n",
    "# Filter warnings related to TensorFlow optimizers on M1/M2 Macs\n",
    "warnings.filterwarnings(\"ignore\", message=\".*please use the legacy Keras optimizer instead.*\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8ce026-13f4-4de8-b981-e301ac99a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam, Adamax, SGD, RMSprop\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f760e2-cc79-493e-9181-7b2cd3bbb9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the SQLite URL\n",
    "storage_url = \"sqlite:///vgg_baseline_study.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c546ec15-1b61-4e6f-a3d1-f4a9e41d6721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adult     460\n",
       "senior    306\n",
       "kitten    171\n",
       "Name: age_group, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(5390) \n",
    "np.random.seed(5390)\n",
    "tf.random.set_seed(5390)\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataframe = pd.read_csv('/Users/astrid/PycharmProjects/audioset-thesis-work/audioset/vggish/embeddings/8april_looped_embeddings.csv')\n",
    "\n",
    "dataframe.drop('mean_freq', axis=1, inplace=True)\n",
    "dataframe.drop('gender', axis=1, inplace=True)\n",
    "\n",
    "def assign_age_group(age, age_groups):\n",
    "    for group_name, age_range in age_groups.items():\n",
    "        if age_range[0] <= age < age_range[1]:\n",
    "            return group_name\n",
    "    return 'Unknown'  \n",
    "\n",
    "# Define age groups\n",
    "age_groups = {\n",
    "    'kitten': (0, 0.5),\n",
    "    'adult': (0.5, 10),\n",
    "    'senior': (10, 20)\n",
    "}\n",
    "\n",
    "# create new column for the age group\n",
    "dataframe['age_group'] = dataframe['target'].apply(assign_age_group, age_groups=age_groups)\n",
    "dataframe['age_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ce943ef-ed4d-41cf-9b38-3310b4db196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_group_split(train_index, val_index, groups):\n",
    "    \"\"\"\n",
    "    Check if any group is present in both training and validation sets.\n",
    "\n",
    "    Parameters:\n",
    "    - train_index: Indices for training data\n",
    "    - val_index: Indices for validation data\n",
    "    - groups: Array of group identifiers corresponding to each sample\n",
    "\n",
    "    Returns:\n",
    "    - Prints out any groups found in both sets and the count of such groups\n",
    "    \"\"\"\n",
    "    train_groups = set(groups[train_index])\n",
    "    val_groups = set(groups[val_index])\n",
    "    common_groups = train_groups.intersection(val_groups)\n",
    "\n",
    "    print(train_groups)\n",
    "    print(val_groups)\n",
    "    print(common_groups)\n",
    "\n",
    "    if common_groups:\n",
    "        print(f\"Warning: Found {len(common_groups)} common groups in both training and validation sets: {common_groups}\")\n",
    "    else:\n",
    "        print(\"No common groups found between training and validation sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab2e79de-6d58-4c23-824d-e657b72b5795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_initial_group_split(groups_train, groups_test):\n",
    "    \"\"\"\n",
    "    Check if any group is present in both the train/validation and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - groups_train: Array of group identifiers for the train/validation set\n",
    "    - groups_test: Array of group identifiers for the test set\n",
    "\n",
    "    Returns:\n",
    "    - Prints out any groups found in both sets and the count of such groups\n",
    "    \"\"\"\n",
    "    train_groups = set(groups_train)\n",
    "    test_groups = set(groups_test)\n",
    "    common_groups = train_groups.intersection(test_groups)\n",
    "\n",
    "    if common_groups:\n",
    "        print(f\"Warning: Found {len(common_groups)} common groups in both train/validation and test sets: {common_groups}\")\n",
    "    else:\n",
    "        print(\"No common groups found between train/validation and test sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63286ea7-da0f-47f3-b15f-61d32b636337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique_cat_ids(df_train, df_val):\n",
    "    \"\"\"\n",
    "    Check if the 'cat_id' column in df_train and df_val are unique.\n",
    "    \n",
    "    Parameters:\n",
    "        df_train (pandas.DataFrame): DataFrame for training data.\n",
    "        df_val (pandas.DataFrame): DataFrame for validation data.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if 'cat_id' column in df_train and df_val are unique, False otherwise.\n",
    "    \"\"\"\n",
    "    # Extract 'cat_id' column from both DataFrames\n",
    "    train_cat_ids = set(df_train['cat_id'])\n",
    "    val_cat_ids = set(df_val['cat_id'])\n",
    "    \n",
    "    # Check if there is any overlap between 'cat_id' in df_train and df_val\n",
    "    is_unique = len(train_cat_ids.intersection(val_cat_ids)) == 0\n",
    "    \n",
    "    return is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb956459-2a43-426e-b430-e91367931609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = dataframe.iloc[:, :-3].values  # all columns except the last three\n",
    "\n",
    "# Encode the 'age_group' column as integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y = label_encoder.fit_transform(dataframe['age_group'].values)\n",
    "\n",
    "# Now use the encoded labels for splitting and one-hot encoding\n",
    "y = encoded_y  # This will be used in the GroupKFold\n",
    "\n",
    "# Convert 'cat_id' column to numpy array to be used as groups array for GroupKFold\n",
    "groups = dataframe['cat_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d79bd6db-81f1-488d-b802-54384a1eb493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform the swaps based on cat_id, ensuring swaps within the same age_group\n",
    "def swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids):\n",
    "    for cat_id in specific_cat_ids:\n",
    "        # Check if the specific cat_id is not in the training/validation set\n",
    "        if cat_id not in dataframe.iloc[train_val_idx]['cat_id'].values:\n",
    "            # Get the age_group of this cat_id\n",
    "            age_group = dataframe[dataframe['cat_id'] == cat_id]['age_group'].iloc[0]\n",
    "                \n",
    "            # Find a different cat_id within the same age_group in the train/val set that is not in the test set\n",
    "            other_cat_ids_in_age_group = dataframe[(dataframe['age_group'] == age_group) & \n",
    "                                                   (dataframe['cat_id'] != cat_id) &\n",
    "                                                   (~dataframe['cat_id'].isin(dataframe.iloc[test_idx]['cat_id']))]['cat_id'].unique()\n",
    "            \n",
    "            # Choose one other cat_id for swapping\n",
    "            if len(other_cat_ids_in_age_group) > 0:\n",
    "                other_cat_id = np.random.choice(other_cat_ids_in_age_group)\n",
    "\n",
    "                # Find all instances of the other_cat_id in the train/val set\n",
    "                other_cat_id_train_val_indices = train_val_idx[dataframe.iloc[train_val_idx]['cat_id'] == other_cat_id]\n",
    "                \n",
    "                # Find all instances of the specific cat_id in the test set\n",
    "                cat_id_test_indices = test_idx[dataframe.iloc[test_idx]['cat_id'] == cat_id]\n",
    "                \n",
    "                # Swap the indices\n",
    "                train_val_idx = np.setdiff1d(train_val_idx, other_cat_id_train_val_indices, assume_unique=True)\n",
    "                test_idx = np.setdiff1d(test_idx, cat_id_test_indices, assume_unique=True)\n",
    "\n",
    "                train_val_idx = np.concatenate((train_val_idx, cat_id_test_indices))\n",
    "                test_idx = np.concatenate((test_idx, other_cat_id_train_val_indices))\n",
    "            else:\n",
    "                print(f\"No alternative cat_id found in the same age_group as {cat_id} for swapping.\")\n",
    "                \n",
    "    return train_val_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb90c0a6-797a-4ba4-a031-f4ddca009e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify differences\n",
    "def find_group_differences(original, new):\n",
    "    # Convert numpy arrays to sets for easy difference computation\n",
    "    original_set = set(original)\n",
    "    new_set = set(new)\n",
    "    # Find differences\n",
    "    moved_to_new = new_set - original_set\n",
    "    moved_to_original = original_set - new_set\n",
    "    return moved_to_new, moved_to_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bafe53c-89b3-45e7-9f44-09023c945916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom logger function for local logs & stored in a .txt\n",
    "def logger(message, file=None):\n",
    "    print(message)\n",
    "    if file is not None:\n",
    "        with open(file, \"a\") as log_file:\n",
    "            log_file.write(message + \"\\n\")\n",
    "\n",
    "log_file_path = \"optuna_vggish_june_8.txt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c97df2b-43ab-4e7f-a2be-ec584b08e7b7",
   "metadata": {},
   "source": [
    "# HYPEROPTIMISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6044a4f9-ff0f-44af-a220-182bddd858d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "# Define the StratifiedGroupKFold splitter for outer CV\n",
    "outer_cv = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the StratifiedGroupKFold splitter for inner CV\n",
    "inner_cv = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate a unique identifier for the current trial\n",
    "    run_id = f\"trial_{trial.number}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    \n",
    "    # Hyperparameters to tune\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    optimizer_key = trial.suggest_categorical('optimizer', ['Adam', 'Adamax', 'RMSprop'])\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'sigmoid'])\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 4)  # Number of layers\n",
    "\n",
    "    # Specific hyperparameters for each layer\n",
    "    units_per_layer = [trial.suggest_categorical(f'units_l{i}', [32, 64, 128, 224, 256, 480, 512]) for i in range(n_layers)]\n",
    "    dropout_rate_per_layer = [trial.suggest_float(f'dropout_l{i}', 0.1, 0.5) for i in range(n_layers)]\n",
    "\n",
    "    # inner loop metrics\n",
    "    losses, accuracies, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "\n",
    "    # outer loop metrics\n",
    "    outer_losses, outer_accuracies, outer_precisions, outer_recalls, outer_f1_scores = [], [], [], [], []\n",
    "\n",
    "    # unseen test set metrics\n",
    "    unseen_losses, unseen_accuracies, unseen_precisions, unseen_recalls, unseen_f1 = [], [], [], [], []\n",
    "\n",
    "    total_inner_fold = 0\n",
    "    outer_fold = 0\n",
    "\n",
    "    try:\n",
    "        # Use the splitter to generate indices for training and testing sets\n",
    "        # Note: GroupShuffleSplit.split returns indices, so we use it to index the arrays\n",
    "        for train_val_idx, test_idx in outer_cv.split(X, y, groups):\n",
    "            outer_fold += 1\n",
    "            logger(f\"outer_fold {outer_fold}\", file=log_file_path)\n",
    "\n",
    "            # Convert indices back to DataFrame for easy manipulation\n",
    "            df_train_val = dataframe.iloc[train_val_idx]\n",
    "            df_test = dataframe.iloc[test_idx]\n",
    "            \n",
    "            # Get the distribution of age groups\n",
    "            training_validation_age_group_distribution = df_train_val['age_group'].value_counts()\n",
    "            testing_age_group_distribution = df_test['age_group'].value_counts()\n",
    "            \n",
    "            # Log the distribution\n",
    "            logger(f\"Training/Validation Set Age Group Distribution:\\n{training_validation_age_group_distribution}\", file=log_file_path)\n",
    "            logger(f\"Testing Set Age Group Distribution:\\n{testing_age_group_distribution}\", file=log_file_path)\n",
    "\n",
    "            # Get the distribution of groups\n",
    "            training_validation_group_distribution = df_train_val['cat_id'].value_counts()  \n",
    "            testing_group_distribution = df_test['cat_id'].value_counts()  \n",
    "            \n",
    "            # Log the distribution\n",
    "            logger(f\"Training/Validation Set Group Distribution:\\n{training_validation_group_distribution}\", file=log_file_path)\n",
    "            logger(f\"Testing Set Group Distribution:\\n{testing_group_distribution}\", file=log_file_path)\n",
    "\n",
    "            # Group by 'age_group' and then list unique 'cat_id' within each age group\n",
    "            unique_cat_ids_per_age_group_train_val = df_train_val.groupby('age_group')['cat_id'].unique()\n",
    "            unique_cat_ids_per_age_group_test = df_test.groupby('age_group')['cat_id'].unique()\n",
    "            \n",
    "            # Log the results\n",
    "            logger(f\"Unique Cat IDs per Age Group in Training/Validation Set:\\n{unique_cat_ids_per_age_group_train_val}\", file=log_file_path)\n",
    "            logger(f\"Unique Cat IDs per Age Group in Testing Set:\\n{unique_cat_ids_per_age_group_test}\", file=log_file_path)\n",
    "\n",
    "            # Calculate the count of unique identifiers per age group for training/validation and testing set\n",
    "            counts_train_val = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_train_val.items()}\n",
    "            counts_test = {age_group: len(identifiers) for age_group, identifiers in unique_cat_ids_per_age_group_test.items()}\n",
    "\n",
    "            # Log the counts of unique identifiers per age group\n",
    "            logger(f\"Count of Unique Cat IDs per Age Group in Training/Validation Set:\\n{counts_train_val}\", file=log_file_path)\n",
    "            logger(f\"Count of Unique Cat IDs per Age Group in Testing Set:\\n{counts_test}\", file=log_file_path)\n",
    "            \n",
    "            X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "            y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "            groups_train_val, groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "            # logging identifier splits \n",
    "            unique_train_val_groups = np.unique(groups_train_val)\n",
    "            unique_test_groups = np.unique(groups_test)\n",
    "            \n",
    "            logger(f\"Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "            logger(f\"Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "\n",
    "            # check group splits\n",
    "            check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "            # Specify the cat_ids that must be in the training/validation set\n",
    "            specific_cat_ids = ['000A', '046A']\n",
    "            \n",
    "            # Perform the swapping operation\n",
    "            train_val_idx, test_idx = swap_cat_id_instances(dataframe, train_val_idx, test_idx, specific_cat_ids)\n",
    "            \n",
    "            # Re-assign the sets based on the updated indices\n",
    "            X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "            y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "            new_groups_train_val, new_groups_test = groups[train_val_idx], groups[test_idx]\n",
    "\n",
    "            # Find differences for training/validation and test sets\n",
    "            moved_to_train_val, removed_from_train_val = find_group_differences(groups_train_val, new_groups_train_val)\n",
    "            moved_to_test, removed_from_test = find_group_differences(groups_test, new_groups_test)\n",
    "            \n",
    "            # Display the results\n",
    "            logger(f\"Moved to Training/Validation Set:\\n{moved_to_train_val}\", file=log_file_path)\n",
    "            logger(f\"Removed from Training/Validation Set:\\n{removed_from_train_val}\", file=log_file_path)\n",
    "            logger(f\"Moved to Test Set:\\n{moved_to_test}\", file=log_file_path)\n",
    "            logger(f\"Removed from Test Set\\n{removed_from_test}\", file=log_file_path)\n",
    "\n",
    "            # Update X_train_val, X_test, y_train_val, y_test, groups_train_val, groups_test based on updated indices\n",
    "            X_train_val = X[train_val_idx]\n",
    "            y_train_val = y[train_val_idx]\n",
    "            groups_train_val = groups[train_val_idx]\n",
    "            \n",
    "            X_test = X[test_idx]\n",
    "            y_test = y[test_idx]\n",
    "            groups_test = groups[test_idx]\n",
    "\n",
    "            # logging identifier splits again after potential swaps\n",
    "            unique_train_val_groups = np.unique(groups_train_val)\n",
    "            unique_test_groups = np.unique(groups_test)\n",
    "            \n",
    "            logger(f\"AFTER SWAP - Unique Training/Validation Group IDs:\\n{unique_train_val_groups}\", file=log_file_path)\n",
    "            logger(f\"AFTER SWAP - Unique Test Group IDs:\\n{unique_test_groups}\", file=log_file_path)\n",
    "            \n",
    "            # Verify the lengths are consistent\n",
    "            logger(f\"Length of X_train_val:\\n{len(X_train_val)}\", file=log_file_path)\n",
    "            logger(f\"Length of y_train_val:\\n{len(y_train_val)}\", file=log_file_path)\n",
    "            logger(f\"Length of groups_train_val:\\n{len(groups_train_val)}\", file=log_file_path)\n",
    "\n",
    "            # check group splits once more\n",
    "            check_initial_group_split(groups_train_val, groups_test)\n",
    "\n",
    "            # Convert the modified indices back to a DataFrame representing the updated df_train_val\n",
    "            df_train_val_updated = dataframe.iloc[train_val_idx].copy()\n",
    "            \n",
    "            for train_index, val_index in inner_cv.split(X_train_val, y_train_val, groups=groups_train_val):\n",
    "                \n",
    "                total_inner_fold += 1\n",
    "                logger(f\"\\n\\nStarting total inner fold nr {total_inner_fold}:\", file=log_file_path)\n",
    "                \n",
    "                # Perform the group split check\n",
    "                check_group_split(train_index, val_index, groups_train_val)\n",
    "\n",
    "                # Data preparation steps \n",
    "                df_train = df_train_val_updated.iloc[train_index]\n",
    "                df_val = df_train_val_updated.iloc[val_index]\n",
    "\n",
    "                unique = check_unique_cat_ids(df_train, df_val) \n",
    "        \n",
    "                if unique:\n",
    "                    logger(f\"\", file=log_file_path)\n",
    "                    logger(f\"NO OVERLAP IN INNER LOOP SPLIT\", file=log_file_path)\n",
    "                    logger(f\"\", file=log_file_path)\n",
    "                else:\n",
    "                    logger(f\"\", file=log_file_path)\n",
    "                    logger(f\"THERE IS OVERLAP IN INNER LOOP SPLIT\", file=log_file_path)\n",
    "                    logger(f\"\", file=log_file_path)\n",
    "        \n",
    "                df_train_cat_ids = df_train['cat_id'].sort_values().unique()\n",
    "                df_val_cat_ids = df_val['cat_id'].sort_values().unique()\n",
    "\n",
    "                logger(f\"df_train_cat_ids:\\n{df_train_cat_ids}\", file=log_file_path)\n",
    "                logger(f\"df_val_cat_ids:\\n{df_val_cat_ids}\", file=log_file_path)\n",
    "        \n",
    "                # Check the distribution\n",
    "                training_age_group_counts = df_train['age_group'].value_counts()\n",
    "                validation_age_group_counts = df_val['age_group'].value_counts()\n",
    "                logger(f\"Training set age group distribution:\\n{training_age_group_counts}\", file=log_file_path)\n",
    "                logger(f\"Validation set age group distribution:\\n{validation_age_group_counts}\", file=log_file_path)\n",
    "\n",
    "                X_train = df_train.iloc[:, :-3].values\n",
    "                X_val = df_val.iloc[:, :-3].values\n",
    "\n",
    "                y_train = label_encoder.transform(df_train['age_group'].values)\n",
    "                y_val = label_encoder.transform(df_val['age_group'].values)\n",
    "                \n",
    "                # perform one final shuffle before training\n",
    "                shuffle_idx = np.random.permutation(len(X_train))\n",
    "                X_train = X_train[shuffle_idx]\n",
    "                y_train = y_train[shuffle_idx]\n",
    "                \n",
    "                y_train_encoded = to_categorical(y_train)\n",
    "                y_val_encoded = to_categorical(y_val)\n",
    "                \n",
    "                scaler = StandardScaler().fit(X_train)\n",
    "                X_train_scaled = scaler.transform(X_train)\n",
    "                X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "                # Optimizer selection\n",
    "                optimizers = {\n",
    "                    'Adam': Adam(learning_rate=learning_rate),\n",
    "                    'RMSprop': RMSprop(learning_rate=learning_rate),\n",
    "                    'SGD': SGD(learning_rate=learning_rate),\n",
    "                    'Adamax': Adamax(learning_rate=learning_rate)\n",
    "                }\n",
    "\n",
    "                class_weights = compute_class_weight(\n",
    "                    class_weight='balanced',\n",
    "                    classes=np.unique(y_train),\n",
    "                    y=y_train\n",
    "                )\n",
    "                weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "                print(f\"Class Weights: {weight_dict}\")\n",
    "                \n",
    "                # Model definition with dynamic number of layers\n",
    "                model = Sequential()\n",
    "                for i in range(n_layers):\n",
    "                    if i == 0:\n",
    "                        model.add(Dense(units_per_layer[i], activation=activation, input_shape=(X_train_scaled.shape[1],)))\n",
    "                    else:\n",
    "                        model.add(Dense(units_per_layer[i], activation=activation))\n",
    "                    model.add(BatchNormalization())\n",
    "                    model.add(Dropout(dropout_rate_per_layer[i]))\n",
    "                model.add(Dense(3, activation='softmax'))\n",
    "                \n",
    "                optimizer = optimizers[optimizer_key]\n",
    "        \n",
    "                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                \n",
    "                # EarlyStopping function\n",
    "                early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=100, verbose=1, restore_best_weights=True)\n",
    "\n",
    "                # Training with EarlyStopping and silent verbose\n",
    "                history = model.fit(X_train_scaled, y_train_encoded, validation_data=(X_val_scaled, y_val_encoded), epochs=1500,\n",
    "                                    batch_size=batch_size, callbacks=[early_stopping], verbose=0, class_weight=weight_dict)\n",
    "                \n",
    "                # Log the number of epochs trained and the last epoch's metrics\n",
    "                epochs_trained = len(history.history['loss'])\n",
    "                last_loss = history.history['loss'][-1]\n",
    "                last_accuracy = history.history['accuracy'][-1]\n",
    "                last_val_loss = history.history['val_loss'][-1]\n",
    "                last_val_accuracy = history.history['val_accuracy'][-1]\n",
    "                logger(f\"Epochs Trained: {epochs_trained}\", file=log_file_path)\n",
    "                logger(f\"Last Training Loss: {last_loss}, Last Training Accuracy: {last_accuracy}\", file=log_file_path)\n",
    "                logger(f\"Last Validation Loss: {last_val_loss}, Last Validation Accuracy: {last_val_accuracy}\", file=log_file_path)\n",
    "                \n",
    "                # Evaluation\n",
    "                val_loss, val_accuracy = model.evaluate(X_val_scaled, y_val_encoded, verbose=0)\n",
    "                y_val_pred = model.predict(X_val_scaled)\n",
    "                y_val_pred_class = np.argmax(y_val_pred, axis=1)\n",
    "                y_val_true_class = np.argmax(y_val_encoded, axis=1)\n",
    "                \n",
    "                # Metric calculation\n",
    "                accuracy = accuracy_score(y_val_true_class, y_val_pred_class)\n",
    "                precision = precision_score(y_val_true_class, y_val_pred_class, average='macro', zero_division=0)\n",
    "                recall = recall_score(y_val_true_class, y_val_pred_class, average='macro', zero_division=0)\n",
    "                f1 = f1_score(y_val_true_class, y_val_pred_class, average='macro', zero_division=0)\n",
    "\n",
    "                logger(f\"\\nrecall for total inner fold nr {total_inner_fold}:\\n{recall}\\n\", file=log_file_path)\n",
    "                \n",
    "                # Storing metrics\n",
    "                losses.append(val_loss)\n",
    "                accuracies.append(accuracy)\n",
    "                precisions.append(precision)\n",
    "                recalls.append(recall)\n",
    "                f1_scores.append(f1)\n",
    "        \n",
    "                # Calculate the average of each metric\n",
    "                avg_loss = np.mean(losses)\n",
    "                avg_accuracy = np.mean(accuracies)\n",
    "                avg_precision = np.mean(precisions)\n",
    "                avg_recall = np.mean(recalls)\n",
    "                avg_f1 = np.mean(f1_scores)\n",
    "            \n",
    "                # At the end of your objective function\n",
    "                trial.set_user_attr('average_loss', avg_loss)\n",
    "                trial.set_user_attr('average_accuracy', avg_accuracy)\n",
    "                trial.set_user_attr('average_precision', avg_precision)\n",
    "                trial.set_user_attr('average_recall', avg_recall)\n",
    "    \n",
    "                logger(f\"average_loss:\\n{avg_loss}\", file=log_file_path)\n",
    "                logger(f\"average_accuracy:\\n{avg_accuracy}\", file=log_file_path)\n",
    "                logger(f\"average_precision:\\n{avg_precision}\", file=log_file_path)\n",
    "                logger(f\"average_recall:\\n{avg_recall}\", file=log_file_path)\n",
    "\n",
    "            # After inner loop, calculate and store the average metrics of the inner folds for the current outer split\n",
    "            inner_average_loss = np.mean(losses)\n",
    "            inner_average_accuracies = np.mean(accuracies)\n",
    "            inner_average_precisions = np.mean(precisions)\n",
    "            inner_average_recalls = np.mean(recalls)\n",
    "            inner_average_f1_scores = np.mean(f1_scores)\n",
    "\n",
    "            outer_losses.append(inner_average_loss)\n",
    "            outer_accuracies.append(inner_average_accuracies)\n",
    "            outer_precisions.append(inner_average_precisions)\n",
    "            outer_recalls.append(inner_average_recalls)\n",
    "            outer_f1_scores.append(inner_average_f1_scores)\n",
    "\n",
    "            # Log the final averages\n",
    "            logger(f\"\\nInner Average Loss for outer fold {outer_fold}: {inner_average_loss}\", file=log_file_path)\n",
    "            logger(f\"Inner Average Accuracy for outer fold {outer_fold}: {inner_average_accuracies}\", file=log_file_path)\n",
    "            logger(f\"Inner Average Precision for outer fold {outer_fold}: {inner_average_precisions}\", file=log_file_path)\n",
    "            logger(f\"Inner Average Recall for outer fold {outer_fold}: {inner_average_recalls}\", file=log_file_path)\n",
    "            logger(f\"Inner Average F1-Score for outer fold {outer_fold}: {inner_average_f1_scores}\", file=log_file_path)\n",
    "            \n",
    "            logger(f\"\\n Starting training on unseen test set\\n\", file=log_file_path)\n",
    "\n",
    "            # EarlyStopping callback modification: monitor 'loss' instead of 'val_loss'\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor='loss',  \n",
    "                min_delta=0.001, \n",
    "                patience=100,  \n",
    "                verbose=1,  \n",
    "                restore_best_weights=True  \n",
    "            )\n",
    "\n",
    "            # one final shuffle\n",
    "            outer_shuffle_idx = np.random.permutation(len(X_train_val))\n",
    "            X_train_val = X_train_val[outer_shuffle_idx]\n",
    "            y_train_val = y_train_val[outer_shuffle_idx]\n",
    "            \n",
    "            # Assuming X_train_val and X_test have been defined earlier along with y_train_val and y_test\n",
    "            # Scale the features\n",
    "            scaler_full = StandardScaler().fit(X_train_val)\n",
    "            X_train_full_scaled = scaler_full.transform(X_train_val)\n",
    "            X_test_scaled = scaler_full.transform(X_test)\n",
    "            \n",
    "            # Encode the labels\n",
    "            y_train_full_encoded = to_categorical(y_train_val)\n",
    "            y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "            # Optimizer selection\n",
    "            optimizers = {\n",
    "                'Adam': Adam(learning_rate=learning_rate),\n",
    "                'RMSprop': RMSprop(learning_rate=learning_rate),\n",
    "                'SGD': SGD(learning_rate=learning_rate),\n",
    "                'Adamax': Adamax(learning_rate=learning_rate)\n",
    "            }\n",
    "\n",
    "            class_weights = compute_class_weight(\n",
    "                class_weight='balanced',\n",
    "                classes=np.unique(y_train_val),\n",
    "                y=y_train_val\n",
    "            )\n",
    "            weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "            print(f\"Class Weights: {weight_dict}\")\n",
    "\n",
    "            # full model definition\n",
    "            model_full = Sequential()\n",
    "            for i in range(n_layers):\n",
    "                if i == 0:\n",
    "                    model_full.add(Dense(units_per_layer[i], activation=activation, input_shape=(X_train_scaled.shape[1],)))\n",
    "                else:\n",
    "                    model_full.add(Dense(units_per_layer[i], activation=activation))\n",
    "                model_full.add(BatchNormalization())\n",
    "                model_full.add(Dropout(dropout_rate_per_layer[i]))\n",
    "            model_full.add(Dense(3, activation='softmax'))\n",
    "            \n",
    "            # Use the selected optimizer\n",
    "            optimizer = optimizers[optimizer_key]\n",
    "            model_full.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            \n",
    "            # Train the model on the full training set\n",
    "            history_full = model_full.fit(X_train_full_scaled, y_train_full_encoded, epochs=1500, batch_size=batch_size,\n",
    "                                          verbose=1, callbacks=[early_stopping], class_weight=weight_dict)\n",
    "            \n",
    "            # Evaluate the model on the held-out test set\n",
    "            test_loss, test_accuracy = model_full.evaluate(X_test_scaled, y_test_encoded)\n",
    "\n",
    "            y_test_pred_prob = model_full.predict(X_test_scaled)\n",
    "            y_test_pred = np.argmax(y_test_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "            y_test_true = np.argmax(y_test_encoded, axis=1)    # Ensure y_test is in the correct format for comparison\n",
    "            \n",
    "            # Calculate additional metrics\n",
    "            test_precision = precision_score(y_test_true, y_test_pred, average='macro') \n",
    "            test_recall = recall_score(y_test_true, y_test_pred, average='macro')\n",
    "            test_f1 = f1_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "            # prepare average of outer f1 scores for Optuna optimisation\n",
    "            unseen_f1.append(test_f1)\n",
    "            # add remaining metrics for logging\n",
    "            unseen_losses.append(test_loss)\n",
    "            unseen_accuracies.append(test_accuracy)\n",
    "            unseen_precisions.append(test_precision)\n",
    "            unseen_recalls.append(test_recall)\n",
    "\n",
    "            # Print final test results\n",
    "            logger(f\"Final Test Results - Loss: {test_loss}, Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1 Score: {test_f1}\", file=log_file_path)\n",
    "\n",
    "            # Generate the confusion matrix\n",
    "            cm = confusion_matrix(y_test, y_test_pred)\n",
    "            logger(f\"Confusion Matrix:\\n {cm}\", file=log_file_path)\n",
    "\n",
    "        # After the outer loop, calculate the overall average metrics across all outer splits\n",
    "        final_avg_loss = np.mean(outer_losses)\n",
    "        final_avg_accuracy = np.mean(outer_accuracies)\n",
    "        final_avg_precision = np.mean(outer_precisions)\n",
    "        final_avg_recall = np.mean(outer_recalls)\n",
    "        final_avg_f1 = np.mean(outer_f1_scores)\n",
    "        \n",
    "        # Log the averages from all folds in this trial (5 outer splits * 5 inner cvs = 25) \n",
    "        logger(f\"\\nFinal Total Averages over all folds in current trial (5 outer splits * 5 inner cvs = 25):\", file=log_file_path)\n",
    "        logger(f\"\\nFinal Average Loss: {final_avg_loss}\", file=log_file_path)\n",
    "        logger(f\"Final Average Accuracy: {final_avg_accuracy}\", file=log_file_path)\n",
    "        logger(f\"Final Average Precision: {final_avg_precision}\", file=log_file_path)\n",
    "        logger(f\"Final Average Recall: {final_avg_recall}\", file=log_file_path)\n",
    "        logger(f\"Final Average F1-Score: {final_avg_f1}\", file=log_file_path)\n",
    "\n",
    "        # After evaluating all outer folds, calculate the overall average F1 score across all outer folds for Optuna\n",
    "        unseen_set_avg_f1 = np.mean(unseen_f1)\n",
    "        # And the remaining metrics for logging\n",
    "        unseen_set_avg_loss = np.mean(unseen_losses)\n",
    "        unseen_set_avg_acc = np.mean(unseen_accuracies)\n",
    "        unseen_set_avg_precision = np.mean(unseen_precisions)\n",
    "        unseen_set_avg_recall = np.mean(unseen_recalls)\n",
    "\n",
    "        logger(f\"\\nFinal Average F1-Score across all OUTER UNSEEN TEST sets in current trial {trial.number}: {unseen_set_avg_f1}\", file=log_file_path)\n",
    "        logger(f\"\\nFinal Average Loss across all OUTER UNSEEN TEST sets in current trial {trial.number}: {unseen_set_avg_loss}\", file=log_file_path)\n",
    "        logger(f\"\\nFinal Average Accuracy across all OUTER UNSEEN TEST sets in current trial {trial.number}: {unseen_set_avg_acc}\", file=log_file_path)\n",
    "        logger(f\"\\nFinal Average Precision across all OUTER UNSEEN TEST sets in current trial {trial.number}: {unseen_set_avg_precision}\", file=log_file_path)\n",
    "        logger(f\"\\nFinal Average Recall across all OUTER UNSEEN TEST sets in current trial {trial.number}: {unseen_set_avg_recall}\\n\", file=log_file_path)\n",
    "        \n",
    "        # Return the final average F1-score for Optuna optimisation \n",
    "        # Return the average F1 from the INNER folds to optimise and aiming to generalise well on unseen outer data as well\n",
    "        # We dont want to optimise on the outer data as this might just learn the 'unseen' data then \n",
    "        return final_avg_f1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!EXCEPTION ERROR!: {e}\")\n",
    "        logger(f\"!EXCEPTION ERROR!: {e}\", file=log_file_path)\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "567b886b-55e7-463e-add3-b8b093b7c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_callback(study, trial):\n",
    "    # Access the latest completed trial\n",
    "    latest_trial = study.trials[-1]\n",
    "\n",
    "    logger(f\"Finished trial # {latest_trial.number} with value: {latest_trial.value}.\", file=log_file_path)\n",
    "    logger(f\"Best so far #:\\n{study.best_value:.4f}\", file=log_file_path)\n",
    "\n",
    "    if study.best_trial:\n",
    "        logger(f\"Best parameters: #:\\n{study.best_value:.4f}\", file=log_file_path)\n",
    "        for key, value in study.best_trial.params.items():\n",
    "            logger(f\"    {key}: {value}\\n\", file=log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b92404e9-d903-416f-8592-ac9f990fccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced80d5a-e57a-4003-af19-e8fb514d7412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-10 09:27:25,619] A new study created in RDB with name: vggish_9_june\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_fold 1\n",
      "Training/Validation Set Age Group Distribution:\n",
      "adult     327\n",
      "senior    261\n",
      "kitten    153\n",
      "Name: age_group, dtype: int64\n",
      "Testing Set Age Group Distribution:\n",
      "adult     133\n",
      "senior     45\n",
      "kitten     18\n",
      "Name: age_group, dtype: int64\n",
      "Training/Validation Set Group Distribution:\n",
      "046A    63\n",
      "000A    39\n",
      "103A    33\n",
      "047A    28\n",
      "057A    27\n",
      "        ..\n",
      "041A     1\n",
      "092A     1\n",
      "049A     1\n",
      "043A     1\n",
      "090A     1\n",
      "Name: cat_id, Length: 86, dtype: int64\n",
      "Testing Set Group Distribution:\n",
      "002B    32\n",
      "074A    25\n",
      "020A    23\n",
      "106A    14\n",
      "059A    14\n",
      "068A    11\n",
      "014B    10\n",
      "072A     9\n",
      "095A     8\n",
      "117A     7\n",
      "099A     7\n",
      "044A     5\n",
      "025C     5\n",
      "021A     5\n",
      "062A     4\n",
      "104A     4\n",
      "014A     3\n",
      "032A     2\n",
      "076A     1\n",
      "048A     1\n",
      "004A     1\n",
      "115A     1\n",
      "110A     1\n",
      "100A     1\n",
      "024A     1\n",
      "026B     1\n",
      "Name: cat_id, dtype: int64\n",
      "Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "age_group\n",
      "adult     [006A, 000A, 033A, 071A, 097B, 019A, 067A, 022...\n",
      "kitten    [111A, 040A, 046A, 047A, 042A, 109A, 050A, 043...\n",
      "senior    [093A, 015A, 097A, 001A, 103A, 028A, 057A, 101...\n",
      "Name: cat_id, dtype: object\n",
      "Unique Cat IDs per Age Group in Testing Set:\n",
      "age_group\n",
      "adult     [074A, 020A, 062A, 002B, 095A, 072A, 099A, 014...\n",
      "kitten                       [044A, 014B, 048A, 115A, 110A]\n",
      "senior                 [106A, 104A, 059A, 025C, 117A, 024A]\n",
      "Name: cat_id, dtype: object\n",
      "Count of Unique Cat IDs per Age Group in Training/Validation Set:\n",
      "{'adult': 47, 'kitten': 11, 'senior': 28}\n",
      "Count of Unique Cat IDs per Age Group in Testing Set:\n",
      "{'adult': 15, 'kitten': 5, 'senior': 6}\n",
      "Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '003A' '005A' '006A' '007A' '008A' '009A'\n",
      " '010A' '011A' '012A' '013B' '015A' '016A' '018A' '019A' '019B' '022A'\n",
      " '023A' '023B' '025A' '025B' '026A' '026C' '027A' '028A' '029A' '031A'\n",
      " '033A' '034A' '035A' '036A' '037A' '038A' '039A' '040A' '041A' '042A'\n",
      " '043A' '045A' '046A' '047A' '049A' '050A' '051A' '051B' '052A' '053A'\n",
      " '054A' '055A' '056A' '057A' '058A' '060A' '061A' '063A' '064A' '065A'\n",
      " '066A' '067A' '069A' '070A' '071A' '073A' '075A' '087A' '088A' '090A'\n",
      " '091A' '092A' '093A' '094A' '096A' '097A' '097B' '101A' '102A' '103A'\n",
      " '105A' '108A' '109A' '111A' '113A' '116A']\n",
      "Unique Test Group IDs:\n",
      "['002B' '004A' '014A' '014B' '020A' '021A' '024A' '025C' '026B' '032A'\n",
      " '044A' '048A' '059A' '062A' '068A' '072A' '074A' '076A' '095A' '099A'\n",
      " '100A' '104A' '106A' '110A' '115A' '117A']\n",
      "No common groups found between train/validation and test sets.\n",
      "Moved to Training/Validation Set:\n",
      "set()\n",
      "Removed from Training/Validation Set:\n",
      "set()\n",
      "Moved to Test Set:\n",
      "set()\n",
      "Removed from Test Set\n",
      "set()\n",
      "AFTER SWAP - Unique Training/Validation Group IDs:\n",
      "['000A' '000B' '001A' '002A' '003A' '005A' '006A' '007A' '008A' '009A'\n",
      " '010A' '011A' '012A' '013B' '015A' '016A' '018A' '019A' '019B' '022A'\n",
      " '023A' '023B' '025A' '025B' '026A' '026C' '027A' '028A' '029A' '031A'\n",
      " '033A' '034A' '035A' '036A' '037A' '038A' '039A' '040A' '041A' '042A'\n",
      " '043A' '045A' '046A' '047A' '049A' '050A' '051A' '051B' '052A' '053A'\n",
      " '054A' '055A' '056A' '057A' '058A' '060A' '061A' '063A' '064A' '065A'\n",
      " '066A' '067A' '069A' '070A' '071A' '073A' '075A' '087A' '088A' '090A'\n",
      " '091A' '092A' '093A' '094A' '096A' '097A' '097B' '101A' '102A' '103A'\n",
      " '105A' '108A' '109A' '111A' '113A' '116A']\n",
      "AFTER SWAP - Unique Test Group IDs:\n",
      "['002B' '004A' '014A' '014B' '020A' '021A' '024A' '025C' '026B' '032A'\n",
      " '044A' '048A' '059A' '062A' '068A' '072A' '074A' '076A' '095A' '099A'\n",
      " '100A' '104A' '106A' '110A' '115A' '117A']\n",
      "Length of X_train_val:\n",
      "741\n",
      "Length of y_train_val:\n",
      "741\n",
      "Length of groups_train_val:\n",
      "741\n",
      "No common groups found between train/validation and test sets.\n",
      "\n",
      "\n",
      "Starting total inner fold nr 1:\n",
      "{'005A', '010A', '018A', '102A', '063A', '031A', '028A', '026A', '101A', '066A', '108A', '034A', '070A', '000B', '001A', '096A', '075A', '012A', '041A', '113A', '035A', '019B', '040A', '093A', '092A', '027A', '097A', '002A', '042A', '008A', '105A', '046A', '069A', '033A', '029A', '025A', '088A', '116A', '087A', '038A', '058A', '026C', '057A', '047A', '109A', '045A', '051A', '049A', '015A', '023B', '103A', '061A', '037A', '023A', '043A', '097B', '006A', '009A', '111A', '003A', '073A', '060A', '067A', '051B', '013B'}\n",
      "{'016A', '025B', '007A', '052A', '071A', '090A', '050A', '054A', '065A', '053A', '000A', '022A', '011A', '091A', '019A', '094A', '036A', '055A', '039A', '064A', '056A'}\n",
      "set()\n",
      "No common groups found between training and validation sets.\n",
      "\n",
      "NO OVERLAP IN INNER LOOP SPLIT\n",
      "\n",
      "df_train_cat_ids:\n",
      "['000B' '001A' '002A' '003A' '005A' '006A' '008A' '009A' '010A' '012A'\n",
      " '013B' '015A' '018A' '019B' '023A' '023B' '025A' '026A' '026C' '027A'\n",
      " '028A' '029A' '031A' '033A' '034A' '035A' '037A' '038A' '040A' '041A'\n",
      " '042A' '043A' '045A' '046A' '047A' '049A' '051A' '051B' '057A' '058A'\n",
      " '060A' '061A' '063A' '066A' '067A' '069A' '070A' '073A' '075A' '087A'\n",
      " '088A' '092A' '093A' '096A' '097A' '097B' '101A' '102A' '103A' '105A'\n",
      " '108A' '109A' '111A' '113A' '116A']\n",
      "df_val_cat_ids:\n",
      "['000A' '007A' '011A' '016A' '019A' '022A' '025B' '036A' '039A' '050A'\n",
      " '052A' '053A' '054A' '055A' '056A' '064A' '065A' '071A' '090A' '091A'\n",
      " '094A']\n",
      "Training set age group distribution:\n",
      "adult     217\n",
      "senior    196\n",
      "kitten    146\n",
      "Name: age_group, dtype: int64\n",
      "Validation set age group distribution:\n",
      "adult     110\n",
      "senior     65\n",
      "kitten      7\n",
      "Name: age_group, dtype: int64\n",
      "Class Weights: {0: 0.858678955453149, 1: 1.2762557077625571, 2: 0.9506802721088435}\n"
     ]
    }
   ],
   "source": [
    "# Enable logging to display information about the optimization process\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "# Create or load the study\n",
    "study = optuna.create_study(study_name=\"vggish_9_june\", storage=storage_url, direction=\"maximize\", load_if_exists=True)\n",
    "\n",
    "study.enqueue_trial({\n",
    "    'activation': 'relu',\n",
    "    'learning_rate': 0.00038188800331973483,\n",
    "    'optimizer': 'Adamax',\n",
    "    'batch_size': 32,\n",
    "    'n_layers': 1,  \n",
    "    'units_l0': 480, \n",
    "    'dropout_l0': 0.27188281261238406,  \n",
    "})\n",
    "\n",
    "# Pass the callback to the optimize method\n",
    "study.optimize(objective, callbacks=[custom_callback])\n",
    "\n",
    "# Display the information about the best trial\n",
    "logger(f\"Number of finished trials: {len(study.trials)}\", file=log_file_path)\n",
    "\n",
    "logger(f\"Best trial:\", file=log_file_path)\n",
    "trial = study.best_trial\n",
    "\n",
    "logger(f\"  Value: {trial.value}\", file=log_file_path)\n",
    "logger(f\"  Params: \", file=log_file_path)\n",
    "for key, value in trial.params.items():\n",
    "    logger(f\"    {key}: {value}\", file=log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30381b7c-5073-4fcc-aeb4-54bacd27be47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ed01fc-ba59-47b2-b72a-a3460638b6b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e9496-835c-4d5f-9e93-02a5f653bd2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79474f8d-2ca6-4ba0-a4a1-338ddf789d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-10 09:41:53,955] Using an existing study with name 'vggish_9_june' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trials: 3\n"
     ]
    }
   ],
   "source": [
    "# Create or load the study\n",
    "study = optuna.create_study(study_name=\"vggish_9_june\", storage=storage_url, direction=\"maximize\", load_if_exists=True)\n",
    "\n",
    "# Get the number of trials\n",
    "num_trials = len(study.trials)\n",
    "\n",
    "print(\"Number of trials:\", num_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2d25cadc-3d3c-4d6c-936c-3bd66fd9455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial ID: 42\n",
      "Best trial value: 0.6505760166987988\n",
      "Best trial parameters: {'learning_rate': 0.00854117044509888, 'optimizer': 'Adam', 'batch_size': 32, 'activation': 'relu', 'n_layers': 1, 'units_l0': 32, 'dropout_l0': 0.17219006828082012}\n"
     ]
    }
   ],
   "source": [
    "# Access the best trial\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"Best trial ID:\", best_trial.number)\n",
    "print(\"Best trial value:\", best_trial.value)\n",
    "print(\"Best trial parameters:\", best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1850c-cfc5-4bf1-aac4-6d9c31cfcfff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f3e204b-c29c-4576-b489-f3f5a80ba1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the particular trial: {'learning_rate': 0.004757171053968943, 'optimizer': 'Adam', 'batch_size': 32, 'activation': 'relu', 'n_layers': 1, 'units_l0': 512, 'dropout_l0': 0.20956287952922775}\n",
      "Value of the particular trial: 0.622956389506926\n"
     ]
    }
   ],
   "source": [
    "trial_index = 44\n",
    "particular_trial = study.trials[trial_index]\n",
    "\n",
    "# Access trial attributes\n",
    "trial_params = particular_trial.params\n",
    "trial_value = particular_trial.value\n",
    "\n",
    "print(\"Parameters of the particular trial:\", trial_params)\n",
    "print(\"Value of the particular trial:\", trial_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ebf0f-8ab4-4fda-93c1-f93ee868fa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41e255-caef-43a7-abeb-4eb0d0e6fc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1233692-26de-45c2-b930-4ca99b2f932f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83fd39-c901-4b44-9d41-b9bffd068e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fac3ed-651d-4ae2-8ab6-06463b5ac090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0709b91-06a0-47d7-9631-374febf1a6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6098de-4851-44f2-926d-8b081720f072",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
